Eine Naturkatastrophe ist eine natürlich entstandene Veränderung der Erdoberfläche oder der Atmosphäre, die auf Lebewesen und insbesondere den Menschen und seine Lebensweise verheerende Auswirkungen hat. 
Auch wenn der Mensch nicht Auslöser von Naturkatastrophen ist, kann er jedoch indirekt zu den Auswirkungen von Naturkatastrophen beitragen beziehungsweise diese verschärfen, beispielsweise durch die globale Erwärmung, Katastrophen begünstigende Arten der Landnutzung oder Besiedlung besonders gefährdeter Bereiche wie zum Beispiel niedrig liegender Küstenabschnitte. Maßnahmen zur Abwehr von Naturkatastrophen werden im Rahmen des Katastrophenschutzes ergriffen.





Ein spektakuläres Naturereignis (beispielsweise ein Gletscherabbruch auf Grönland) genügt nicht für den Sachverhalt einer Naturkatastrophe; im engeren Sinne kann ein Naturereignis nur dann zur Katastrophe werden, wenn es sich auf Menschen und ihre Lebensweise und modernen, kulturellen Gewohnheiten auswirkt. Wenn hingegen Menschen die Verursacher der Katastrophe in der Natur sind, spricht man von einer Umweltkatastrophe. Auch Seuchen (Epidemien) und Ungezieferplagen rechnet man normalerweise nicht unter den Begriff, wohl aber andere Schädlingsplagen, die sich primär auf das Wirtschaftsleben, und erst als deren Folge auf die Gesundheit auswirken.
Der Zeitraum, in dem die Veränderungen stattfinden, reicht von Sekunden (Erdbeben) bis zu Jahrzehnten (Dürren, Klimaschwankungen). Das Maß der Auswirkung auf den Menschen liegt dem Begriff Katastrophe zugrunde. Erheben lässt sich diese als Zahl der Katastrophenopfer, als volkswirtschaftlicher Schaden, aber auch als Versicherungsschaden.
Als „Katastrophe größeren Ausmaßes“ beziehungsweise „außergewöhnliche Katastrophe hauptsächlich natürlicher Art“ etwa definiert der Art. 2 (2) der Verordnung (EG) Nr. 2012/2002[1] zur Errichtung des  Solidaritätsfonds der Europäischen Union:[2]

„Eine Katastrophe, die in zumindest einem der betroffenen Staaten Schäden verursacht, die auf über 3 Milliarden Euro […] oder mehr als 0,6 Prozent seines BIP geschätzt werden.“
Zusätzlich werden auch angeführt:

Ein natürliches Ereignis in einer Region, „welche[s] den größten Teil der Bevölkerung in Mitleidenschaft zieht und schwere und dauerhafte Auswirkungen auf die Lebensbedingungen und die wirtschaftliche Stabilität der Region hat.“
In diese Kategorie der EU fallen etwa ein Dutzend Ereignisse der letzten 100 Jahre in Europa, von denen die Hitzewelle 2003 mit 70.000 Todesopfern und das Elbehochwasser 2002 mit Schäden in Höhe von etwa 18 Milliarden Euro als verheerendste zu verzeichnen sind. Weltweit gehen solche Ereignisse in diesem Zeitraum in die Hunderte, als teuerste bezifferte Katastrophen der Geschichte gelten das Erdbeben von Kōbe 1995 und Hurrikan Katrina 2005 mit bis zu 100 Milliarden US-Dollar volkswirtschaftlichem Schaden. Was die opferreichste Naturkatastrophe der Geschichte ist, lässt sich kaum sagen; zu nennen wären die Dürren in Indien 1965 bis 1967 mit an die 1,5 Millionen Toten, und die Überschwemmungen in Indien 1955 mit 45 Millionen Obdachlosen – über frühe Ereignisse liegen seltener Angaben über Opferzahlen vor, und kaum monetäre Schätzungen, die sich durch Unsicherheiten der Bemessungsgrundlage nicht ermitteln lassen.


Die Betrachtung, Analyse und Bewertung von Naturkatastrophen hängt stets von verschiedenen Faktoren ab. Die wichtigsten Faktoren sind:

Globale Bevölkerungszunahme (exponentielle Entwicklung). (Im Jahr 1804 lebten eine Milliarde Menschen auf der Erde, im Jahr 2022 sind es bereits über acht Milliarden.)
Insgesamt steigender Lebensstandard in fast allen Ländern der Erde führt zu wachsenden Wertbeständen, die im Falle einer Katastrophe betroffen sind. Dies betrifft insbesondere den Fall der Versicherungsschäden und verzerrt die Bewertung von Ereignissen anhand von Schadsummen zugunsten der Industriestaaten. Zum anderen sind Folgeschäden wie Hungersnöte und Seuchen mit steigendem Lebensstandard stark sinkend.
Konzentration von Bevölkerung und Werten in Großstadträumen: Entstehung zahlreicher Megastädte auch in gefährdeten Regionen (zum Beispiel Tokio: 35 Millionen Einwohner).
Besiedelung und Industrialisierung stark exponierter Regionen, insbesondere an Küsten, in Flussniederungen, Tourismus in Gefahrenzonen, zum Beispiel in Florida. Hier auch die zunehmende Flächenversiegelung zu beachten.
Anfälligkeit moderner Gesellschaften und Technologien, Bautechnik, Geräte, Netzwerke; Probleme auch bei Zulieferern (Lieferkette). Siehe Abschnitt Klimawandel im Artikel Vulnerabilität. Siehe auch Infrastruktur.
Weltweite Änderungen der Umweltbedingungen, Klimawandel, Wasserverknappung, Verlust der Artenvielfalt.

Die folgende Aufstellung erfolgt nach nicht von Menschen herrührenden (nicht anthropogenen) Ursachen. Viele dieser Ursachen lassen sich allerdings auch direkt auf Menschen zurückführen (Eindeichungen und Abholzung bei Überschwemmungen, Überweidung bei Dürreereignissen).
Endogene/tektonische Ursachen:

Erdbeben und Seebeben, auch mit Erdverflüssigung als Folge
Vulkanausbrüche mit Lavafluss, Ascheregen oder pyroklastischen Strömen, Vulkanexplosionen, als Folgen auch Erdbeben, Wetteranomalien wie Vulkanischer Winter und Wasserstandsanomalien wie Gletscherlauf sowie Lahare als Folgen nach Starkregen
Tsunamis (vulkanologische oder geodynamische Ursachen, auch astronomische, also Meteoreinschläge wären möglich, sind in der Menschheitsgeschichte nicht verzeichnet)
Giftgasausbrüche aus vulkanischen Becken oder Seen
Gravitatorische Ursachen:

Massenbewegungen: Steinschlag, Erdrutsche, Bergstürze, Muren, Erdfall
Lawinen
Lahare (Schlammfluten nach Vulkanismus)
Klimatische Ursachen:

Wetteranomalien (Unwetter, Extremwetterereignisse)
Wasserstandsanomalien aufgrund von Wettern: Hochwasser (an Binnengewässern), Sturmflut (an Küsten)
Windanomalien: Sturm/Orkan (als Stärkeklassen), Trogorkan, Tornado, Hurrikan/Taifun (als Typen), Schneeverwehung, Sturmflut (als Folgen)
Niederschlagsanomalien: plötzliche Starkregen und langdauernde Dauerregen (mit nachfolgenden Hochwässern), „Schneechaos“ (mit nachfolgenden Lawinen oder Schneedruck), Hagelschlagsereignisse, Glatteis und Eisregen, Muren und Lahare
Wärmeanomalien: Hitzeanomalien (Sommeranomalien), Jahrhundertsommer, Dürren, winterliche Wärmeereignisse (Tauwetter mit nachfolgendem Hochwasser)
Kälteanomalien: Extremwinter, „ausgefallene“ Sommer, sommerliche Schneeeinbrüche
Gezeitenanomalien
Smog (endogene Mitursachen)
Biologische Ursachen:

Schädlingsplagen, wie Heuschreckeneinfall
Extraterrestrische Ursachen:

Meteoriteneinschläge
Weltraumwetter (Sonnenwinde, kosmische Strahlung)

Die Weltbank hat 2005 in ihrem Report Natural Disaster Hotspots: A Global Risk Analysis Karten publiziert, die die Verteilung der Risiken auf Weltkarten zeigen. Etliche davon sind zu sehen auf den Seiten der Columbia University.[3] Nach dem 2016 erschienenen Bericht der Weltbank waren in der Dekade 2005 bis 2014 durchschnittlich 17 Millionen Menschen pro Jahr von Naturkatastrophen betroffen; in der Dekade 1976 bis 1985 waren es noch 60 Millionen Menschen gewesen. Zugleich verzehnfachten sich die dabei entstandenen Kosten von 14 auf mehr als 140 Milliarden US-Dollar pro Jahr. Durch die menschengemachte Globale Erwärmung und die starke Zunahme der Weltbevölkerung beziehungsweise der Bevölkerungsdichte in vielen Regionen der Welt werden in Zukunft deutlich mehr Menschen von Naturkatastrophen betroffen sein als früher. Wenn keine Schutzmaßnahmen (das heißt Klimaschutz und Anpassung an die globale Erwärmung) getroffen würden, könnten bis 2050 etwa 1,3 Milliarden Menschen durch Naturkatastrophen bedroht werden und sich die bis dahin entstehenden Kosten auf 158 Billionen US-Dollar belaufen. Dies ist etwa das Doppelte des derzeitigen Weltsozialproduktes. Die in den besonders betroffenen Küstenstädten anfallenden Schadenskosten könnten von 6 Milliarden US-Dollar im Jahr 2010 auf eine Billion US-Dollar im Jahr 2070 ansteigen.[4]
Größere Versicherungskonzerne führen in der Regel geographisch organisierte Risikostatistiken, die ihnen als Berechnungsgrundlage für Versicherungsprämien dienen. Die EM-DAT OFDA/CRED International Disasters Database der Weltgesundheitsorganisation dokumentiert seit 1888 die weltweiten Katastrophen. Demnach ereigneten sich zwischen 1900, 2000 und 2003 insgesamt 9195 größere Katastrophen mit jeweils mindestens 10 Toten. Davon hatten Wetterkatastrophen mit 57 Prozent den höchsten Anteil, keine 20 Prozent waren geologischen Ursprungs (Vulkanausbrüche, Erdbeben), wie auch die in die geologische Kategorie gezählten Tsunamis; der Rest waren biologische Katastrophen (Seuchen und Plagen).


Internationale Forschungsgesellschaft Interpraevent (Hrsg.): Alpine Naturkatastrophen – Lawinen, Muren, Felsstürze, Hochwasser. Leopold Stocker, Graz 2009 ()
Nicolai Hannig: Kalkulierte Gefahren. Naturkatastrophen und Vorsorge seit 1800. Wallstein, Göttingen 2019.
Gerrit Jasper Schenk (Hrsg.): Katastrophen. Vom Untergang Pompejis bis zum Klimawandel. Thorbecke, Ostfildern 2009, ISBN 978-3-7995-0844-5.
Trevor Day: Faszination Naturkräfte. Eine eindrucksvolle Reise um die Erde. Dorling Kindersley Verlag, München 2002, ISBN 3-8310-0268-1.
Michael Matheus, Gabriella Piccinni, Giuliano Pinto, Gian Maria Varanini (Hrsg.): Le calamità ambientali nel tardo medioevo europeo: realtà, percezioni, reazioni, Atti del XII convegno del Centro di Studi sulla civiltà del tardo medioevo, S. Miniato 31 maggio – 2 giugno 2008. (Collana di Studi e Ricerche 12), Florenz 2010.
Lee Davis: Das große Lexikon der Naturkatastrophen. Verlag für Sammler, Graz 2003, ISBN 978-3-85365-199-5.











Die Erdoberfläche ist die Grenzfläche zwischen der festen Erdkruste (einschließlich der Böden) und den Gewässern auf der einen sowie der Atmosphäre auf der anderen Seite. Sie lässt sich nach verschiedenen Kriterien in Hemisphären (Halbkugeln, von altgriechisch ἥμισυς hemisys „halb“ und σφαῖρα sphaira „Kugel“) einteilen, also in Hälften der Erdoberfläche.
Gelände­höhen auf der Erdoberfläche werden auf den mittleren Meeresspiegel bezogen. Diese Niveaufläche – das Geoid – hat genähert die Form eines Ellipsoids und eine Oberfläche von 510 Millionen km², wovon rund 71 % von Meeren bedeckt sind.



Die Physische Geographie beschäftigt sich mit den Großformen der Erdoberfläche und ihren Systemzusammenhängen.
Die Geomorphologie (Teil der Geographie) erforscht die genaue Form (das Relief) der Erdoberfläche und (gemeinsam mit der Geologie) seine Entstehung. 37,4 % der Landoberfläche der Erde liegen zwischen 1000 und 2000 m über Meereshöhe.[1]
Die Geodäsie befasst sich mit der Vermessung der Erdoberfläche und der darauf befindlichen Infrastruktur sowie – gemeinsam mit der Geophysik – mit dem Erdschwerefeld.
Die Bodenkunde untersucht die oberste, organisch geprägte Schicht unterhalb der Erdoberfläche.
Boden bildet in weiten Teilen der Landgebiete, vor allem in Ebenen und Hügellandschaften in Regionen mit feuchtem Klima, die oberste Schicht unterhalb der Erdoberfläche. Er entsteht durch Verwitterung von Festgestein und aus Lockergestein durch Anreicherung dieser mineralischen Substanzen mit organischer Substanz (Humus). Je nach Grad der Verwitterung, den chemischen und physikalischen Eigenschaften des Ausgangsgesteins sowie den herrschenden Umweltbedingungen entstehen unterschiedliche Bodenarten und Bodentypen. In gebirgigen Gegenden, vor allem im Hochgebirge sowie unter extremen klimatischen Bedingungen besteht die Erdoberfläche hingegen oft aus nacktem Fels oder aus Lockergestein, das kaum oder keinerlei Bodenbildungsprozessen unterworfen ist.[2]

[Bearbeiten | Quelltext bearbeiten]

Geodäsie: Die Nord- und die Südhemisphäre, wie sie sich aus der Breite bezüglich des Erdäquators ergeben, sowie die östliche und die westliche Hemisphäre, nach dem Längengrad bezüglich des Nullmeridians und des 180. Längengrads. Der einzige Staat der Erde, dessen Staatsgebiet in allen vier Erdhemisphären liegt, ist Kiribati, ein Inselstaat im Pazifik.
Geomorphologie: Die Wasserhemisphäre und die Landhemisphäre. Erstere umfasst den ganzen pazifischen Raum und ist zu 89 % von Meeren bedeckt, zweitere ungefähr den atlantischen Raum und Eurasien mit etwa 50 % Festland.
Daneben bezeichnen Nord- und Südhemisphäre wie auch West- und Osthemisphäre kultur- und wirtschaftspolitische Einteilungen, die aber verhältnismäßig willkürlich gewählt sind. Die Verwendung in diesem Zusammenhang etablierte sich in der Zeit des Kalten Kriegs in der Mitte des 20. Jahrhunderts. Südhemisphäre bezog sich auf die Dritte Welt, Osthemisphäre auf den vom Kommunismus bzw. Realsozialismus beeinflussten Raum Europas und Asiens (Zweite Welt). Heute wird diese Einteilung aufgrund der geänderten geopolitischen Lage in der Fachliteratur kaum mehr verwendet.
In den Verträgen von Tordesillas und Saragossa (1494, 1529) wurde im Zuge des Kolonialismus die Erdoberfläche nach Längengrad in einen spanischen und einen portugiesischen Machtbereich aufgeteilt.
Üblich ist noch die Einteilung in Alte Welt (Eurasien, Afrika) und Neue Welt (beide Amerika), die auch relativ unspezifisch ist.
[Bearbeiten | Quelltext bearbeiten]
Die Geomorphologie gliedert die Erdoberfläche in Gebiete, die von Gewässern bedeckt sind: Seen, Flüsse und Meere, sowie in Gebiete, die nicht von Gewässern bedeckt sind: Festland und Inseln.
Während der Ausdruck „Oberfläche“ bei den nicht von Gewässern bedeckten Gebieten relativ einfach als die Grenzfläche zwischen der Litho- und/oder Pedosphäre und der Atmosphäre zu verstehen ist (Geländeoberkante), bezieht er sich bei Gewässern entweder auf die sichtbare Gewässeroberfläche (Wasserspiegel) oder die Grenzfläche zwischen Lithosphäre (einschließlich der Sedimente bzw. „subhydrischen Böden“) und Wasserkörper (Gewässergrund, engl. sediment-water interface). Bei genauerer Betrachtung aber ist auch bei den Landmassen wahlweise die „von oben sichtbare“ Fläche einschließlich der Vegetationsdecke und Überbauung (Topographie), oder nur Gelände­oberfläche (Orographie) gemeint.
Bei großflächig vergletscherten Regionen wie der Arktis und der Antarktis, wo zudem Teile des Eisschildes als Schelfeis weit in die Küstengewässer hineinreichen, stellt sich die Frage, ob die Oberfläche der Eiskörper zur Erdoberfläche zählt oder nicht.




Gesamtflächeder Erde
510.000.000 km²
100 %


Wasserfläche
360.570.000 km²
70,7 %


Landfläche
149.430.000 km²
29,3 %

[Bearbeiten | Quelltext bearbeiten]
Der Anteil der Landfläche beträgt etwa 148,9 Mio. km² (29 %); das Land verteilt sich auf Kontinente und Inseln:[3]



Kontinent
Landfläche
Anteil


Asien (ohne Polarinseln)
044,4 Mio. km²
031 %


Amerika (ohne Polargebiete)
038,3 Mio. km²
027 %


Afrika
029,3 Mio. km²
020 %


Antarktika
013,2 Mio. km²
009 %


Europa (ohne Island, Nowaja Semlja, atlantische Inseln)
009,9 Mio. km²
007 %


Australien (mit Tasmanien)
007,7 Mio. km²
005 %


gesamt
148,9 Mio. km²
100 %

Bezogen auf die eisfreien Gebiete der Erde (demnach ohne den Großteil von Grönland und der Antarktis) wird die Landfläche von natürlichen- und vom Menschen geprägten Großlebensräumen geprägt, die Anfang des 21. Jahrhunderts folgende Größenordnungen umfassen:[4]



Dauernutzungsraum des Menschen(Wohngebiete, Infrastruktur, intensiv genutzte Flächen) 2004[5]
72.084.920 km2
53 %


Landwirtschaftlich genutzte Fläche 2009[6]
48.827.330 km2
35,9 %


Extensiv od. saisonal genutzter Naturraum 2004[5]
42.162.880 km2
31 %


gesamte Waldfläche (genutzt und ungenutzt) 2010[7]
40.204.320 km²
29,6 %


Ungenutzte, „wilde“ Naturräume 2004[5]
21.761.480 km2
16 %

[Bearbeiten | Quelltext bearbeiten]
Der Anteil der Wasserfläche beträgt ca. 361,2 Mio. km² (71 %); das Wasser verteilt sich hauptsächlich auf Ozeane:



Ozean
%
mittlere Tiefe


Pazifischer Ozean
47 %
3870 m


Atlantischer Ozean
24 %
3380 m


Indischer Ozean
20 %
3600 m


Südlicher Ozean
05 %



Arktischer Ozean
04 %


[Bearbeiten | Quelltext bearbeiten]
Die mittlere Höhe der Festlandsflächen liegt bei ungefähr 700 m (Europa 300 m, Asien 880 m, Amerika 610 m, Afrika 660 m, Ozeanien und Australien 300 m). Ihren höchsten Punkt erreicht die Erdoberfläche mit dem Mount Everest bei 8.848 Metern über dem Meeresspiegel. Der tiefste frei zugängliche Punkt der Erdoberfläche befindet sich am Ufer des Toten Meeres, dessen Wasseroberfläche 423 Meter unter Meeresniveau liegt. Der tiefste Punkt der Oberfläche der kontinentalen Erdkruste befindet sich unter dem Denman-Gletscher des Antarktischen Eisschildes, wo eine Tiefe von etwa 3.500 m unter dem Meeresspiegel erreicht wird.[8] Die mittlere Tiefe der Meere beträgt etwa 3.500 m und die tiefste Stelle der Oberfläche der Erdkruste bzw. der Lithosphäre befindet sich im Marianengraben bei ungefähr 11.000 Metern unter dem Meeresspiegel.

[Bearbeiten | Quelltext bearbeiten]
Vergleich der Oberfläche der Erde mit anderen Planeten des Sonnensystems und dem Erdmond:



Himmelskörper
Oberfläche in km²


Jupiter *
61.420.000.000


Saturn *
42.610.000.000


Uranus *
8.083.000.000


Neptun *
7.620.000.000


Erde
510.100.000


Venus
460.200.000


Mars
144.600.000


Merkur
74.760.000


Mond
37.960.000

(*) Zu beachten ist hierbei, dass Jupiter, Saturn, Uranus und Neptun Gasplaneten ohne feste Oberfläche sind. Bei ihnen wird die „Oberfläche“ anhand des Nullniveaus berechnet, welches per definitionem das Niveau ist, bei dem der Gasdruck 1 Bar beträgt.







Die Atmosphäre der Erde, auch Erdatmosphäre (von altgriechisch ἀτμός atmós, deutsch ‚Dampf‘ und σφαῖρα sphaira, deutsch ‚Kugel‘) ist die gas­förmige Hülle der Erdoberfläche und eine der sogenannten Erdsphären. Sie hat einen hohen Anteil an Stickstoff und Sauerstoff und somit oxidierende Verhältnisse.
Ihre vertikale Gliederung ist durch unterschiedliche Temperaturen bedingt. Das Wettergeschehen findet in den unteren etwa 10 Kilometern statt, der Troposphäre. Die höheren Schichten haben keinen großen Einfluss mehr.



→ Hauptartikel: Luft
Die bodennahen Schichten bis in etwa 90 km Höhe (Kármán-Linie der Raumfahrt) haben eine recht gleichförmige Zusammensetzung, weshalb man auch von Homosphäre spricht. Was als Luft bezeichnet wird, besteht im Wesentlichen bei Außerachtlassen des wechselnden Wasserdampfgehalts (d. h. in Volumenprozent trockener, wasserdampffreier Luft) aus: 
78,08 % Stickstoff (N2), 20,95 % Sauerstoff (O2) und 0,93 % Argon (Ar), dazu Aerosole und Spurengase, darunter Kohlenstoffdioxid (CO2, mit derzeit 0,04 %, nach Wasserdampf der wichtigste Verursacher des Treibhauseffekts), ferner Methan (CH4), Ozon (O3), Fluorchlorkohlenwasserstoffe, Schwefeldioxid (SO2) und Stickstoff­verbindungen.[1]

Siehe auch: Kohlenstoffdioxid in der Erdatmosphäre

Tabellarische Auflistung einiger Gase in der Atmosphäre


Gas

Prozentanteil


Stickstoff

78,08 %


Sauerstoff

20,95 %


Argon

0 0,93 %


Kohlenstoffdioxid

0 0,04 %

Für die Entstehung des Wetters ist neben der Energie­zufuhr durch die Sonnenstrahlung und ihrer tages- und jahreszeitlichen Schwankung hauptsächlich der Gehalt an Wasserdampf verantwortlich. Dieser kommt in wechselnder Konzentration von 0 % Vol. bis etwa 4 % Vol. in der Luft vor, siehe Luftfeuchtigkeit. Die regionale Sonneneinstrahlung hängt über den Gehalt an Aerosolen auch von der Transparenz der Atmosphäre ab.
Die Hochatmosphäre ist ein bereits sehr dünnes Gas, in das auch hochenergetische Anteile der Sonnenstrahlung noch eindringen können. Durch kurzwelliges UV-Licht werden die Moleküle dissoziiert und teilweise ionisiert. Ferner kommt es in Höhen über etwa 100 km auch zu einer Entmischung der Bestandteile nach ihrer unterschiedlichen molaren Masse, weshalb dieser Abschnitt auch Heterosphäre genannt wird. Mit wachsender Höhe nehmen daher die Anteile leichterer Teilchen wie Wasserstoffatome und Helium zu. Diese beiden Elemente entweichen thermisch bedingt allmählich in den Weltraum.








Die Atmosphäre weist eine Masse von etwa 5,15 · 1018 kg auf (5,15 Billiarden Tonnen), also knapp ein Millionstel der Erdmasse. Sie besteht hinsichtlich ihres vertikalen Temperaturverlaufs, insbesondere dessen Gradienten, aus mehreren Schichten:

Troposphäre von der Erdoberfläche bis zur Tropopause in Höhen zwischen 7 km (Polargebiete) und 17 km (Tropen)
Stratosphäre bis zur Stratopause in 50 km Höhe
Mesosphäre bis zur Mesopause in 80 bis 85 km Höhe
Thermosphäre (siehe auch unten, Ionosphäre)
Exosphäre darüber.
Die Troposphäre wird auch als untere Atmosphäre bezeichnet, Stratosphäre und Mesosphäre gemeinsam als mittlere Atmosphäre und die Thermosphäre als obere Atmosphäre.
Vor allem in der Troposphäre – der Wettersphäre – zeigt sich eine Dynamik innerhalb der Temperaturschichtung und des Gehalts an Wasserdampf, weshalb dort auch die jeweilige Schichtungsstabilität eine große Rolle spielt.
Außer nach dem Temperaturverlauf lässt sich die Lufthülle auch nach anderen Gesichtspunkten einteilen:

Nach dem aerodynamischen Zustand
Prandtl-Schicht (etwa 0–50 m)
Ekman-Schicht (etwa 50–1000 m)
Prandtl-Schicht + Ekman-Schicht = planetare Grenzschicht = Peplosphäre
Freie Atmosphäre (>1 km)
Nach dem Durchmischungsgrad
Die Homosphäre ist turbulent durchmischt und reicht bis zur Homopause in etwa 100 km Höhe.
Darüber beginnt die Heterosphäre. Hier trennen sich die Teilchen nach ihrer Molmasse, da die molekulare Diffusion dominiert.
Nach dem radio-physikalischen Zustand der Atmosphäre
Neutrosphäre (Gase überwiegend im neutralen, also nicht-ionisierten Zustand)
Ionosphäre (ionisierte Gase, in der Thermosphäre eingelagert, >80 km)
Plasmasphäre (vollständige Ionisation aller Teilchen, >1000 km,)
Magnetosphäre
Nach chemischen Gesichtspunkten lassen sich außerdem die Ozonosphäre (Ozonschicht in 16–50 km Höhe) und eine Chemosphäre (20–600 km) abgrenzen.


Der Übergang zwischen Exosphäre und Weltraum ist kontinuierlich, man kann keine scharfe Obergrenze der Atmosphäre ziehen. In der Exosphäre (oberhalb der Exobase in ~600 km Höhe) ist die mittlere freie Weglänge so groß, dass Teilchen entweichen können, wenn sie die Fluchtgeschwindigkeit erreichen können. Einzelnen Wasserstoffteilchen wird das durch Zusammenstöße bereits bei mittleren Geschwindigkeiten von 3–4 km/s möglich.
Seitens der Fédération Aéronautique Internationale wird die Homopause bzw. eine Höhe von rund 100 km (Kármán-Linie) als Grenze angesehen. Diese Definition ist international weitestgehend anerkannt, wenn sie auch keine uneingeschränkte Gültigkeit besitzt. So wird zum Beispiel von der NASA die Mesopause (etwa 80 km) als Grenze definiert.


Die untere Atmosphäre, insbesondere die Troposphäre, ist das Forschungsfeld der Meteorologie, wohingegen die mittlere und obere Atmosphäre (Stratosphäre, Mesosphäre) in den Bereich der Aerologie gehören.
Messungen erfolgen in Bodennähe mit dem vollen Spektrum der meteorologischen Messgeräte. In der Höhe, besonders in Bezug auf Höhenprofile, stellen Radiosonden, meteorologische Raketen, Lidars, Radars und Wetter- beziehungsweise Umweltsatelliten die wichtigsten Messverfahren dar. In der Zukunft werden voraussichtlich auch Höhenplattformen wie das High Altitude and Long Range Research Aircraft eine größere Rolle spielen.


→ Hauptartikel: Entwicklung der Erdatmosphäre
Die Entwicklung der Atmosphäre ist ein Teil der chemischen Evolution der Erde und zudem ein wichtiges Element der Klimageschichte. Sie wird heute in vier wesentliche Entwicklungsstufen unterschieden.
Am Anfang stand die Entstehung der Erde vor etwa 4,56 Milliarden Jahren. Dabei verfügte sie schon sehr früh über eine vermutlich aus Wasserstoff (H2) und Helium (He) bestehende Gashülle, die jedoch wieder verloren ging.


Durch die langsame Abkühlung der Erde und den dabei auftretenden Vulkanismus kam es zu einer umfangreichen Ausgasung aus dem Erdinneren. Die dadurch erzeugte Atmosphäre bestand zu etwa 80 % aus Wasserdampf (H2O), zu 10 % aus Kohlendioxid (CO2) und zu 5 bis 7 % aus Schwefelwasserstoff. Dabei handelt es sich um die Produkte des Vulkanismus, die auch heute noch beobachtet werden können. Der hohe Anteil des Wasserdampfs erklärt sich dadurch, dass die Atmosphäre zu diesem Zeitpunkt noch zu warm war, um Niederschläge bilden zu können. Es gab also noch keine Gewässer auf der Erde. Der eigentliche Ursprung des Wassers ist umstritten.
Nachdem die Temperatur der Atmosphäre unter den Siedepunkt des Wassers fiel, kam es zu einem extrem langen Dauerregen, nach dessen Ende sich die Ozeane gebildet hatten und dementsprechend die anderen Atmosphärengase relativ zum Wasserdampf angereichert wurden.
Die hohe UV-Einstrahlung bedingte eine photochemische Zerlegung der Wasser-, Methan- und Ammoniakmoleküle, wodurch sich Kohlenstoffdioxid und Stickstoff relativ anreicherten. Die leichten Gase wie Wasserstoff oder Helium verflüchtigten sich in den Weltraum. Kohlenstoffdioxid wurde in großen Mengen in den Ozeanen gelöst und von C-autotrophen Mikroorganismen zum Teil verbraucht. Unverändert blieb der inerte Stickstoff. Dieser wurde mit der Zeit weiter relativ angereichert und bildete vor etwa 3,4 Milliarden Jahren den Hauptbestandteil der Atmosphäre.


Der Sauerstoff O2 spielt die Hauptrolle bei der weiteren Entwicklung zur heutigen Atmosphäre. Cyanobakterien mit oxygener Photosynthese führten als C-Autotrophe zu einem weiteren Absinken der Kohlenstoffdioxidkonzentration, bildeten aber vor allem (möglicherweise schon vor etwa 3,5 Milliarden Jahren beginnend) Sauerstoff. Die Sauerstoffkonzentration der Atmosphäre blieb jedoch zunächst gering, weil der gebildete Sauerstoff in den Ozeanen bei der Oxidation von Eisen(II)-Ionen und Schwefelwasserstoff verbraucht wurde. Erst vor etwa zwei Milliarden Jahren begann Sauerstoff in die Atmosphäre zu entweichen, als die mit Sauerstoff reagierenden Stoffe knapp wurden. Vor einer Milliarde Jahren überstieg die Sauerstoffkonzentration der Atmosphäre drei Prozent, wodurch sich im Verlauf der nächsten 400 Millionen Jahre allmählich eine erste Ozonschicht bilden konnte. Vor 500–600 Millionen Jahren stieg der Sauerstoffgehalt, bedingt durch das erste massenhafte Auftreten von Landpflanzen, rapide an und erreichte vor 350 Millionen Jahren erstmals das heutige Niveau. Nach mehreren starken Schwankungen während des Erdmittelalters erreichte der Luftsauerstoffgehalt schließlich den heutigen Wert von 21 %.


Helmut Kraus: Die Atmosphäre der Erde – Eine Einführung in die Meteorologie. Springer, Berlin 2004, ISBN 3-540-20656-6.
Kshudiram Saha: The Earth’s Atmosphere – Its Physics and Dynamics. Springer, Berlin 2008, ISBN 978-3-540-78426-5
Mark Z. Jacobson: 0-521-54865-9 of Atmospheric Modeling. Cambridge University Press, Cambridge 2005, ISBN 0-521-54865-9
C. N. Hewitt, Andrea V. Jackson (Herausgeber): Handbook of Atmospheric Science – Principles and Applications. Blackwell, Malden (Massachusetts) 2003, ISBN 0-632-05286-4
Kristian Schlegel: Vom Regenbogen zum Polarlicht – Leuchterscheinungen in der Atmosphäre. Springer Spektrum, Heidelberg 2001, ISBN 3-8274-1174-2
Edmond Murad, Iwan P. Williams: Meteors in the Earth’s Atmosphere – Meteoroids and Cosmic Dust and their Interactions with the Earth’s Upper Atmosphere. Cambridge University Press, Cambridge 2002, ISBN 0-521-80431-0



 – Aufbau
astronomie.de: 
 (englisch)

scinexx.de:  22. Februar 2019


Die Erdatmosphäre










Troposphäre |
Tropopause |
Stratosphäre |
Stratopause |
Mesosphäre |
Mesopause |
Thermosphäre |
Thermopause |
Exosphäre |
Exopause






Neutrosphäre | Ionosphäre | Magnetosphäre




Homosphäre | Heterosphäre






Lebewesen



Von oben links, im Uhrzeigersinn: Rote Mauerbiene, Fichtensteinpilz, Schimpanse, das Wimpertierchen Isotricha intestinalis, Asiatischer Hahnenfuß und eine Grünalge (aus der Ordnung Volvocales)



Systematik





Klassifikation:

Lebewesen




Domänen



Eukaryoten (Eukaryota)
Archaeen (Archaea)
Bakterien (Bacteria)

Lebewesen sind organisierte Einheiten, die unter anderem zu Stoffwechsel, Fortpflanzung, Reizbarkeit, Wachstum und Evolution fähig sind.[1][2] Lebewesen prägen entscheidend das Bild der Erde und die Zusammensetzung der Erdatmosphäre (Biosphäre). Neuere Schätzungen lassen vermuten, dass 30 Prozent der gesamten Biomasse der Erde auf unterirdisch lebende Mikroorganismen entfallen.[3][4] Rezente Lebewesen stammen immer von anderen Lebewesen ab (Abstammungstheorie). Über die Entstehung von Lebewesen aus abiogenen Vorformen wird intensiv geforscht. Zu den ältesten Spuren irdischer Lebewesen gehören insbesondere die Stromatolithen.
Die Biologie untersucht die heute bekannten Lebewesen und ihre Evolution sowie die Grenzformen des Lebens (z. B. Viren) mit naturwissenschaftlichen Methoden.





Kennzeichen

Beispiel Lebewesen

Beispiel Nicht-Lebewesen


Entropie


Export

Lebewesen als selektiv offene thermodynamische Systeme mit Subsystemen (Organen), die für Entropieexport[5] sorgen. So kann die aktuelle Entropie des Systems unterhalb der den Tod kennzeichnenden maximal möglichen Entropie gehalten werden.

Technische Systeme mit Mechanismen zur Selbstreparatur. Datenkommunikation mit Fehlerkorrektur. Wie auch bei Lebewesen sichert hier Redundanz den erforderlichen Abstand zwischen aktuell erreichter und maximal möglicher Entropie.


Energieaustausch mit der Umgebung


Aufnahme

Pflanzen nehmen Lichtenergie auf und erzeugen durch Photosynthese Biomasse (Primärproduktion).
Energiegewinnung aus Nahrung durch Stoffwechsel mit der Umgebung.
In der Tiefsee treten aus Schwarzen Rauchern Schwefel und Metallsulfide aus. Aus ihrer Oxidation gewinnen dort lebende lithotrophe Mikroorganismen Energie. Sie fungieren dort als Nahrungsquelle einer Lebensgemeinschaft.[3][4][6]


Felsen erwärmen sich am Tag durch Aufnahme von Energie durch Licht …


Abgabe

Alle Lebewesen, jedoch in besonderem Ausmaß Säugetiere, geben Energie direkt als Wärme und indirekt in stofflichen Ausscheidungen ab

… und geben sie in der Nacht wieder ab


Stoffaustausch mit der Umgebung


Aufnahme
Nahrungsaufnahme

Betanken eines Autos mit Benzin


Abgabe

Tiere geben Kohlenstoffdioxid und Wasser ab

Abgase des Autos bestehen (vor allem) aus Kohlenstoffdioxid und Wasser


Stoffwechsel (chemische Umwandlung von Stoffen)

alle Lebewesen
(Anmerkung: Viren, Viroide und Prionen sind nicht zu Stoffwechsel befähigt)


brennende Kerze


Informationsaustausch


Empfangen von Information
Pflanzen erkennen den Sonnenstand

Belichtungsmesser des Fotoapparates misst Lichtstärke


Senden von Information
Warntracht der Wespen, Sprache der Bienen und der Menschen

Verkehrsampel


Reaktion auf Reize aus der Umwelt


Anpassung/Ausrichtung

Pflanzen richten ihre Blätter nach dem Sonnenstand aus

Der Sonne nachgeführte Solarzellen


Wachstum


Volumenzunahme

Eine Hefezelle nimmt nach der Zellteilung an Volumen zu

Wachstum eines Kochsalz-Kristalls


Zellteilung

Stammzellen des Knochenmarkes.
Wachstum ist die Folge von Zellteilung (Vermehrung): Durch Wachstum wird die zur Masse der Zelle relative Oberfläche geringer. Das verringert die Entropieexportmöglichkeit[7] der Zelle. Die Teilung erhöht die Oberfläche wieder. Es kann wieder mehr Entropie exportiert werden.


„Zellteilung“ ist ein originär organischer Begriff, kann also keine anorganische Entsprechung haben.


Selbstreproduktion (Fortpflanzung)


Vermehrung

Die durch Zellteilung entstandenen Zellen sind ihrer Mutterzelle ähnlich. Kopie der DNA, also Vererbung.

Bei technischen Systemen noch nicht ausgereift, aber theoretisch möglich; sich selbst reproduzierende (siehe auch Rekursion) Computerprogramme sind Praxis (Computerviren).


Stoffliche Grundlage


Grundbausteine
Biomoleküle
Wassermolekül


Informationsträger

DNA, RNA

Metallkristall (Metallgitter)

Lebewesen kennzeichnende Merkmale findet man vereinzelt also auch bei technischen, physikalischen und chemischen Systemen. Insbesondere zeigt Feuer je nach Interpretation einen großen Teil dieser Eigenschaften.

Auf alle lebenden Organismen (Lebewesen) müssen zumindest auf der Ebene der Zelle alle Kennzeichen zutreffen.
Tote Organismen wiesen in ihrer Vergangenheit alle Kennzeichen auf.
Latentes Leben haben Organismen, die zwar nicht alle Kennzeichen aufweisen, also toten Organismen oder unbelebten Gegenständen ähnlich sind, jederzeit aber zu lebenden Organismen werden können. (Beispiele: Sporen von Bakterien oder Pilzen).
Unbelebte Gegenstände zeigen zur Zeit ihrer Existenz nicht alle Kennzeichen.
Drei wesentliche Eigenschaften haben sich aber herauskristallisiert, die für alle Lebewesen als Definitionskriterien gelten sollen:

Stoffwechsel (Metabolismus) während zumindest einer Lebensphase, was eine Kompartimentierung durch eine Wand oder Membran bedingt,
Fähigkeit zur Selbstreproduktion und
die mit der Selbstreproduktion verbundene genetische Variabilität als Bedingung evolutionärer Entwicklung.
Diese Einschränkung würde aber viele hypothetische Frühstadien der Entwicklung des Lebens sowie rezente Grenzformen des Lebens, wie Viren, kategorisch ausschließen. Ausführlich wird dieser Aspekt im Abschnitt Lebewesen: Begriffsprobleme behandelt.


Lebewesen bestehen vorwiegend aus Wasser, organischen Kohlenstoffverbindungen und häufig aus mineralischen oder mineralisch verstärkten Schalen und Gerüststrukturen (Skelette).
Alle Lebewesen (Pflanzen, Tiere, Pilze, Protisten, Bakterien und Archaeen) sind aus Zellen oder Synzytien (mehrkernigen Zellverschmelzungen, z. B. Ciliaten und viele Pilze) aufgebaut, d. h. zelluläre Organismen (Cytota). Sowohl die einzelne Zelle als auch die Gesamtheit der Zellen (eines mehrzelligen Organismus) sind strukturiert und kompartimentiert, das heißt, sie bilden ein komplex aufgebautes System voneinander abgegrenzter Reaktionsräume. Sie sind untereinander und zur Außenwelt hin durch Biomembranen abgetrennt.
Jede Zelle enthält in ihrem Erbgut alle zum Wachstum und für die vielfältigen Lebensprozesse notwendigen Anweisungen.
Im Lauf des individuellen Wachstums differenzieren sich die Zellen zu verschiedenen Organen, die jeweils bestimmte Funktionen für das Gesamtsystem, das Individuum, übernehmen.


[Bearbeiten | Quelltext bearbeiten]
Es ist bis heute nicht gelungen, mit Sicherheit alle Elemente zu identifizieren, die wirklich alle Lebewesen für ihr Wachstum benötigen. Eindeutig ist nur, dass die elementaren Bausteine der biologischen Makromoleküle für alle lebenden Zellen essentiell sind, das sind Kohlenstoff (C), Wasserstoff (H), Sauerstoff (O) und Stickstoff (N) als Hauptbestandteile und Phosphor (P) und Schwefel (S) in geringeren Anteilen. Es ist bisher auch nicht gelungen, irgendwelche Organismen zu finden, die ohne Magnesium (Mg) und Zink (Zn) auskämen. Bei allen anderen Elementen, auch solchen, die einige Lebewesen in größeren Mengen, als Makronährstoffe, benötigen, ist nicht gesichert, ob der Bedarf wirklich essentiell ist. So gibt es zum Beispiel Milchsäurebakterien, die kein Eisen (Fe) benötigen.[8] Viele Prokaryoten sind imstande, Mangel an Nährelementen mit anderen, selten genutzten Elementen zu substituieren.[9] Einige für die meisten Organismen giftige Elemente können für ganz wenige, spezialisierte Organismen nützlich sein, etwa Cadmium (Cd) in einigen Kieselalgen.[10]
Bei komplexeren, mehrzelligen Organismen, wie etwa auch beim Menschen, ist der Bedarf stärker festgelegt: Der Mensch benötigt zum Leben 20 Elemente; ein weiteres, Chrom (Cr), war lange umstritten, gilt nun aber nur noch, in extrem geringen Mengen, als nützliches, aber nicht essentielles Spurenelement.[11]  17 Elemente sind für alle Pflanzen essentiell; viele Pflanzen nutzen aber auch Elemente, teilweise in größeren Mengen, die Säugetiere wie der Mensch gar nicht benötigen, etwa Aluminium (Al) oder Silicium (Si).[12] Man sollte also nicht aus den Bedürfnissen des Menschen auf diejenigen der Lebewesen generell schließen, es werden nach wie vor neue Organismen mit exotischen Wegen des Stoffwechsels entdeckt.

[Bearbeiten | Quelltext bearbeiten]
Lebewesen sind vor allem durch in ihnen enthaltene reproduzierende Moleküle gekennzeichnet. Bekannt sind heute die Polynukleotide DNA und RNA, aber auch andere Moleküle haben möglicherweise diese Eigenschaft. Ferner enthalten sie Eiweiße (Proteine), makromolekulare Kohlenhydrate (Polysaccharide) sowie komplexe Moleküle wie Lipide und Steroide. Alle diese Makromoleküle und komplexen Moleküle kommen nicht in der unbelebten Natur vor, sie können von unbelebten Systemen nicht hergestellt werden. Kleinere Bausteine wie Aminosäuren und Nukleotide dagegen sind auch in der unbelebten Natur, zum Beispiel in interstellaren Gasen oder in Meteoriten, zu finden und können auch abiotisch entstehen.
Daneben enthalten die Zellen der Lebewesen zu einem großen Teil Wasser und darin gelöste anorganische Stoffe.
Alle bekannten Lebensvorgänge finden in Anwesenheit von Wasser statt.



Die biologische Systematik versucht, eine sinnvolle Gruppierung aller Lebewesen zu erstellen. Die oberste Stufe wird dabei von den Domänen gebildet. Man unterscheidet nach molekularbiologischen Kriterien drei Domänen: die eigentlichen Bakterien (Bacteria), die Archaeen (Archaea), früher auch Archaebakterien genannt und die Eukaryoten (Eukaryota). Die beiden erstgenannten Domänen enthalten alle Lebewesen ohne Zellkern, die Prokaryoten genannt werden. Die Domäne der Eukaryoten umfasst alle Lebewesen mit Zellkern, darunter fallen Tiere (inklusive der Menschen), Pflanzen und Pilze sowie die Protisten. Dabei sind die Eukaryoten und Archaeen näher miteinander verwandt.[13]



 Lebewesen  







 Bakterien (Bacteria)






   




  Archaeen   (Archaea)  







 Crenarchaeota






   


 Thaumarchaeota






   


 Euryarchaeota



Vorlage:Klade/Wartung/3






  Eukaryoten   (Eukaryota)  












 Amorphea (z. B. Tiere, Pilze)






   


 Diaphoretickes (z. B. Pflanzen)










   


 Excavata















Vorlage:Klade/Wartung/Style


[Bearbeiten | Quelltext bearbeiten]
Die folgenden Eigenschaften von Lebewesen kommen auch bei unbelebten Systemen der Natur und der Technik vor:
Lebewesen sind in der Terminologie der Systemtheorie:

offen: Sie stehen in lebenslangem Energie-, Stoff- und Informationsaustausch mit der Umwelt.[14]
komplex: Leben setzt eine gewisse Komplexität in der Organisation des Systems voraus.
dynamisch: Sie sind zumindest auf der biochemischen Ebene dauernd Reizen und Zwängen der Umwelt ausgesetzt, können aber zeitweise einen stationären Zustand einnehmen, weisen also eine Konstanz von Struktur und Leistung auf. Diese Veränderungen sind einerseits auf dem System innewohnende Bedingungen zurückzuführen (Beispiel: Erzeugung genetischer Variation durch Rekombination bei der Fortpflanzung), andererseits durch Umwelteinflüsse und Umweltreize. Lebewesen wirken wiederum auf ihre Umwelt verändernd zurück. (Beispiel: Veränderung der Zusammensetzung der Atmosphäre durch die Photosynthese.)
deterministisch: Auch wenn alle Eigenschaften der Lebewesen durch die Naturgesetze bestimmt sind, lassen sich aufgrund ihrer Komplexität vor allem für emergente Eigenschaften kaum mathematisch exakte Aussagen über die Vorhersagbarkeit ihrer Eigenschaften und Entwicklung und ihres Verhaltens machen: Durch die für wissenschaftliche Untersuchungen notwendige Reduktion lassen sich zwar Gesetzmäßigkeiten für einzelne Elemente ermitteln. Daraus lassen sich aber nicht immer Gesetzmäßigkeiten für das Gesamtsystem ableiten.
stabil und adaptiv: Lebewesen können trotz störender Einflüsse aus der Umwelt ihre Struktur und ihr inneres Milieu für längere Zeit aufrechterhalten. Andererseits können sie sich auch in Struktur und Verhalten verändern und Umweltänderungen anpassen.
autopoietisch: Lebewesen sind sich selbst replizierende Systeme, wobei einerseits die Kontinuität von Struktur und Leistung über lange Zeiträume hinweg gewährleistet ist, andererseits durch die Ungenauigkeit der Replikation Möglichkeiten zur evolutionären Anpassung an Umweltänderungen bestehen.
autark: Lebewesen sind bis zu einem gewissen Grad von der Umwelt unabhängig. (Siehe dazu die Erörterung der Problematik der Autarkie.)
[Bearbeiten | Quelltext bearbeiten]
Die folgenden Organisationsformen von Lebewesen kommen auch bei unbelebten Systemen der Natur und der Technik vor:

Als komplexe, heterogene Systeme bestehen Lebewesen aus vielen Elementen unterschiedlicher Struktur und Funktion, die durch zahlreiche, unterschiedliche Wechselwirkungen miteinander verknüpft sind.
Lebewesen sind hierarchisch strukturiert: Sie bestehen aus zahlreichen unterschiedlichen Elementen (Subsystemen), die durch zahlreiche Beziehungen miteinander verknüpft sind und selbst wieder aus zahlreichen Untereinheiten bestehen, welche selbst wieder Systeme darstellen und aus Subsystemen bestehen (zum Beispiel Organe bestehen aus Zellen, diese enthalten Organelle, welche aus Biomolekülen aufgebaut sind).
Lebewesen sind auch selbst wieder Elemente von komplexen Systemen höherer Ordnung (zum Beispiel Familienverband, Population, Biozönose), sind also ebenfalls mit zahlreichen weiteren Systemen (andere Lebewesen, unbelebte und technische Systeme) verknüpft.
Alle Lebewesen sind Systeme mit speziellen Informations­bahnen und Informationsspeichern.
[Bearbeiten | Quelltext bearbeiten]
Wie die komplexen physikalischen Systeme der unbelebten Natur (wie zum Beispiel das Sonnensystem) entstehen auch bei Lebewesen Strukturen durch Selbstorganisation. Darüber hinaus besitzen Lebewesen im Gegensatz zu Systemen der unbelebten Natur das genetische Programm, welches jedoch ebenfalls in ähnlicher Weise in Systemen der Technik vorkommen kann (siehe Genetische Programmierung). Durch dieses Programm werden Lebensvorgänge ausgelöst, gesteuert und geregelt. Dazu gehört auch die Reproduktion dieses Programms. Dieses Programm ist teleonomisch, ohne teleologisch sein zu können: Es gibt die Richtung der ontogenetischen Entwicklung und des Verhaltens der Organismen vor und grenzt sie in einem gewissen Rahmen von anderen Entwicklungsmöglichkeiten und Verhaltensweisen ab. Fehlen Teile des Programms oder weisen sie Fehlfunktionen auf, können sich – außerhalb eines Toleranzbereiches – langfristig keine überlebensfähigen Organismen entwickeln.

[Bearbeiten | Quelltext bearbeiten]
Die Entwicklungsgeschichte des Lebens auf der Erde (Evolutionsgeschichte) hat einen einmaligen Verlauf. Auch wenn man die Ausgangsbedingungen wiederherstellen könnte, würde sich möglicherweise ein ähnlicher Ablauf ergeben, wie er schon einmal stattgefunden hat, aber höchstwahrscheinlich nicht exakt der gleiche. Der Grund dafür ist die Vielzahl von zufälligen Zusammentreffen von Einflussfaktoren, die seit dem Beginn des Lebens die weitere Entwicklung bestimmt haben. Diese zufälligen Einflüsse werden durch Selektions- und Anpassungsprozesse teilweise wieder ausgeglichen, trotzdem ist eine genau identische Entwicklung unter realen Bedingungen nicht wahrscheinlich.
Die Entwicklung der verschiedenen Arten von Lebewesen wird in der Evolutionstheorie behandelt. Dieser von Charles Darwin begründete Zweig der Biologie erklärt die Vielfalt der Lebensformen durch Mutation, Variation, Vererbung und Selektion. Die Evolutionstheorien haben zum Ziel, die Veränderungen von Lebensformen im Laufe der Zeit zu erklären und die Entstehung der frühesten Lebensformen nachvollziehbar zu machen. Für Letzteres gibt es eine Reihe von Konzepten und Hypothesen (beispielsweise RNA-Welt, siehe auch Chemische Evolution).
Die ältesten bisher gefundenen fossilen Spuren von Lebewesen sind mikroskopisch kleine Fäden, die als Überreste von Cyanobakterien gelten. Allerdings werden diese in 3,5 Milliarden Jahre alten Gesteinen gefundenen Ablagerungen nicht allgemein als Spuren von Leben angesehen, da es auch rein geologische Erklärungen für diese Formationen gibt.
Die derzeit populärste Theorie zur Entstehung autotrophen Lebens postuliert die Entwicklung eines primitiven Metabolismus auf Eisen-Schwefel-Oberflächen unter reduzierenden Bedingungen, wie sie in der Umgebung von vulkanischen Ausdünstungen anzutreffen sind.[15] Während der Frühphase der Evolution irdischer Lebewesen, die im geologischen Zeitraum vor zwischen 4,6 und 3,5 Milliarden Jahren (Präkambrium) stattfand, war die Erdatmosphäre wahrscheinlich reich an Gasen wie Wasserstoff, Kohlenstoffmonoxid und Kohlenstoffdioxid, während die heißen Ozeane relativ hohe Konzentrationen an Ionen von Übergangsmetallen wie gelöstem Eisen (Fe2+) oder Nickel (Ni2+) enthielten. Ähnliche Bedingungen finden sich heute in der Umgebung von hydrothermalen Schloten, die während plattentektonischer Prozesse auf dem Meeresgrund entstanden sind. In der Umgebung solcher als Schwarze Raucher (englisch black smokers) bezeichneten Schlote gedeihen thermophile methanogene Archaeen auf der Grundlage der Oxidation von Wasserstoff und der Reduktion von Kohlenstoffdioxid (CO2) zu Methan (CH4). Diese extremen Biotope zeigen, dass Leben unabhängig von der Sonne als Energielieferant gedeihen kann, eine grundlegende Voraussetzung für die Entstehung und Aufrechterhaltung von Leben vor dem Aufkommen der Photosynthese.
Neuere Ansätze gehen davon aus, dass die Evolution nicht an der Art, sondern am Individuum und seinen Genen ansetzt (siehe Soziobiologie und Verhaltensbiologie).


[Bearbeiten | Quelltext bearbeiten]
Hier ist die äußerste Grenze letztlich die Zellmembran, die Pellicula, die Zellwand oder eine andere einhüllende und begrenzende Struktur. Bei höheren Organisationsstufen übernehmen Abschluss- und Deckgewebe wie Epidermis, Epithel, Haut oder Rinde diese Funktion.
Viele Organismen geben Stoffe an die Umwelt ab und schaffen sich damit eine eigene Umwelt im Nahbereich, ein Mikromilieu. Beispiel: Schleimkapsel von Pneumococcus. Hier hängt die physische Abgrenzung des Individuums von der Fragestellung ab.

[Bearbeiten | Quelltext bearbeiten]
Die Abgrenzung eines einzelnen Lebewesens von anderen, eigenständigen Lebewesen ist nicht trivial. Das Wort Individuum bedeutet nach seiner lateinischen Herkunft ein Unteilbares. In dieser Bedeutung ist es nicht für alle Lebewesen praktikabel. Zwar kann man die meisten höheren Tiere nicht teilen, ohne sie oder den abgetrennten Teil damit zu töten. Sie sind also nicht teilbar. Einen Hund als Individuum anzusprechen ist daher kein Problem. Dagegen kann man von einem „individuellen“ Baum einen Ableger abteilen und diesen zu einem neuen Exemplar heranwachsen lassen. Damit ist das vermeintliche Baum-Individuum im Grunde ein „Dividuum“, denn es leben nicht zwei Teile eines Baumindividuums weiter, sondern aus einem Exemplar sind zwei entstanden, das ursprüngliche Exemplar wurde vermehrt. Viele Pflanzen bedienen sich dieses Verfahrens der Ausbreitung systematisch, z. B. durch Ableger. Oft wachsen so ganze Rasen oder Wälder heran, die eigentlich einem einzigen zusammenhängenden Exemplar angehören, das aber jederzeit an beliebiger Stelle in mehrere Exemplare geteilt werden könnte.
Durch die Möglichkeit des Klonens entsteht die Fähigkeit zur Abtrennung eines neuen lebensfähigen Exemplars, auch für Säugetiere (siehe Klonschaf Dolly). Damit wird der Begriff Individuum in vielen Bereichen der Biologie mehr oder weniger hinfällig und müsste dort durch einen anderen, besser zutreffenden ersetzt werden, etwa durch den Begriff Exemplar.
Bei Schleimpilzen und kolonienbildenden Einzellern (Beispiel Eudorina) lassen sich individuelle, autarke Zellen unterscheiden. Sie gehen aber zumindest zeitweise Verbindungen miteinander ein, in welcher sie ihre Individualität und Unabhängigkeit aufgeben, also einem mehrzelligen Organismus gleichen.

Siehe auch: Individuum#Biologie
[Bearbeiten | Quelltext bearbeiten]
Aufgrund der komplexen Wechselwirkungen von Organismen mit ihrer Umwelt kann man nur eingeschränkt von Autarkie sprechen:

So sind Lebewesen bezüglich der Energie nie autark, sie sind immer auf eine externe Energiequelle angewiesen, die in der Regel letztlich durch die Sonne gegeben ist. Organismen, die als Energiequelle nur Licht oder die chemische Energie anorganischer Stoffe benötigen, also nicht auf andere Lebewesen als Energielieferanten angewiesen sind, können als energetisch autark betrachtet werden.
Autotrophe Organismen sind in dem Sinne stofflich autark, als sie aus anorganischen Stoffen körpereigene organische Stoffe herstellen und diese im Stoffwechsel wieder zu anorganischen Stoffen abbauen. So lässt sich eine photosynthetisch aktive Pflanze in einem von der Umgebungsluft abgeschlossenen Glasgefäß bei ausreichender Beleuchtung am Leben erhalten, da sich ein Gleichgewicht zwischen Photosynthese und Atmung einstellen kann. Wachstum und Fortpflanzung sind in diesem System allerdings nur so lange möglich wie der Vorrat an Wasser und Nährsalzen ausreicht. Heterotrophe Organismen sind in diesem Sinne nicht autark, da sie auf die von anderen Lebewesen vorgefertigten Nährstoffe angewiesen sind.
Übergeordnete Systeme wie zum Beispiel eine Lebensgemeinschaft (Biozönose) können wiederum energetische und stoffliche Autarkie erreichen, wenn bestimmte Organismengruppen in ausreichender Zahl und mit einer ausgeglichenen Vermehrungsrate vorhanden sind. (Siehe dazu ökologisches Gleichgewicht.) So hat sich in der Tiefsee eine autarke Lebensgemeinschaft zwischen chemoautotrophen Bakterien, Röhrenwürmern, Krebsen und Fischen ausgebildet. Die Ökologie untersucht unter anderem, welche Mindestanforderungen eine abgeschlossene Lebensgemeinschaft erfüllen muss, um autark zu sein, das heißt, einen geschlossenen Stoffkreislauf zu ermöglichen. Letztlich kann die Gesamtheit aller Lebewesen der Erde als eine autarke Lebensgemeinschaft aufgefasst werden (vergleiche dazu die Gaia-Hypothese, die die Erde als einen Organismus auffasst.)
Alle Lebewesen sind bezüglich eines dem System innewohnenden Programms, des genetischen Systems, autark. Damit können sie selbst ihre Lebensvorgänge auslösen, steuern und regeln. (Siehe Systemverhalten). (In diesem Sinne wären auch Viren und Viroide autark, ihr Programm ist aber nicht vollständig, sie sind auch auf die Programme ihrer Wirte angewiesen). Diese Autarkie ist insofern vollständig, als auch die Programmierung, also die Erstellung des genetischen Quellcodes nicht von außen, durch einen „Programmierer höherer Ordnung“, vorgenommen werden muss. Andererseits reichen die Programme nicht aus, um alle Lebensvorgänge zu determinieren: So kann sich zum Beispiel das Gehirn ohne Einfluss der Umwelt nicht fertig entwickeln. In völliger Dunkelheit würde die Sehrinde nicht ihre volle Funktionsfähigkeit erlangen.
Alle Lebewesen sind bezüglich Wachstum, Reparatur und Reproduktion autark. Sie stellen die für sie charakteristischen Systemelemente (Biomoleküle, Zellorganelle, Zellen) selbst her, gleichen mit Hilfe von Reparaturmechanismen strukturelle Störungen innerhalb gewisser Grenzen von selbst aus und sind fähig, ähnliche Kopien von sich herzustellen. Die Herstellung identischer Kopien ist prinzipiell aufgrund physikalischer und chemischer Gesetzmäßigkeiten auf keiner Systemebene möglich. Die dadurch zwangsläufige Variation führt in Zusammenwirken mit der Umwelt zu Evolution auf allen Systemebenen. (Siehe dazu Systemtheorie der Evolution)
Bei der Entwicklung der Systemtheorie durch Physiker, Mathematiker und Techniker gingen diese immer wieder auf Analogien in Struktur und Verhalten von Lebewesen ein. Diese Betrachtung von Lebewesen als Systeme führte dazu, dass Konzepte der Kybernetik, Informatik und der Systemtheorie Eingang in die Biologie gefunden haben, zuletzt und umfassend in der Systemtheorie der Evolution.

[Bearbeiten | Quelltext bearbeiten]
Lebewesen sind als offene Systeme seit ihrer Existenz stets weit vom thermodynamischen Gleichgewicht entfernt. Sie weisen einen hohen Ordnungsgrad und damit eine niedrige Entropie auf. Diese können nur dadurch aufrechterhalten werden, dass die Erhöhung des Ordnungsgrades energetisch mit Prozessen gekoppelt wird, welche die hierfür notwendige Energie liefern.[5] (Beispiel: Aufbau von organischen Stoffen niedriger Entropie wie Glukose, DNA oder ATP, aus anorganischen Stoffen hoher Entropie wie Kohlenstoffdioxid, Wasser und Mineralsalzen durch Photosynthese und Stoffwechsel.) Tritt der Tod ein, stellt sich das thermodynamische Gleichgewicht ein, der hohe Ordnungsgrad kann nicht mehr aufrechterhalten werden, die Entropie wird größer. Leben kann thermodynamisch als die Rückkopplung eines offenen Systems mit seiner Umgebung verstanden werden, welches auf Kosten dieser die eigene Ordnung aufrechterhält. Diese Definition steht mit einer der möglichen Formulierungen des 2. Hauptsatzes der Thermodynamik in Einklang, nach dem die Änderung der Entropie eines Gesamtsystems Null oder größer Null ist. Damit die Ordnung eines Systems aufrechterhalten bleiben oder zunehmen kann, muss die Unordnung der Umgebung mindestens in gleichem Maße zunehmen, sodass die Änderung des Gesamtsystems in Summe mindestens Null ist.

[Bearbeiten | Quelltext bearbeiten]
Viren kommen einerseits als nackte Nukleinsäuren in den Wirtszellen vor, andererseits außerhalb von Zellen als Virionen, die aus der Nukleinsäure und einer Protein­hülle bestehen. Die meisten Wissenschaftler zählen Viren nicht zu den Lebewesen. Wird beispielsweise eine Zellstruktur als grundlegendes Kennzeichen von Lebewesen angesehen, sind Viren nicht zu den Lebewesen zu rechnen, da sie weder Zellen sind noch aus Zellen aufgebaut sind. Zwei weitere Kriterien sind noch wichtiger: Viren haben keinen eigenen Stoffwechsel und sie pflanzen sich nicht selbständig fort. Ihre Vermehrung erfolgt ausschließlich durch die Biosynthese-Maschinerie der Wirtszellen, die dabei durch die Virus-Nukleinsäure gesteuert wird.
Eine Einstufung als „Grenzfall des Lebens“ ist jedoch naheliegend. Die Existenz der Viren könnte in der Evolution auf einen Übergang von „noch nicht lebendig“ zu „lebendig“ hinweisen. Allerdings könnten sich die Viren auch aus „echten“ Lebewesen wie den Bakterien rückentwickelt haben.
Mittlerweile ist es gelungen, eine Nukleinsäure mit der Sequenz des Poliovirus durch DNA-Synthese künstlich zu erzeugen; auf die gleiche Weise hat man bereits viele weitere DNA- und RNA-Abschnitte für gentechnische Experimente erzeugt. Schleust man dann in dieser Weise erzeugte DNA-Stränge in Zellen ein, entstehen in der Folge komplette, natürliche Polioviren. Das Experiment verdeutlicht, dass die Grenze zwischen Lebewesen und Nicht-Lebewesen schwierig zu bestimmen ist.
Viren sind durch Mutationen und Selektion der Evolution unterworfen. Im weiteren Sinne gilt dies aber auch für viele Nicht-Lebewesen, zum Beispiel für einzelne Gene (Das egoistische Gen), aber auch für Verhaltensweisen und kulturelle Errungenschaften wie Werkzeuge, Techniken und Ideen (Mem-Theorie). Die Evolution der Viren ist deshalb kein hinreichender Beweis dafür, dass Viren Lebewesen seien.


→ Hauptartikel: Liste der Listen von Superlativen#Biologie und Kategorie:Liste (biologische Rekorde)
Der Dunklen Hallimasch-Pilz gilt mit rund 9 Quadratkilometer (je nach Quelle um die 880 Hektar oder 965 Hektar) erstreckt. Dieser Pilz ist nach derzeitigem Kenntnisstand bezogen auf seine Fläche das größte Lebewesen der Erde und der größte Pilz der Erde. Sein Gewicht beträgt schätzungsweise 600 Tonnen.
Der General Sherman Tree in Kalifornien (USA), ein Exemplar des Riesenmammutbaumes, wiegt 1.950 Tonnen (Stand 1938) und ist das vermutlich schwerste nicht-klonale Lebewesen der Erde.

Portal: Lebewesen – Übersicht zu Wikipedia-Inhalten zum Thema Lebewesen
Außerirdisches Leben
Biota

Hans-Joachim Flechtner: Grundbegriffe der Kybernetik – eine Einführung. Wissenschaftliche Verlags-Gesellschaft, Stuttgart 1970.
Anna Maria Hennen: Die Gestalt der Lebewesen. Versuch einer Erklärung im Sinne der aristotelisch-scholastischen Philosophie. Königshausen & Neumann, Würzburg 2000, ISBN 3-8260-1800-1.
Sven P. Thoms: Ursprung des Lebens. Fischer-Taschenbuch-Verlag, Frankfurt 2005, ISBN 3-596-16128-2.




 – Zoombarer Stammbaum aller rezenten Lebewesen-Arten



Als Landnutzung (auch Flächennutzung)[1][2] wird die Art der Inanspruchnahme von Böden und Landflächen (Teilen der festen Erdoberfläche) durch den Menschen bezeichnet. Bei speziell landwirtschaftlicher Nutzung spricht man auch von Bodennutzung. Gelegentlich wird der Begriff Bodennutzung auch synonym zu Landnutzung verwendet.
Die verschiedenen Nutzungsarten von Land- und Forstwirtschaft, Industrie, Siedlungswesen, Verkehr, Brachland usw. – die z. B. in Deutschland Anteile von 55 %, 29 %, 11 % und 5 % ausmachen – werden in Form einer schematischen Klassifizierung erfasst, die in Industrieländern relativ genau und aufwendig erfolgt und etwa 20 bis 50 Klassen umfasst, während sich Entwicklungsländer auf etwa 10 bis 15 Nutzungsklassen beschränken.
Die Art der Boden- und Landnutzung hat sich in Europa seit dem Mittelalter[3] durch die Industrialisierung merklich gewandelt und ist seit der Mitte des 20. Jahrhunderts zunehmend zum Thema der Raumplanung geworden. Sowohl in den Verdichtungsgebieten als auch im ländlichen Raum ergeben sich Nutzungskonflikte aus der Überlagerung und Konkurrenz unterschiedlicher Nutzungsarten sowie ihren direkten und indirekten Auswirkungen. Neben dem menschlichen Alltag, den kulturräumlichen Strukturen und der Wirtschaft ist auch der Naturhaushalt betroffen, insbesondere der Boden- und Wasserhaushalt, lokales Klima, Ökosystem und Artenvielfalt, z. B. durch die nutzungsbedingten stofflichen und strukturellen Belastungen. Gleichzeitig nimmt die Bedeutung ländlicher Gebiete als Ausgleichsraum der urbanen Räume und durch Auslagerung städtischer Funktionen ins Umland zu. Daher ist eine periodische Feststellung der Landnutzung und ihrer Veränderungen erforderlich.
Die Erfassung der Landnutzung ging historisch meist von der Finanzverwaltung aus (Ertrags- und Grundsteuer), während sie heute eine interdisziplinäre Aufgabe ist, zu der vor allem die Landwirtschaft, die Geographie, die Geodäsie und Fernerkundung sowie die Raumplanung beitragen, in geringerem Maß Bodenkunde, Forstwirtschaft, regionale Agrarpolitik und staatliche Agrarförderung.




Das Umweltbundesamt berechnete bei der Erhebung vom 31. Dezember 2015 folgende Flächennutzung in Deutschland:[4]

51,6 % landwirtschaftliche Fläche
30,6 % Waldfläche
13,7 % Siedlungs- und Verkehrsfläche
2,4 % Wasserfläche
1,7 % sonstige Flächen

Vergleichend dazu die Veränderungen zur Erhebung von 1936 (Deutschland in den damaligen Grenzen):[5]

43,6 % Ackerland
27,3 % Wald
17,4 % Wiesen und Weiden
4,9 % Wege, Wasser und Eisenbahn
3,8 % Ödland
1,4 % Siedlungsfläche
Anmerkung: Auffällig starke Veränderungen gab es im Bereich der Siedlungs- und Verkehrsflächen. Inklusive der annähernd gleich gebliebenen Wasserflächen, stiegen diese um das 2,5-Fache. Zu berücksichtigen ist, dass die Bevölkerungszahl „nur“ um etwa 26 % im gleichen Zeitraum gestiegen ist. Die Verkleinerung der Staatsfläche von Deutschland ist dagegen in dieser Verhältnisaufstellung von untergeordneter Bedeutung.


Bei der Unterscheidung  nach der Intensität der Flächennutzung bestehen fließende Übergänge zwischen beiden Formen, denn jede Landnutzung weist einen eigenen Grad an Intensivierung auf.
intensive Landnutzung
Bewirtschaftungsformen mit verschiedenen (kosten)intensiven Investitionen und Maßnahmen zur Melioration der Flächen und Steigerung des Bodenertrags wie:

dichtes Wegenetz
Anlegung einer effektiven Ent- und Bewässerung
starker Einsatz von Düngemitteln
Flurbereinigungmaßnahmen
starker Maschineneinsatz
Einsatz von Pflanzenschutzmitteln und leistungsfähigen Sorten
oft hoher Grad an Spezialisierung
Beispiele: Konventionelle Landwirtschaft, Gewächshausanbau, Massentierhaltung, die meisten Plantagen, Reisterrassen
extensive Landnutzung
Die Nutzung von Landflächen mit nur geringen bis fehlenden Geldinvestitionen in Flächen wie:

geringer bis fehlender Düngemitteleinsatz
viel Einsatz von Handarbeit, schonende Bodenbearbeitung
Kleinparzellige Strukturen
Anbau traditioneller Sorten
Verzicht auf Pflanzenschutzmittel
oft hohe Vielfalt an Betriebsfeldern
Beispiele: viele traditionelle Landnutzungssysteme (aber nicht alle), Wanderfeldbau, Dreifelderwirtschaft, Plenterwald, Almen, mobile Weidewirtschaft, Nomadismus
nachhaltige Landnutzung
Nachhaltige Landnutzung ist die Nutzung von Flächen in einer Weise, bei der die wesentlichen Eigenschaften, die Stabilität und die natürliche Regenerationsfähigkeit der Flächen bewahrt bleibt. Viele traditionelle (nicht alle) und einige intensive Landnutzungen gelten als nachhaltig.
Nachhaltigkeit ist das wesentliche Ziel der biologischen Landwirtschaft, das u. a. durch Ausschluss von Kunstdünger und Gentechnik, Schonung des Grundwassers, Belassung natürlicher Feldraine und Böschungen oder Gewässerrückbau erreicht werden soll.


In Europa wird die Landnutzung seit etwa 1800 terrestrisch (durch systematische Begehung) erfasst – z. B. in Deutschland und Österreich-Ungarn im Zuge der Steuer- und Landesvermessung als „Kulturklasse“. Sie geht seit damals auch in die Steuerbemessung ein und wird seit den 1970er Jahren zunehmend durch Satelliten- und Remote-sensing-Methoden ergänzt bzw. verfeinert.
Mitte der 1980er Jahre wurde die Klassifizierung der Landflächen (allerdings Bodenbedeckung) auf eine EU-weit einheitliche Typisierung umgestellt und aktualisiert. Im Rahmen des CORINE-Programms werten Experten in jedem Mitgliedsland der EU digitale Satellitenbilder aus. Die Daten werden in einem Geoinformationssystem (GIS) aufbereitet und liegen nun als digitale Karten etwa im Maßstab 1:100.000 vor.
Die 13 Hauptklassen der Bodenbedeckung (landcover), die für alle EU-Länder den Rahmen bilden, sind:

Siedlungsflächen (inkl. Verkehrsflächen)
Ackerflächen
Dauerkulturen
Grünland
Laub- und Mischwald
Nadelwald
Alpine Matten
Latschen, Krummholz
Felsflächen
Spärliche Vegetation
Gletscher
Feuchtflächen
Wasserflächen.
Eine ganz andere Klassifizierung ist das LCCS (Land Cover Classification System), welches die Ernährungs- und Landwirtschaftsorganisation FAO als globalen, aber nur groben Rahmen vorgeschlagen hat. Von den acht Hauptklassen beziehen sich je vier auf (un-)kultivierte Landflächen bzw. auf (un-)kultivierte Wasserflächen. Auch dieses System ist – vor allem für Ackerflächen – feiner unterteilbar.


[Bearbeiten | Quelltext bearbeiten]
Im Kontext der agrarischen Landnutzung, insbesondere beim Anbau von Energiepflanzen zur Erzeugung von Agrarkraftstoffen, wird zwischen direkter und indirekter Landnutzungsänderung (direct Land Use Change, kurz dLUC, bzw. indirect Land Use Change oder iLUC) unterschieden. Erstere bezeichnet die Umwandlung von Land, das vorher nicht für den Anbau von Feldfrüchten genutzt wurde, in Anbauflächen von Pflanzenrohstoffen. Die indirekte Landnutzungsänderung beschreibt den Effekt, dass für den Anbau von Energiepflanzen Flächen genutzt werden, die ursprünglich für die Erzeugung von Nahrungsmitteln bestimmt waren. Somit steigen einerseits die Lebensmittelpreise aufgrund einer Angebotsknappheit und andererseits findet eine Verdrängung der Nahrungs- und Futtermittelproduktion statt, für die dann neue Flächen landwirtschaftlich erschlossen werden müssen.[6]
Seit dem Inkrafttreten der Erneuerbare-Energien-Richtlinie (2009/28/EG), die vorsieht, ab 2020 mindestens 10 Prozent der fossilen Kraftstoffnachfrage durch regenerative Energien zu ersetzen, werden so genannte Biotreibstoffe in der EU über gesetzliche Beimischungsquoten, Steuervergünstigungen und Subventionen stark gefördert.[7] Für den Einsatz der Biokraftstoffe wurde vor allem der Klimaschutz angeführt. Kritiker weisen jedoch auf die durch iLUC verursachten Treibhausgasemissionen hin (z. B. durch die Regenwaldrodung für Ölpalmplantagen zur Produktion von Biodiesel) und es wird diskutiert, ob und inwieweit diese so genannten iLUC-Faktoren auf die für die Produktion von Biotreibstoffen verwendeten Rohstoffe und deren Herkunft angerechnet werden sollen. Das Institute for European Environmental Policy kommt zu dem Ergebnis, dass der zusätzliche Bedarf von 15,1 Millionen Tonnen Rohöleinheiten Biotreibstoff bis 2020 (im Vergleich zu 2008) zu einer indirekten Landnutzungsänderung von 4,1 bis 6,9 Millionen Hektar führen würde (eine Fläche knapp größer als die Niederlande bzw. etwas kleiner als Irland).[8]
Die Europäische Kommission hat in diesem Zusammenhang mehrere Studien über indirekte Landnutzungsänderungen und deren Berücksichtigung in Auftrag gegeben, deren überarbeitete Versionen später teilweise nach öffentlichem Druck veröffentlicht wurden.[9] Die Studien kommen zu dem Ergebnis, dass indirekte Landnutzungsänderungen einen deutlichen Einfluss auf die Klimabilanz von Biokraftstoffen haben. Besonders Biodiesel aus Pflanzenölen wie Palmöl, Raps und Soja kann unter Umständen mehr Kohlenstoff freisetzen als fossiler Diesel.[10] In Reaktion auf die Ergebnisse sollen Biotreibstoffe wie das in Deutschland verkaufte E10 ab 2020 nicht mehr von der EU subventioniert werden.[11]

[Bearbeiten | Quelltext bearbeiten]

Landnutzungsänderungen seit 1960 betreffen laut einer Studie 17 % der Landfläche. Wenn mehrmalige Änderungen berücksichtigt werden, sind es 32 %, „etwa das Vierfache“ früherer Schätzungen. Die Forscher untersuchten auch die Ursachen und identifizierten dabei den Landwirtschaft-beeinflussenden internationalen Handel als Haupttreiber.[13][12]

[Bearbeiten | Quelltext bearbeiten]



Im folgenden Absatz fehlen noch wichtige Informationen. Hilf der Wikipedia, indem du sie recherchierst und einfügst.

Landnutzungsänderungen haben Auswirkungen auf den Klimawandel, die Nahrungsmittelsicherheit und die Biodiversität.

[Bearbeiten | Quelltext bearbeiten]
Bei der Umwandlung von Gewässern, landwirtschaftlichen Flächen und Waldflächen in Siedlungs- und Verkehrsflächen spricht man von Flächenverbrauch. In Deutschland war eine Verringerung des jährlichen Flächenverbrauchs auf 30 ha pro Tag bis zum Jahr 2020 eines der Ziele der Nachhaltigkeitsstrategie.[14]

[Bearbeiten | Quelltext bearbeiten]
In der globalen Betrachtung wird der Verlust von biologisch produktiven Flächen häufig auch mit dem Begriff Landverbrauch beschrieben. Hierunter fällt auch das Problem, dass auf Anbauflächen oder Abbauflächen Produkte für den Export erzeugt werden, wobei die einheimische Bevölkerung in keiner Weise profitiert. Der Begriff Landverbrauch steht in enger Beziehung zu dem Modell des ökologischen Fußabdrucks.


Global werden drei Viertel der eisfreien Landoberfläche vom Menschen genutzt. Große Teile der Landbedeckung Wald wurden und werden in Ackerland umgewandelt. Andere Areale werden beispielsweise durch Beweidung oder Holzernte genutzt. Die Art der Landnutzung hat einen erheblichen Einfluss auf das Erdsystem. In die Kreisläufe von Kohlenstoff, Nährstoffen und Wasser wird eingegriffen. Die Biodiversität wird in der Regel vermindert.
Etwa ein Drittel des gesamten CO2-Ausstoßes im Zeitraum 1850–2000 ist auf Entwaldung zurückzuführen.[15]


Extensive Landnutzung in Mitteleuropa
Landnutzung in den Tropen
Kulturareale der Erde: Spiegelbild der Vegetationszonen und traditionellen Landnutzung

JEK: Handbuch der Vermessungskunde. Band Ia. J.B. Metzler, Stuttgart 1955.
Johannes Müller: Landschaftselemente aus Menschenhand. Spektrum-Verlag, Heidelberg 2005.
.
Walter Kühbauch (1993): Intensität der Landnutzung im Wandel der Zeit. Die Geowissenschaften; 11, 4; 121–129; doi:.


Erich Tasser, Ulrike Tappeiner: 





KatS ist eine Weiterleitung auf diesen Artikel. Zu weiteren Bedeutungen der Buchstabenfolge siehe Kats (Begriffsklärung).




Die Artikel Katastrophenschutz und Katastrophenhilfe überschneiden sich thematisch. Informationen, die du hier suchst, können sich also auch im anderen Artikel befinden.Gerne kannst du dich an der betreffenden Redundanzdiskussion beteiligen oder direkt dabei helfen, die Artikel zusammenzuführen oder besser voneinander abzugrenzen (→ Anleitung).



Katastrophenschutz (KatS) bezeichnet die Maßnahmen, die getroffen werden, um Menschen, Umwelt und bestimmte Sachwerte in oder vor der Entstehung einer Katastrophe zu schützen und die Versorgung der Menschen zu wahren.[1] Abgegrenzt vom Katastrophenschutz wird der Schutz der Bevölkerung im Kriegsfall. Letzterer wird im offiziellen Sprachgebrauch der Bundesrepublik Deutschland als Zivilschutz bezeichnet und gemeinsam mit dem Katastrophenschutz unter dem Oberbegriff des Bevölkerungsschutzes zusammengefasst;[2] in Österreich und der Schweiz ist der Sprachgebrauch anders.[3][4]
Zu den Maßnahmen gehören neben unmittelbaren Einsätzen und Hilfeleistungen auch vorbereitende Maßnahmen, wie zum Beispiel die Aufstellung entsprechender Hilfseinrichtungen und -pläne oder das Festlegen von Standard-Einsatz-Regeln (SER) zur schnellen Reaktion bei gleichen Lagen, die Abwehr von Schäden im Katastrophenfall sowie im Nachgang die Beseitigung von Katastrophenschäden.




Schutz für die Zivilbevölkerung in Kriegszeiten war in der Zeit der festgelegten Schlachtaufstellung (Kriegsführung) und auch der Grabenkämpfe des Ersten Weltkriegs kein besonderes Thema, da der Großteil der Bevölkerung eines Landes nicht von den oft auf abgelegenen Geländen stattfindenden Schlachten betroffen war oder dieser Schutz einfach nicht wichtig genug genommen wurde.
Auch die Versorgung bei Naturkatastrophen wurde zunächst selten organisiert vorgenommen. Die ländliche Bevölkerung musste und konnte sich selbst helfen. In den Städten oblag die Bekämpfung von Schadensereignissen den örtlichen Behörden, die dafür Hilfstruppen zum Beispiel in Form einer Feuerwehr aufstellten oder auch medizinische Hilfe (wie im Falle einer Pestepidemie) und die Versorgung mit Nahrungsmitteln leistete.

[Bearbeiten | Quelltext bearbeiten]
Vorbeugende Schutzmaßnahmen wurden mit zunehmender Organisation des Gemeinwesens getroffen, hierzu gehören Feuerlöschordnungen oder auch Maßnahmen zum Schutz vor Hochwassern (Entwässerungskanäle, Deiche).
Das Rote Kreuz, gegründet 1863 von Henry Dunant unter dem Eindruck der Schlacht von Solferino als neutrale Hilfsorganisationen für Kriegszeiten, nahm schon bald seine Aufgaben auch bei zivilen Unglücksfällen und Katastrophen wahr. In diese Zeit fallen auch die Bildung von weiteren Hilfsvereinen und die Professionalisierung des Feuerlöschwesens zusammen mit der zunehmenden Übernahme von Verantwortung der Staatsmacht für das Gemeinwohl. Mit der Industrialisierung ist eine Zunahme von größeren technischen Unglücken verbunden, die vor allem in den Industriegebieten schon früh zur Aufstellung von speziellen Arbeiterorganisationen (zum Beispiel des Arbeiter-Samariter-Bundes) führte.
Überregionale Katastrophenhilfe wurde dabei zunächst oft vom Militär organisiert, das als einzige Organisation über entsprechend einsetzbare Einheiten verfügte. Den zivilen Hilfsdiensten oblag in solchen Situationen vor allem das Sammeln von Spenden und Hilfsgütern.

[Bearbeiten | Quelltext bearbeiten]
Der Zweite Weltkrieg machte in den betroffenen Ländern die gezielte Organisation von Hilfsmaßnahmen im großen Maßstab erforderlich (zum Beispiel während der Luftschlacht um England, respektive dem Luftkrieg). Die Einheiten der Feuerwehren, der zivilen Rettungsorganisationen und des Militärs mussten überregional koordiniert werden, zum Teil wurden eigene Organisationsformen als Luftschutz aufgestellt.
Unter dem Eindruck des Zweiten Weltkriegs wurden 1949 die Genfer Konventionen neu gefasst und mit dem vierten Abkommen „über den Schutz von Zivilpersonen in Kriegszeiten“ ergänzt. Hier wurde neben den bis dahin vereinbarten Schutzzeichen auch das neue Zivilschutzzeichen, ein blaues Dreieck auf orangefarbigem Grund, eingeführt.
Mit dem Koreakrieg begann 1950 die heiße Phase des Kalten Krieges. Unter diesem Eindruck wurden moderne Zivilschutzmaßnahmen in vielen Ländern vorangetrieben, die auch Auswirkungen auf die Katastrophenschutzorganisation hatten. Es wurde versucht, den Auswirkungen von Massenvernichtungswaffen entgegenzuwirken. Dabei stand vor allem die historisch neuartige Möglichkeit eines Atomkriegs vor Augen.
Die internationale Zusammenarbeit im Katastrophenschutz verstärkte sich, sowohl in der Folge Militärbündnisse (NATO, Warschauer Pakt) mit gleichartiger Ausrüstung und Vorgehensweise in den verbündeten Ländern als auch auf ziviler oder verwaltungstechnischer Ebene oder im Rahmen der Vereinten Nationen (United Nations Disaster Relief Organization 1971) beziehungsweise der Organisationen der Internationalen Rotkreuz- und Rothalbmond-Bewegung.
Im Zuge der Entwicklungshilfe werden in vielen Ländern auch Maßnahmen zum Katastrophenschutz gefördert, um vor allem regelmäßige Naturkatastrophen überstehen zu können.

Siehe auch: Woche der Winterbereitschaft und des Brandschutzes
[Bearbeiten | Quelltext bearbeiten]
Das Ende des Kalten Krieges führte in den frühen 1990er-Jahren zu einem starken Abbau des Katastrophen- und Zivilschutzes in Europa, da man die Notwendigkeit weitgehend nicht mehr sah. Die Verantwortung für Schutzmaßnahmen wurde auf niedrigere Verwaltungsebenen übertragen oder an freiwillige Projekte übergeben. Da schnell erkannt wurde, dass es immer noch Situationen geben kann, die den normalen Rettungsdienst überfordern (zum Beispiel Naturkatastrophen oder in gewissen Ländern Kernkraftwerks- und Chemieunfälle), wurde mit relativ begrenzten Mitteln versucht, vorbereitende Maßnahmen zu treffen (zum Beispiel Gefahrenzonenplanung) und Hilfskräfte auch für größere Schadenslagen vorzuhalten.
Nach den Terroranschlägen in den Vereinigten Staaten im Jahr 2001 und den grenzüberschreitenden Hochwasserereignissen (Oderhochwasser 1997, Elbehochwasser 2002, Hochwasser in West- und Mitteleuropa 2021) begann sich diese Entwicklung umzukehren. Katastrophenschutz wurde wieder in größerem Zusammenhang gesehen, diesmal losgelöst vom militärischen Aspekt.
Mit der Entscheidung des Rates der Europäischen Union vom 23. Oktober 2001 über ein Gemeinschaftsverfahren zur Förderung einer verstärkten Zusammenarbeit bei Katastrophenschutzeinsätzen (2001/792/EG, Euratom) wurde auf EU-Ebene ein Verfahren für die gegenseitige Hilfeleistung in Katastrophenfällen eingerichtet. Im Bedarfsfall besteht damit für die Mitgliedsländer die Möglichkeit, den Katastrophenhilfe-Mechanismus der EU zu aktivieren und Ressourcen der Gemeinschaftsmitglieder anzufordern.
Bei einer Katastrophe sind auch Kulturgüter gefährdet. Beispielsweise beim Schweizer Zivilschutz, der auch in Katastrophenlagen zuständig ist, ist der Kulturgüterschutz teil des Aufgabenbereichs.[5]

[Bearbeiten | Quelltext bearbeiten]
[Bearbeiten | Quelltext bearbeiten]
Mit dem Rückgang der Bevölkerungszahl, der Alterung der Gesellschaft und schrumpfenden Kohorten von Personen in jüngeren und mittleren Jahrgängen (demografischer Wandel) sowie dem Wegfall des Ersatzdienstes im Katastrophenschutz verfestigen sich für den Katastrophenschutz zunehmend Probleme bei der Nachwuchsrekrutierung. So prognostiziert beispielsweise das Bundesinstitut für Bevölkerungsforschung allein bei den Mitgliederzahlen der Freiwilligen Feuerwehren und des Rettungswesens einen Schwund um ein Viertel bis zum Jahr 2025.[6]
Die Rekrutierungsprobleme werden zusätzlich verstärkt durch eine Diskrepanz zwischen den Strukturanforderungen der Hilfsorganisationen und den individuellen Bedürfnissen und Möglichkeiten potentieller freiwilliger Helfer. Während die Hilfsorganisationen vor allem auf kontinuierliche Engagements abstellen und hohe qualifikatorische Voraussetzungen von ihren Mitgliedern einfordern, geht der Trend in der Bevölkerung eher in Richtung episodischer, projektbezogener Engagementformen („Strukturwandel des Ehrenamtes“).[7]

[Bearbeiten | Quelltext bearbeiten]
Im Zuge der Klimakrise und deren Auswirkungen auf Deutschland und Europa, ist ein erhöhtes Einsatzaufkommen nachvollziehbar, dessen Trend sich voraussichtlich fortsetzen wird.[8][9][10] Auf konzeptioneller und strategischer Ebene wird daher um eine Aktualisierung und Verbindung der Themenfelder gerungen.[11][12][13][14]


[Bearbeiten | Quelltext bearbeiten]
Das Emergency Response Team (auch: Incident response team) einer Organisation oder einer Behörde kann noch vor Eintreffen der eigentlichen Hilfskräfte eingesetzt werden, um den Umfang und die Einsatzorte der Hilfskräfte zu erkunden und in Zusammenarbeit mit bereits aktiven, zum Beispiel den lokalen Helfern vorzubereiten. Dies trifft regelmäßig vor international zu koordinierenden Hilfseinsätzen zu. Diese Teams setzen sich neben Fachkräften entsprechend der Notlage vor allem aus Logistikern zusammen, die abschätzen können, wie weit die vorhandene Infrastruktur, zum Beispiel eines Flughafens, noch genutzt werden kann beziehungsweise ob es nötig ist, eine vom Einsatzort unabhängige Infrastruktur für die Einsatzkräfte aufzubauen.

[Bearbeiten | Quelltext bearbeiten]
Bei zahlreichen Naturgefahren ist durch mathematische Modelle und technische Maßnahmen eine gewisse Vorhersage möglich; manchmal kann ein Ereignis auch abgewendet werden. Zu solchen Gefahren zählen u. a.:

Tsunami nach einem Seebeben: Bei größerer Entfernung vom Epizentrum kann rechtzeitig eine Warnung an betroffene Küstengebiete ergehen. Nach dem großen Tsunami 2004 wurden im Pazifik und einigen anderen Regionen Warndienste aufgebaut.
Stürme / Wirbelstürme (Hurrikan / Taifun): Einen hocheffizienten Katastrophenschutz betreibt bspw. Taiwan seit Jahrzehnten im Hinblick auf Taifune.[15] So kommen selbst bei den stärksten Taifunen in Taiwan nur wenige Menschen ums Leben oder zu Schaden. Personenschäden sind meist auf das Nichtbefolgen von Behördenanweisungen zurückzuführen. (Siehe auch: Sturmwarnung)
Erdbeben: Hier sind allenfalls sehr unsichere Prognosen des Zeitpunkts möglich; jene für Nachbeben sind etwas genauer. (Siehe auch: Erdbebenfrühwarnung)
Hochwasser: Moderne Prognosemethoden verarbeiten Niederschlags- und Pegelmessungen auf Basis von Abflussmodellen und digitalen Geländehöhen. Die errechneten Pegelstände sind bei guten Modellen etwa dezimetergenau. (Siehe auch: Hochwasserwarnung)
Bergstürze können meist nur prognostiziert werden, wenn schon vorausgehende Ereignisse stattfanden und mittels Geotechnik laufend Überwachungsmessungen erfolgen
Hangrutschungen sind bei „verdächtigen“ Berghängen gut prognostizierbar, wenn Geotechnik und Geodäsie ständige Überwachungsnetze installieren und ein automatischer Datenfluss auch über den aktuellen Niederschlag erfolgt
Bei Muren und Lawinen sind solche Prognosen unsicherer, doch können Gefährdungspotentiale angegeben werden.
Epidemien / Pandemien: In der Pandemienprävention könnten durch mathematische Modellierung, Diagnostik-, Kommunikations- und Informationstechnologien bis dato unbekannte potenzielle Pathogene identifiziert, gemeldet und deren mögliche Evolution vorausgesagt werden. Mehrere Ansätze erlauben ein Abwenden einer potenziellen Pandemie. Der Nationale Pandemieplan für Deutschland nennt Maßnahmen, die im Falle der Gefahr einer massiven Ausbreitung von übertragbaren Krankheiten zu deren Verhütung und Bekämpfung beitragen können.
Asteroiden: Zur Verhinderung eines Asteroidenimpakts werden diese (z. B. vom Space Situational Awareness Programme) ständig beobachtet und verschiedene planetare Verteidigungsstrategien entwickelt.
Weltraumwetter: Durch Ereignisse wie Sonnenwinde oder kosmische Strahlung können insbesondere elektronische Systeme auf der Erde beeinflusst werden.
[Bearbeiten | Quelltext bearbeiten]
Eine Reihe von Infrastrukturkomponenten könnte nach einer Katastrophe mit Hilfe von Technologien schnell ad hoc wiederhergestellt werden.

[Bearbeiten | Quelltext bearbeiten]
Drahtlose Meshnets können schnell eingesetzt werden,[16] um Internetverbindungen zu ermöglichen, ausgefallene Mobilfunknetze zu ersetzen und die Kommunikation in Notfällen und nach Katastrophen zu ermöglichen – auch für die Koordinierung der Katastrophenhilfe und Notrufe.[17][18][19] Mesh-Netzwerke wie B.A.T.M.A.N. werden häufig von freiwilligen Gemeinschaften mit geringen Ressourcen open-source entwickelt und eingesetzt.

[Bearbeiten | Quelltext bearbeiten]
Notstromsysteme – wie mobile Mikrogeneration, mobile Lade- und Stromversorgungsstationen – sowie Smart Grids[20][21] können bei Ausfall der normalen Stromversorgung wichtige elektrische Systeme unterstützen oder die Stromversorgung für kleine Regionen wiederherstellen, deren Verbindungen zum Hauptstromnetz unterbrochen wurden.

[Bearbeiten | Quelltext bearbeiten]
Die Verkehrsinfrastrukturrouten können durch eine Katastrophe unpassierbar werden, was die Logistik, Evakuierung und Katastrophenhilfe erschwert.
Technologien können es ermöglichen, das Verkehrsnetz schnell und ad hoc wiederherzustellen oder Teile davon zu ersetzen. Dazu gehört der schnelle Bau stabiler Brücken mittels mobiler, leichter und/oder lokal beschaffter Materialien oder Komponenten, was in einigen Fällen von Militärs umgesetzt wurde.[22][23][24]

[Bearbeiten | Quelltext bearbeiten]
Katastrophenabfälle werden häufig ad hoc entsorgt.[25] Die bei einer Katastrophe anfallenden Abfälle können die bestehenden Abfallentsorgungseinrichtungen überfordern und andere Hilfsmaßnahmen beeinträchtigen.[26] Je nach Art der Katastrophe, ihrem Ausmaß und ihrer Wiederherstellungsdauer müssen konventionelle Abfälle möglicherweise auf ähnliche Weise entsorgt werden, wobei beide Abfallarten auch mit der Wiederherstellung des Verkehrsnetzes verbunden sind.

[Bearbeiten | Quelltext bearbeiten]
Notunterkünfte werden manchmal als ein Element von Infrastruktur betrachtet. Die vorübergehende Unterbringung von Menschen und Tieren nach Katastrophen kann Teil des Katastrophenschutzes sein.[27][28] Manchmal werden bestehende private Unterkunftsinfrastrukturen und -logistik für den Katastrophenschutz umgewidmet.[29]

[Bearbeiten | Quelltext bearbeiten]
Die Infrastruktur für Wasserversorgung, Entwässerung und Kanalisation sowie das Funktionieren von Kläranlagen kann durch Katastrophen gestört werden.[30]

[Bearbeiten | Quelltext bearbeiten]
Langfristige Katastrophenhilfe sowie die medizinische Infrastruktur in Katastrophengebieten mit erhöhtem Gesundheitsrisiko kann auch Infrastruktur für Impfungen umfassen.[31][32][33]

[Bearbeiten | Quelltext bearbeiten]
Freiwillige Helfer sowie andere an der Katastrophenhilfe beteiligte Personen wie Einheimische und zivile Organisationen wie das Technische Hilfswerk können mit Hilfe von Websites und ähnlichen IKT koordiniert werden – z. B. zur Vermeidung von Staus,[34] anderen Behinderungen des Verkehrsnetzes und „Katastrophentouristen“, zur Zuteilung verschiedener Formen von Hilfe an bedürftige Orte, zur Meldung vermisster Personen und zur Steigerung der Effizienz. Nach den Überschwemmungen in Europa im Jahr 2021 wurden solche Websites für einzelne betroffene Regionen eingerichtet.[35]

[Bearbeiten | Quelltext bearbeiten]
Ein schneller und zuverlässiger Informationsaustausch, koordiniertes Verhalten und gewisse Selbstaufopferung spielen im Katastrophenfall eine Rolle für die individuelle und kollektive Sicherheit. Eine Studie zeigte, dass soziale Netzwerke nur schlecht als Kanäle für unbequeme Wahrheiten, die Menschen lieber ignorieren würden, funktionieren können und dass das Zusammenspiel zwischen Kommunikation und Handeln von der Struktur sozialer Netzwerke abhängen kann. Sie zeigte auch, dass Kommunikationsnetzwerke in Testszenarien notwendige „Evakuierungen“ unterdrücken, weil sie im Vergleich zu Gruppen isolierter Individuen spontan und diffus falsche Sicherheit vermitteln. Zudem erleiden größere Netzwerke mit einem geringeren Anteil an (gut) informierten Personen – oder entsprechende Präsenz und Darstellung der entsprechenden Informationen – mehr Schaden durch von Menschen verursachte Fehlinformationen.[36][37]


[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Bevölkerungsschutz (Deutschland)
[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Zivilschutz (Österreich) und Katastrophenhilfsdienst
Als oberste Behörde ist in Österreich das Innenministerium zuständig, während die einzelnen zivilen Organisationen, die für den Katastrophenschutz herangezogen werden, aufgrund landesgesetzlicher Basis arbeiten.
Je nach Schadenslage kann ein bestimmtes Gebiet zum Katastrophengebiet erklärt werden. Je nach Ausdehnung kann ein Bürgermeister, Bezirkshauptmann oder Landeshauptmann die Katastrophe ausrufen.
Die Katastrophenschutzgesetzgebung obliegt den einzelnen Bundesländern. Damit treten bestimmte Notstandsgesetze in Kraft um die Auswirkungen in den Griff zu bekommen.
In erster Linie ist die Bekämpfung von Katastrophen Aufgabe der Feuerwehr mit den durch sie organisierten Katastrophenhilfsdiensten und den Rettungsorganisationen und ruht damit hauptsächlich auf Freiwilligenorganisationen. Aber auch das Bundesheer kann zu Assistenzhilfsleistungen herangezogen werden. Um auch Freiwillige unter der Zivilbevölkerung einbinden zu können, wurde 2007 das Team Österreich unter der Leitung vom Roten Kreuz und dem ORF gegründet.
Die Leitung der Katastrophenhilfe erfolgt sowohl in operativ-taktischer als auch in administrativer Hinsicht im Rahmen der Einsatzleitungen und Koordinationsausschüsse auf Bezirks- und Landesebene. In überregionalen und grenzüberschreitenden Katastrophenfällen erfolgt die Koordination von Verwaltungsmaßnahmen im Rahmen des Staatlichen Krisen- und Katastrophenschutzmanagements beim Bundesministerium für Inneres, in Einzelfällen auch durch das Bundeskanzleramt. Wenn Personen durch eine Katastrophe im Ausland betroffen sind, so zählt die Hilfe zu den Aufgaben des Außenministeriums.
Die Bundeswarnzentrale im Bundesministerium für Inneres dient als permanente Ansprechstelle. Die Zusammenarbeit mit den Bundesländern und der erforderliche Informationsaustausch erfolgt über Landeswarnzentralen.
Mit Beschluss der Bundesregierung vom 20. Januar 2004 wurde ein Koordinationsausschuss für das Staatliche Krisen- und Katastrophenschutzmanagement eingerichtet, der alle Bundesministerien und Bundesländer sowie Einsatzorganisationen und Medien unter dem Vorsitz des Generaldirektors für die öffentliche Sicherheit einschließt.
Österreich verfügt damit über ein flächendeckendes System des vorbeugenden und abwehrenden Katastrophenschutzes (Staatliche Krisen- und Katastrophenschutzmanagement, SKKM). Darüber hinaus ist Österreich in die internationalen Netzwerke der grenzüberschreitenden Katastrophenhilfe der EU, NATO/PfP und der Vereinten Nationen eingebunden und hat mit zahlreichen Staaten bilaterale Vereinbarungen für die gegenseitige Hilfe in Katastrophenfällen abgeschlossen, auf die im Bedarfsfall zurückgegriffen werden kann[38]. Ein Beispiel dafür bietet die mittlerweile aufgelöste Einheit CRAFT Austria, eine international einsetzbaren Truppe aus Feuerwehr, Polizei und Johanniter-Unfallhilfe.

[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Zivilschutz (Schweiz)
[Bearbeiten | Quelltext bearbeiten]
In den USA ist zentral die Federal Emergency Management Agency (FEMA) zuständig. Daneben sind verschiedene Behörden mit unterschiedlichen Aspekten des Katastrophenschutzes befasst, beispielsweise erarbeitet der United States Geological Survey Katastrophenszenarien wie das Arkstorm-Szenario.[39] Mit Seuchen befassen sich die Centers for Disease Control and Prevention (CDCs)[40] und mit durch Pipelines verursachte Umweltkatastrophen befasst sich die Pipeline and Hazardous Materials Safety Administration (PHMSA), die hierzu sogar ein Fusion Center, das National Hazardous Materials Fusion Center (IAFC Hazmat Center) betreibt.[41]

[Bearbeiten | Quelltext bearbeiten]
Fast alle Staaten haben gegen Katastrophen für den Katastrophenschutz zuständige Organisationen, zumindest rudimentär. Arme Länder oder Länder mit instabilen politischen Verhältnissen sind beim Eintritt einer Katastrophe oft auf Hilfe durch andere Staaten (von Deutschland aus zum Beispiel durch die Bundesanstalt Technisches Hilfswerk) sowie internationale nichtstaatliche Institutionen und Organisationen wie beispielsweise die Internationale Rotkreuz- und Rothalbmond-Bewegung angewiesen.

[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: UN-Nothilfekoordinator und International Civil Defence Organisation
[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: EU-Zivilschutz-Mechanismus
Die EU verfügt seit Lissabon mit Art. 196 AEUV (Förderung der Zusammenarbeit der Mitgliedstaaten) über eine neue Zuständigkeitsbestimmung im Katastrophenschutz:

Unterstützung und Ergänzung der Tätigkeit auf nationaler, regionaler und kommunaler Ebene mit Hinblick auf
Risikoprävention
Ausbildung
Einsätze
Förderung einer schnellen und effizienten Zusammenarbeit zwischen den einzelnen Stellen
Verbesserung der Kohärenz der Maßnahmen auf internationaler Ebene
Diese Politik fällt unter Art. 6 lit. f) AEUV (Unterstützungs-, Koordinierungs- und Ergänzungskompetenz). Wegen dieser Kompetenzbegrenzung sowie des Subsidiaritätsprinzips kommt die Ausübung dieser Politik allein dann in Betracht, wenn die Mitgliedstaaten allein mit der katastrophalen Lage überfordert sind. Die Kompetenzgrenze der Union ist zudem überschritten, wenn auf Art. 196 AEUV eine Notfallabwehrkapazität gestützt wird, die von den Entscheidungen der (souveränen) Mitgliedstaaten unabhängig ist. Die EU darf keinen eigenständigen Katastrophenschutz betreiben oder die Mitgliedstaaten aus ihrer Rolle als Verantwortliche für den Katastrophenschutz herausdrängen.

Siehe auch: Beobachtungs- und Informationszentrum

Martin Diebel: Atomkrieg und andere Katastrophen. Zivil- und Katastrophenschutz in der Bundesrepublik und Großbritannien nach 1945. Schöningh 2017, ISBN 978-3-506-78745-3.
Volker Hielscher, Lukas Nock: Perspektiven des Ehrenamtes im Zivil- und Katastrophenschutz. Metaanalyse und Handlungsempfehlungen. Saarbrücken, November 2014, ISSN   (PDF; 1 MB)
Jürgen Bittger: Großunfälle und Katastrophen. Stuttgart 1996, ISBN 3-7945-1712-1.
Bundesamt für Bevölkerungsschutz und Katastrophenhilfe (Hrsg.): Bevölkerungsschutz, Ausgabe 4/2008 mit Fokus zur Geschichte des Katastrophen- und Zivilschutzes in Deutschland.
Wolf R. Dombrowsky, Katastrophe und Katastrophenschutz, Wiesbaden: Deutscher Universitäts-Verlag 1989.
Wolf R. Dombrowsky, Willi Streitz, Jörg Horenzcuk: Erstellung eines Schutzdatenatlasses, „Zivilschutzforschung. Neue Folge“, Bd. 51, Schriftenreihe der Schutzkommission beim Bundesminister des Innern, Bundesverwaltungsamt, Bonn 2003.
Sven Fuchs, Lamiss Khakzadeh, Karl Weber (Hrsg.): Recht im Naturgefahrenmanagement. Studien-Verlag, Innsbruck 2006, ISBN 3-7065-4326-5.
Andreas Linhardt: Feuerwehr im Luftschutz 1926–1945. Braunschweig 2002, ISBN 3-8311-3738-2.
Schutzkommission beim Bundesminister des Innern: Dritter Gefahrenbericht. Bericht über mögliche Gefahren für die Bevölkerung bei Großkatastrophen und im Verteidigungsfall, Bundesamt für Bevölkerungsschutz und Katastrophenhilfe, Bonn 2006, ISSN .


Portal: Katastrophenschutz – Übersicht zu Wikipedia-Inhalten zum Thema Katastrophenschutz

 im Katalog der Deutschen Nationalbibliothek
Deutschland: 
Deutschland: 
Deutschland:  des Kieler Instituts für Krisenforschung mit Fallstudien, Fachbeiträgen, Tagungshinweisen
Österreich: 



Ein Gletscher (in Tirol und Süddeutschland auch Ferner, in Österreich auch Kees, in der Schweiz auch Firn genannt)[1][2][3] ist eine aus Schnee hervorgegangene Eismasse mit einem klar definierten Einzugsgebiet, die sich aufgrund von Hangneigung, Struktur des Eises, Temperatur und der aus der Masse des Eises und den anderen Faktoren hervorgehenden Schubspannung eigenständig bewegt.
Bei der Betrachtung der geomorphologischen Höhenstufen der Hochgebirge wird die Gletscherregion als glaziale Höhenstufe bezeichnet.[4]
Gletscher speichern derzeit 70 % des Süßwassers auf der Erde und sind nach den Ozeanen die größten Wasserspeicher. Sie bedecken in den Polargebieten große Teile der Landflächen. Gletscher sind bedeutende Wasserzulieferer für viele Flusssysteme und haben entscheidenden Einfluss auf das Weltklima. Seit Mitte des 19. Jahrhunderts ist nahezu weltweit ein deutlicher Rückgang der Gletscher zu beobachten (siehe Gletscherschwund seit 1850).
Gletscher sind auch bedeutende Landschaftsformer, insbesondere waren sie dies in den Kaltzeiten (Eiszeitalter) des Pleistozäns, in welchen auf der Nordhalbkugel Inlandeismassen (Fennoskandischer Eisschild) bis in das nördliche Mitteleuropa hineinreichten. Die Gletscher der Alpen und des Schwarzwalds (wie etwa der Feldberg-Gletscher) die in den Kaltzeiten sogar bis ins Alpenvorland vorstoßen konnten, formten gewaltige Trogtäler und prägen die Landschaft bis heute.
Unter Wissenschaftlern gibt es kein allgemein anerkanntes Kriterium, ab welcher Dimension von einem Gletscher gesprochen werden kann.[5] Jedoch muss nach den Maßstäben des United States Geological Survey einerseits die Dicke mindestens 100 ft (30,48 m) betragen (damit die Masse ausreichend für die Eigenbewegung ist),[6] andererseits die Oberfläche mindestens 0,1 km² messen.[5][6]



Das ursprünglich schweizerdeutsche Wort Gletscher entwickelte sich aus romanischen Dialektformen (vgl. heutiges glačer im Wallis[7]), die von vulgärlateinisch *glaciārium abstammen, welches von spätlateinisch glacia und lateinisch glaciēs („Eis“) abstammt.[8]
In den Ostalpen ist vom Oberinntal bis zum Zillertal (Zamser Grund) die Bezeichnung Ferner (vgl. Firn) üblich; damit wurde also zunächst der Schnee von fern(d), d. h. aus dem letzten Jahr bezeichnet. Östlich des Zillertals (Venedigergruppe, Hohe Tauern) verwendet man die Bezeichnung Kees, die wahrscheinlich aus einer vorindogermanischen Sprache stammt.[9]


Gletscher benötigen eine Reihe von entscheidenden Faktoren zu ihrer Entstehung. So ist eine langfristig ausreichend niedrige Temperatur nötig, damit es zu Schneefall kommt. Die Höhenlinie, ab der im langjährigen Mittel mehr Schnee fällt als dort abtauen kann, ist die klimatische Schneegrenze. Diese kann bedingt durch Beschattung oder exponierte Sonnenlagen (z. B. Südhang in einem Gebirge der Nordhalbkugel) lokal um mehrere hundert Meter vom eigentlichen Mittelwert der Region abweichen. Man spricht in diesem Fall von der orografischen Schneegrenze. Nur oberhalb dieser Grenzlinien kann bei geeignetem Relief auf Dauer so viel Schnee fallen, dass dieser eine Metamorphose durchlaufen kann.

[Bearbeiten | Quelltext bearbeiten]
Der Prozess der Ansammlung von Schneemassen wird Akkumulation genannt und infolgedessen der Entstehungsbereich eines Gletschers mit Akkumulationsgebiet (Nährgebiet) bezeichnet. Reicht die Schneemächtigkeit aus, dass durch die Auflast der oberen die tieferen Schichten zusammengepresst werden, beginnt die Metamorphose des Schnees hin zu Gletschereis. Dabei wird durch den in der Tiefe immer höher werdenden Druck die im Neuschnee noch 90 % des Volumens ausmachende, in Hohlräumen eingeschlossene Luft herausgepresst. In Gletschereis kann somit der Luftanteil bis auf etwa 2 % sinken. Eis mit einem so geringen Luftanteil besitzt meist eine bläuliche, seltener auch leicht grünliche Farbe.
Höhere Temperaturen beeinflussen die Metamorphose positiv auf zweierlei Wegen. Zum einen bilden sich in wärmeren (temperierten) Gletschern in der Regel kleinere Eiskristalle, wodurch hier und auch in den Vorstufen des Eises wie Firn und granularem Eis (in mancher Literatur auch Firneis genannt) eine Bewegung möglich ist, bei der leichter Luft freigesetzt werden kann. Darüber hinaus kann auch oberflächliches Material aufschmelzen und erneut gefrieren, ohne den Gletscher zu verlassen. So kann zumindest in kleineren Mengen sogar im Tageszyklus eine Verwandlung von Schnee in Eis stattfinden, ohne dass die bei der Druckmetamorphose üblichen Zwischenstufen durchlaufen werden.
Es bedarf 10 m Neuschnee bei einer Dichte von 0,1 g/cm3, um 1,10 m Gletschereis mit einer Dichte von 0,9 g/cm3 zu produzieren. Dies entspricht wiederum einer Wassersäule von 1 m.[10]

[Bearbeiten | Quelltext bearbeiten]
Die Gleichgewichtslinie ist eine Höhengrenze der Glaziologie. Unterhalb dieser Linie im sogenannten Zehrgebiet (Ablationsgebiet) des Gletschers ist der Massenverlust durch Ablation größer als der Zuwachs an Gletschereis. Im oberhalb liegenden Nährgebiet (Akkumulationsgebiet) wird mehr Gletschereis gebildet als durch Ablation verloren geht. In vielen Gebieten entspricht die Gleichgewichtslinie größtenteils der Firngrenze.[11] Die Gleichgewichtslinie wird im Fachjargon auch als Equilibrium Line Altitude (ELA) bezeichnet.

[Bearbeiten | Quelltext bearbeiten]
Schmelzwasser kann den Gletscher oberflächlich (supraglazial) oder an seinem Grund (subglazial) verlassen und wird so dem Massenhaushalt des Gletschers entzogen. Subglaziale Schmelzwasser treten meist aus einer als Gletschertor bezeichneten Öffnung in der Gletscherzunge aus, die sich im Zehrgebiet befindet, dem Gegenstück zum Nährgebiet über der Gleichgewichtslinie. Ist ein solcher Abfluss versperrt bzw. tritt nicht auf, entsteht ein unter dem Eis befindlicher, verborgener Gletschersee, die sog. Wassertasche.
Insbesondere polare Gletscher verlieren auch durch den Prozess der Sublimation an Masse, wobei Wasser direkt vom festen in den gasförmigen Aggregatzustand übergeht.
Manche Gletscher werden darüber hinaus durch das Relief zu Massenverlust gezwungen. Dies ist der Fall, wenn beispielsweise bei einem Gebirgsgletscher Eis über eine steile Felskante stürzt oder eine Inlandeismasse bis an eine Küste heranwächst und sich dort kein Schelfeis ausbilden kann, sondern der Gletscher hier zum Abkalben gezwungen ist. Dabei brechen Teile des Eises heraus und können daraufhin als Eisberge über das Meer treiben. Tafeleisberge entstehen, wenn an der Front eines Schelfeises Teile kalben. Durch die Verdrängung des Wassers können kalbende Gletscher gefährliche Flutwellen auslösen.


→ Hauptartikel: Gletscherdynamik


Nur sich bewegende Eismassen werden als Gletscher bezeichnet. Dies schließt auf Wasser treibendes Eis wie Eisberge oder Packeis aus. Generell sind zwei grundlegende Formen der Bewegung von Gletschern zu unterscheiden:

[Bearbeiten | Quelltext bearbeiten]
Üben die höher liegenden Teile eines Gletschers eine ausreichende Schubkraft auf die tiefer und damit vor ihnen liegenden Gletscherabschnitte aus, so wird dieser Druck durch eine Fließbewegung des Eises abgebaut. Auf molekularer Ebene besteht Eis aus übereinanderliegenden Molekülschichten mit relativ schwachen Bindungskräften zwischen den einzelnen Schichten. Wenn die Spannung, die auf die darüberliegende Schicht einwirkt, die Bindungskräfte zwischen den Schichten übersteigt, bewegt sich die obere schneller als die darunterliegende Schicht. Dabei verschiebt sich die gesamte Eismasse also nicht gleichmäßig, sondern abhängig von den Möglichkeiten der Eiskristalle, sich innerhalb des Gesamtgefüges zu bewegen. An der Gletschersohle sowie den Flanken eines Gletschers kann das Eis oft am anstehenden Gestein festfrieren, wodurch hier keine Bewegung möglich ist. Daher ist die Fließgeschwindigkeit eines Gletschers an der Oberfläche höher als an der Sohle und an den Seiten niedriger als in der Mitte.

[Bearbeiten | Quelltext bearbeiten]
Basales Gleiten tritt vor allem bei temperierten Gletschern mit Basis-Temperaturen knapp unter 0 °C auf, da an der Basis ein Film von flüssigem Wasser existiert, auf dem das Eis gleitet (siehe auch Wandernde Felsen). Da der Schmelzpunkt von Eis durch Druckzunahme pro 100 m auflastendem Eis um etwa 0,07 °C sinkt (Druckaufschmelzung), darf ein temperierter Gletscher von 500 m Dicke an seiner Basis minimal eine Temperatur von −0,35 °C haben. Einige Gletscher sind mit −1,9 °C bis −32 °C aber deutlich kälter als der Druckschmelzpunkt, sodass hier nur die Reibungswärme für die Produktion von flüssigen Wasser in Frage kommt.[12]

[Bearbeiten | Quelltext bearbeiten]
Reliefbedingt können in einem Gletscher verschiedene Oberflächenformen wie Quer- und Längsspalten, Séracs oder Ogiven entstehen, welche dadurch auch als Indikatoren für die Form des Untergrunds und das Fließverhalten eines Gletschers dienen.
Querspalten entstehen hierbei durch eine Längsdehnung der Gletscheroberfläche. Dies geschieht, wenn der vordere und damit tiefere Teil eines Gletschers schneller fließen kann als der dahinter- und höherliegende. Dieser Prozess wird Extending Flow genannt. Nicht immer entstehen bei Extending Flow auch Querspalten, jedoch sind umgekehrt die Querspalten stets ein klares Anzeichen für Extending Flow. Längsspalten entstehen dagegen durch eine Querdehnung der Gletscheroberfläche. Dies ist häufig bei Vorlandgletschern zu beobachten, welche aus einem engeren Tal in eine weite Ebene austreten, wo sich das Eis weit ausdehnen kann.



Ogiven sind nach dem gleichnamigen gotischen Stilelement benannte regelmäßige Hell-Dunkel-Muster quer zur Fließrichtung. Diese Streifenmuster bilden sich unterhalb mancher Eisbrüche aus, wenn die Durchlaufzeit des Eises im Bruch in etwa mit einem ungeraden Vielfachen eines halben Jahres übereinstimmt.

Jahreszeitlich bedingte Massenbilanzschwankungen im Eisbruch, ggf. in Verbindung mit Compressive Flow an dessen unterem Ende (höherliegende Teile eines Gletschers bewegen sich schneller als tieferliegende), führen zu sogenannten Wave Ogives (Wellen-Ogiven), die sich in der Folge als Stauchwülste durch den abfließenden Gletscher ziehen.
Band Ogives (Streifen-Ogiven), auch Forbes-Bänder genannt, gehen auf jahreszeitlich unterschiedlich intensiven Staub- und Polleneintrag zurück. Sie ziehen sich in der Folge als regelmäßige Streifenmuster durch eine relativ glatte Gletscheroberfläche. Das Eis der dunklen Bänder hat im Sommer den Bruch durchlaufen, wobei Schmelzvorgänge die Ansammlung der dunklen Partikel auf der Oberfläche des Gletschers begünstigen. Die hellen Streifen stammen von Eis, das vornehmlich im Winter den Bruch passiert hat.
Ogiven erhalten ihre charakteristische Bogenform dadurch, dass die Fließgeschwindigkeit in der Mitte des Gletschers höher als an seinen Rändern ist.[13]
Séracs sind Eistürme, die durch das Zusammenwirken von Längs- und Querdehnung entstehen und daher meist zusammen mit oder nahe bei Längs- und Querspalten auftreten.

[Bearbeiten | Quelltext bearbeiten]
 Nördliche Abbruchkante der Gletscherzunge des Perito-Moreno-Gletschers im Lago Argentino, dem größten See Argentiniens
Ein Eissturz ist der Abbruch von größeren Eisstücken eines Gletschers. Das abgebrochene Eis wird auch Sturzeis genannt.[14][15]





[Bearbeiten | Quelltext bearbeiten]
Auslassgletscher
bilden sich am Rand von Eiskappen oder Eisschilden, wenn das Eis durch relativ schmale Auslässe fließen muss, die vom Relief vorgegeben sind. Meist haben sie die Form von Talgletschern, manchmal auch von Vorlandgletschern.
Eisstrom
Bereiche von Eisschilden mit erheblich höherer Fließgeschwindigkeit als das umgebende Eis. Große Teile des Abflusses der Eisschilde erfolgt über die Eisströme.
Eisstromnetz
Wachsen Talgletscher so stark an, dass das Gletschereis die Talscheiden überfließen kann, spricht man von einem Eisstromnetz – es besteht kein direkter Zusammenhang zu obigem Begriff Eisstrom. Die Bewegung des Eises wird aber dennoch vor allem vom vorhandenen Relief gesteuert. Die Gletscher der Alpen erzeugten auf dem Höhepunkt der letzten Vereisung ein solches Netz. Heute findet man solche Eisstromnetze noch zum Beispiel in Franz-Josef-Land (Nordpolarmeer), Spitzbergen oder Alaska.
Hanggletscher
Meist vergleichsweise kleine Eisansammlung an einem Berghang, die ohne deutliche Zungenbildung enden oder über eine Wandstufe abbrechen („Eisbalkon“). Ein Extremfall ist der Hängegletscher.
Hängegletscher
sind Gletscher, die an steilen Felswänden mit über 40° Neigung „hängen“. Oft haben sie kein Zehrgebiet, da die Zungen durch das eigene Gewicht abbrechen oder in einem tiefergelegenen Hang- oder Talgletscher enden. Ihr Nährgebiet wird meist von großen Firnrinnen, Eiskappen oder Hanggletschern gebildet.
Inlandeis oder Eisschild
Die größten Gletscherflächen überhaupt. Eismassen, die so mächtig werden, dass sie das Relief fast vollständig überdecken und sich auch weitgehend unabhängig von ihm bewegen (z. B. in Grönland oder der Antarktis). Einige Wissenschaftler unterscheiden jedoch die großen Inlandeismassen von den kleineren Gletschern und bezeichnen sie deshalb nicht als Gletscher.
 Kargletscher

Eismassen geringer Größe, die sich sonnengeschützt in einer Mulde, dem sogenannten Kar, befinden. Kargletscher besitzen keine deutlich ausgebildete Gletscherzunge. Oft sind sie Hängegletscher. Durch die geschützte Mulde können sie tiefer auftreten als Talgletscher.
 Lawinengletscher oder Lawinenkesselgletscher
Gletscher, die unterhalb der Schneegrenze liegen und daher kein eigenes Nährgebiet haben. Sie liegen meist im Schutz großer sonnenabgewandter Bergwände und werden von abgelagertem Lawinenschnee gespeist. Daher können sie noch sehr weit unterhalb der Schneegrenze auftreten. Obwohl sie nicht sehr groß werden, zeigen sie je nach Verhältnissen alle typischen Gletschermerkmale wie Eisbewegung und Gletscherspalten. Beispiel: Höllentalferner.
Piedmontgletscher oder Vorlandgletscher
Eismassen, die sich aus den Tälern des Gebirges vorschieben, breiten sich ringförmig beziehungsweise fächerförmig im vorgelagerten Flachland aus. Der größte Gletscher dieser Art ist der Malaspinagletscher in Alaska.
Plateaugletscher oder Eiskappe
Wie Inlandeis eine größere, dem Relief übergeordnete Vergletscherung, aber weniger mächtig (Beispiele: der Vatnajökull auf Island, oder der Jostedalsbreen in Skandinavien)
 Talgletscher
Eismassen, die ein deutlich begrenztes Einzugsgebiet besitzen und sich unter dem Einfluss der Schwerkraft in einem Tal abwärts bewegen. Klassisch dafür sind die großen Gebirgsgletscher. Sowohl die Menge des Schmelzwassers als auch die Fließgeschwindigkeit des Gletschers variieren im Jahresverlauf mit einem Maximum im Sommer. Obwohl Talgletscher nur etwa ein Prozent der vergletscherten Gebiete der Erde ausmachen, sind sie wegen ihres imposanten Aussehens der bekannteste Gletschertyp (Beispiel: Aletschgletscher). Sie können selbst außerhalb der Polargebiete gewaltige Ausmaße annehmen: Die größten Gletscher dieser Art sind der Fedtschenko-Gletscher (78 km) im Pamir, der Kahiltnagletscher (77 km) am Denali (Mount McKinley) (Alaska) und der Baltoro-Gletscher (57 km, mit seinen Zuflüssen Godwin-Austen- und Gasherbrum-Gletscher etwa 78 km) im Karakorum.





Von links nach rechts: Hanggletscher, Kargletscher, Talgletscher, Vorlandgletscher, Schelfeis.
Ein Blockgletscher ist trotz seines Namens kein Gletscher, da er nicht aus Schnee hervorgeht, sondern aus mit Eis vermischtem Schutt und Felsblöcken. Er kriecht sehr langsam talwärts, was seiner völlig steinigen Oberfläche eine meist wellenförmige Struktur verleiht, und ist eine Erscheinung des Permafrostes (Dauerfrostboden).

[Bearbeiten | Quelltext bearbeiten]
temperierter Gletscher
Gletscher, deren Eistemperatur sich überall am Druckschmelzpunkt befindet
kalter Gletscher
Gletscher, deren Eistemperatur sich deutlich unter dem Druckschmelzpunkt befindet
polythermischer Gletscher
Gletscher, die sowohl Bereiche mit temperiertem als auch kaltem Eis aufweisen


→ Hauptartikel: Glazialmorphologie
Gletscher sind bedeutende Landschaftsformer, die in ihrer Wirksamkeit den Wind und das fließende Wasser deutlich übertreffen. Insbesondere während des Eiszeitalters, als große Teile der Nordhemisphäre vergletschert waren, wurden sehr große Gebiete durch sie umgeformt. Dies betrifft etwa den Alpenraum und andere Hochgebirge sowie Nordeuropa und das nördliche Mitteleuropa, große Gebiete in Nordamerika sowie im nördlichen Asien. Die Wirkung der Gletscher beruht vor allem auf dem von ihnen mitgeführten Moränenmaterial. Man unterscheidet Formen der glazialen Abtragung (Erosion) von Formen und Sedimenten in Aufschüttungsgebieten.

[Bearbeiten | Quelltext bearbeiten]

[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Gletscherschliff
Im Gletschereis mitgeführtes Gesteinsmaterial verschiedener Korngrößen – von feinem Ton bis zu mehrere Meter messenden Findlingen – kann im Gesteinsuntergrund deutliche Spuren hinterlassen. Feinkörniges Material bewirkt dabei in der Regel einen Schliff vergleichbar mit der Wirkung von Schleifpapier, während größere Partikel deutliche Kratzspuren und Rillen im Fels hinterlassen können, unterstützt durch den starken Druck und die Bewegungsgewalt des Gletschers. Diese Rillen werden Gletscherschrammen genannt.
Diese Formen bezeugen eine Bewegung des Gletschereises über den Untergrund und sind daher ein Beweis dafür, dass der einstige Gletscher sich hier durch basales Fließen bewegen konnte und nicht am Untergrund festgefroren war.

[Bearbeiten | Quelltext bearbeiten]

Gletscher können ihren Untergrund stark formen. Ragt aus dem felsigen Untergrund ein Hindernis im Pfad eines Gletschers, so entsteht eine charakteristische Form. An der Seite des Felsens, die der Fließrichtung des Eises zugewandt ist (Luv), erhöht sich der Druck im Eis, wodurch hier leichter ein Schmelzwasserfilm entstehen kann, auf welchem der Gletscher gleitend über den Felsen fließen kann. Das vom Gletscher mitgeführte Material führt dabei zu einer Erosion des Felsens. Die Luv-Seite erhält so eine stromlinienartige Form ähnlich wie bei einer Sanddüne. Dieser Prozess wird Detersion genannt. Auf der abgewandten Seite (Lee) ist der Druck wiederum deutlich geringer, wodurch sich hier kein Schmelzwasserfilm bilden kann. Stattdessen friert das Eis am Felsen fest und bei der Weiterbewegung des Gletschers wird das Eis mitgeführt und dabei werden Teile aus dem Felsen herausgebrochen. Aus der Detersion an der Luv- und der Detraktion an der Lee-Seite entsteht ein so genannter Rundhöcker. Solche können heute als Hinterlassenschaften der pleistozänen Vereisung in den Alpen gefunden werden.

[Bearbeiten | Quelltext bearbeiten]
Durch Flüsse entstehen in Gebirgen zumeist tief eingeschnittene V-förmige Kerbtäler. Im Gegensatz dazu sind Gletscher zu einer sehr viel stärkeren Seitenerosion fähig, wodurch glazial geformte Täler eine markante U-Form besitzen und als Trogtäler bezeichnet werden.
Dabei wurde auch oft vorglaziales Material in den Urtälern von den Gletschern ausgeschürft und mitgeführt. Dadurch wurden frühere Schichten fluvialer Sedimente durch glazialen Geschiebemergel ersetzt. Deutlich sichtbar ist oft an den Talhängen die Schliffgrenze, welche markiert, bis zu welcher Mächtigkeit einst ein Gletscher das Tal ausgefüllt hatte.


[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Nunatak
In Eisstromnetzen, wie man sie heute beispielsweise in Alaska noch vorfindet oder wie sie im Pleistozän in den Alpen ausgeprägt waren, vermögen Gletscher auch Talscheiden zu überfließen und diese daher auch erosiv zu formen.
Ragt ein Berg aus einem Eisstromnetz oder einer Inlandvereisung hinaus, bezeichnet man diesen als Nunatak (Plural: Nunataker oder Nunatakker). Die nicht durch Gletschereis geformte Spitze eines Nunatak wird auch als Horn bezeichnet, welches sich durch seine schroffen Kanten deutlich vom stärker gerundeten niedrigeren Bereich des Berges unterscheidet.

[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Fjell
Als Landschaftsform, in der auch Bergspitzen einst von Eis überformt wurden und heute nur noch als gerundete Kuppen vorhanden sind, ist das skandinavische Fjell sehr bezeichnend für die formende Gewalt der einst auf Nordeuropa auflastenden Eismassen.

[Bearbeiten | Quelltext bearbeiten]
[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Glaziale Serie


Moränen: Als Moräne bezeichnet man die Gesamtheit des vom Gletscher transportierten Materials. Da Gletscher feste Körper sind, können sie alle Korngrößenklassen, vom Ton über Sand bis hin zu gröbsten Blöcken, aufnehmen, transportieren und wieder ablagern. Je nach der Lage zum Gletscher bezeichnet man sie als Ober-, Seiten-, Mittel-, Innen-, Unter- oder Endmoräne. Der Begriff „Moräne“ bezieht sich mittlerweile eher auf die entsprechenden Landschaftsformen und nicht mehr auf das eigentliche Material, welches heute als Geschiebemergel bezeichnet wird.
Ablagerungsformen: Bei zurückgetauten Gebirgsgletschern sind die Moränen die am weitesten verbreiteten Ablagerungen, die leicht mit dem betreffenden Gletscher (wenn er noch vorhanden ist) in Verbindung zu bringen sind. Im nördlichen Mitteleuropa und im Alpenvorland haben die Gletscher als typische Formengesellschaft die Glaziale Serie mit den Elementen Grundmoräne, Endmoräne, Sander und (nur in Norddeutschland) Urstromtal hinterlassen. Auch hier gibt es zahlreiche Kleinformen wie zum Beispiel Findlinge, Drumlins, glaziale Rinnen, Oser (Einzahl Os) und Kames.

Kontinentalplatten befinden sich normalerweise in einem Zustand des Gleichgewichts zwischen der durch ihre Masse und die Gravitation bedingte Kraft und dem Auftrieb durch den Erdmantel. Dieses Gleichgewicht ist die Isostasie. Es kann jedoch dadurch gestört werden, dass sich auf eine Kontinentalplatte oder Teile davon große Mächtigkeiten einer Inlandvereisung anlagern. Durch das zusätzliche Gewicht wird die Erdkruste zu einer vertikalen Ausgleichsbewegung gezwungen, um wieder den Zustand der Isostasie zu erreichen.
Das Inlandeis über Skandinavien bewirkte ein deutliches Absinken dieses Gebiets in den Kaltzeiten. Nach dem Abschmelzen dieser Massen lag der Großteil Finnlands sogar unter dem Meeresspiegel. Seitdem hebt sich Nordeuropa auch wieder erneut als Ausgleichsbewegung. Die Hebungsraten erreichen hier bis zu 9 mm pro Jahr.


Durch das massive Binden von Wasser in Form von Eis auf Landflächen sank in den Kaltzeiten der Meeresspiegel und lag bis zu 150 Meter niedriger als heute. Dadurch fiel u. a. die heutige Nordsee trocken und bildete eine Landbrücke zwischen Europa und Britannien. Maas und Themse waren Nebenflüsse des Rheins.
Wenn die heute noch vorhandenen Eismassen abschmelzen würden, stiege der Meeresspiegel um weitere 60 bis 70 Meter. Mit einem durch Abschmelzen insbesondere von Eis der Antarktis bedingten Meeresspiegelanstieg wird im Rahmen der globalen Erwärmung gerechnet. Die Prognosen von Klimaexperten weichen dabei noch stark voneinander ab. Stark bedroht wären hiervon besonders sehr tief liegende Länder wie Bangladesch oder die Depressionsgebiete in den Niederlanden.



Obwohl Gletscher nur einen geringen Teil der Erdoberfläche ausmachen, ist weitgehend unumstritten, dass sie je nach Größe das lokale wie weltweite Klima stark beeinflussen. Dabei sind zwei physikalische Eigenschaften von Bedeutung:

Die Albedo der Erdoberfläche erhöht sich auf einem Gletscher bedeutend, solang er nicht ausgeapert ist: Eintreffendes Sonnenlicht wird zu nahezu 90 % zurückgespiegelt, wodurch es seinen wärmenden Energieeintrag in die Biosphäre nicht entfalten kann. Ein einmal ausgedehnter Gletscher hat daher die Tendenz, weiter abzukühlen und sich weiter zu vergrößern. Über ihm entsteht in Verbindung mit tiefen Temperaturen ein Hochdruckgebiet.
Gletscher wirken als Wasserspeicher. Es wird als Eis in den Gletschern gespeichert und so dem Wasserreservoir vorübergehend oder länger anhaltend entzogen. Mit dem Abschmelzen der Gletscher infolge der Erwärmung des Klimas kann es zu einem Anstieg des Meeresspiegels kommen. Dies gilt vor allem für die Eisschilde Grönlands und der Antarktis.
Die Wirkung des vermehrten Eintrags von Schmelzwasser auf die Meeresströmungen, insbesondere auf das Golfstromsystem, ist derzeit Gegenstand wissenschaftlicher Untersuchungen. Eine Theorie besagt, dass durch das Abschmelzen des arktischen Packeises bzw. des grönländischen Eisschildes der Salzgehalt im Nordpolarmeer sinkt, dadurch die Dichte des Meerwassers sich verringert und das Meerwasser bei Island nicht mehr absinkt. Dies kann den gesamten Golfstrom abbremsen und sogar zu einer Abkühlung des Klimas in Europa führen. Ob und inwieweit dieser Effekt stärker ist als die globale Erwärmung, ist nicht geklärt.
Umgekehrt werden Gletscher natürlich auch vom Klima beeinflusst und unterliegen starken Veränderungen. Diese sind nicht immer vorhersehbar. Der Zusammenhang zwischen Gletscherrückgang bzw. -vorstößen mit klimatischen Änderungen ist selten eindeutig, da ein Vorstoß aufgrund veränderter Fließgeschwindigkeiten durch stärkere Abschmelzung (besseres Gleiten auf dem Schmelzwasser) verursacht oder durch vermehrte Eisbildung in früheren Zeiten und langsames Tieferfließen verzögert werden kann. Aussagekräftiger sind daher die Massenbilanzen – d. h. die Differenzen zwischen neugebildetem und abgeschmolzenem Eis. Eine bedeutende Rolle spielen dabei auch die Niederschläge, für die aufgrund des Klimawandels eine Zunahme prognostiziert wird. Für einen Gletscher ist dann die Frage, ob diese erhöhte Niederschlagsmenge als Schnee oder als Regen herunter kommt. Schnee fördert die Eisbildung, Regen die Abschmelzung.
Auch Gebirgsgletscher unterliegen deutlichen Schwankungen. Bei plateauförmigen Gletschern wie z. B. dem Gepatschferner sind die Einzugsgebiete sehr flach. Bei nur geringem Anstieg der Durchschnittstemperatur und damit Erhöhung der Schneegrenze können große Akkumulationsflächen komplett unter die Schneegrenze fallen, was den Massehaushalt des Gletschers vollständig umwirft. Durch das Einsinken der Gletscheroberfläche (allein im Jahrhundertsommer 2003 am Gepatschferner durchschnittlich 5 m) reicht eine nachträgliche Abkühlung um denselben Betrag nicht mehr aus, um die Masseverluste auszugleichen, da die jetzt tiefer liegende Eisoberfläche weiterhin unterhalb der Schneegrenze bleibt.
Gletscher sind ein Indikator für langfristige Klimaänderungen.[17] Infolge der globalen Erwärmung kommt es seit Beginn der Industrialisierung weltweit zu einer massiven Gletscherschmelze.[18][19]



In den Gletschern weltweit sind ca. 70 % des weltweiten Süßwassers als Schnee oder Eis gespeichert; sie dienen etwa einem Drittel der Weltbevölkerung zur Wasserversorgung.[20]
In vielen Regionen stellen Gletscher damit (noch) eine sichere Wasserversorgung der Flüsse in der niederschlagsarmen Sommerzeit dar, da sie vor allem in dieser Zeit abschmelzen. Sie wirken darüber hinaus ausgleichend auf den Wasserstand, zum Beispiel beim Rhein.
In den wüstenhaften Gebirgsregionen des Pamir und Karakorum werden die Talböden und Berghänge fast ausschließlich mithilfe von Gletscherwasser bewässert und urbar gemacht. Auch in den trockenen Tälern der Alpen (Vinschgau, Wallis) gibt es ausgedehnte Netze von Kanälen, die teilweise heute noch genutzt werden. Eine Gefahr können die aus früheren Zeiten im Eis eingeschlossenen Umweltgifte sein.[21][22]



Auf Grund ihrer imposanten Erscheinung haben Gletscher heute eine enorme Bedeutung für den Tourismus in Gebirgen und in den hohen Breiten. Sie sind immer ein Anziehungspunkt, wenn sie verkehrstechnisch erschlossen sind. Dann eignen sie sich auch für den Wintersport als schneesicheres Gletscherskigebiet.
Bis zur allgemeinen Verbreitung von Kühlanlagen wurde an einigen Gletschern das Gletschereis abgebaut und exportiert.


Gletscher bilden einen Kryal genannten Lebensraum, in dem beispielsweise Biofilme, Schneealgen und Gletscherflöhe leben.
Der Taylor-Gletscher in der Antarktis bedeckt ein sehr seltenes mikrobielles Ökosystem. Die Blood Falls sind ein rotfarbener Ausfluss aus der Gletscherzunge.


[Bearbeiten | Quelltext bearbeiten]
Die Vorstellung, dass Gletscher die Landschaften dieser Erde entscheidend mitgeformt haben, ist noch nicht alt. Bis weit ins 19. Jahrhundert hinein hielten die meisten Gelehrten daran fest, dass die Sintflut die Gestalt der Erde geprägt habe und für Hinterlassenschaften wie Findlinge verantwortlich sei.

Alpen
Die Schweizerische Naturforschende Gesellschaft schrieb 1817 einen Preis für ein Thesenpapier zu dem Thema aus „Ist es wahr, dass unsere höheren Alpen seit einer Reihe von Jahren verwildern?“ und grenzte weiters ein, gesucht sei „eine unpartheyische Zusammenstellung mehrjähriger Beobachtungen über das teilweise Vorrücken und Zurücktreten der Gletscher in den Quertälern, über das Ansetzen und Verschwinden derselben auf den Höhen; Aufsuchung und Bestimmung der hier und da durch die vorgeschobenen Felstrümmer kenntlichen ehemaligen tiefern Grenzen verschiedener Gletscher“.
Ausgezeichnet wurde 1822 eine Arbeit von Ignaz Venetz, der wegen der Verteilung von Moränen und Findlingen schloss, dass einst weite Teile Europas vergletschert waren. Er fand jedoch nur Gehör bei Jean de Charpentier, der wiederum 1834 Venetz’ These in Luzern vortrug und es schaffte, Louis Agassiz davon zu überzeugen. Dem rednerisch begabten Agassiz, der in den folgenden Jahren intensive Studien zur Gletscherkunde betrieb, gelang es schließlich, die einstige Vergletscherung weiter Gebiete als allgemeine Lehrmeinung durchzusetzen.

Norddeutschland
In Norddeutschland wurden erste Belege für eine Vergletscherung aus Skandinavien bereits von 1820 bis 1840 gesammelt. Sie konnten die alte Lehrmeinung jedoch nicht zum Einsturz bringen. Erst ab 1875 setzte sich, bedingt durch die Erkenntnisse des schwedischen Geologen Otto Torell, der in Rüdersdorf bei Berlin eindeutige Gletscherschliffe nachwies, die Vereisungstheorie auch in Norddeutschland durch.

[Bearbeiten | Quelltext bearbeiten]
Im Nährgebiet eines Gletschers wandelt sich Schnee zu Gletschereis um, dabei werden organische und anorganische Gegenstände mit eingeschlossen. Mit der Zeit fließt das Eis talwärts und so bewegen sich die Gegenstände ins Zehrgebiet, wo das Gletschereis auftaut. Im Jahresverlauf ist im Monat September auf der Nordhalbkugel die Eisschmelze am höchsten, so dass zu dieser Zeit am wahrscheinlichsten archäologische Funde gemacht werden können. Neben diesem wandernden Eis gibt es vereinzelt Vertiefungen, wo sich Eis über längere Zeit stationär hält, das jetzt wegen der globalen Klimaerwärmung auftaut. Der Vorteil dieser stationären Eisflächen liegt darin, dass die beim Fließen eines Gletschers entstehenden Kräfte auf die eingeschlossenen Gegenstände entfallen. So fanden sich am Schneidejoch, einem Gebirgspass in den Berner Alpen, aus verschiedenen Zeitepochen Fundstücke von früheren Passgängern.[23] Die berühmte Gletschermumie Ötzi wiederum befand sich in einer rund 40 m langen, 2,5–3 m tiefen und 5–8 m breiten Felsmulde,[24] über die ein Gletscher sich über 5300 Jahre lang hinwegbewegte, ohne das Eis in der Mulde zu verändern.

[Bearbeiten | Quelltext bearbeiten]
Das Eis der Gletscher kann zur Erforschung der Klimageschichte der Erde dienen. Dazu werden Eisbohrkerne entnommen und analysiert. Für das Greenland Ice Core Project bohrte man bis in eine Tiefe von 3029 Metern, wo das Eis ein Alter von mehr als 200.000 Jahren erreicht, und im European Project for Ice Coring in Antarctica konnte sogar 900.000 Jahre altes Eis erbohrt werden.
Ein weiteres mit Gletschern in Verbindung stehendes Klimaarchiv ist Gletscherholz. Das sind Überreste von Bäumen, die vor Jahrhunderten im Eis eingeschlossen wurden und bei denen die Jahresringe ausgewertet werden können.[25]

[Bearbeiten | Quelltext bearbeiten]


Die von Gletschern ausgehenden Gefahren werden nach ihren Ursachen in folgende Kategorien eingeteilt:

Gefahren durch Längen- und Geometrieänderungen: Durch Geometrieänderungen können Bauwerke, die sich unmittelbar am Gletscherrand befinden, gefährdet sein. Nach Gletscherrückgang freigelegte Moränen und Felswände können instabil werden, so dass es zu Rutschungen und Hangabstürzen kommt.
Gefahren durch Gletscherhochwasser: Gletscherhochwasser sind meist nicht niederschlagsbedingt, sondern entstehen, wenn durch den Gletscher aufgestaute Seen oder in den Eismassen gespeicherte verborgene Wassertaschen sich plötzlich entleeren. Diese Ausbrüche verursachen oft verheerende Flutwellen, die zu großen Schäden im Tal führen. In Island nennt man diese Ausbrüche Gletscherlauf.
Gefahren durch Gletscher- und Eisstürze, Gletscherbruch: Bei Hängegletschern kommt es regelmäßig zu großen Eisabbrüchen. Dadurch ausgelöste Eislawinen oder Eisstürze können eine Gefahr für Siedlungen und Verkehrswege sein, und beim Auftreffen auf Wasserflächen durch den Verdrängungsdruck der Wassermassen gefährliche Flutwellen auslösen.
Gletscherspalten sind bis zu Dutzende Meter tiefe Risse im Eis und bergen beim Begehen der Gletscheroberfläche die Gefahr des Hineinstürzens und zusätzlich des darin Verklemmens. Heimtückisch ist, dass sie durch Schneeüberlagerung schwer erkennbar sein können und diese Schneebrücken bei Belastung mitunter einbrechen. Ein nicht aperer Gletscher sollte daher nicht allein, sondern nur in einer Seilschaft betreten werden, wobei die Abstände der Seilschaftsmitglieder ausreichend groß gewählt werden sollten, um auf den plötzlichen Sturz eines anderen reagieren zu können.
Durch das Abtauen von Gletscherdämmen, die Eisstauseen bilden, können Flutkatastrophen verursacht werden. Die größten bekannten Flutkatastrophen Europas[26], Asiens[27][28] und Amerikas[29] sind darauf zurückzuführen.
Durch Vulkanismus hervorgerufene subglaziale Eruptionen können, zusätzlich zu den Gefahren eines Vulkanausbruchs Gletscherlauf und Flutkatastrophen auslösen.



[Bearbeiten | Quelltext bearbeiten]
Zurzeit sind 15 Millionen Quadratkilometer der festen Erdoberfläche von Gletschereis bedeckt. Das entspricht etwa 10 % aller Landflächen. Während der letzten Kaltzeit waren es 32 % der Landoberfläche.

Größe

Der größte Gletscher der Erde (ohne Inlandeis) ist der Lambert-Gletscher (Antarktis).
Der größte außerpolare Gebirgsgletscher der Erde ist mit 4275 km² Fläche der Malaspina (Alaska).
Der längste außerpolare Talgletscher der Erde ist der Fedtschenko-Gletscher im Pamir in Tadschikistan mit 77 km Länge
Der flächenmäßig größte europäische Gletscher ist mit 8200 km² Fläche der Austfonna (Spitzbergen/Norwegen).
Ihm folgt mit 8100 km² Fläche der größte Plateaugletscher Islands, der Vatnajökull. Mit bis zu 900 m Dicke ist er vom Volumen der größte europäische Gletscher.
Der größte europäische Festlandgletscher ist mit ca. 500 km² Fläche der Jostedalsbreen (Norwegen).
Der größte und längste Alpen-Gletscher ist der Aletschgletscher (117,6 km² / 23,6 km lang; Schweiz).
Der größte der fünf Gletscher in Deutschland ist, Stand 2018, der Höllentalferner.[30]
Der größte Gletscher in Österreich ist die Pasterze am Großglockner.
Der größte und längste Gletscher im Kaukasus ist der Besengi bei der Besengi-Mauer in der Besengi-Region.
Der größte Gletscher in der tropischen Klimazone ist die Eiskappe des Coropuna in Peru. Bis in die 2010er Jahre galt die Quelccaya-Eiskappe als größter Tropengletscher, ihre Schmelzrate war aber noch höher als die am Coropuna, so dass sie nurmehr zweitgrößter ist.[31]
Der größte Gletscher Südamerikas ist das Campo de Hielo Sur in Argentinien und Chile.
Minimale Höhe der Gletscherzunge in den Alpen

Der Glacier des Bossons am Mont Blanc reichte bis auf etwa 1.400 m Höhe über dem Meeresspiegel hinunter (Stand 2008).[32]
Fließgeschwindigkeit

Alpen-Gletscher bewegen sich mit bis zu 150 m pro Jahr.
Himalaya-Gletscher fließen mit bis zu 1500 m im Jahr, also bis 4 m am Tag.
Die Auslassgletscher Grönlands bewegen sich bis zu 10 km pro Jahr bzw. bis zirka 30 m am Tag. Der Jakobshavn Isbræ an der grönländischen Westküste gilt als der Gletscher mit der dauerhaft größten Geschwindigkeit,[33] Surge-Gletscher können aber während der aktiven Phase noch erheblich schneller fließen und mehr als 100 m pro Tag zurücklegen.
Äquatornähe

Die äquatornächsten Gletscher befinden sich auf dem Vulkan Cayambe (Ecuador).
Der äquatornächste Gletscher, der sogar ins Meer kalbt, ist der Ventisquero San Rafael, ein Teil des Campo de Hielo Norte (Chile) nahe dem 47. südlichen Breitengrad (genau: 46,689° S, 73,848° W-46.689-73.848, entspricht auf der Nordhalbkugel etwa der Breitenlage von Bozen).

Exaration – Prozess der Gletschererosion
Glazialmorphologie – Aufbau der Gletscher
Gletschermilch – Mittelmoräne – Gletschermühle – Bergschrund – Randkluft – Toteis
Verschiedene Gletscher: Kategorie Gletscher – Liste Schweizer Gletscher – Gletscher Islands – Liste der norwegischen Gletscher
Künstlicher Gletscher
Umweltgeschichte
Neptunismus

Frank Ahnert: Einführung in die Geomorphologie. 3. Auflage. UTB, Stuttgart 2003, ISBN 3-8252-8103-5.
Reinhard Böhm: Gletscher im Klimawandel. ZAMG, Wien 2007, ISBN 978-3-200-01013-0 
Kurt Brunner: Gletscherdarstellungen in alten Karten der Alpen. In: Cartographica Helvetica, Heft 2/1990, ISSN , S. 9–19. doi:10.5169/seals-1132
Eidgenössische Technische Hochschule Zürich 1988 (Hrsg.) Schnee, Eis und Wasser Alpiner Gletscher: Tagung am 26. Jan. 1988 in Zürich: Festschrift Hans Röthlisberger zum 65. Geburtstag am 1. Feb. 1988. (Mitteilungen der Versuchsanstalt für Wasserbau, Hydrologie und Glaziologie an der Eidgenössischen Technischen Hochschule Zürich, Nr. 94, ZDB-ID )
Richard Finsterwalder: . In: Jahrbuch des Deutschen und Österreichischen Alpenvereins (Überbrückungsband der Alpenvereinszeitschrift 1943–1951). Schmitt, München 1951, S. 60–66. (Online bei ALO)
Andrea Fischer, Bernd Ritschel: Alpengletscher. Tyrolia, Innsbruck/Wien 2020, ISBN 978-3-7022-3846-9.
Dominik Jost, Max Maisch: Von der Eiszeit in die Heisszeit: eine Zeitreise zu den Gletschern. Zytglogge, Oberhofen 2006, ISBN 3-7296-0723-5.
Hanspeter Holzhauser:  In: Historisches Lexikon der Schweiz.
Friedrich Wilhelm, Erich Obst, Josef Schmithüsen: Lehrbuch der Allgemeinen Geographie. Band 3/3: Schneekunde und Gletscherkunde. De Gruyter, Berlin 1974, ISBN 3-11-004905-8.



 im Katalog der Deutschen Nationalbibliothek

Deutsches Zentrum für Luft- und Raumfahrt, Animation 6. Oktober 2016, 
 (Fotografien, wissenschaftliche Literaturliste, GeoDataZone 2010)



 (Früher/heute-Bilder von Simon Oberli)
Nytimes.com, James Brooke:  („Verlorene Welten in der kanadischen Gletscherschmelze“)
Albert Hafner,  (PDF; 6 MB)
sueddeutsche.de 23. November 2007:  (Zum Klimawandel in den Alpen)
 Große Gletscherkunde-Seite auf Deutsch und Englisch
Tages-Anzeiger 2. August 2017, Mathias Lutz, Marc Brupbacher: 
Vimeo.com,  mit Kryosphären-Experte Konrad Steffen (WSL/ETH)
Youtube.com: Dokumentation über Gletscher, , 






Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Katastrophe (Begriffsklärung) aufgeführt.




Dieser Artikel oder Absatz stellt die Situation in Deutschland dar. Bitte hilf uns dabei, die Situation in anderen Staaten zu schildern.


Eine Katastrophe (altgriechisch καταστροφή katastrophé „Umwendung“, aus κατά katá „herab-“, „nieder-“ und στρέφειν stréphein „wenden“) ist ein folgenschweres Unglücksereignis. Oft wird der veraltende Begriff Verheerung als synonym angesehen.



Das Wort bedeutet eigentlich Wendung und bezeichnet speziell den Wendepunkt der Handlung in der Tragödie,[1] d. h. den Punkt, an dem sich das Schicksal des Helden zum Glück oder Unglück entscheidet. Hieraus entwickelte sich die Verallgemeinerung des Begriffs als entscheidendes Ereignis im Leben eines Menschen oder eines Volkes, als unglückliches Naturereignis usw.[2][3]
Eine Katastrophe ist im Zivil-, Bevölkerungs- und Katastrophenschutz eine größere Gefährdungs- und Gefahrenlage oder ein Schadenereignis. Ersteres umfasst drohenden, letzteres eingetretenen Schaden.
Die „Wendung“ (Peripetie) „zum Guten oder zum Schlechten“ war im antiken griechischen Drama ein zwingend erforderlicher dramaturgischer Kunstgriff der Handlung, um die Protagonisten – und mit ihnen das Publikum – entweder durch neuerliche „Wendung zum Guten“ einer Katharsis (Läuterung) zuzuführen oder bei einer „Wendung zum Schlechten“ für Fehlverhalten der Verdammung anheimfallen zu lassen. Dadurch ist der Begriff bis heute sowohl ethisch besetzt und auch sozialromantisch verklärt, wie auch Gegenstand der Sensationslust.
Eine nüchterne Bestimmung des Begriffs bereitet daher gewisse Schwierigkeiten.
Eine fachliche Definition, die Kriterien zur Katastrophenfeststellung (Einstufung als Katastrophenzustand) gibt, lautet etwa:



„Katastrophen sind durch elementare oder technische Vorgänge oder von Menschen ausgelöste Ereignisse, die in großem Umfang das Leben oder die Gesundheit von Menschen, die Umwelt, das Eigentum oder die lebensnotwendige Versorgung der Bevölkerung gefährden oder schädigen.“


– Tiroler Katastrophenmanagementgesetz[4]
Eine andere Sichtweise zur Definition präzisiert den schwammigen „großen Umfang“ weiter durch das Verhältnis des Schadens zu den regionalen Hilfsmöglichkeiten:



„Katastrophen sind […] Großschadenereignisse, die […] von den für die Gefahrenabwehr zuständigen Behörden mit eigenen Kräften und Mitteln nicht angemessen bewältigt werden können.“


– Katastrophenschutzgesetz Berlin[5]
Das Bayerische Katastrophenschutzgesetz vom 31. Juli 1970 definierte im Art 1 BayKSG: „Katastrophe im Sinne dieses Gesetzes ist eine so erhebliche gemeine Gefahr oder Not oder ein so schwerer Unglücksfall, daß Hilfe und Schutz nur wirksam gewährt werden können, wenn die dazu berufenen Behörden, Dienststellen und Hilfsorganisatinen unter einheitlicher Leitung der Katastrophenschutzbehörden zusammenwirken.“
Solche Definitionen seitens des Gesetzgebers sind Basis der Anforderung weiterer Hilfsmaßnahmen, personeller und technischer Natur ebenso wie von Hilfsgeldzahlungen. In diesem Sinne beschreibt der Begriff, dass die lokalen Strukturen und Kräfte mit der Situation überfordert sind, und ist von der Größenordnung (der Geographie wie der Betroffenen) unabhängig, kann also eine einzelne Wohnstelle oder Gemeinde ebenso betreffen wie einen ganzen Landstrich oder einen Staat. Typischerweise wird die Katastrophe in den Grenzen einer Verwaltungseinheit festgestellt.


Katastrophe im engeren Sinn ist eine länger andauernde und meist großräumige Schadenlage, die mit der normalerweise vorgehaltenen Gefahrenabwehr (Feuerwehr, Rettungsdienst, Polizei) nicht angemessen bewältigt werden kann und die nur mit überregionaler (oder internationaler) Hilfe und zusätzlichen Ressourcen (Militär sowie nicht-organisierte Bevölkerungsteile) unter Kontrolle gebracht werden kann.
Typisch dabei ist, dass durch das Ereignis (wie etwa Erdbeben, Hochwasser, Waldbrandserie)

die Infrastruktur (Straßen, Brücken, Wasserversorgung, Energieversorgung) beeinträchtigt und teilweise zerstört ist und/oder
die örtlichen Hilfskräfte und Hilfsressourcen (wie Polizei, Feuerwehr, Krankenhäuser) selbst geschädigt sind.
Regelmäßig kommt es zum Ausfall der Telekommunikationssysteme; sowohl wegen Überlastung als auch technischer Funktionsunfähigkeit. Mobilfunkanlagen können wie Festnetze beschädigt werden, aber auch bei Stromausfall nach einiger Zeit (Batteriepufferung) versagen.
Können dagegen nach mehrstündiger Anlaufphase, großräumiger Nachbarschaftshilfe aus nicht betroffenen Bereichen und Alarmierung von Hintergrunddiensten (dienstfreien Schichten, Freiwilligen Feuerwehren, Hilfsorganisationen wie dem Roten Kreuz, deren Schnelleinsatzgruppen sowie in Deutschland dem THW, beispielsweise durch Ausrufung des Ausnahmezustands) die akuten Gefahren etwa binnen eines Tages im Wesentlichen beseitigt werden, so spricht man im engeren Sinn nur von einem „Massenunfall“, einem „Großschadenereignis“ beziehungsweise „Massenanfall von Verletzten der Stufe 1 oder 2“. Lokale Ereignisse werden in aller Regel nicht als Katastrophen eingestuft, weil zum einen das Schadenausmaß begrenzt bleibt, zum anderen aus der näheren Umgebung genügend freie Hilfskräfte herangeführt werden können.
Gemäß dieser Begrifflichkeit (nach DIN 13050, DIN 14011) war beispielsweise

das Oderhochwasser 1997 eine Katastrophe, auch wenn auf deutscher Seite keine Menschen zu Schaden kamen, weil die regionalen Kräfte zur Deichverteidigung und damit Gefahrenbeseitigung bei weitem nicht ausreichten. Nationale Unterstützung und massiver Einsatz der Bundeswehr wurde für das mehrwöchige Geschehen erforderlich; „normale“ Bürger befüllten Sandsäcke.
der ICE-Unfall von Eschede 1998 noch keine Katastrophe, weil innerhalb einiger Stunden die regionalen Feuerwehren, das THW sowie die Rettungsdienste die Verletzten befreien und in Krankenhäuser bringen konnten. „Regional“ meint hier: Osthälfte Niedersachsens einschließlich Hamburg. Der Einsatz einzelner Hubschrauber zur weiteren Fernverlegung fällt dabei unter Nachbarschaftshilfe zur bestmöglichen Wiederherstellung der Gesundheit.
Die Akutphase ist diejenige, in der Gefahren für Menschen (unversorgte Verletzungen, aber auch Hunger, Seuchen, Kälte) weiter bestehen, Feuer unkontrolliert brennen oder Hochwasser noch nicht zurücksinkt. Nicht mehr zur Katastrophenlage zählen dagegen Aufräumarbeiten, Genesung und Wiederaufbau bei behelfsmäßiger Unterbringung und Versorgung betroffener Menschen.
Interpol verwendet aus polizeilicher Sicht (mit einem Schwerpunkt auf Identifizierung betroffener Personen und Getöteter) folgende Definition für eine Katastrophe:



„Eine Katastrophe ist ein unerwartetes Ereignis, bei dem zahlreiche Menschen getötet oder verletzt werden. Die Ereignisse, die zu Katastrophen führen können, sind vielfältiger Natur. Denkbar sind somit Einsätze nach Verkehrsunfällen, Naturkatastrophen, technischen Unfällen (Brand, Explosionen), terroristischen Anschlägen und kriegerischen Ereignissen. Hierbei ist zwischen einer offenen und einer geschlossenen Katastrophenform zu unterscheiden.Eine „offene Katastrophe“ ist ein Großschadensereignis, bei dem eine Gruppe unbekannter Personen getötet wurde, über die es keine vorherigen Aufzeichnungen oder Zugehörigkeiten gibt. Bei diesen Ereignissen ist es schwierig, Angaben über die Zahl der Opfer zu erhalten.Eine „geschlossene Katastrophe“ ist ein Großschadensereignis, bei dem eine Gruppe von Personen getötet wurde, die einem festen Kollektiv (z. B. Flugzeugabsturz mit Passagierliste) angehört. Handelt es sich um eine geschlossene Katastrophe, sind die antemortalen Vergleichsdaten i. d. R. schneller zu erheben. Denkbar sind auch Mischformen (Absturz eines Flugzeuges in ein Wohngebiet).“


– Disaster Victim Identification – Handbuch Interpol 2009[6]

Eingetretene oder drohende Katastrophen, pragmatisch aufgezählt, sind unter anderem:

Gesellschaftliche Katastrophen; betreffend Völkerrechte, Menschenrechte, Religionsfreiheit, Krieg und Frieden, Rechte von ethnischen Minderheiten:
Völkermord, Massenmord, Pogrom, Versklavung, Vertreibung
Hungersnot
Zivilisationskollaps
Wirtschaftliche Katastrophen:
Weltwirtschaftskrise,
Finanzkrise ab 2007
Katastrophen technisch-biologisch-medizinischer Art:
Nukleare Katastrophen (A-Gefahren, atomare Gefahren)
Seuchen (B-Gefahren, biologische Gefahren, Epidemien, Pandemien)
Chemiekatastrophen (C-Gefahren)
Datennetzbezogene Katastrophen (D-Gefahren)
Elektromagnetisch ausgelöste Katastrophen (E-Gefahren)
Katastrophen durch Freisetzung von mechanischer oder thermischer Energie (F-Gefahren: Druck (Zusammenstöße), Orkane, Brand, Explosionen), wie zum Beispiel
Unfälle der Binnenschifffahrt,
Unfälle der Luftfahrt,
schwere Seeunfälle,
Unglücke im Bergbau,
schwere Unfälle im Schienenverkehr,
Stauanlagenunfälle
Brückeneinstürze
Brand- und Explosionsunglücke
Unfälle auf Bohr- und Förderplattformen
bedeutende Ölunfälle
Häufig unterscheidet man, abhängig von der Ursache, zwischen „Naturkatastrophen“ und „technischen Katastrophen“.

„Naturkatastrophen“ sind Naturereignisse, denen Menschen ausgesetzt sind und die zum Ersticken, Ertrinken, Verdursten, Verhungern, Erfrieren, Verbrennen und vergleichbaren ernsthaften körperlichen Beeinträchtigungen (z. B. Krankheiten, Verätzungen) führen (wie Meteoreinschläge, Vulkanausbrüche, Lawinen, Erd- und Seebeben, Hochwasser, Waldbrände u. a. m.) Naturkatastrophen bis hin zur Klimakatastrophe sind in ihren Auswirkungen meist auch sozial beziehungsweise kulturell beeinflusst (sogenannte Man Made Disasters – siehe Hungersnot): Wenn z. B. Menschen Vulkanabhänge nicht besiedelt hätten, wäre ein Ausbruch oft keine „Katastrophe“.
„Technische Katastrophen“ haben als Auslöser ein Versagen (dazu gehört auch Fehlbedienung) einer technischen Einrichtung. Diejenigen „technischen Katastrophen“, die eine verheerende ökologische Beeinträchtigung bewirken, bezeichnet man auch als Umweltkatastrophen. Unfälle im Verkehr zu Wasser, Land und in der Luft gehören häufig zu den technischen Unfällen; sie sind hier unter anderen Kategorien, z. B. Brückeneinstürze oder Brand- und Explosionsunglücke, zu finden; als rein lokale Ereignisse handelt es sich jedoch in der Regel nicht um Katastrophen.

Ein Katastrophenmanagement soll sicherstellen, dass in einem Notfall angemessen reagiert werden kann.
Es besteht vorauslaufend im Allgemeinen aus:

Bedrohungs-(Worst-Case-)Analysen
Definieren von wahrscheinlichen Katastrophenfällen
Festlegen von Handlungsanweisungen
Beschaffung notwendiger Mittel und Vorhaltung bzw. Bevorratung an geeigneten Orten
Simulation von Katastrophenfällen und Überprüfung, ob die für einen Notfall festgelegten Mittel und Verfahren wirksam sind.
Es muss nachlaufend umfassen:

Sichere Wasserversorgung oder -lieferung
Offene Berichterstattung
Klare Kommandopfade
Robuste Kommunikationswege durch mobile Notfalleinrichtungen
Zuverlässige Einsatzlogistik
Vorrang für Transportwege
Nachdruck bei Leitungsreparaturen
Katastrophenmanagement umfasst

typischerweise als Katastrophe bezeichnete Ereignisse wie Feuer, Wasserschäden oder Erdbeben,
und auch die Fälle, in denen das Sicherheitsmanagement versagt hat.
Forschungen zum Katastrophenmanagement wie auch zur wirtschaftlichen Bedeutung von Katastrophen sind an den Universitäten selten, aber etabliert. Lars Michael Clausen hat die Katastrophensoziologie in Deutschland eingeführt.[7] Sein Schüler Martin Voss gründete eine Katastrophenforschungsstelle an der FU Berlin. Das Kieler Institut für Krisenforschung (Krisennavigator) forscht zu wirtschafts- und sozialwissenschaftlichen Aspekten. Die Deutsche Gesellschaft für Krisenmanagement e. V. (DGfKM) ist der Berufsverband der Krisen- und Katastrophenmanager.
Bei einer Katastrophe können auch Güter von hohem ideellen Wert bedroht sein. Ihren Erhalt zu sichern ist Ziel des Kulturgutschutzes.


Die Berichterstattung und Kommentierung mit Blick auf Katastrophen spielt für die Massenmedien eine erhebliche Rolle. Katastrophen sind unter der Rubrik Schaden ein zentraler Nachrichtenwert und gehören traditionell zu den Themen, die Medien vorrangig beachten und die beim Publikum auf großes Interesse stoßen. Auch die Kommunikationswissenschaft beachtet dieses Forschungsfeld seit langer Zeit sehr stark.


Philipp Henn, Gerhard Vowe: Facetten von Sicherheit und Unsicherheit. Welches Bild von Terrorismus, Kriminalität und Katastrophen zeigen die Medien? In: Medien & Kommunikationswissenschaft, 3/2015, S. 341–362.
Jörg Trempler: Katastrophen. Ihre Entstehung aus dem Bild. Wagenbach, Berlin 2013, ISBN 3-8031-5185-6 ( im Deutschlandradio).
François Walter: Katastrophen. Eine Kulturgeschichte vom 16. bis ins 21. Jahrhundert. Reclam, Stuttgart 2010, ISBN 978-3-15-010699-0.
Vladimir Petrovič Karcev, Petr Michajlovič Chazanovskij: Warum irrten die Experten? 3. Auflage. Verlag Technik, Berlin 1990, ISBN 3-341-00545-5.
Lars Clausen, Elke M. Geenen, Elísio Macamo (Hrsg.): Entsetzliche soziale Prozesse. Theorie und Empirie der Katastrophen. LIT, Münster 2003, ISBN 3-8258-6832-X.
Wolf R. Dombrowsky: Katastrophe und Katastrophenschutz. Eine soziologische Analyse. Deutscher Universitäts-Verlag, Wiesbaden 1989, ISBN 3-8244-4029-6.
Len Fisher: Katastrophen. Wie die Wissenschaft hilft, sie vorherzusagen. Übersetzt von Jürgen Neubauer. Eichborn, Frankfurt am Main 2011, ISBN 978-3-8218-6553-9.
Mohamed Gad-el-Hak (Hrsg.): Large-Scale Disasters. Prediction, Control, and Mitigation. Cambridge University Press, Cambridge 2008, ISBN 978-0-521-87293-5.
Ned Halley: Das große Buch der Katastrophen. Tessloff, Nürnberg 2000, ISBN 3-7886-0499-9.
Michael Kloepfer: Katastrophenrecht einschließlich Zivilschutz, Brandschutz, Rettungsdienst. Nomos, Baden-Baden 2009, ISBN 978-3-8329-4009-6.
Jörg Meidenbauer (Hrsg.): Die großen Katastrophen und Unglücksfälle. Chronik-Verlag, Gütersloh 1997, ISBN 3-577-14551-X.
Charles Perrow: Normale Katastrophen. Campus, Frankfurt am Main 1992, ISBN 3-593-34125-5.
Sebastian Roth: Krisen-Bildung. Aus- und Weiterbildung von KriseninterventionshelferInnen. Kovac, Hamburg 2008, ISBN 978-3-8300-3537-4.
Bundesamt für Bevölkerungsschutz und Katastrophenhilfe (Hrsg.): Dritter Gefahrenbericht der Schutzkommission beim Bundesminister des Innern. Bundesamt für Bevölkerungsschutz und Katastrophenhilfe, Bonn 2006, ISSN .
Martin Voss: Symbolische Formen. Grundlagen und Elemente einer Soziologie der Katastrophe. Transcript, Bielefeld 2006, ISBN 3-89942-547-2.
Gerrit Jasper Schenk, Jens Ivo Engels (Hrsg.): Historical Disaster Research. Concepts, Methods and Case Studies „Disaster“ / Historische Katastrophenforschung. Begriffe, Konzepte und Fallbeispiele. In: Historical Social Research / Historische Sozialforschung. 32, Nr. 3, 2007 (Sonderausgabe).
Patrick Masius, Jana Sprenger, Eva, Mackowiak (Hrsg.): Katastrophen machen Geschichte. Umweltgeschichtliche Prozesse im Spannungsfeld von Ressourcennutzung und Extremereignis. Universitätsverlag Göttingen, Göttingen 2010 ISBN 978-3-941875-21-0  (PDF; 3,3 MB).
Michaela Maier, Karin Stengel, Joachim Marschall: Nachrichtenwerttheorie. Nomos, Baden-Baden 2010, ISBN 978-3-8329-4266-3.
Rene Mono, Helmut Scherer: Wer zählt die Toten, nennt die Orte. Ist der internationale Nachrichtenfluss von Länderfaktoren oder Ereignismerkmalen determiniert? In: Publizistik, 2/2012, S. 135–159.
Johan Galtung, Mari Holmboe Ruge: The Structure of Foreign News. The Presentation of the Congo, Cuba and Cyprus Crisis in Four Norwegian Newspapers. In: Journal of Peace Research, 2/1965, S. 64–91.
Winfried Schulz: Die Konstruktion von Realität in den Nachrichtenmedien. Alber, Freiburg und München 1976, ISBN 3-495-47331-9.
Olaf Briese, Timo Günther: Katastrophe: Terminologische Vergangenheit, Gegenwart und Zukunft. In: Archiv für Begriffsgeschichte, 51, 2009, S. 155–95.
Olaf Briese: »Genommen auß den Comoedien«. Katastrophenbegriffe der neuzeitlichen Geologie. In: M. Eggers, M. Rothe (Hrsg.): Wissenschaftsgeschichte als Begriffsgeschichte. transcript, Bielefeld 2009, S. 23–50.
Mischa Meier: Zur Terminologie der (Natur-)Katastrophe in der griechischen Historiographie - einige einleitende Anmerkungen. In: G. J. Schenk, J. I. Engels (Hrsg.): Historical Disaster Research. Concepts, Methods and Case Studies – Historische Katastrophenforschung. Begriffe, Konzepte und Fallbeispiele. Köln 2007 (= Historical Social Research, 32.3 [2007]), S. 44–56.
Markus Bertsch, Jörg Trempler (Hrsg.): Entfesselte Natur: Das Bild der Katastrophe seit 1600. Michael Imhof Verlag, Petersberg 2018, ISBN 978-3-7319-0705-3.




Konferenzen und Meetings
 (englisch)
Katastrophenforschung
 (deutsches Portal zur Katastrophenforschung, Spin-off der Universität Kiel)
 (im Webarchiv)
 der Freien Universität Berlin (KFS)
 („KatNet“, Netzwerk mit deutschsprachiger Mailingliste und Newsletter)
 (DKKV)
Beispiele
Zum Hurrikan Katrina:  in Louisiana und Mississippi (englisch)
 auf anabell.de
 (englisch)
, Deutschlandfunk: Studiozeit – Aus Kultur- und Sozialwissenschaften im Juni 2011


Eine Umweltkatastrophe ist eine von Menschen verursachte, plötzliche und äußerst starke Beeinträchtigung der Umwelt, die die Krankheit oder den Tod von vielen Lebewesen zur Folge hat. Dies macht den deutlichen Unterschied zur Naturkatastrophe aus, die ihre Ursache in rein natürlichen, nicht vom Menschen beeinflussten Vorgängen hat.[1]


Eine Umweltkatastrophe wird meist ausgelöst durch einen Betriebsunfall (wie z. B. der Dioxin-Unfall von Seveso 1976,[2] das Bhopalunglück von 1984,[3] die nukleare Katastrophe von Tschernobyl 1986,[4] die Öltanker-Unfälle Amoco Cadiz 1978,[5] Exxon Valdez 1989[6] oder Prestige 2002)[7] und Verkehrsunfälle z. B. von Tanklastwagen mit Gefahrgut. Es kann sich aber auch um die Folgen schleichender Umweltverschmutzung handeln, die sich dann jedoch, in vergleichsweise sehr viel kürzerer Zeit gravierend in ihren Auswirkungen und Folgeerscheinungen zeigt, wie z. B. der Treibhauseffekt, das Ozonloch,[8] das Waldsterben[9] oder die Austrocknung des Aralsees.[10] Im Bereich der Luftverschmutzung stellt die Smog-Katastrophe in London 1952 ein bekanntes Beispiel dar.[11]
Einiges deutet darauf hin, dass Umweltkatastrophen eine große Rolle bei der Entwicklung des Umweltbewusstseins spielen. Während die Umweltverschmutzung oft schleichend oder für die menschlichen Sinnesorgane nicht wahrnehmbar ist, lösen Umweltkatastrophen durch ihr plötzliches und heftiges Auftreten bei vielen Menschen Ängste und Sorgen aus und lassen so Umweltbewusstsein und aktiven Umweltschutz wachsen.[12]



Auf Umweltkatastrophen zurückzuführende Schäden werden aufgrund ihrer Ursache nur bedingt durch Haftpflichtversicherungen und Liegenschaftsversicherungen gedeckt (z. B. der durch die Gebäudeversicherung abgedeckte Schaden durch abstürzende Satellitenteile).[13] Umweltschäden katastrophalen Ausmaßes können durch Brandstiftung oder Achtlosigkeit und Unaufmerksamkeit ausgelöst werden, wie z. B. eine Brandkatastrophe, welche sich zu einer Umweltkatastrophe ausweitet, oder der Unfall eines Gefahrguttransporters zu Land, zu Luft oder zur See. Oft können geringfügige Ursachen durch den Ketten- oder Domino-Effekt schnell das Ausmaß einer Naturkatastrophe erreichen.[14] Auch schon der durch Klimaveränderung vorbereitete katastrophale Sturm- und Flutschaden sprengt die Grenzen des herkömmlichen Elementarschadens.[15]
Zur Absicherung derartiger Schäden jenseits des z. B. durch die Gebäudeversicherung passiv oder Kfz-Haftpflichtversicherung aktiv abgedeckten Risikos durch Versicherung und Rückversicherung wird daher an Modellen für eine Katastrophenversicherung gearbeitet.[16]


Unterschieden werden:

Brandkatastrophen
Flutkatastrophen infolge von Stauanlagenunfällen
Chemiekatastrophen
Gefahrgutunfälle
Nuklearkatastrophen
Seuchen und Tierseuchen
Ölunfälle und Ölpesten
Smogkatastrophen
Globale Erwärmung

Biologische Invasion
Katastrophenversicherung
Katastrophentheorie
Katastrophensoziologie
Liste von Katastrophen
Liste der Städte mit der weltweit stärksten Luftverschmutzung

Patrick Masius, Jana Sprenger, Eva, Mackowiak (Hrsg.): Katastrophen machen Geschichte. Umweltgeschichtliche Prozesse im Spannungsfeld von Ressourcennutzung und Extremereignis. Universitätsverlag Göttingen, Göttingen 2010, ISBN 978-3-941875-21-0. 







Nachbeben ist eine Weiterleitung auf diesen Artikel. Zu den Spielfilmen siehe Erdbeben (Film) und Nachbeben (Film).


Als Erdbeben werden messbare Erschütterungen des Erdkörpers bezeichnet. Sie entstehen durch Masseverschiebungen, zumeist als tektonische Beben infolge von Verschiebungen der tektonischen Platten an Bruchfugen der Lithosphäre, in weniger bedeutendem Maße auch durch vulkanische Aktivität, Einsturz oder Absenkung unterirdischer Hohlräume, große Erdrutsche und Bergstürze sowie durch Sprengungen.[1][2] Erdbeben, deren Herd unter dem Meeresboden liegt, werden auch Seebeben oder unterseeische Erdbeben genannt. Diese unterscheiden sich von anderen Beben zum Teil in den Auswirkungen wie zum Beispiel der Entstehung eines Tsunamis, jedoch nicht in ihrer Entstehung.
Erdbeben bestehen in aller Regel nicht aus einer einzelnen Erschütterung, sondern ziehen meist weitere nach sich. Man spricht in diesem Zusammenhang von Vorbeben und Nachbeben mit Bezug auf ein stärkeres Hauptbeben. Treten Erdbeben über einen längeren, begrenzten Zeitraum gehäuft auf, so spricht man von einem Erdbebenschwarm oder Schwarmbeben. Solche treten vor allem in vulkanisch aktiven Regionen auf. In Deutschland gibt es gelegentlich Erdbebenschwärme im Vogtland und am Hochstaufen.
Der deutlich größte Anteil aufgezeichneter Erdbeben ist zu schwach, um von Menschen wahrgenommen zu werden. Starke Erdbeben können Bauten vernichten, Tsunamis, Lawinen, Steinschläge, Bergstürze und Erdrutsche auslösen und dabei Menschen töten. Sie können die Gestalt der Erdoberfläche verändern und zählen zu den Naturkatastrophen. Die Wissenschaft, die sich mit Erdbeben befasst, heißt Seismologie.
Die zehn stärksten seit 1900 gemessenen Erdbeben fanden mit einer Ausnahme alle an der Subduktionszone rund um den Pazifik, dem sogenannten Pazifischen Feuerring, statt (s. Liste unten).
Laut einer Analyse von mehr als 35.000 Naturkatastrophen-Ereignissen durch das Karlsruher Institut für Technologie (KIT) kamen von 1900 bis 2015 weltweit insgesamt 2,23 Millionen Menschen durch Erdbeben ums Leben.[3]



vergrößern und Informationen zum Bild anzeigenPanoramafoto von San Francisco nach dem Erdbeben 1906
Schon in der Antike fragten sich Menschen, wie Erdbeben und Vulkanausbrüche entstehen.
Man schrieb diese Ereignisse häufig Göttern zu (in der griechischen Mythologie dem Poseidon). Manche Wissenschaftler im alten Griechenland glaubten, die Kontinente schwämmen auf dem Wasser und schaukelten wie ein Schiff hin und her. Andere Leute glaubten, Erdbeben brächen aus Höhlen aus. In Japan gab es den Mythos des Drachen, der den Erdboden erzittern ließ und Feuer spie, wenn er wütend war. Im europäischen Mittelalter schrieb man Naturkatastrophen dem Wirken Gottes zu. Mit der Entdeckung und Erforschung des Magnetismus entstand die Theorie, man könne Erdbeben wie Blitze ableiten. Man empfahl daher Erdbebenableiter nach Art der ersten Blitzableiter.
Erst Anfang des 20. Jahrhunderts kam die heute allgemein anerkannte Theorie von der Plattentektonik und der Kontinentaldrift durch Alfred Wegener auf. Ab der Mitte des 20. Jahrhunderts wurden die Erklärungsmuster der tektonischen Beben verbreitet diskutiert. Bis zum Beginn des 21. Jahrhunderts konnte man daraus allerdings keine Technik zur sicheren Vorhersage von Erdbeben entwickeln.



[Bearbeiten | Quelltext bearbeiten]

Erdbeben entstehen vor allem durch dynamische Prozesse im Erdinneren. Eine Folge dieser Prozesse ist die Plattentektonik, also die Bewegung der Lithosphärenplatten, die von der oberflächlichen Erdkruste bis in den lithosphärischen Mantel reichen.
Besonders an den Plattengrenzen, an denen sich verschiedene Platten auseinander („Spreizungszone“), aufeinander zu („Subduktions-“ bzw. „Kollisionszone“) oder aneinander vorbei („Transformverwerfung“) bewegen, bauen sich mechanische Spannungen innerhalb des Gesteins auf, wenn sich die Platten in ihrer Bewegung verhaken und verkanten. Wird die Scherfestigkeit der Gesteine dann überschritten, entladen sich diese Spannungen durch ruckartige Bewegungen der Erdkruste und es kommt zum tektonischen Beben. Dabei kann mehr als das Hundertfache der Energie einer Wasserstoffbombe freigesetzt werden. Da die aufgebaute Spannung nicht auf die unmittelbare Nähe der Plattengrenze beschränkt ist, kann der Entlastungsbruch in selteneren Fällen auch im Inneren der Platte auftreten, wenn dort das Krustengestein eine Schwächezone aufweist.
Die Temperatur nimmt zum Erdinneren hin stetig zu, weshalb das Gestein mit zunehmender Tiefe immer leichter deformierbar wird und schon in der unteren Erdkruste nicht mehr spröde genug ist, um brechen zu können. Erdbeben haben ihren Ursprung daher meist in der oberen Erdkruste, in wenigen Kilometern Tiefe. Vereinzelt werden jedoch Beben mit Herden bis in 700 km Tiefe nachgewiesen. Solche „Tiefherdbeben“ treten vor allem an Subduktionszonen auf. Dort bewegen sich zwei Platten aufeinander zu, wobei die dichtere der beiden unter jene mit der geringeren Dichte geschoben wird und in den Erdmantel abtaucht. Der abtauchende Teil der Platte (engl. slab) erwärmt sich im Mantel jedoch relativ langsam, sodass dessen Krustenmaterial auch noch in größeren Tiefen bruchfähig ist. Die Hypozentren von Erdbeben, die innerhalb eines Slabs auftreten, ermöglichen somit Schlüsse auf die Position desselben in der Tiefe („Wadati-Benioff-Zone“). Als Auslöser dieser Tiefherdbeben gilt unter anderem die Volumenänderung des Slab-Gesteins infolge von Mineralumwandlungen unter den im Mantel herrschenden Temperatur- und Druckbedingungen.
Ferner kann aufsteigendes Magma in vulkanischen Zonen – meist eher schwache – Erdbeben verursachen.
Bei unterseeischen Erdbeben, beim Ausbruch ozeanischer Vulkane oder beim Auftreten unterseeischer Erdrutsche können sogenannte Tsunamis entstehen. Bei plötzlicher vertikaler Verlagerung großer Teile des Ozeanbodens entstehen Wellen, die sich mit Geschwindigkeiten von bis zu 800 Kilometern pro Stunde fortbewegen. Auf dem offenen Meer sind Tsunamis kaum wahrnehmbar; läuft die Welle jedoch in flacherem Wasser aus, steilt sich der Wellenberg auf und kann am Ufer in extremen Fällen bis zu 100 Meter Höhe erreichen. Am häufigsten entstehen Tsunamis im Pazifik. Deshalb besitzen die an den Pazifik angrenzenden Staaten ein Frühwarnsystem, das Pacific Tsunami Warning Center. Nachdem am 26. Dezember 2004 etwa 230.000 Menschen nach einem verheerenden Erdbeben im Indischen Ozean starben, wurde auch dort ein Frühwarnsystem errichtet.

[Bearbeiten | Quelltext bearbeiten]
Sehr flachgründige und nur lokal spürbare Erdbeben können durch Frost ausgelöst werden, wenn größere Mengen Wasser im Boden oder im Gesteinsuntergrund gefrieren und sich dabei ausdehnen. Dadurch entstehen Spannungen, die sich in kleineren Erschütterungen entladen, die dann an der Oberfläche als „Erdbeben“ und grollendes Geräusch wahrgenommen werden. Das Phänomen tritt meist zu Beginn einer strengen Frostperiode auf, wenn die Temperaturen rapide von Werten über dem Gefrierpunkt auf Werte weit unter den Gefrierpunkt gefallen sind.[4]

[Bearbeiten | Quelltext bearbeiten]
Neben natürlich ausgelösten Erdbeben gibt es auch anthropogene, also menschengemachte. Diese induzierte Seismizität ist nicht zwangsläufig absichtlich oder wissentlich herbeigeführt, wie z. B. im Fall von aktiver Seismik oder infolge von Atomwaffentests, sondern es sind oft Ereignisse, die als unbeabsichtigte „Nebenwirkungen“ menschlicher Aktivitäten auftreten. Zu diesen Aktivitäten gehören unter anderem die Förderung fossiler Kohlenwasserstoffe (Erdöl und Erdgas), die durch Veränderung des Porendrucks die Spannungsverhältnisse im Gestein der Lagerstätte verändert, oder auch die (versuchte) Nutzung von Erdwärme (→ Geothermie).[5]
Anthropogene Erdbeben finden auch beim Einsturz von bergbaulich verursachten unterirdischen Hohlräumen (Gebirgsschlag) statt. Die Magnitude dieser Erdbeben liegt in den allermeisten Fällen im Bereich von Mikrobeben oder Ultramikrobeben. Nur selten erreicht sie den Wert spürbarer Beben.
Einige der stärksten anthropogenen Erdbeben ereigneten sich infolge des Aufstauens großer Wassermengen in Stauseen durch die Auflasterhöhung im Untergrund in der Nähe großer Verwerfungen. Das Wenchuan-Erdbeben in China im Jahr 2008 (Magnitude 7,9), das rund 90.000 Todesopfer forderte, gilt als Kandidat für das bislang stärkste durch Stauseen ausgelöste Erdbeben weltweit.[6]

[Bearbeiten | Quelltext bearbeiten]

Erdbeben erzeugen Erdbebenwellen verschiedenen Typs, die sich über und durch die ganze Erde ausbreiten und von Seismographen (bzw. Seismometern) überall auf der Erde in Seismogrammen aufgezeichnet werden können. Die mit starken Erdbeben einhergehenden Zerstörungen an der Erdoberfläche (Spaltbildung, Schäden an Gebäuden und Verkehrsinfrastruktur usw.) sind auf die „Oberflächenwellen“ zurückzuführen, die sich an der Erdoberfläche ausbreiten und eine elliptische Bodenbewegung auslösen.
Die Fortpflanzungsgeschwindigkeit eines Bebens beträgt im Normalfall ca. 3,5 km/s (nicht zu verwechseln mit der oben angegebene Wellengeschwindigkeit bei Seebeben). In sehr seltenen Fällen kommt es aber zur überschallschnellen Ausbreitung des Bebens, wobei bereits Fortpflanzungsgeschwindigkeiten von ca. 8 km/s gemessen wurden. Bei einem überschallschnellen Beben breitet sich der Riss schneller aus als die seismische Welle, was normalerweise umgekehrt abläuft. Bisher konnten erst 6 überschallschnelle Beben aufgezeichnet werden.[7]

[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Hypozentrum
Durch Aufzeichnung und Auswertung der Stärke und Laufzeiten von Erdbebenwellen in weltweit verteilten Observatorien kann man die Position des Erdbebenherds bestimmen, das „Hypozentrum“. Dabei fallen auch Daten über das Erdinnere an. Die Positionsbestimmung unterliegt als Messung an Wellen der gleichen Unschärfe, die bei Wellen in anderen Bereichen der Physik bekannt sind. Im Allgemeinen nimmt die Unschärfe der Ortsbestimmung mit zunehmender Wellenlänge zu. Eine Quelle von langperiodischen Wellen kann also nicht so genau lokalisiert werden wie die von kurzperiodischen Wellen. Da schwere Erdbeben den größten Teil ihrer Energie im langperiodischen Bereich entwickeln, kann besonders die Tiefe der Quelle nicht genau bestimmt werden. Die Quelle der seismischen Wellen kann sich im Laufe eines Bebens bewegen, so etwa bei schweren Beben, die eine Bruchlänge von mehreren hundert Kilometern aufweisen können. Nach internationaler Übereinkunft wird dabei die zuerst gemessene Position als Hypozentrum des Erdbebens bezeichnet, also der Ort, wo das Beben begonnen hat. Der Ort auf der Erdoberfläche direkt über dem Hypozentrum heißt Epizentrum. Der Zeitpunkt des Bruchbeginns wird als „Herdzeit“ bezeichnet.
Die Bruchfläche, die das Erdbeben auslöst, wird in ihrer Gesamtheit als „Herdfläche“ bezeichnet. In den meisten Fällen erreicht diese Bruchfläche die Erdoberfläche nicht, sodass der Erdbebenherd in der Regel nicht sichtbar wird. Im Fall eines größeren Erdbebens, dessen Hypozentrum in nur geringer Tiefe liegt, kann die Herdfläche bis an die Erdoberfläche reichen und dort zu einem deutlichen Versatz führen. Der genaue Ablauf des Bruchprozesses legt die „Abstrahlcharakteristik“ des Bebens fest, bestimmt also, wie viel Energie in Form von seismischen Wellen in jede Richtung des Raumes abgestrahlt wird. Dieser Bruchmechanismus wird als Herdvorgang bezeichnet. Der Ablauf des Herdvorganges kann aus der Analyse von Ersteinsätzen an Messstationen rekonstruiert werden. Das Ergebnis einer solchen Berechnung ist die Herdflächenlösung.

[Bearbeiten | Quelltext bearbeiten]
Es gibt drei grundlegende Typen von Erdbebenereignissen, welche die drei Arten der Plattengrenzen widerspiegeln: In Spreizungszonen, wo die tektonischen Platten auseinanderdriften, wirkt eine Zugspannung auf das Gestein (Extension). Die Blöcke zu beiden Seiten der Herdfläche werden also auseinandergezogen und es kommt zu einer Abschiebung (engl.: normal fault), bei welcher der Block oberhalb der Bruchfläche nach unten versetzt wird. In Kollisionszonen, wo sich Platten aufeinander zubewegen, wirkt dagegen eine Kompressionsspannung. Das Gestein wird zusammengestaucht und es kommt, abhängig vom Neigungswinkel der Bruchfläche, zu einer Auf- oder Überschiebung (engl. reverse fault bzw. thrust fault), bei welcher der Block oberhalb der Bruchfläche nach oben versetzt wird. In Subduktionszonen kann sich die abtauchende Platte mitunter großflächig verhaken, was in der Folge zu einem massiven Spannungsaufbau und letztlich zu besonders schweren Erdbeben führen kann. Diese werden gelegentlich auch als Megathrust-Erdbeben bezeichnet. Der dritte Herdtyp wird als „Blattverschiebung“ (engl. strike-slip fault) bezeichnet, der an „Transformverwerfungen“ vorkommt, wo sich die beteiligten Platten seitlich aneinander vorbeischieben.
In der Realität wirken die Kräfte und Spannungen jedoch zumeist schräg auf die Gesteinsblöcke, da sich die Lithosphärenplatten verkanten und dabei auch drehen können. Die Platten bewegen sich daher im Normalfall nicht gerade aufeinander zu oder aneinander vorbei, so dass die Herdmechanismen zumeist eine Mischform aus einer Auf- oder Abschiebung und einer seitwärts gerichteten Blattverschiebung darstellen. Man spricht hier von einer „Schrägauf-“' bzw. „Schrägabschiebung“ (engl. oblique fault).
Die räumliche Lage der Herdfläche kann durch die drei Winkel Φ, δ und λ beschrieben werden:[8][9]

Φ bezeichnet das Streichen (engl.: strike) der Herdfläche. Dies ist der Winkel zwischen der geographischen Nordrichtung und der Schnittlinie der einfallenden Herdfläche mit der Horizontalen (Streichlinie). Das Streichen kann Werte zwischen 0° und 360° annehmen; eine nach Osten einfallende Herdfläche wäre durch eine Nord-Süd-verlaufende Streichlinie gekennzeichnet und würde damit ein Streichen von Φ = 0° aufweisen.
δ bezeichnet das Fallen, also die Neigung (engl.: dip) der Herdfläche. Das ist der Winkel zwischen der Horizontalen und der Herdfläche. Er kann Werte zwischen 0° und 90° annehmen; eine exakt senkrecht verlaufende Bruchfläche hätte eine Neigung von δ = 90°.
λ bezeichnet die Richtung des Versatzes (engl.: rake), die in der Ebene des Versatzes bestimmt wird. Dies ist der Winkel zwischen dem Streichen der Herdfläche und dem Richtungsvektor des Versatzes, der Werte zwischen 0° und 360° annehmen kann. Wird z. B. das Hangende, also der oben liegende Block, exakt nach oben verschoben, wäre λ = 90°. Steht die Herdfläche exakt senkrecht, wird – in Streichrichtung blickend – der rechte Block als das „Hangende“ definiert. Für eine linkslaterale Verschiebung wäre λ = 0°, für eine rechtslaterale Verschiebung wäre λ = 180°.
[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Erdbebenskala
Um Erdbeben miteinander vergleichen zu können, ist es notwendig, deren Stärke zu ermitteln. Da eine direkte Messung der freigesetzten Energie eines Erdbebens schon allein auf Grund der Tiefenlage des Herdprozesses nicht möglich ist, wurden in der Seismologie verschiedene Erdbebenskalen entwickelt.

[Bearbeiten | Quelltext bearbeiten]
Die ersten Erdbebenskalen, die Ende des 18. bis Ende des 19. Jahrhunderts entwickelt wurden, konnten nur die Intensität eines Erdbebens beschreiben, also die Auswirkungen auf Menschen, Tiere, Gebäude und natürliche Objekte wie Gewässer oder Berge.
Im Jahre 1883 entwickelten die Geologen M. S. De Rossi und F. A. Forel eine zehnstufige Skala zur Bestimmung der Intensität von Erdbeben.
Wichtiger wurde jedoch die im Jahre 1902 eingeführte zwölfteilige Mercalliskala. Sie beruht allein auf der subjektiven Einschätzung der hör- und fühlbaren Beobachtungen sowie der Schadensauswirkung auf Landschaft, Straßen oder Gebäude (Makroseismik).
1964 wurde sie zur MSK-Skala und später zur EMS-Skala weiterentwickelt.
Intensitätsskalen werden auch heute noch verwendet, wobei verschiedene Skalen existieren, die an die Bauweise und Bodenverhältnisse des jeweiligen Landes angepasst sind. Die räumliche Verteilung der Intensitäten wird häufig durch Fragebogenaktionen zuständiger Forschungseinrichtungen (in Deutschland beispielsweise bundesweit durch die BGR per Online-Formular) ermittelt und in Form von Isoseistenkarten dargestellt. Isoseisten sind Isarithmen gleicher Intensitäten.[10] Die Möglichkeit zur Erfassung von Intensitäten beschränkt sich auf relativ dicht besiedeltes Gebiet.

[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Magnitude (Erdbeben)
Durch die Entwicklung und stetige Verbesserung von Seismometern ab der zweiten Hälfte des 19. Jahrhunderts eröffnete sich die Möglichkeit, objektive, auf physikalischen Größen basierende Messungen vorzunehmen, was zur Entwicklung der Magnitudenskalen führte. Diese ermöglichen über empirisch gefundene Beziehungen und physikalische Gesetzmäßigkeiten, von den an seismologischen Messstationen aufgezeichneten ortsabhängigen Amplitudenwerten auf die Stärke eines Bebens zurückzuschließen.
Es gibt verschiedene Methoden, die Magnitude zu berechnen. Die unter Wissenschaftlern gebräuchlichste Magnitudenskala ist heute die Momenten-Magnituden-Skala (Mw). Diese ist logarithmisch und endet bei der Mw 10,6. Man nimmt an, dass bei diesem Wert die feste Erdkruste komplett zerbricht. Die Erhöhung um eine Magnitude entspricht einer 32-fach höheren Energiefreisetzung. Von den Medien wird die in den 1930er Jahren von Charles Francis Richter und Beno Gutenberg eingeführte Richterskala am häufigsten zitiert, die auch als Lokalbebenmagnitude bezeichnet wird. Zur exakten Messung der Erdbebenstärke benutzt man Seismographen, die in 100 km Entfernung zum Epizentrum des Erdbebens liegen sollten. Mit der Richter-Skala werden die seismischen Wellen in logarithmischer Einteilung gemessen. Sie diente ursprünglich der Quantifizierung von Erdbeben im Raum Kalifornien. Liegt eine Erdbebenmessstation zu weit vom Erdbebenherd entfernt (> 1000 km) und ist die Stärke des Erdbebens zu groß (ab etwa Magnitude 6), kann diese Magnitudenskala jedoch nicht oder nur eingeschränkt verwendet werden.[10] Sie ist aufgrund der einfachen Berechnung und der Vergleichbarkeit mit älteren Erdbebeneinstufungen vielfach auch in der Seismologie noch in Gebrauch.

[Bearbeiten | Quelltext bearbeiten]
Nach einer Publikation aus dem Jahr 2017 lassen sich bei starken Erdbeben in den Seismometer­aufzeichnungen geringfügige Schwankungen des Gravitationsfelds der Erde nachweisen, die durch die Massenverschiebung ausgelöst werden. Diese Signale breiten sich mit Lichtgeschwindigkeit durch den Erdkörper aus, das heißt deutlich schneller als die primären Erdbebenwellen (P-Wellen), die für gewöhnlich als erstes von den Seismometern registriert werden und eine Geschwindigkeit von höchstens 10 km/s erreichen können. Außerdem sollen sie eine genauere Bestimmung der Magnitude eines Bebens ermöglichen, insbesondere an Messstationen, die relativ nahe am Erdbebenherd liegen. Beides bedeutete eine deutliche Verbesserung bei der Erdbebenfrühwarnung.[11]

[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Erdbebenvorhersage

Die zeitlich und räumlich exakte Vorhersage von Erdbeben ist nach dem heutigen Stand der Wissenschaft nicht möglich. Die verschiedenen bestimmenden Faktoren sind qualitativ weitestgehend verstanden. Auf Grund des komplexen Zusammenspiels aber ist eine genaue Quantifizierung der Herdprozesse bislang nicht möglich, sondern nur die Angabe einer Wahrscheinlichkeit für das Auftreten eines Erdbebens in einer bestimmten Region.
Allerdings kennt man Vorläuferphänomene (engl. precursors). Einige davon äußern sich in der Veränderung geophysikalisch messbarer Größen, wie z. B. der seismischen Geschwindigkeit, der Neigung des Erdbodens oder der elektromagnetischen Eigenschaften des Gesteins. Andere Phänomene basieren auf statistischen Beobachtungen, wie etwa das Konzept der seismischen Ruhe, die bisweilen auf ein bevorstehendes größeres Ereignis hindeutet.
Wiederholt wurde auch von ungewöhnlichem Verhalten bei Tieren kurz vor größeren Erdbeben berichtet. Dadurch gelang im Fall des Haicheng-Erdbebens vom Februar 1975 die rechtzeitige Warnung der Bevölkerung.[12] In anderen Fällen wurde jedoch kein auffälliges Verhalten bei Tieren im Vorfeld eines Erdbebens beobachtet. Eine Meta-Analyse, in der 180 Publikationen berücksichtigt wurden, in denen mehr als 700 Beobachtungen auffälligen Verhaltens bei mehr als 130 verschiedenen Arten im Zusammenhang mit 160 verschiedenen Erdbeben dokumentiert sind, ergab im Abgleich mit Daten des globalen Erdbebenkatalogs des International Seismological Centre (ISC-GEM), dass das räumlich-zeitliche Muster der Verhaltensanomalien auffallend mit dem Auftreten von Vorbeben übereinstimmt. Demnach wäre zumindest ein Teil der Verhaltensanomalien schlicht durch die Vorbeben erklärbar, die von den oft mit sensibleren Sinnesorganen ausgestatteten Tieren über größere Entfernungen zum Epizentrum wahrgenommen werden können.[13] Zwar beschäftigten sich viele Studien mit ungewöhnlichem Verhalten, aber es war unklar, was überhaupt ungewöhnliches Verhalten ist und welche Verhaltensanomalien als Vorläuferphänomen gelten. Beobachtungen sind meist anekdotisch, und es fehlen systematische Auswertungen und längere Messreihen. Es gibt deshalb bisher keine Hinweise darauf, dass Tiere verlässlich vor Erdbeben warnen können.[13]
Alle bekannten Vorläuferphänomene variieren jeweils sehr stark in Zeitverlauf und Größenordnung. Zudem wäre der instrumentelle Aufwand, der für eine lückenlose Erfassung dieser Phänomene erforderlich wäre, aus heutiger Sicht finanziell und logistisch nicht realisierbar.

[Bearbeiten | Quelltext bearbeiten]
Neben den „konventionellen“, spürbaren und bisweilen sehr zerstörerischen Erdbeben, gibt es auch sogenannte „unkonventionelle“ oder „langsame“ Beben, deren Quellen nicht unterhalb, sondern an der Erdoberfläche liegen und sehr langperiodische (Periodendauer ca. 20 bis 150 s) Oberflächenwellen aussenden. Diese Wellen müssen mittels spezieller Algorithmen aus global oder kontinentweit aufgezeichneten seismischen Daten herausgefiltert werden und können anhand ihrer Charakteristik und mitunter weiteren Kriterien bestimmten Quellen zugeordnet werden. Zu solchen unkonventionellen Erdbeben gehören die Gletscherbeben, die durch Kalbungsvorgänge an großen polaren Gletschern ausgelöst werden, sowie die Sturmbeben, die bei starken Stürmen (Hurrikane u. ä.) unter bestimmten Umständen durch die Interaktion sturminduzierter langperiodischer Meereswellen mit größeren Untiefen im Bereich der Schelfkante erzeugt werden.[14]


Die wichtigsten bekannten Erdbebengebiete sind in der Liste der Erdbebengebiete der Erde aufgeführt. Eine umfassende Aufstellung historisch überlieferter Erdbebenereignisse befindet sich in der Liste von Erdbeben.


Die folgende Liste wurde nach Angaben des USGS zusammengestellt.[15] Die Werte beziehen sich, wenn nicht anders angegeben, auf die Momenten-Magnitude MW, wobei zu berücksichtigen ist, dass unterschiedliche Magnitudenskalen nicht direkt miteinander vergleichbar sind. Es werden die Werte angegeben, die das International Seismological Centre veröffentlicht.



Rang

Bezeichnung

Ort

Datum

Stärke

Anmerkungen


1.

Erdbeben von Valdivia 1960

Chile

22. Mai 1960

9,6

ca. 5.000 Tote[16]


2.

Karfreitagsbeben 1964

Alaska

27. März 1964

9,3

Tsunami mit einer maximalen Höhe von etwa 67 Metern


3.

Erdbeben im Indischen Ozean 2004

vor Sumatra

26. Dezember 2004

9,1

Durch das Beben und den nachfolgenden Tsunami starben etwa 230.000 Menschen. Über 1,7 Millionen Küstenbewohner rund um den Indischen Ozean wurden obdachlos.


4.

Tōhoku-Erdbeben 2011

östlich vor Honshū, Japan

11. März 2011

9,0

18.500 Menschen starben, 450.000 Menschen wurden obdachlos und mit einem direkten Schaden von etwa 296 Milliarden Euro[3] gilt es als das bislang teuerste Erdbeben überhaupt.[17][18] Aufgrund des nachfolgenden Tsunamis kam es auch zur Fukushima-Katastrophe im Atomkraftwerk Fukushima Daiichi.


5.

Erdbeben von Kamtschatka 1952

Kamtschatka, Russland

4. November 1952

8,9




6.

Erdbeben in Chile 2010

Chile

27. Februar 2010

8,8

521 Tote, 56 Vermisste


6.

Erdbeben Ecuador-Kolumbien 1906

Ecuador / Kolumbien

31. Januar 1906

8,8

ca. 1.000 Tote


7.

Erdbeben bei den Rat Islands 1965

Rat Islands, Alaska

4. Februar 1965

8,7




8.

Erdbeben vor Sumatra 2012

vor der Küste Sumatras

11. April 2012

8,6




8.

Erdbeben vor Sumatra 2005

vor Nord-Sumatra

28. März 2005

8,6

Über 1.000 Tote


8.

Erdbeben in Araucanía 1960

Araucanía

22. Mai 1960

8,6




8.

Erdbeben bei den Andreanof Islands 1957

Andreanof Islands, Alaska

19. März 1957

8,6




8.

Assam-Erdbeben 1950

Grenzregion China-Indien

15. August 1950

8,6

1.526 ToteEs ist das stärkste registrierte Erdbeben an Land.


8.

Erdbeben bei den Aleuten 1946

bei den Aleuten

1. April 1946

8,6




Das Ausmaß der durch ein Erdbeben hervorgerufenen Schäden hängt zunächst von der Stärke und Dauer des Bebens ab sowie von der Besiedlungsdichte und der Anzahl und Größe der Bauwerke in dem betroffenen Bereich. Wesentlich ist aber auch die Erdbebensicherheit der Bauwerke. In der europäischen Norm EC 8 (in Deutschland DIN EN 1998-1) sind die Grundlagen für die Auslegung von Erdbebeneinwirkungen für die verschiedenen Bauarten Holz, Stahl, Stahlbeton, Verbundbauweise, Mauerwerk Bemessungskriterien definiert.


Erdbebenlicht
Liste von Erdbeben in Deutschland
Liste von Erdbeben in Österreich
Liste von Erdbeben in der Schweiz
Liste von Erdbeben des 21. Jahrhunderts

Bruce A. Bolt: Erdbeben – Schlüssel zur Geodynamik. Spektrum Akademischer Verlag, Heidelberg 1995, ISBN 3-86025-353-0. — Eine gute Einführung auch für Laien.
Emanuela Guidoboni, John E. Ebel: Earthquakes and tsunamis in the past: a guide to techniques in historical seismology. Cambridge University Press, 2009, ISBN 978-0-521-83795-8. — Wissenschaftliches Lehrbuch der historischen Seismologie in englischer Sprache.
Silvia Einsporn, Franziska Hohm, Sylvia Jakuscheit (Redaktion): Haak TaschenAtlas Vulkane und Erdbeben, Bearbeitet von Harro Hess, Justus Perthes Verlag, Gotha 2003, ISBN 3-623-00020-5.
Thorne Lay, Terry C. Wallace: Modern Global Seismology. International Geophysics. Band 58, Academic Press, San Diego/London 1995, ISBN 0-12-732870-X. — Umfangreiches wissenschaftliches Standardwerk in englischer Sprache.
Christian Rohr: Extreme Naturereignisse im Ostalpenraum: Naturerfahrung im Spätmittelalter und am Beginn der Neuzeit. Umwelthistorische Forschungen, Band 4, Böhlau, Köln u. a. 2007, ISBN 978-3-412-20042-8. — Differenzierte Studie zur Naturwahrnehmung.
Götz Schneider: Erdbeben – Eine Einführung für Geowissenschaftler und Bauingenieure. Spektrum Akademischer Verlag, München 2004, ISBN 3-8274-1525-X. — Eine etwas kompliziertere Einführung mit einigen mathematischen Darstellungen.
Peter M. Shearer: Introduction to Seismology. 2. Auflage. Cambridge University Press, Cambridge (UK) u. a. 2009, ISBN 978-0-521-88210-1. — Wissenschaftliches Lehrbuch in englischer Sprache.
Gerhard Waldherr: Erdbeben: das außergewöhnliche Normale; zur Rezeption seismischer Aktivitäten in literarischen Quellen vom 4. Jahrhundert v. Chr. bis zum 4. Jahrhundert n. Chr. Geographica historica. Band 9, Stuttgart 1997, ISBN 3-515-07070-2. — Grundlegend für die Rezeptionsgeschichte von Erdbeben.
Gerhard H. Waldherr, Anselm Smolka (Hrsg.): Antike Erdbeben im alpinen und zirkumalpinen Raum: Befunde und Probleme in archäologischer, historischer und seismologischer Sicht. Beiträge des Interdisziplinären Workshops Schloss Hohenkammer, 14./15. Mai 2004 (Earthquakes in Antiquity in the alpine and circum-alpine region: findings and problems from an archaeological, historical and seismological viewpoint). (= Geographica historica. Band 24). Steiner, Stuttgart 2007, ISBN 978-3-515-09030-8. — Gesammelte Beiträge einer internationalen Tagung zur historischen Seismologie.




 im Katalog der Deutschen Nationalbibliothek

 (Memento vom 24. Januar 2010 im Internet Archive)



 (Memento vom 20. Oktober 2012 im Internet Archive)
 (englisch)
 (). Quelle für die Darstellung der Erdbeben sind Daten des USGS.  (Hat Probleme im Vollbildmodus. Fenster daher bitte zuvor verkleinern).
 des National Geophysical Data Center (NGDC), NOAA (englisch)
 (englisch)
 (englisch)
BBC News 20. September 2012, Ed Young:  (Memento vom 23. September 2012 im Internet Archive)
visualcapitalist.com vom 29. Mai 2020, Nicholas LePan:  („Grafik zur Stärke und Häufigkeit von Erdbeben“)
[Bearbeiten | Quelltext bearbeiten]







 – Quake Catcher Network, BOINC






Dieser Artikel  behandelt den Wassermangel – zu anderen Bedeutungen siehe Dürre (Begriffsklärung).



Dürre ist ein extremer, über einen längeren Zeitraum vorherrschender Zustand, in dem weniger Wasser oder Niederschlag verfügbar ist als erforderlich. Dürre ist nicht nur ein physikalisches Phänomen, sondern auch ein Wechselspiel zwischen der Verfügbarkeit und dem Wasserbedarf von Organismen. Dürre tritt oft in Gegenden auf, wo Kontinentalklima herrscht.
Unterschieden wird häufig zwischen meteorologischer Dürre, hydrologischer Dürre, landwirtschaftlicher Dürre und sozio-ökonomischer Dürre.




Im Allgemeinen werden vier Typen von Bedingungen als Dürre bezeichnet:
[1]

Meteorologische Dürre respektive klimatologische Trockenheit entsteht, wenn Niederschlag über einen längeren Zeitraum unterdurchschnittlich fällt.
Hydrologische Dürre ist zu verzeichnen, wenn die Wasserstände der Gewässer unter einen Normalwert fallen (Niedrigwasser) und die Wasserreserven in den Seen, Wasserreservoirs oder Wasserspeichern unter den statistischen Durchschnitt fallen. Die Form ist die langfristigere Folge der meteorologischen Dürre
Bodentrockenheit und in Folge Landwirtschaftliche Dürre ist gegeben, wenn ein Wassermangel in der Wurzelschicht des Bodenprofils herrscht, und es zu wenig Wasser für eine durchschnittliche landwirtschaftliche Produktion von Nutzpflanzen gibt. Das kann an langedauernd zu wenig Niederschlag liegen, aber auch andere Gründe für absinkenden Grundwasserspiegel haben (wie zu hohe Entnahme, Verlagerung von Grundwasserströmen), aber auch ein prinzipielles bodenkundliches Charakteristikum eines Bodens oder Landstrichs sein (siehe auch Turgeszenz, Turgor; Welke).
Sozio-ökonomische Dürre herrscht schließlich, wenn durch Wassermangel in Flüssen o. ä. Warentransportketten oder Energieversorgung eingeschränkt werden.[2]

Dürreperioden können regelmäßig auftreten, je nach Klimaprofil (Sommertrockenes Klima, Winterdürre usf., vergleiche Singularität), oder ein Ausnahmeereignis sein, das Wochen oder Jahre anhalten kann (Extremwetter), oder ein weitgehend permanenter klimatologischer oder regionaler Zustand (siehe etwa Wüstenklima, Versteppung, Karst, Inneralpines Becken), der sich in erdgeschichtlichem Maßstab wandelt. Eine Mischform ist das periodisch, aber unregelmäßig auftretende El-Niño-Phänomen, welches Überschwemmungen in Südamerika und Dürren in Afrika auslösen kann.[3]
Zur Quantifizierung von Dürren gibt es verschiedene Systeme, etwa den Palmer-Dürre-Index.
Siehe auch: Dürre-Index
Als Megadürre bezeichnet man eine über einen Zeitraum von mindestens einem Jahrzehnt anhaltende Dürre oder, allgemeiner, besonders intensive oder lang anhaltende Dürren.[4]

[Bearbeiten | Quelltext bearbeiten]
Engpässe in der Wasserversorgung
geringere Ernten, hohe Preise für die geernteten Güter
weniger Viehfutter, hohe Preise für tierische Produkte
Behinderung des Schiffsverkehrs wegen des niedrigen Wasserstandes.
Engpässe in der Stromversorgung:[5]
Wasserkraftwerke können weniger Strom produzieren
die Belieferung von Steinkohlekraftwerken per Schiff wird bei niedrigen Wasserständen aufwändiger (die Frachtschiffe können nicht voll beladen werden)
Wärmekraftwerke müssen, vor allem im Sommer, ihre Leistung drosseln (zum einen haben sie mengenmäßig zu wenig Kühlwasser; zum anderen darf das Kühlwasser beim Zurückfließen in den Fluss nur eine gewisse Maximaltemperatur haben. Je wärmer das Wasser vor Entnahme schon ist, desto weniger Kühlleistung kann es erbringen).[6]
Waldbrand- und Flurbrandgefahr (potenziell: Flächenbrand)
Bodenerosion
Sand- und Staubstürme
[Bearbeiten | Quelltext bearbeiten]
Im Rahmen der vom deutschen Bundesamt für Bevölkerungsschutz und Katastrophenhilfe (BBK) durchgeführten Risikoanalysen im Bevölkerungsschutz wurde im Jahr 2018 die Risikoanalyse Dürre veröffentlicht.[7]
Das analysierte Dürreszenario erstreckt sich über sechs Jahre und leitet sich aus der extremen Dürreperiode in Deutschland in den Jahren 1971 bis 1976 ab. Für dieses Ereignis wurde eine Wiederkehrwahrscheinlichkeit von etwa 450 Jahren abgeschätzt. Aufgrund von Hitzewelle und Kälteperiode wurde eine erhöhte Mortalität ermittelt. Die untersuchten Auswirkungen des Dürreszenarios auf kritische Infrastrukturen in Deutschland erbrachten eine Vielzahl von Hinweisen auf erkannte Defizite und Verbesserungsvorschlägen.


[Bearbeiten | Quelltext bearbeiten]


Beschreibung

Auswirkungen

Bemerkungen


22. Jahrhundert v. Chr.

Katastrophale Dürre im östlichen Nordafrika und Teilen des mittleren Orients.[8]

Untergang des Alten Reiches in Ägypten und des Akkadischen Reiches in Mesopotamien.[9]


Spätes 8. Jahrhundert v. Chr.

Dürre in Griechenland.

Möglicherweise Auslöser des Lelantischen Krieges zwischen Chalkis und Eretria


9. und 10. Jahrhundert

Drei schwere, mehrjährige Dürreperioden im Abstand von 50 Jahren (um 810, um 860, um 910).

Die Zivilisation der klassischen Maya kollabierte.[9]


1069

England

Dürre: fast 50.000 Menschen verhungerten. Viele mussten sich in Leibeigenschaft verkaufen, um zu überleben.[9]


1199 und 1202

Ägypten

Die jährliche Nilschwemme blieb aus. 100.000 Menschen verhungerten.


1540

Europa

Elfmonatige „Megadürre“[10][11][12]


1669–1670

Indien

Hungersnot in Bengalen 1770 – schätzungsweise etwa 10 Millionen Tote.[13]


1876–1877

Indien

Drei Millionen Menschen starben an Unterernährung, ebenfalls drei Millionen an Cholera. 36 Millionen Menschen waren insgesamt von der Katastrophe betroffen.[9]


1930–1938

Drei Dürrejahre (1930, 1935, 1937) innerhalb eines Jahrzehnts in Nordamerika, die als Dust Bowl bezeichnet werden.

Missernten, Entvölkerung einiger Landstriche im Mittleren Westen.[9]


1973–1983

Sahelzone

Hungersnot in der Sahelzone – 2 Millionen Menschen starben an den Folgen von Unterernährung und Krankheiten.[14]

[Bearbeiten | Quelltext bearbeiten]

Die Dürre von 1540 wird von einigen Autoren als „die schlimmste Dürre des Jahrtausends in Deutschland“ beschrieben, von anderen wird diese These allerdings bezweifelt.[12][15] Eine Untersuchung ergab, dass es in dieser Zeit über 11 Monate kaum regnete, ein Ereignis, das durch heutige Klimamodelle nicht simuliert werden kann.[16] Die Temperaturen sollen fünf bis sieben Grad über dem Mittel des 20. Jahrhunderts gelegen haben.[17]
1857 hatte eine Dürre im Emsland erhebliche Auswirkungen.[18][19]
2003 war ein sogenannter Jahrhundertsommer. Etwa vom 1. bis 15. August 2003 gab es eine Hitzewelle in großen Teilen Europas.
In Deutschland war das erste Halbjahr 2011 extrem trocken.[20]
Das Wetter in den Monaten März, April und Mai („Frühjahr“) 2011 fasste der Deutsche Wetterdienst u. a. so zusammen:[21]

„Mit 10,1 Grad Celsius zweitwärmstes Frühjahr seit 1881“ („2,4 Grad höher als der Klimawert von 7,7 °C“)
„der sonnigste Frühling seit Beginn der Sonnenscheinmessungen im Jahr 1951.“ (699 Stunden - gut 50 Prozent über dem langjährigen Mittel von 459 Stunden)
„Extreme Trockenheit, besonders in der Mitte Deutschlands“
„Mit im Mittel spärlichen 88 Litern pro Quadratmeter (l/m²) - im Durchschnitt fallen sonst 186 l/m² - erlebte Deutschland den zweittrockensten Frühling seit Beginn der Messungen vor 130 Jahren. Den meisten Regen erhielten noch die Gebiete am unmittelbaren Alpenrand. … Am trockensten war es im südlichen Rheinland-Pfalz, im nördlichen Baden-Württemberg, in Hessen, in Unterfranken und im südlichen Thüringen. … Vor allem die Landwirtschaft litt unter der großen Dürre. So waren die Wiesen zwar früh schnittreif, die Erträge an Heu und Gras-Silage aber nur gering. Das Getreide blieb im Wuchs zurück und zeigte Ende Mai deutliche Anzeichen der Notreife. Im Mai waren die Pegel der meisten deutschen Flüsse so niedrig wie seit etwa 100 Jahren nicht mehr zu dieser Jahreszeit.“
Eine weitere Trockenheit gab es im Herbst 2011. September und Oktober brachten unterdurchschnittliche Niederschläge; der November war gebietsweise der trockenste November seit Beginn der Wetteraufzeichnungen.
Im Jahr 2018 kam es zu der Dürre und Hitze in Europa 2018, die u. a. in Deutschland großflächig schwere gesellschaftliche Folgen verursachte. Es kam zu großen Ernteausfällen, Niedrigwasser samt Transportproblemen über Wasserstraßen und zu zahlreichen Waldbränden. Diese Dürre setzte sich in den folgenden Jahren weiter fort. In Teilen Deutschlands, insbesondere Teilen von Brandenburg, Berlin, Sachsen-Anhalt, Niedersachsen und Frankens, setzte sich diese Dürre bis mindestens Sommer 2022 fort. In anderen Teilen Deutschlands löste sich die 2018 begonnene Dürre im Laufe des niederschlagsreichen Jahres 2021 auf. Dort bildete sich ab dem deutlich zu trockenen und zu warmen Winter 2021/22 eine neue Dürre aus.[22]

[Bearbeiten | Quelltext bearbeiten]
Von lang andauernden Trockenzeiten, die über das durchschnittliche Maß hinausgehen, sind in Europa vor allem die Mittelmeerländer betroffen.
2007 kam es in Griechenland, Spanien und Portugal zu monatelangen Dürren und zahlreichen Waldbränden. Stellenweise fiel fast der gesamte Wald den Flammen zum Opfer, was teilweise auf Brandlegungen der Bodenspekulation zurückgeht. Neue Gesetze für ein langjähriges Bauverbot sollen dies verhindern.
In weiten Teilen Spaniens herrschte von Frühjahr 2007 bis 2010 extreme Dürre – in einigen Provinzen regnete es 18 Monate lang nicht. Der Niederschlag war 2007/08 regional sehr unterschiedlich verteilt: während am Mittelmeer die 1½-jährige Dürre herrschte, gab es im April 2008 Überschwemmungen in Andalusien und in den spanischen Nordprovinzen.
Die regionalen Behörden bekämpften den Trinkwassermangel an der Küste mit Entsalzungsanlagen, was allerdings für die Bewässerung der Kulturen nicht ausreichte. Ab Beginn 2008 wurde daher der Einsatz von Tankschiffen geplant und an die EU-Solidarität appelliert. Die wasserreicheren Nordprovinzen lehnten einen Wassertransport in den Süden ab.[23]


Feuerspeiender Drache als Symbolisierung einer Dürre

Robert K. Booth u. a.: A severe centennial-scale drought in midcontinental North America 4200 years ago and apparent global linkages. In: The Holocene. Band 15, 2005, S. 321–328 (doi:10.1191/0959683605hl825ft).
Gerald Haug u. a.: Climate and the Collapse of Maya Civilization. In: Science. Band 299, 2003, S. 1731–1735. (doi:10.1126/science.1080444).
John McK. Camp II: A Drought in the Late Eighth Century B. C. In: Hesperia. Band 48, 1979, S. 397–411 (doi:10.2307/147843).
Benjamin I. Cook: Drought - An Interdisciplinary Perspective. Columbia University Press, New York 2019, ISBN 978-0-231-17689-7.




Claudia Krampe:  In: Naturgewalt.de. Archiviert vom Original am 21. April 2012; abgerufen am 17. November 2013 (vermutlich 2004). 
Helmholtz-Zentrum für Umweltforschung – UFZ, 
 (mit Daten des Erdbeobachtungsprogramms Copernicus)
Johannes Gutenberg-Universität Mainz: 
ZDF, . Arte, , YouTube, . Dokumentation von Jens Niehuss, Deutschland 2021, 43/54 Minuten.





Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Katastrophe (Begriffsklärung) aufgeführt.




Dieser Artikel oder Absatz stellt die Situation in Deutschland dar. Bitte hilf uns dabei, die Situation in anderen Staaten zu schildern.


Eine Katastrophe (altgriechisch καταστροφή katastrophé „Umwendung“, aus κατά katá „herab-“, „nieder-“ und στρέφειν stréphein „wenden“) ist ein folgenschweres Unglücksereignis. Oft wird der veraltende Begriff Verheerung als synonym angesehen.



Das Wort bedeutet eigentlich Wendung und bezeichnet speziell den Wendepunkt der Handlung in der Tragödie,[1] d. h. den Punkt, an dem sich das Schicksal des Helden zum Glück oder Unglück entscheidet. Hieraus entwickelte sich die Verallgemeinerung des Begriffs als entscheidendes Ereignis im Leben eines Menschen oder eines Volkes, als unglückliches Naturereignis usw.[2][3]
Eine Katastrophe ist im Zivil-, Bevölkerungs- und Katastrophenschutz eine größere Gefährdungs- und Gefahrenlage oder ein Schadenereignis. Ersteres umfasst drohenden, letzteres eingetretenen Schaden.
Die „Wendung“ (Peripetie) „zum Guten oder zum Schlechten“ war im antiken griechischen Drama ein zwingend erforderlicher dramaturgischer Kunstgriff der Handlung, um die Protagonisten – und mit ihnen das Publikum – entweder durch neuerliche „Wendung zum Guten“ einer Katharsis (Läuterung) zuzuführen oder bei einer „Wendung zum Schlechten“ für Fehlverhalten der Verdammung anheimfallen zu lassen. Dadurch ist der Begriff bis heute sowohl ethisch besetzt und auch sozialromantisch verklärt, wie auch Gegenstand der Sensationslust.
Eine nüchterne Bestimmung des Begriffs bereitet daher gewisse Schwierigkeiten.
Eine fachliche Definition, die Kriterien zur Katastrophenfeststellung (Einstufung als Katastrophenzustand) gibt, lautet etwa:



„Katastrophen sind durch elementare oder technische Vorgänge oder von Menschen ausgelöste Ereignisse, die in großem Umfang das Leben oder die Gesundheit von Menschen, die Umwelt, das Eigentum oder die lebensnotwendige Versorgung der Bevölkerung gefährden oder schädigen.“


– Tiroler Katastrophenmanagementgesetz[4]
Eine andere Sichtweise zur Definition präzisiert den schwammigen „großen Umfang“ weiter durch das Verhältnis des Schadens zu den regionalen Hilfsmöglichkeiten:



„Katastrophen sind […] Großschadenereignisse, die […] von den für die Gefahrenabwehr zuständigen Behörden mit eigenen Kräften und Mitteln nicht angemessen bewältigt werden können.“


– Katastrophenschutzgesetz Berlin[5]
Das Bayerische Katastrophenschutzgesetz vom 31. Juli 1970 definierte im Art 1 BayKSG: „Katastrophe im Sinne dieses Gesetzes ist eine so erhebliche gemeine Gefahr oder Not oder ein so schwerer Unglücksfall, daß Hilfe und Schutz nur wirksam gewährt werden können, wenn die dazu berufenen Behörden, Dienststellen und Hilfsorganisatinen unter einheitlicher Leitung der Katastrophenschutzbehörden zusammenwirken.“
Solche Definitionen seitens des Gesetzgebers sind Basis der Anforderung weiterer Hilfsmaßnahmen, personeller und technischer Natur ebenso wie von Hilfsgeldzahlungen. In diesem Sinne beschreibt der Begriff, dass die lokalen Strukturen und Kräfte mit der Situation überfordert sind, und ist von der Größenordnung (der Geographie wie der Betroffenen) unabhängig, kann also eine einzelne Wohnstelle oder Gemeinde ebenso betreffen wie einen ganzen Landstrich oder einen Staat. Typischerweise wird die Katastrophe in den Grenzen einer Verwaltungseinheit festgestellt.


Katastrophe im engeren Sinn ist eine länger andauernde und meist großräumige Schadenlage, die mit der normalerweise vorgehaltenen Gefahrenabwehr (Feuerwehr, Rettungsdienst, Polizei) nicht angemessen bewältigt werden kann und die nur mit überregionaler (oder internationaler) Hilfe und zusätzlichen Ressourcen (Militär sowie nicht-organisierte Bevölkerungsteile) unter Kontrolle gebracht werden kann.
Typisch dabei ist, dass durch das Ereignis (wie etwa Erdbeben, Hochwasser, Waldbrandserie)

die Infrastruktur (Straßen, Brücken, Wasserversorgung, Energieversorgung) beeinträchtigt und teilweise zerstört ist und/oder
die örtlichen Hilfskräfte und Hilfsressourcen (wie Polizei, Feuerwehr, Krankenhäuser) selbst geschädigt sind.
Regelmäßig kommt es zum Ausfall der Telekommunikationssysteme; sowohl wegen Überlastung als auch technischer Funktionsunfähigkeit. Mobilfunkanlagen können wie Festnetze beschädigt werden, aber auch bei Stromausfall nach einiger Zeit (Batteriepufferung) versagen.
Können dagegen nach mehrstündiger Anlaufphase, großräumiger Nachbarschaftshilfe aus nicht betroffenen Bereichen und Alarmierung von Hintergrunddiensten (dienstfreien Schichten, Freiwilligen Feuerwehren, Hilfsorganisationen wie dem Roten Kreuz, deren Schnelleinsatzgruppen sowie in Deutschland dem THW, beispielsweise durch Ausrufung des Ausnahmezustands) die akuten Gefahren etwa binnen eines Tages im Wesentlichen beseitigt werden, so spricht man im engeren Sinn nur von einem „Massenunfall“, einem „Großschadenereignis“ beziehungsweise „Massenanfall von Verletzten der Stufe 1 oder 2“. Lokale Ereignisse werden in aller Regel nicht als Katastrophen eingestuft, weil zum einen das Schadenausmaß begrenzt bleibt, zum anderen aus der näheren Umgebung genügend freie Hilfskräfte herangeführt werden können.
Gemäß dieser Begrifflichkeit (nach DIN 13050, DIN 14011) war beispielsweise

das Oderhochwasser 1997 eine Katastrophe, auch wenn auf deutscher Seite keine Menschen zu Schaden kamen, weil die regionalen Kräfte zur Deichverteidigung und damit Gefahrenbeseitigung bei weitem nicht ausreichten. Nationale Unterstützung und massiver Einsatz der Bundeswehr wurde für das mehrwöchige Geschehen erforderlich; „normale“ Bürger befüllten Sandsäcke.
der ICE-Unfall von Eschede 1998 noch keine Katastrophe, weil innerhalb einiger Stunden die regionalen Feuerwehren, das THW sowie die Rettungsdienste die Verletzten befreien und in Krankenhäuser bringen konnten. „Regional“ meint hier: Osthälfte Niedersachsens einschließlich Hamburg. Der Einsatz einzelner Hubschrauber zur weiteren Fernverlegung fällt dabei unter Nachbarschaftshilfe zur bestmöglichen Wiederherstellung der Gesundheit.
Die Akutphase ist diejenige, in der Gefahren für Menschen (unversorgte Verletzungen, aber auch Hunger, Seuchen, Kälte) weiter bestehen, Feuer unkontrolliert brennen oder Hochwasser noch nicht zurücksinkt. Nicht mehr zur Katastrophenlage zählen dagegen Aufräumarbeiten, Genesung und Wiederaufbau bei behelfsmäßiger Unterbringung und Versorgung betroffener Menschen.
Interpol verwendet aus polizeilicher Sicht (mit einem Schwerpunkt auf Identifizierung betroffener Personen und Getöteter) folgende Definition für eine Katastrophe:



„Eine Katastrophe ist ein unerwartetes Ereignis, bei dem zahlreiche Menschen getötet oder verletzt werden. Die Ereignisse, die zu Katastrophen führen können, sind vielfältiger Natur. Denkbar sind somit Einsätze nach Verkehrsunfällen, Naturkatastrophen, technischen Unfällen (Brand, Explosionen), terroristischen Anschlägen und kriegerischen Ereignissen. Hierbei ist zwischen einer offenen und einer geschlossenen Katastrophenform zu unterscheiden.Eine „offene Katastrophe“ ist ein Großschadensereignis, bei dem eine Gruppe unbekannter Personen getötet wurde, über die es keine vorherigen Aufzeichnungen oder Zugehörigkeiten gibt. Bei diesen Ereignissen ist es schwierig, Angaben über die Zahl der Opfer zu erhalten.Eine „geschlossene Katastrophe“ ist ein Großschadensereignis, bei dem eine Gruppe von Personen getötet wurde, die einem festen Kollektiv (z. B. Flugzeugabsturz mit Passagierliste) angehört. Handelt es sich um eine geschlossene Katastrophe, sind die antemortalen Vergleichsdaten i. d. R. schneller zu erheben. Denkbar sind auch Mischformen (Absturz eines Flugzeuges in ein Wohngebiet).“


– Disaster Victim Identification – Handbuch Interpol 2009[6]

Eingetretene oder drohende Katastrophen, pragmatisch aufgezählt, sind unter anderem:

Gesellschaftliche Katastrophen; betreffend Völkerrechte, Menschenrechte, Religionsfreiheit, Krieg und Frieden, Rechte von ethnischen Minderheiten:
Völkermord, Massenmord, Pogrom, Versklavung, Vertreibung
Hungersnot
Zivilisationskollaps
Wirtschaftliche Katastrophen:
Weltwirtschaftskrise,
Finanzkrise ab 2007
Katastrophen technisch-biologisch-medizinischer Art:
Nukleare Katastrophen (A-Gefahren, atomare Gefahren)
Seuchen (B-Gefahren, biologische Gefahren, Epidemien, Pandemien)
Chemiekatastrophen (C-Gefahren)
Datennetzbezogene Katastrophen (D-Gefahren)
Elektromagnetisch ausgelöste Katastrophen (E-Gefahren)
Katastrophen durch Freisetzung von mechanischer oder thermischer Energie (F-Gefahren: Druck (Zusammenstöße), Orkane, Brand, Explosionen), wie zum Beispiel
Unfälle der Binnenschifffahrt,
Unfälle der Luftfahrt,
schwere Seeunfälle,
Unglücke im Bergbau,
schwere Unfälle im Schienenverkehr,
Stauanlagenunfälle
Brückeneinstürze
Brand- und Explosionsunglücke
Unfälle auf Bohr- und Förderplattformen
bedeutende Ölunfälle
Häufig unterscheidet man, abhängig von der Ursache, zwischen „Naturkatastrophen“ und „technischen Katastrophen“.

„Naturkatastrophen“ sind Naturereignisse, denen Menschen ausgesetzt sind und die zum Ersticken, Ertrinken, Verdursten, Verhungern, Erfrieren, Verbrennen und vergleichbaren ernsthaften körperlichen Beeinträchtigungen (z. B. Krankheiten, Verätzungen) führen (wie Meteoreinschläge, Vulkanausbrüche, Lawinen, Erd- und Seebeben, Hochwasser, Waldbrände u. a. m.) Naturkatastrophen bis hin zur Klimakatastrophe sind in ihren Auswirkungen meist auch sozial beziehungsweise kulturell beeinflusst (sogenannte Man Made Disasters – siehe Hungersnot): Wenn z. B. Menschen Vulkanabhänge nicht besiedelt hätten, wäre ein Ausbruch oft keine „Katastrophe“.
„Technische Katastrophen“ haben als Auslöser ein Versagen (dazu gehört auch Fehlbedienung) einer technischen Einrichtung. Diejenigen „technischen Katastrophen“, die eine verheerende ökologische Beeinträchtigung bewirken, bezeichnet man auch als Umweltkatastrophen. Unfälle im Verkehr zu Wasser, Land und in der Luft gehören häufig zu den technischen Unfällen; sie sind hier unter anderen Kategorien, z. B. Brückeneinstürze oder Brand- und Explosionsunglücke, zu finden; als rein lokale Ereignisse handelt es sich jedoch in der Regel nicht um Katastrophen.

Ein Katastrophenmanagement soll sicherstellen, dass in einem Notfall angemessen reagiert werden kann.
Es besteht vorauslaufend im Allgemeinen aus:

Bedrohungs-(Worst-Case-)Analysen
Definieren von wahrscheinlichen Katastrophenfällen
Festlegen von Handlungsanweisungen
Beschaffung notwendiger Mittel und Vorhaltung bzw. Bevorratung an geeigneten Orten
Simulation von Katastrophenfällen und Überprüfung, ob die für einen Notfall festgelegten Mittel und Verfahren wirksam sind.
Es muss nachlaufend umfassen:

Sichere Wasserversorgung oder -lieferung
Offene Berichterstattung
Klare Kommandopfade
Robuste Kommunikationswege durch mobile Notfalleinrichtungen
Zuverlässige Einsatzlogistik
Vorrang für Transportwege
Nachdruck bei Leitungsreparaturen
Katastrophenmanagement umfasst

typischerweise als Katastrophe bezeichnete Ereignisse wie Feuer, Wasserschäden oder Erdbeben,
und auch die Fälle, in denen das Sicherheitsmanagement versagt hat.
Forschungen zum Katastrophenmanagement wie auch zur wirtschaftlichen Bedeutung von Katastrophen sind an den Universitäten selten, aber etabliert. Lars Michael Clausen hat die Katastrophensoziologie in Deutschland eingeführt.[7] Sein Schüler Martin Voss gründete eine Katastrophenforschungsstelle an der FU Berlin. Das Kieler Institut für Krisenforschung (Krisennavigator) forscht zu wirtschafts- und sozialwissenschaftlichen Aspekten. Die Deutsche Gesellschaft für Krisenmanagement e. V. (DGfKM) ist der Berufsverband der Krisen- und Katastrophenmanager.
Bei einer Katastrophe können auch Güter von hohem ideellen Wert bedroht sein. Ihren Erhalt zu sichern ist Ziel des Kulturgutschutzes.


Die Berichterstattung und Kommentierung mit Blick auf Katastrophen spielt für die Massenmedien eine erhebliche Rolle. Katastrophen sind unter der Rubrik Schaden ein zentraler Nachrichtenwert und gehören traditionell zu den Themen, die Medien vorrangig beachten und die beim Publikum auf großes Interesse stoßen. Auch die Kommunikationswissenschaft beachtet dieses Forschungsfeld seit langer Zeit sehr stark.


Philipp Henn, Gerhard Vowe: Facetten von Sicherheit und Unsicherheit. Welches Bild von Terrorismus, Kriminalität und Katastrophen zeigen die Medien? In: Medien & Kommunikationswissenschaft, 3/2015, S. 341–362.
Jörg Trempler: Katastrophen. Ihre Entstehung aus dem Bild. Wagenbach, Berlin 2013, ISBN 3-8031-5185-6 ( im Deutschlandradio).
François Walter: Katastrophen. Eine Kulturgeschichte vom 16. bis ins 21. Jahrhundert. Reclam, Stuttgart 2010, ISBN 978-3-15-010699-0.
Vladimir Petrovič Karcev, Petr Michajlovič Chazanovskij: Warum irrten die Experten? 3. Auflage. Verlag Technik, Berlin 1990, ISBN 3-341-00545-5.
Lars Clausen, Elke M. Geenen, Elísio Macamo (Hrsg.): Entsetzliche soziale Prozesse. Theorie und Empirie der Katastrophen. LIT, Münster 2003, ISBN 3-8258-6832-X.
Wolf R. Dombrowsky: Katastrophe und Katastrophenschutz. Eine soziologische Analyse. Deutscher Universitäts-Verlag, Wiesbaden 1989, ISBN 3-8244-4029-6.
Len Fisher: Katastrophen. Wie die Wissenschaft hilft, sie vorherzusagen. Übersetzt von Jürgen Neubauer. Eichborn, Frankfurt am Main 2011, ISBN 978-3-8218-6553-9.
Mohamed Gad-el-Hak (Hrsg.): Large-Scale Disasters. Prediction, Control, and Mitigation. Cambridge University Press, Cambridge 2008, ISBN 978-0-521-87293-5.
Ned Halley: Das große Buch der Katastrophen. Tessloff, Nürnberg 2000, ISBN 3-7886-0499-9.
Michael Kloepfer: Katastrophenrecht einschließlich Zivilschutz, Brandschutz, Rettungsdienst. Nomos, Baden-Baden 2009, ISBN 978-3-8329-4009-6.
Jörg Meidenbauer (Hrsg.): Die großen Katastrophen und Unglücksfälle. Chronik-Verlag, Gütersloh 1997, ISBN 3-577-14551-X.
Charles Perrow: Normale Katastrophen. Campus, Frankfurt am Main 1992, ISBN 3-593-34125-5.
Sebastian Roth: Krisen-Bildung. Aus- und Weiterbildung von KriseninterventionshelferInnen. Kovac, Hamburg 2008, ISBN 978-3-8300-3537-4.
Bundesamt für Bevölkerungsschutz und Katastrophenhilfe (Hrsg.): Dritter Gefahrenbericht der Schutzkommission beim Bundesminister des Innern. Bundesamt für Bevölkerungsschutz und Katastrophenhilfe, Bonn 2006, ISSN .
Martin Voss: Symbolische Formen. Grundlagen und Elemente einer Soziologie der Katastrophe. Transcript, Bielefeld 2006, ISBN 3-89942-547-2.
Gerrit Jasper Schenk, Jens Ivo Engels (Hrsg.): Historical Disaster Research. Concepts, Methods and Case Studies „Disaster“ / Historische Katastrophenforschung. Begriffe, Konzepte und Fallbeispiele. In: Historical Social Research / Historische Sozialforschung. 32, Nr. 3, 2007 (Sonderausgabe).
Patrick Masius, Jana Sprenger, Eva, Mackowiak (Hrsg.): Katastrophen machen Geschichte. Umweltgeschichtliche Prozesse im Spannungsfeld von Ressourcennutzung und Extremereignis. Universitätsverlag Göttingen, Göttingen 2010 ISBN 978-3-941875-21-0  (PDF; 3,3 MB).
Michaela Maier, Karin Stengel, Joachim Marschall: Nachrichtenwerttheorie. Nomos, Baden-Baden 2010, ISBN 978-3-8329-4266-3.
Rene Mono, Helmut Scherer: Wer zählt die Toten, nennt die Orte. Ist der internationale Nachrichtenfluss von Länderfaktoren oder Ereignismerkmalen determiniert? In: Publizistik, 2/2012, S. 135–159.
Johan Galtung, Mari Holmboe Ruge: The Structure of Foreign News. The Presentation of the Congo, Cuba and Cyprus Crisis in Four Norwegian Newspapers. In: Journal of Peace Research, 2/1965, S. 64–91.
Winfried Schulz: Die Konstruktion von Realität in den Nachrichtenmedien. Alber, Freiburg und München 1976, ISBN 3-495-47331-9.
Olaf Briese, Timo Günther: Katastrophe: Terminologische Vergangenheit, Gegenwart und Zukunft. In: Archiv für Begriffsgeschichte, 51, 2009, S. 155–95.
Olaf Briese: »Genommen auß den Comoedien«. Katastrophenbegriffe der neuzeitlichen Geologie. In: M. Eggers, M. Rothe (Hrsg.): Wissenschaftsgeschichte als Begriffsgeschichte. transcript, Bielefeld 2009, S. 23–50.
Mischa Meier: Zur Terminologie der (Natur-)Katastrophe in der griechischen Historiographie - einige einleitende Anmerkungen. In: G. J. Schenk, J. I. Engels (Hrsg.): Historical Disaster Research. Concepts, Methods and Case Studies – Historische Katastrophenforschung. Begriffe, Konzepte und Fallbeispiele. Köln 2007 (= Historical Social Research, 32.3 [2007]), S. 44–56.
Markus Bertsch, Jörg Trempler (Hrsg.): Entfesselte Natur: Das Bild der Katastrophe seit 1600. Michael Imhof Verlag, Petersberg 2018, ISBN 978-3-7319-0705-3.




Konferenzen und Meetings
 (englisch)
Katastrophenforschung
 (deutsches Portal zur Katastrophenforschung, Spin-off der Universität Kiel)
 (im Webarchiv)
 der Freien Universität Berlin (KFS)
 („KatNet“, Netzwerk mit deutschsprachiger Mailingliste und Newsletter)
 (DKKV)
Beispiele
Zum Hurrikan Katrina:  in Louisiana und Mississippi (englisch)
 auf anabell.de
 (englisch)
, Deutschlandfunk: Studiozeit – Aus Kultur- und Sozialwissenschaften im Juni 2011





Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Schaden (Begriffsklärung) aufgeführt.

Der Schaden (veraltet auch Schade, von mittelhochdeutsch schade) ist jeder materielle oder immaterielle Nachteil, den eine Person oder Sache durch ein Ereignis erleidet. Die Begriffe Schädigung und Beschädigung stehen dabei sowohl für das Zufügen beziehungsweise Erleiden eines Schadens wie auch synonym für den Schaden selbst.[1]






Dieser Artikel oder Abschnitt bedarf einer grundsätzlichen Überarbeitung. Näheres sollte auf der Diskussionsseite angegeben sein. Bitte hilf mit, ihn zu verbessern, und entferne anschließend diese Markierung.

Schaden ist immer eine unfreiwillige Einbuße, die jemand an seinen geschützten Rechtsgütern erleidet.[2]
Der Begriff ist damit generell sowohl ein wirtschaftlicher als auch ein juristischer. Er kann sowohl für die teilweise Zerstörung beziehungsweise den Defekt von Sachen (Sachschaden) wie auch für die körperliche oder gesundheitliche Beeinträchtigung von Personen (Personenschaden) stehen.[3] Schaden umfasst damit sowohl den Vermögensschaden, also den in Geld oder geldwerten Gütern (Verpflichtungen) ausdrückbaren Nachteil, als auch den ideellen oder nichtmateriellen Nichtvermögensschaden (Beeinträchtigung der Ehre). Nach der Differenzhypothese ist der Vermögensschaden der Unterschied zwischen der Vermögenslage des Geschädigten, wie sie sich infolge des schadenstiftenden Ereignisses ergeben hat, und seiner Vermögenslage, wie sie ohne dieses Ergebnis bestehen würde, wenn dabei der Ersatzanspruch selbst unberücksichtigt bleibt. Der entstandene Schaden kann nicht nur in Verlusten oder sonstigen Vermögensminderungen bestehen, sondern auch in einem entgangenen Gewinn. Hierbei wird dem Geschädigten eine Vermögensmehrung zugestanden, die er noch nicht realisiert hatte.



Schäden können in verschiedenen Formen und aus verschiedenen Gründen auftreten. Der Schaden kann ein Vermögens- oder Nichtvermögensschaden sein. Materielle Schäden können nach Art der Schädigung etwa in Bau-, Elektronik-, Fahrzeug- oder Motorschaden sowie Wald- und Flurschaden, sowie nach der Schadensursache z. B. in Blitz-, Brand-, Hochwasser-, Sturm-, Hagel-, Unfall- oder Feuchtigkeitsschaden unterteilt werden. Der Umfang der Schädigung beziehungsweise des notwendigen Ersatzes wird mit Teilschaden und Totalschaden erfasst.

An Vermögen kann ein in Geld messbarer materieller Schaden entstehen. Nach  Abs. 1 BGB  gibt es einen Geldersatz in der Regel nur für diesen Vermögensschaden. Zum ersatzfähigen Vermögensschaden gehört dem BGH zufolge auch die nutzlos aufgewendete Urlaubszeit,[4] die entgangene Gebrauchsmöglichkeit eines Kraftfahrzeuges[5] oder der zeitweise Fortfall der Nutzungsmöglichkeit durch Störung des Internets.[6]
Ein immaterieller Nichtvermögensschaden soll nur in besonderen Situationen ersetzt werden und kann etwa Körperverletzung, Gesundheitsschädigung, Ehrverletzung oder Freiheitsentziehung sein.[7] Entstehen aus einem Nichtvermögensschaden Aufwendungen (etwa Krankenhausaufenthalt), so gehören diese wiederum zum Vermögensschaden. Einen Geldersatz für den Nichtvermögensschaden gibt es nur in den vom Gesetz ausdrücklich erwähnten Fällen wie  Abs. 2 BGB (Schmerzensgeld u. a.),  BGB (Entschädigung für entgangene Urlaubsfreude) und  und  GG (Verletzung des Persönlichkeitsrechts). Bereits die im Gesetz erwähnte Formulierung „billige Entschädigung“ signalisiert, dass offenbar kein vollständiger Ausgleich für immaterielle Einbußen gewährt werden soll.[7]
Nach dem Kausalzusammenhang zwischen dem Ereignis und dem hierdurch entstandenen Schaden unterscheidet man

unmittelbare Schäden: sind die eingetretenen Schäden selbst,
mittelbare Schäden sind die Folgeschäden aus unmittelbaren Schäden.

Das Schadensrecht in Deutschland ist in den § bis  BGB geregelt, ohne dass eine Legaldefinition des Schadensbegriffs angeboten wird. Hier werden Art, Inhalt und Umfang einer Schadensersatzleistung bestimmt. Sie bilden jedoch keine eigenständige Anspruchsgrundlage und sind deshalb nur anwendbar, wenn ein Schadensersatzanspruch aufgrund anderer Vorschriften entstanden ist. Der Schaden, von dem in den §§ 249 ff. BGB ausgegangen wird, besteht in dem Unterschied zwischen der Vermögenslage des Geschädigten, wie sie sich infolge des schadenstiftenden Ereignisses ergeben hat, und seiner Vermögenslage, wie sie ohne dieses Ergebnis bestehen würde, wenn dabei der Ersatzanspruch selbst unberücksichtigt bleibt.[8] Der Begriff des Schadens ist also kein reiner Rechtsbegriff, sondern ein auf die Rechtsordnung bezogener wirtschaftlicher Begriff. Wer Schadensersatz zu leisten hat, hat die Pflicht, die gleiche wirtschaftliche Lage wiederherzustellen, wie sie ohne den Eintritt des zum Schadensersatz verpflichtenden Umstandes bestanden hätte. Er hat also den Geschädigten wirtschaftlich so zu stellen, wie er ohne den Schaden gestanden hätte.[9] Damit besteht also das Prinzip der Totalreparation, unabhängig vom Verschuldensgrad den gesamten Schaden zu ersetzen.


Der Schaden bemisst sich grundsätzlich nach der tatsächlich eingetretenen Vermögensminderung und der tatsächlich ausgebliebenen Vermögensmehrung. Er ist also in der Regel konkret zu berechnen. Teilweise ist aber auch eine abstrakte Berechnung möglich, die nicht auf die tatsächlich eingetretene Minderung abstellt, sondern auf den „gewöhnlichen Lauf der Dinge“ und den typischen Durchschnittsverlust. Dies ist z. B. der Fall beim Ersatz des entgangenen Gewinns nach § 252 Satz 2 BGB. Hier kann der Geschädigte entweder die tatsächlich ausgebliebene Vermögensmehrung geltend machen (konkrete Schadensberechnung), oder aber die ausgebliebene Vermögensmehrung, die nach dem gewöhnlichen Lauf der Dinge eingetreten wäre (abstrakte Schadensberechnung). Eine abstrakte Schadensberechnung findet sich auch in  Abs. 2 HGB.
Eine Schadensberechnung ist aufgrund der Differenzhypothese nur sehr schwer möglich, da sie oft an einer exakten Bestimmung des Vermögens nach dem Schadensereignis und einer hypothetischen Vermögenssituation ohne Schadenseintritt scheitert. Damit ein vorübergehender Nutzungsausfall ersatzfähig wird, hat der BGH Anforderungen an die Vermögensgegenstände gestellt:

der Vermögensgegenstand muss kommerzialisiert sein,[10]
die Nutzungseinbuße muss für den Geschädigten „fühlbar“ sein,[11]
es muss sich um einen objektbezogenen Eingriff handeln[12] und
die Nutzungseinbuße an Luxusgütern (Schwimmbad, Pelzmantel, Motorsportboot) stellt keinen ersatzfähigen Vermögensnachteil dar.[13]
Die Bewertung von Schäden ist oft problematisch, weil kein einheitlicher Bewertungsmaßstab existiert oder möglich ist. Begriffe wie hoher Schaden, geringer Schaden oder auch positiver Schaden lassen ebenfalls keine vergleichbare Aussage zur Wertigkeit eines Schadens zu. Daher gilt im Schadenersatzrecht der so genannte normative Schadensbegriff. Mit zu berücksichtigen sind Streuschäden, die nicht direkt auf einen Schadensfall anzurechnen sind, sondern deren Folgekosten darstellen, wie zum Beispiel Schienenersatzverkehr oder Taxirechnungen von Fahrgästen nach Sperrung einer Eisenbahnstrecke.
Allgemein lässt sich der Wert eines Schadens jedoch als Gegenwartswert, das heißt als Summe aktueller und zukünftiger und auf die Gegenwart bezogener Teilschäden beschreiben. Praktisch bietet sich die Möglichkeit, die durch den Schaden beziehungsweise die durch das schädigende Ereignis verursachte Veränderung, das heißt den Wegfall positiver und die Zunahme negativer zukünftiger Zahlungsströme als Zahlungsreihe zu modellieren und deren Barwerte zu summieren. Dafür bietet sich das Netto-Barwert- bzw. Discounted-Cash-Flow-Modell, eventuell ergänzt um eine Kaufkraftbereinigung, an.


Grundsätzlich muss jedermann seinen Schaden selbst tragen, insbesondere den durch Zufall eingetretenen („casum sentit dominus“). Nach diesem Grundsatz trägt der Eigentümer einen durch zufälligen Untergang entstandenen Schaden selbst ( BGB). Einen Schaden ersetzt erhält er entweder durch eine Versicherung oder durch Schadensersatzansprüche gegen die Schädiger oder Dritte. Die Pflicht, dem Geschädigten Schadensersatz zu leisten, erfordert einen besonderen Rechtsgrund kraft Gesetzes oder aus einem Vertragsverhältnis.

Gesetzliche Schadensersatzansprüche bestehen im Vertragsrecht (insbesondere §, , , , , , , ,  BGB), im Deliktsrecht (§ ff. BGB), im Sachenrecht ( BGB), im Familienrecht (§,  BGB) und im Erbrecht (§,  Abs. 2,  BGB).
Vertragliche Schadensersatzansprüche können einen oder alle Vertragspartner verpflichten, bei Eintritt eines bestimmten Ereignisses Schadensersatz zu leisten. Hierzu muss ein vertragliches Schuldverhältnis zwischen dem Geschädigten und dem Schädiger vorliegen.
Verlangt wird in beiden Fällen, dass ein eingetretener Schaden auf einer Rechtsverletzung beruhen muss (Kausalität).
Unter bestimmten Voraussetzungen wird der verursachte Schaden dem Schädiger zugerechnet, so dass er Schadensersatz leisten muss. In diesem Zusammenhang sind die Schadensminderungspflicht des Geschädigten sowie die Drittschadensliquidation beim Auseinanderfallen von Anspruchsinhaber und Geschädigtem von Bedeutung. In der Schifffahrt wird ein gegebenenfalls eingetretener Schadensfall mit Hilfe der Verklarung untersucht. Das Rechtsgebiet, das sich mit der Überwälzbarkeit des Schadens beschäftigt, ist das Schadenersatzrecht.


Das Schadensrecht kennt drei Arten der Schadensersatzleistung, und zwar die Naturalrestitution ( Abs. 1 und 2 BGB), den Wertersatz ( BGB) und den Ersatz eines entgangenen Gewinns ( BGB).[14]

Bei der Naturalrestitution ist der Zustand wiederherzustellen, der ohne das schädigende Ereignis bestünde. Sie betrifft Vermögens- und Nichtvermögensschäden.
Ist die Naturalrestitution nicht möglich, unzumutbar oder ungenügend, kommt es – nur bei Vermögensschäden – zum Wertersatz.
Nach der Legaldefinition gilt als entgangen „der Gewinn, welcher nach dem gewöhnlichen Lauf der Dinge oder nach den besonderen Umständen, insbesondere nach den getroffenen Anstalten und Vorkehrungen, mit Wahrscheinlichkeit erwartet werden konnte“ (§ 252 S. 2 BGB). Schadensersatzleistung wäre also dessen Ausgleich.

Der Schadensbegriff ist von zentraler Bedeutung für jede Art von Schadensversicherung, bei der der Versicherungsfall vorliegt, wenn das versicherte Ereignis eingetreten und dem Versicherten ein Schaden entstanden ist. Im Haftpflichtschadensfall ist der Unfallverursacher verpflichtet, dem Unfallopfer gemäß § 249 BGB den Schaden zu ersetzen, den er unfallbedingt erlitten hat. Der Unfallgeschädigte ist so zu stellen, wie er stehen würde, wenn der Unfall nicht eingetreten wäre. Im Haftpflichtschadenfall tritt kraft Gesetzes an die Stelle des Schädigers die Haftpflichtversicherung des Unfallbeteiligten (§ 3 Pflichtversicherungsgesetz). Zwischen dem eingetretenen Schaden und der Versicherungsleistung muss keine Identität bestehen, eine Versicherungsleistung kann auch niedriger ausfallen als der eingetretene Schaden. Von einem Totalschaden spricht man z. B., wenn die Wiederherstellung des beschädigten Fahrzeuges entweder nicht möglich (technischer Totalschaden) oder unwirtschaftlich ist (wirtschaftlicher Totalschaden).


Das sorgfältige Feststellen und das pflichtgemäße Berichterstatten der Schadenshöhe und -ursache nach Gebäudebränden forderten das Kurfürstentum Trier und weitere Kurfürstentümer des Heiligen Römischen Reiches bereits im 18. Jahrhundert durch Erlass entsprechender Anordnungen. Der Schadensbericht war an die „churfürstliche Landesregierung ohne allen Verzug“ zu erstatten.[15]


[Bearbeiten | Quelltext bearbeiten]
Das österreichische Recht geht von einem weiten Schadensbegriff aus. Gemäß  ABGB ist ein Schade (sic) „jeder Nachtheil, welcher jemanden an Vermögen, Rechten oder seiner Person zugefüget worden ist“. Besondere Haftungstatbestände (in Österreich: Amtshaftungsgesetz, Organhaftpflichtgesetz, Dienstnehmerhaftpflichtgesetz etc.) sowie Gefährdungshaftungen können dieses System modifizieren.

[Bearbeiten | Quelltext bearbeiten]
Auch in der Schweiz besteht ein Sachschaden in der Vermögenseinbuße, die aus der Beschädigung, Zerstörung oder dem Verlust einer Sache resultiert. Dabei wird das zum Schaden führende, nicht vorauszusehende Ereignis als „Unbill“ bezeichnet. Umstritten ist, ob Nutzungsstörungen bzw. Funktionsbeeinträchtigungen ein Sachschaden sind. Die Verletzung oder Tötung eines Tieres ist ebenfalls ein Sachschaden. Der entgangene Gewinn etwa durch Produktionsausfall („Chômage“) bei Verletzung eines Stromkabels[16] ist ein mittelbarer Sachschaden.






Frank Saliger: , HRRS, Aug./Sept. 2012.



Bitte den Hinweis zu Rechtsthemen beachten!


Der EU-Solidaritätsfonds (EUSF), auch Solidaritätsfonds der Europäischen Union genannt, wurde 2002 von der Europäischen Kommission ins Leben gerufen,[1] um Mitgliedsstaaten der Europäischen Union (EU), sowie deren Beitrittskandidaten[2] nach Naturkatastrophen großen Ausmaßes (evtl. auch Nuklearkatastrophen o. ä.), zügig finanzielle Unterstützung zukommen zu lassen. Anlass war damals die sog. Jahrhundertflut in Mitteleuropa.
Seitdem wurde der Fonds in 100 Katastrophenfällen von 28 Staaten in einem Volumen von insgesamt rund 7 Milliarden Euro in Anspruch genommen.[3] Deutschland erhielt nach EU-Angaben bis zum Jahr 2013 insgesamt rund 611 Millionen Euro, alleine 444 Millionen im Zuge des Hochwassers von 2002 (Jahrhundertflut).[2] Österreich erhielt aus dem Fonds bis zum Jahr 2014 170,6 Millionen Euro, denen nur Einzahlungen von 84,3 Millionen Euro gegenüberstehen.[4] Die höchste Summe für einen einzelnen Katastrophenfall wurde an Italien nach der Erdbebenserie in Mittelitalien seit 2016 ausgezahlt, nämlich 1,2 Milliarden Euro.[5]



Der EUSF wurde nicht mit dem Ziel eingerichtet, sämtliche von Naturkatastrophen verursachten Schäden zu decken. Er ist im prinzipiell darauf ausgerichtet, nicht versicherbare öffentliche Schäden zu beschränken und deckt daher beispielsweise private Verluste nicht ab. Mittel- bis langfristige Maßnahmen wie etwa Wiederaufbau, wirtschaftliche Unterstützungen und Präventionen können jedoch u. U. im Rahmen anderer Instrumente förderungsfähig sein. Infrage kommen hier insbesondere die EU-Strukturfonds sowie der Europäische Landwirtschaftsfonds für die Entwicklung des ländlichen Raums.[6]
Im Zuge der COVID-19-Pandemie wurde der Anwendungsbereich des EUSF am 30. März 2020 auf schwere öffentliche Gesundheitsnotstände ausgeweitet.[7][8]


Für EUSF-Mittel existiert kein „fester Topf“. Die Gelder, die neben dem regulären EU-Haushalt finanziert werden, richten sich nach dem jeweiligen Bedarf. Die jährlich im Haushalt zur Verfügung gestellte Summe beträgt seit 2014 500 Millionen Euro zu Preisen von 2011. Nicht verwendete Haushaltsmittel können auf das Folgejahr übertragen werden.[9] Für 2013 gibt es widersprüchliche Aussagen, ob diese Grenze bereits erreicht werden würde.[10][2] Die Auszahlung an Österreich fand dann am 14. Februar 2014 statt, nachdem der Antrag am 8. August 2013 gestellt wurde.[11]


[Bearbeiten | Quelltext bearbeiten]
Lediglich EU-Mitgliedsstaaten sowie Staaten in EU-Beitrittsverhandlungen können einen Hilfsantrag stellen, wenn die Schäden aus einer Naturkatastrophe (evtl. auch Nuklearkatastrophe o. ä.)

0,6 Prozent des Bruttonationaleinkommens oder
drei Milliarden Euro zu Preisen von 2011 betragen.[12]
[Bearbeiten | Quelltext bearbeiten]
Die Regierungen der betroffene EU-Mitgliedsstaaten müssen innerhalb von zwölf Wochen (bis 2014 zehn Wochen[13]) nach Eintreten der Katastrophe Unterstützung aus dem EUSF bei der Europäischen Kommission beantragen, welche über den Antrag entscheidet. Die Kommission schlägt dem Europäischen Parlament und dem Rat der Europäischen Union die als angemessen erachtete Beihilfesumme vor.
Bisher wurde der Fonds bei in 100 Katastrophenfällen genutzt. Darunter waren Überschwemmungen, Waldbrände, Erdbeben, Stürme und Dürren. Dabei wurden 28 verschiedene europäische Länder mit über 7 Milliarden Euro unterstützt.[3]

[Bearbeiten | Quelltext bearbeiten]
Damit es letzten Endes zu einer Auszahlung von Mitteln kommen kann, müssen das Europäische Parlament sowie der Rat der Europäischen Union die Mobilisierung genehmigen, da diese gemeinsam die Haushaltsbehörde bilden. Sobald Mittel im EU-Haushalt zur Verfügung stehen, kann die Beihilfe ausgezahlt werden.[3]







Dieser Artikel ist nicht hinreichend mit Belegen (beispielsweise Einzelnachweisen) ausgestattet. Angaben ohne ausreichenden Beleg könnten demnächst entfernt werden. Bitte hilf Wikipedia, indem du die Angaben recherchierst und gute Belege einfügst.



Erdbeben von Kōbe




 



Datum

17. Januar 1995


Uhrzeit

05:46:52 Uhr


Intensität

7  


Magnitude

7,2 MW 








Epizentrum

34° 35′ 54″ N, 135° 2′ 6″ O34.598333135.035Koordinaten: 34° 35′ 54″ N, 135° 2′ 6″ O


Land

Japan


Tsunami

Nein


Tote

4.571 Menschen[1]


Verletzte

rund 14.700 Menschen[1]


Sachschaden

etwa 100 Milliarden US-Dollar




Das Erdbeben von Kōbe (jap. 阪神・淡路大震災 Hanshin Awaji daishinsai, dt. „Hanshin-Awaji-Erdbebenkatastrophe“), offizielle Bezeichnung „Süd-Hyōgo-Erdbeben“ (兵庫南部地震 Hyōgo nambu jishin), ereignete sich am 17. Januar 1995. Das Beben der Nojima-Verwerfung von Awaji zum Berg Rokkō begann um 05:46:52 Uhr Ortszeit, hielt etwa 20 Sekunden an und erreichte eine Stärke von 7,3 nach der japanischen (Lokalbeben-)Magnitudenskala Mj (nach der alten Definition bis 2003), oder Mw 7,2 auf der Momenten-Magnituden-Skala. Es war das erste Beben, das auf der 1949 eingeführten JMA-Skala, einer Intensitätsskala, die höchstmögliche Stufe 7 erreichte. Sein Epizentrum lag etwa 20 km südwestlich vom Stadtzentrum von Kōbe in der Straße von Akashi, das Hypozentrum lag in einer Tiefe von 16 km.[1]



Durch das Erdbeben und seine Folgen starben allein in der Stadt Kobe 4.571 Menschen, rund 14.700 Menschen wurden verletzt;[1] unter den Toten waren überdurchschnittlich viele ältere Bürger und Frauen. Insgesamt gab es 6 434 Tote.
300.000 Menschen wurden durch das Erdbeben obdachlos, viele davon erst durch die mehr als 300 vom Beben ausgelösten Brände. Nach einem besonders regenarmen Sommer waren die Zisternen der Stadt nicht mit Löschwasser aufgefüllt worden, so dass die Feuerwehr den meisten Bränden tatenlos zusehen musste.
61.000 Gebäude wurden völlig zerstört, 7300 brannten aus und 55.000 wurden in größerem Ausmaß beschädigt.[1]
Die Hanshin-Autobahn, die auf Stelzen durch das Kōbe-Ōsaka-Gebiet führt, brach über eine Länge von etwa fünf Kilometern zusammen. Auch zahlreiche andere Gebäude, die als sicher galten, hielten dem Beben nicht stand. Typisch war der Kollaps im Erdgeschoss oder in einem mittleren Geschoss.
Zur Zeit des Erdbebens waren Büros und Firmen unbesetzt, Geschäfte sowie Straßen leer, Straßen- und Schienenverkehr noch fast im Ruhezustand. Zu anderer Tageszeit hätte die Zahl der Opfer um ein Vielfaches höher gelegen.
Zugang und Zufahrten zum Hafen wurden zerstört und Hafenanlagen stark beschädigt.[1]
Die Gesamtsumme aller durch das Erdbeben verursachten Schäden wird auf etwa 100 Milliarden US-Dollar geschätzt.


Staatliche Stellen wurden im In- und Ausland wegen zahlreicher Versagen heftig kritisiert. Dringend benötigte Güter wie Nahrungsmittel, Wasser und Decken wurden tagelang gar nicht, später nur völlig unzureichend ins Krisengebiet geschafft; Notunterkünfte von staatlicher Seite nicht bereitgestellt. Ein Großteil der arbeitslos gewordenen und sich selbst überlassenen Bevölkerung verstopfte mit PKWs die wenigen passierbaren Straßen z. B. nach Osaka, um Nötiges für sich und Nachbarn einzukaufen.
Die Kehrseite japanischer Organisation trat zutage: Mangel an Eigeninitiative ließ Polizei und später herbeigerufene Gruppen von Soldaten zu untätigen Statisten werden. Eine effiziente Verkehrsleitung etwa auf der Hauptachse, Route #2, wurde erst fünf Tage nach dem Beben organisiert. Tragische Einzelschicksale nicht geretteter Angehöriger hinterließen Verbitterung.
Auf der anderen Seite konnten sich staatliche Stellen kaum überwinden, außer Finanzmitteln auch tatkräftige ausländische Hilfe zu akzeptieren. Für Schlagzeilen sorgte etwa das Festsetzen der Schweizer Lawinenrettungsgruppe mit ihren Hunden am Flughafen Kansai, die mit Quarantäne-Bestimmungen tagelang hingehalten und schließlich auf bereits von Schutt geräumte freie Flächen geführt wurden. Solidarität aus dem Ausland, vor allem aber eine Welle freiwilliger Hilfsaktionen im Land, fing einen Teil der staatlichen Versäumnisse auf.
Im Anschluss wurde das Katastrophenmanagement entscheidend verbessert, indem den lokalen Feuerwehren und der Armee stärkeres eigenverantwortliches Handeln erlaubt wurde, sodass beim Erdbeben in Niigata 2004 die Behörden wesentlich schneller reagierten.[2]





Südseite von Tokyu Hands in Sannomiya






Nordseite von Tokyu Hands






Hankyu-Bahnhof Sannomiya






Stadtbezirk Hyogo






Im Stadtbezirk Hyogo






Geschäft im Stadtbezirk Hyogo






Als Folge der tektonischen Verschiebungen wurden die Pfeiler der Akashi-Kaikyō-Brücke, die sich zum Zeitpunkt des Bebens im Bau befand und heute Honshū mit der Insel Awaji verbindet, um fast einen Meter auseinandergeschoben. Die Bauarbeiten konnten allerdings ohne Verzögerungen fortgesetzt werden.
Der japanische Aktienindex Nikkei 225 fiel am Tag nach dem Erdbeben um über tausend Punkte. Dies führte indirekt zum Ende der Barings Bank, da deren Mitarbeiter Nick Leeson hohe Summen in Optionen auf den Nikkei investiert hatte. Die letztendlichen Verluste von über 1,4 Milliarden US-Dollar trieben die Barings Bank in den Bankrott.
Der Hafen von Kōbe, vormals der umschlagstärkste Nicht-Ölhafen der Welt, fand nach den Zerstörungen nicht mehr zu seiner früheren Rolle zurück. Ebenso büßten die Schuhindustrie und andere verarbeitende Gewerbe dauerhaft an Substanz ein.
Kōbe erhielt im Zuge des Wiederaufbaus eine modernere, auf Erdbebensicherheit und Katastrophenmanagement ausgerichtete Infrastruktur.
Der 17. Januar ist, vor allem in Kansai, zum Tag des Katastrophenschutzes und der freiwilligen Hilfe (防災とボランティアの日, Bōsai to Borantia no Hi) geworden (zusätzlich zum Tag des Katastrophenschutzes am 1. September).
Im Gedenken an die Opfer wird alljährlich im Dezember in Kōbe das Lichterfest Kōbe Luminarie abgehalten.


Stadtbezirk Nagata
Stadtbezirk Higashinada
Tōhoku-Erdbeben 2011


 Erdbebendatenbank der NOAA

 (PDF; 129 kB) city.kobe.jp; Stand: 1. Januar 2009
 (Kinki Regional Development Bureau)
Osamu Kunii, Masumi Akagi, Etsuko Kita:  (PDF). In: Medicine & Global Survival. Volume 2, 1995, Number 4
Anselm Smolka (1996): Das große Hanshin-Erdbeben. Geowissenschaften 14, 18–22 doi:10.2312/geowissenschaften.1996.14.18
Alexander Kast (1996): Kobe – Zentrum des Kansai-Bebens: vorher und nachher. Geowissenschaften 14, 24–27 doi:10.2312/geowissenschaften.1996.14.24




Dieser Artikel behandelt den Hurrikan Katrina des Jahres 2005. Andere Stürme mit dem Namen Katrina finden sich unter Tropischer Sturm Katrina.


Hurrikan Katrina


Kategorie-5-Hurrikan (SSHWS)


Hurrikan Katrina bei größter Stärke am 28. August 2005


Entstehung

23. August 2005


Auflösung

31. August 2005


Spitzenwind-geschwindigkeit




175 mph (280 km/h) (1 Minute anhaltend)




Niedrigster Luftdruck

902 mbar (hPa; 26,7 inHg)


Tote

1836 gesamt


Sachschäden

108 Milliarden US-$ (2005)


BetroffeneGebiete

Bahamas, Süd-Florida, Kuba, Louisiana (insbesondere New Orleans und Umgebung), Mississippi, Alabama, Florida Panhandle, Ostküste der Vereinigten Staaten


Saisonübersicht:Atlantische Hurrikansaison 2005

Der Hurrikan Katrina gilt als eine der verheerendsten Naturkatastrophen in der Geschichte der Vereinigten Staaten. Der Hurrikan richtete Ende August 2005 in den südöstlichen Teilen der USA, insbesondere an der dortigen Golfküste, gewaltige Schäden an und erreichte zeitweise die Stufe 5. Zu den betroffenen Bundesstaaten gehörten Florida, Louisiana (besonders der Großraum New Orleans), Mississippi, Alabama und Georgia.
Durch den Sturm und seine Folgen kamen 1836 Menschen ums Leben. Der Sachschaden belief sich auf etwa 108 Milliarden US-Dollar. Insbesondere die Stadt New Orleans war stark betroffen: Durch ihre geographische Lage führten zwei Brüche im Deichsystem dazu, dass bis zu 80 Prozent des Stadtgebietes bis zu 7,60 Meter tief unter Wasser standen.



[Bearbeiten | Quelltext bearbeiten]



Der Hurrikan bildete sich am 23. August während der Atlantischen Hurrikansaison 2005 über den Bahamas und überquerte Florida zunächst als gemäßigter Hurrikan der Kategorie eins, bevor er im Golf von Mexiko rasant an Stärke gewann und zu einem der heftigsten Wirbelstürme wurde, die dort jemals verzeichnet wurden. Als er das Land erreichte und die Überflutung von New Orleans auslöste, hatte er schon bedeutend an Energie verloren und war bereits in die Kategorie drei abgestuft worden.

[Bearbeiten | Quelltext bearbeiten]
Am 23. August bildete sich bei den südöstlichen Bahamas das zwölfte tropische Tiefdruckgebiet (tropical depression) der Saison als Folge der Wechselwirkung einer tropischen Welle und den Überbleibseln des zehnten tropischen Sturmtiefs. Unter günstigen Voraussetzungen konnte sich daraus schon am Morgen des nächsten Tages ein gewaltiger tropischer Sturm entwickeln, der fortan den Namen „Katrina“ trug. Schon am 24. August verstärkte sich die Zyklone zu einem tropischen Sturmtief (tropical storm). Am Morgen des 25. August 2005, kurz nachdem Katrina als Hurrikan Stufe eins klassifiziert worden war, zog er unter weiterer Intensivierung zunächst nach Nordwesten, dann nach Westen und erreichte in der Nähe von Miami zwischen den Städten Hallandale und Aventura schließlich die Südspitze Floridas. 14 Menschen kamen dabei ums Leben.[1] Katrina schwächte sich über Land leicht ab und wurde für einige Stunden vom Hurrikan zum Tropensturm herabgestuft.
Eine Stunde, nachdem er den Golf von Mexiko erreicht hatte, erlangte er wieder den Status eines Hurrikans. Durch hohe Wassertemperaturen um 30 °C sowie infolge einer starken Divergenz der Höhenströmung setzte ein rapider Druckabfall und damit eine massive Verstärkung ein. Am Morgen des 27. August erreichte der Sturm die dritte Stufe der Saffir-Simpson-Hurrikan-Windskala (major hurrican), wodurch er zum dritten Großen Hurrikan des Jahres anwuchs. Der Kerndruck war mittlerweile auf 940 hPa gefallen sowie die Windgeschwindigkeiten auf 185 km/h angestiegen. Am Morgen des 28. August 2005 wurde er schließlich in Stufe fünf gesetzt und um ein Uhr nachmittags erreichte er seine maximale Stärke. Katrina wies zu diesem Zeitpunkt Windgeschwindigkeiten von bis zu 280 km/h sowie Sturmböen von bis zu 344 km/h auf. Sein Kerndruck war auf 902 hPa abgefallen. Katrina war damit einer der schwersten gemessenen Stürme im Golf von Mexiko, wurde aber nur wenige Wochen später von Hurrikan Rita übertroffen.
In den frühen Morgenstunden des 29. August 2005 (Montag), kurz nachdem er durch interne turbulente Prozesse auf die Stufe vier zurückgestuft wurde, traf er bei Buras-Triumph in Louisiana auf die Südküste der USA. Beim Auftreffen auf das Festland verringerte sich die Windgeschwindigkeit auf 200 km/h. Nachdem er sich über das südöstliche Louisiana bewegt hatte, wurde er in der Nähe des Mississippi River zum dritten Mal von Land gesichtet. Dabei schwächte er sich in der Nacht zum 30. August zum tropischen Sturm und schließlich zum tropischen Tief ab.[2]
Etwa 1,3 Millionen Menschen verließen nach entsprechenden Aufrufen der lokalen Behörden das Gebiet rund um New Orleans und flüchteten bis nach Texas. Schon einige Tage vor dem Landgang Katrinas bei New Orleans hatte der National Weather Service vor Katrina gewarnt und kontinuierlich neue Modellrechnungen über Intensität und Zugbahn des Hurrikans veröffentlicht sowie Informationen über die zu erwartenden Niederschläge und Flutwellen bereitgestellt. Die Beobachtungsdaten stammten hauptsächlich von Wettersatelliten und Hurrikan-Fliegern, die in die mittleren Höhenbereiche des Wirbelsturms einflogen und Fallsonden (Dropsonden) aussetzten. Diese Sonden lieferten Messdaten über Windgeschwindigkeit, Luftdruck, Temperatur und Luftfeuchte, die per Funk zur Bodenstation gesendet wurden. Hurrikan-Piloten berichteten, dass die Turbulenzen im eye-wall, dem Cumulonimbus-Wolkenwall um das Auge des Orkans, unvorstellbare Intensitäten erreicht haben sollen.[3]


[Bearbeiten | Quelltext bearbeiten]
Beim Auftreffen von Katrina auf Florida gab es nur ungenügende Warnungen, da sich der Sturm sehr schnell von einem harmlosen Unwetter in einen Hurrikan verwandelt hatte. Als Katrina in Höhe Miami-Dade- und Broward County auf das südliche Florida traf, konnte die Küstenwache viele Personen, die im betroffenen Gebiet wohnten, evakuieren. Am 25. August 2005 erreichte der Hurrikan die Städte Aventura (Miami-Dade County) und Hallandale (Broward County). Allerdings hatten die Prognosen des National Hurricane Center (NHC) zutreffend vorausgesagt, dass sich Katrina auf die Größe eines Hurrikans verstärken würde, bevor er das Land erreichte; Beobachtungen und entsprechende Warnungen waren bereits zwischen 31,5 und 19,5 Stunden vorher veröffentlicht worden, also nur geringfügig verspätet gegenüber dem üblichen Zielkorridor von 24 bis 36 Stunden.
Als Reaktion auf das Vorrücken von Katrina auf die Küste rief Floridas Gouverneur Jeb Bush am 24. August den Notstand aus. Im südlichen Teil des Bundesstaates wurden daraufhin Unterkünfte eröffnet sowie Schulen geschlossen. Ebenso wurde eine Reihe von (meist freiwilligen) Evakuierungsaufforderungen erlassen. Für die besonders gefährdeten Wohnungen in Martin County wurde die Evakuierung gesetzlich angeordnet.

[Bearbeiten | Quelltext bearbeiten]
Am Vormittag des 25. August um zehn Uhr hatte sich Katrina, die sich noch im Golf von Mexiko befand, auf die Stufe drei vergrößert. Am Nachmittag erkannte das National Hurricane Center, dass Katrina bereits den Weg über die Halbinsel von Florida eingeschlagen hatte, und revidierte seine überarbeitete Prognose, wonach der Sturm vom Zipfel Floridas direkt zur Mississippi-Küste ziehen würde. Das NHC richtete daraufhin am 27. August um zehn Uhr vormittags ein besonderes Augenmerk auf die Situation im südöstlichen Louisiana, einschließlich New Orleans und dessen nähere Umgebung. Am Nachmittag beschloss das NHC, die Beobachtung auf die Küstenlinien der Staaten Mississippi und Alabama sowie die Küstengebiete Louisianas bis nach Intracoastal City auszudehnen.
Am 27. August, bevor der Sturm wieder die Küste erreichte, der mittlerweile auf Stufe 3 hochgestuft worden war, rief US-Präsident George W. Bush den Notstand für die drei Bundesstaaten Louisiana, Mississippi und Alabama aus. Am selben Abend erhöhte das NHC seine Prognose für den Abschnitt Morgan City (Louisiana) und der Grenze zwischen Florida und Louisiana wiederum, indem es zwölf Stunden nach der vorherigen Bekanntgabe eine Hurrikanwarnung verkündete. Ferner gab es für den Küstenbereich des nordwestlichen Floridas eine Warnung bezüglich eines tropischen Sturms heraus.
Am 28. August, als die Größe von Katrina bekannt wurde, dehnte das NHC seine Warnungen auf den gesamten Küstenbereich von Louisiana und den größten Teil des nordwestlichen Floridas aus. Das Büro New Orleans/Baton Rouge des nationalen Wetterdienstes gab daraufhin einen anschaulichen Lagebericht heraus, der voraussagte, dass die Region nach dem „vernichtenden Schaden“, der von Katrina verursacht worden war, „auf Wochen unbewohnbar“ sein werde; zu dieser Zeit waren die Auswirkungen von Katrina mit denen des Hurrikan Camille aus dem Jahr 1969 vergleichbar.
In weiten Gebieten des südöstlichen Louisiana sowie in den Küstengebieten der Bundesstaaten Mississippi und Alabama gab es sowohl auf freiwilliger als auch auf gesetzlich angeordneter Basis Evakuierungen. Insgesamt wurden etwa 1,2 Millionen Bewohner der Golfküste evakuiert.

[Bearbeiten | Quelltext bearbeiten]

Am 26. August wurde die Möglichkeit einer noch nie da gewesenen Katastrophe fest einkalkuliert. Viele Computermodelle hatten den potenziellen Weg von Katrina 230 Kilometer westlich vom Nordwesten Floridas festgelegt, die Stadt New Orleans lag genau im Zentrum der wahrscheinlichsten Route. Die Wahrscheinlichkeit, dass die Zugroute die Stadt trifft, betrug 17 Prozent, am 28. August erhöht auf 29 Prozent. Die Risiken eines direkten Auftreffens des Hurrikans auf New Orleans waren bekannt: Studien der Federal Emergency Management Agency und des United States Army Corps of Engineers hatten bereits davor gewarnt, dass dies zu einer massiven Überflutung führen könnte. Dadurch würden Tausende ertrinken, noch viele weitere würden an Krankheiten und an Mangel an sauberem Trinkwasser sterben, da sich das Flutwasser nur langsam aus der Stadt zurückziehen würde.
Abgesehen von möglichen Dammbrüchen sollte das vordere rechte Viertel des Hurrikans mit den stärksten Winden eine 8,5 Meter hohe Flutwelle verursachen; die Funktionsträger des Notfallmanagements befürchteten, dass diese die Deiche der Stadt New Orleans überwinden könnte und so eine Flutkatastrophe verursachen würde. Die besondere Gefahr für New Orleans beruhte auf seiner Lage: Insbesondere die Gebiete am nahe gelegenen Pontchartrain-See befinden sich unter dem Niveau des Meeresspiegels, die Stadt selbst zu etwa 80 %, ihr näherer Umkreis zu etwa 20 %.
Deshalb sollten die Stadt New Orleans und die gefährdeten Bereiche Louisianas an diesem Tag erstmals zwangsevakuiert werden. Ein Hurrikan der Stufe drei hätte den Southeast Louisiana Hurricane Evacuation and Sheltering Plan vom Januar 2000 auslösen sollen. Der Plan verteilte klar die Zuständigkeit der staatlichen Stellen; Personen, die über keine Kraftfahrzeuge verfügten, sollten mit Schulbussen evakuiert werden. Die Busse versanken jedoch ungenutzt.
Wer die Stadt nicht rechtzeitig verlassen konnte, sollte jetzt im Louisiana Superdome, dem Football-Stadion in New Orleans, Zuflucht finden. Die Zahl der Menschen, die in den Superdome flohen, lag zwischen 20.000 und 60.000. Auch der Superdome wurde während des Sturms schwer beschädigt und später von den Fluten eingeschlossen, so dass er ebenfalls evakuiert werden musste.

[Bearbeiten | Quelltext bearbeiten]

In Vorbereitung auf den Sturm aktivierte der Staat Mississippi seine Nationalgarde am 26. August. Zusätzlich stellte die Regierung des Bundesstaates am Folgetag sein Operationszentrum für Notfälle in Dienst, und die lokalen Verwaltungen begannen, Evakuierungsbefehle auszuführen. Am 28. August um 19 Uhr führten elf Countys und elf Städte Zwangsevakuierungen durch. Am Morgen des Folgetags waren es bereits 412 Countys und 61 Städte. Zudem wurden in den Küstengemeinden 57 Notunterkünfte und 31 zusätzliche Unterkünfte, die im Bedarfsfall ebenfalls zur Verfügung stehen sollten, eingerichtet.
Der Plan von Louisiana für die Evakuierung im Falle eines Hurrikans sieht vor, dass lokale Verwaltungen von Gebieten an beziehungsweise in der Nähe der Küste Evakuierungsmaßnahmen in drei Phasen durchführen. Dabei sollen diese 50 Stunden vor dem Start der tropischen Windböen in der unmittelbaren Küstenregion beginnen. Gebiete, die der zweiten Phase zugeordnet sind, sollen 40 Stunden vor dem Einbruch des Sturmes evakuiert werden und Gebiete der Phase drei, zu der auch New Orleans gehört, 30 Stunden vor dem Sturm.
Allerdings waren mehrere solcher Fürsorge leistenden privaten Einrichtungen, die sich auf Busunternehmen und Evakuierungsrettungsdienste verließen, nicht in der Lage, ihren Aufträgen nachzukommen. Der Vorrat an Treibstoff und Ersatzautos war nicht sehr hoch, und mehrere öffentliche Nahverkehrssysteme waren vor dem Eintreffen des Sturms geschlossen worden. Nach einigen Schätzungen wurden 80 % der 1,3 Millionen Einwohner der Metropolregion von New Orleans evakuiert, und weitaus weniger Menschen blieben zurück als bei der Evakuierung nach dem Hurrikan Ivan im Jahr 2004.
Am 28. August, einem Sonntag, war fast die gesamte Infrastruktur entlang der Golfküste geschlossen worden, einschließlich des Eisenbahnverkehrs der Canadian National Railway und der Amtrak, der in die betroffene Region führte, sowie das Kernkraftwerk Waterford. Das NHC hielt seine Warnungen bis zum Tagesende des 29. August aufrecht, als Katrina bereits den Staat Mississippi erreicht hatte.


[Bearbeiten | Quelltext bearbeiten]
Nach dem Sturm wurden 1836 Tote offiziell bestätigt. Ray Nagin, der Bürgermeister von New Orleans, vermutete zunächst, dass bis zu 10.000 Menschen an den Folgen des Sturms gestorben seien. Im Januar 2006 wurden laut CNN noch etwa 3200 Personen vermisst. In den ersten Tagen warteten viele auf ihren Häuserdächern auf Rettung. Trinkwasser in der Region wurde knapp, da das Leitungssystem durch den Bruch einer Versorgungsleitung mit Flutwasser kontaminiert wurde.
Hurrikan Katrina ist der kostspieligste Wirbelsturm, der die USA bisher heimsuchte. Experten schätzten anfangs die Schäden auf mehr als 26 Milliarden Euro. Später wurde diese Zahl auf mindestens 125 Milliarden Euro korrigiert. Der Versicherungsschaden belief sich auf 62,2 Milliarden US$.[4] Mit dieser Schadensgröße übertrifft er Hurrikan Andrew, der 1992 den Süden Floridas verwüstete und die bis dahin größte Sturmkatastrophe seit Beginn der Aufzeichnung von Stürmen in den Vereinigten Staaten war. Die Größe des materiellen Schadens überstieg ebenfalls die des Seebebens im Indischen Ozean 2004. Der Hurrikan übertraf auch die wirtschaftlichen Schäden der Terroranschläge am 11. September 2001 bei Weitem.
Experten gingen von einer Million obdachlos gewordener Menschen aus. Etwa fünf Millionen Menschen hatten keinen Strom. Schätzungen gingen davon aus, dass es über zwei Monate dauern könne, bis dieser wieder flächendeckend verfügbar sei.
Wegen der Versorgungskrise wurde versucht, in den Staaten Louisiana und Mississippi den Ausnahmezustand auszurufen und das Kriegsrecht zu verhängen, was die Gesetze der beiden Staaten eigentlich nur im tatsächlichen Kriegsfall zulassen. Dennoch wurde in der Stadt New Orleans am 1. September 2005 das Kriegsrecht verhängt. Die Gouverneurin von Louisiana forderte die Nationalgarde auf, Plünderer zu erschießen.

[Bearbeiten | Quelltext bearbeiten]

Am 25. August traf Hurrikan Katrina im Süden Floridas zum ersten Mal auf Land, wo er als Hurrikan der ersten Stufe mit einer Windgeschwindigkeit von 130 Kilometern pro Stunde aufschlug. An einigen Orten gab es heftige Regenfälle, und in der Stadt Homestead betrug der Wasserpegel mindestens 35 Zentimeter. Im Monroe County maß die Sturmflut zwischen einem und anderthalb Metern. Mehr als eine Million Menschen verfügten über keinerlei Elektrizität mehr, und der in Florida entstandene Schaden wurde auf einen Betrag von 1 bis 2 Milliarden Dollar geschätzt, größtenteils durch die Flut und umgestürzte Bäume verursacht. Laut Bericht gab es in Florida insgesamt 14 Menschen, die durch Hurrikan Katrina umkamen.[5]
Die meisten Inseln der Florida Keys erlebten die tropischen Windböen von Katrina, als sich das Zentrum des Sturmes in Richtung Norden bewegte, wobei der Sturm laut Berichten über die Dry Tortugas zog. Auch auf dieser Inselgruppe gab es starke Regenfälle, davon allein 25 Zentimeter in Key West. Am 26. August bildete sich ein Tornado der Stärke F1 auf der Fujita-Skala aus einem äußeren Regenband von Katrina und zog durch die Stadt Marathon. Dieser Tornado beschädigte einen Hangar am Flughafen und verursachte einen Sachschaden von etwa fünf Millionen Dollar.
Obwohl Hurrikan Katrina deutlich nördlich von Kuba blieb, brachte er am 29. August tropische Windböen und in den westlichen Regionen der Insel Regenfälle von mehr als 20 Zentimetern mit sich. Sie beschädigten Telefon- und Stromkabel und etwa 8000 Menschen wurden in der Region Pinar del Río evakuiert. Laut Fernsehberichten aus Kuba stand die Küstenstadt Batabanó zu 90 Prozent unter Wasser. Allerdings gab es in Kuba keine Berichte über Todesfälle infolge von Hurrikan Katrina.

[Bearbeiten | Quelltext bearbeiten]

Am 29. August kam Hurrikan Katrina in der Nähe von Buras-Triumph mit Winden von 205 Kilometern pro Stunde als Sturm der Stufe 3 an. Sie hatte sich aber erst kurze Zeit zuvor von der Stärke 4 abgeschwächt und der Radius der stärksten Winde war riesig. Es ist möglich, dass im äußersten Südosten Louisianas kurzzeitig Winde der Stärke 4 über Land wehten. Obwohl die Sturmflut östlich des Wegs des Auges in Mississippi höher war, traf eine sehr große Flut die Küste von Louisiana. Die Höhe der Flut ist aufgrund fehlender Daten nicht bekannt, obwohl ein Flutpegel in Plaquemines Parish eine Sturmflut mit einem Übermaß von mehr als vier Metern angezeigt hatte und in Grand Isle eine Flut von drei Metern registriert wurde.
Hurrikan Katrina bescherte Louisiana heftige Regenfälle mit bis zu 25 Zentimetern, die in einem breiten Streifen im Osten des Staates fielen. In der Gegend von Slidell waren die Regenfälle noch heftiger; der höchste Wasserstand, der im Staat verzeichnet wurde, war ungefähr 38 Zentimeter. Infolge der Regenfälle und der Sturmflut stieg der Pegel des Pontchartrain-Sees und verursachte entlang des nordöstlichen Ufers große Überflutungen, die die Gemeinden von Slidell bis Mandeville betrafen. Das Wasser zerstörte mehrere Brücken einschließlich der Interstate-10-Zwillingsbrücke, die Slidell mit New Orleans verbindet. Fast 900.000 Menschen in Louisiana waren durch Hurrikan Katrina ohne Strom.
Im besonders schwer mitgenommenen St. Bernard Parish, das Katrina vollständig überflutete, ging die Suche nach Vermissten nur langsam voran. Laut einem Interview der The Times-Picayune aus New Orleans hatte der Coroner im November 2005 immer noch versucht, vom Amerikanischen Roten Kreuz eine Liste der Vermissten zu bekommen. Während auf dieser Liste einige Opfer waren, deren Leichen in ihren Häusern gefunden wurden, wurde die überwältigende Mehrheit durch Mundpropaganda und durch Listen der Kreditkartengesellschaften ausfindig gemacht. Bis Dezember 2005 standen insgesamt 147 Personen auf der offiziellen Vermisstenliste.
Allein in Louisiana starben 490 Menschen durch den starken Sturm. Einige starben auch in ihren Häusern, da diese durch den Sturm zerstört wurden.

[Bearbeiten | Quelltext bearbeiten]

 Satellitenbilder von New Orleans


Obgleich die Deiche („Levees“) des Mississippi River bei New Orleans hielten, durchbrachen die aufgepeitschten Flutwellen die kleineren Wände zweier Kanäle auf einer Länge von 150 m. Ab diesem Zeitpunkt floss unkontrolliert Brackwasser aus dem Lake Pontchartrain in die Stadt New Orleans. Da sich New Orleans zwischen dem Lake Pontchartrain und dem Mississippi sowie unterhalb von deren Wasserspiegel befindet, standen nach dem Bruch der Dämme bis zu 80 Prozent des Stadtgebietes bis zu 7,60 Meter tief unter Wasser. Es gelang nicht, die Dämme mit Sandsäcken abzudichten. Der Vorschlag, das Loch mit einem Schiff zu stopfen, wurde nicht umgesetzt. Wegen des Stromausfalls konnte das Wasser zunächst nicht abgepumpt werden. Die Stadt war über die Zufahrtsstraßen nicht mehr zu erreichen oder zu verlassen. Einer der beiden Flughäfen musste seinen Betrieb einstellen, da er komplett unter Wasser stand. Der zweite Flughafen wurde von Hurrikan Katrina nicht vollständig zerstört. Das Flughafengebäude und die Landepiste blieben intakt. Lediglich auf Radar und Bodenbeleuchtung mussten die Piloten verzichten. Nach Angaben der Flughafenleitung konnten rund 300 Flüge täglich abgewickelt werden.
An weiteren Stellen hatte das Wasser begonnen, die Deiche zu unterhöhlen. Selbst gegen die neu entstandenen Dammbrüche schienen die Krisenmanager der Region machtlos, da sowohl die notwendige Zahl an Helfern, als auch das Material und die Gerätschaften fehlten, den Ursachen entgegenzuwirken.
Die Wetteraussichten verhießen nichts Gutes: Für das Wochenende war eine schwere Wetterfront gemeldet, die die Hilfsarbeiten weiterhin erschwert hätten. Beim Bruch weiterer Dammteile oder bei neuem starken Niederschlag wäre nicht nur die Stadt vollständig überflutet worden, sondern auch das Hinterland mit schätzungsweise 20.000 dortigen Bewohnern vom Hochwasser betroffen gewesen. Dies wäre auch organisatorisch für die Rettungsmannschaften ein schwerer Rückschlag gewesen, da die Erreichbarkeit der Stadt aus dem Hinterland heraus mittels Hubschraubern dann nicht mehr reibungslos gesichert gewesen wäre.
Die Evakuierung des Louisiana Superdome, der eine Notunterkunft für zahlreiche Menschen darstellte, wurde ausgesetzt, nachdem angeblich ein Hubschrauber beschossen worden war. Rund um den Superdome wurden Mülltonnen in Brand gesetzt.[6] Auch die bereits angelaufene Evakuierung mit Bussen wurde ausgesetzt, nachdem bereits die ersten Busse im Reliant Astrodome in Houston angekommen waren. Der Astrodome sollte als Ersatz für den Superdome herhalten und den evakuierten Menschen als Notunterkunft dienen. Doch bereits am 2. September war der Astrodome überfüllt und konnte keine weiteren Flüchtlinge mehr aufnehmen. Berichte über Schüsse auf Rettungshubschrauber wurden unterdessen gegenüber ABC News von einer Federal-Aviation-Administration-Sprecherin dementiert.[7]


Die stärksten Hurrikans in den Vereinigten Staaten
Stärke wird nur auf Grund des Luftdrucks im Zentrum angegeben.


Rang

Hurrikan

Saison

Luftdruck(in mbar)


1

Labor Day

1935

892


2

Camille

1969

900


3

Irma

2017

914


4

Katrina

2005

920


5

Andrew

1992

922


6

Indianola

1886

925


7

Florida Keys

1919

927


8

Okeechobee

1928

929


9

Miami

1926

930


10

Donna

1960

932


Quelle: HURDAT,[8] Hurricane Research Division[9]

Die Evakuierung des Superdomes wurde am 3. September erneut unterbrochen, weil immer noch zu wenige Busse zur Verfügung standen,[10] und am Tag darauf abgeschlossen.[11]
Angesichts der einsetzenden Skandalberichterstattung vieler Medien schien in der Stadt Anomie zu herrschen, gegen die die Polizei und das Militär verzweifelt den Versuch unternahmen, die Lage unter ihre Kontrolle zu bringen. Zeitweise wurden alle Rettungseinsätze in der Stadt abgebrochen, da es wiederholt zu Angriffen auf die Rettungsmannschaften gekommen sei.
Über zwei Krankenhäuser wurde berichtet, sie würden von Plünderern besetzt. In das Convention Center seien 10.000 bis 20.000 Menschen geflüchtet. Diese Einrichtungen wurden in den ersten Tagen nach der Katastrophe vollkommen vernachlässigt.[12][13] Die Menschen dort mussten ganz ohne Versorgung auskommen. Es kursierten Berichte, dass Banden in der Nacht Jugendliche im Convention Center vergewaltigten und töteten. Am 3. September begann die Evakuierung des Convention Center, die am Tag darauf abgeschlossen wurde.[11]
Die Seuchengefahr durch das verschmutzte Wasser, in dem Leichen, Abfälle, Chemikalien und Kot trieben, stieg stetig. Besonders bakterielle Darminfektionen und Hepatitis A wurden befürchtet. Es wurden einige Fälle von Ruhr gemeldet. Das Risiko eines Ausbruchs von Cholera und Typhus wurde noch als relativ gering eingestuft.
Am Ostufer der Stadt kam es am Morgen des 2. September zu zwei Detonationen. Am 3. September berichtete CNN von zwei großen Bränden in der Industriegegend am Mississippi.[14]
Nach Aussagen des Bürgermeisters Ray Nagin sollte es zwischen drei und vier Monate dauern, bis die Menschen wieder in die Stadt zurückkehren könnten. Es wurde allerdings auch erwogen, die Stadt ganz oder zumindest zum Teil aufzugeben. Der republikanische Kongressabgeordnete Dennis Hastert meinte, es sei sinnlos, in eine Stadt zu investieren, die unterhalb des Meeresspiegels liege.[15] Drei Jahre später lebten von den ursprünglichen 450.000 Bewohnern noch 120.000 Bewohner über die USA verteilt, und die Mieten stiegen um bis zu 50 Prozent. Fast jeder zweite dieser Evakuierten lebte noch in Notunterkünften oder erhielt noch bis März 2009 Mietgutscheine. Die Stadt hatte sich entschieden, die Besiedlungsdichte in den sozial schwachen Wohngebieten drastisch zu senken, zu diesem Zweck die Wohnanlagen nicht zu sanieren und vor allem in Innenstadtlage abzureißen, um diese für gemischtere Mieterschichten neu zu bebauen.[16] Von den fünf öffentlichen Schulen blieben noch 2008 vier Schulen geschlossen und erst die Hälfte der Krankenhäuser funktionierte wieder.[17]

[Bearbeiten | Quelltext bearbeiten]

Die Golfküste von Mississippi erlitt am 29. August massiven Schaden durch die Auswirkungen von Hurrikan Katrina. Es wurden insgesamt 238 Todesopfer gezählt und 67 vermisst. Die Stadt Biloxi wurde größtenteils zerstört. Der materielle Schaden lag in Milliardenhöhe. Nachdem Katrina für kurze Zeit das erste Mal in Louisiana auf Land getroffen war, verließ sie das Meer endgültig an der Grenze zwischen Louisiana und Mississippi. Der Sturm zog als Hurrikan der Stufe 3 über die Städte Bay St. Louis und Waveland mit anhaltenden Winden von 195 Kilometern pro Stunde. Das kräftige vordere rechte Viertel von Katrina zog über die mittleren und westlichen Küstengebiete Mississippis und verursachte eine Sturmflut, die in vielen Gegenden bis zu zehn Kilometern in das Inland eindrang und bis zu 20 Kilometern an Orten, die an den Buchten oder Flüsse liegen. In einigen Gebieten reichte die Sturmflut sogar bis an die Interstate 10 heran.
Katrina verwüstete die Küste von Mississippi auf einer Länge von über 160 Kilometern; die Beschädigungen zogen sich bis nach Alabama fort. Über viele Stunden erhöhte sich der Wasserspiegel um 9 Meter[18] bzw. über 12 Meter[19] und wurde durch großen Wellengang begleitet. Die Winde hielten fast 36 Stunden lang an.
65.380 Häuser wurden in Mississippi insgesamt beschädigt oder zerstört,[20] davon alleine rund 19.900 in Biloxi. In vielen Straßenblöcken widerstand kein einziges Haus dem Hurrikan. Boote und Haushaltsgeräte wurden nach dem Unwetter oft erst Kilometer entfernt wiedergefunden. Wind, Regen und die Sturmflut machten einige Wohngebiete, die unmittelbar am Strand lagen, dem Erdboden gleich. Ein Wohnungskomplex mit ungefähr 30 Bewohnern, die nach einer Unterkunft gesucht hatten, brach in sich zusammen. Erste Schätzungen von Funktionsträgern des Staates rechneten damit, dass 90 Prozent der Strukturen innerhalb eines Kilometers entlang der Küste komplett zerstört wurden. Mehr als die Hälfte der insgesamt 13 Casinos im Staat, die auf Prunkschiffen zu Wasser gelassen worden waren, um dem auf dem Festland geltenden Glücksspielgesetz des Staates zu entgehen, trieben die Wellen hunderte Meter ins Inland.

[Bearbeiten | Quelltext bearbeiten]
Obwohl Katrina in der Region um die Staaten Mississippi und Louisiana auf Land traf, wurden auch Alabama und der Nordwesten Floridas von einer großen Sturmflut und tropischen Windböen in Mitleidenschaft gezogen. Anhaltende Winde mit einer Geschwindigkeit von 107 Kilometern pro Stunde wurden in Mobile in Alabama registriert. Die Sturmflut war dort ungefähr drei Meter hoch. Entlang der Mobile Bay verursachte die Flut große Überschwemmungen, die mehrere Kilometer weit ins Festland eindrangen. Ebenso traten in Alabama insgesamt vier Tornados auf.


Ein in Bau befindlicher Bohrturm am Mobile River zerbrach an seinem Liegeplatz und wurde zwei Kilometer weit nach Norden getrieben, bevor er auf der Cochrane Bridge in der Nähe der Stadt Mobile aufschlug. Der Schaden auf Dauphin Island war drastisch, da die Flut mehrere Häuser zerstörte und einen neuen Kanal durch den westlichen Teil der Insel zerschnitt. Ein küstennaher Bohrturm strandete ebenfalls auf der Insel. Genau wie in Mississippi verursachte die Sturmflut auch an der Küstenlinie Alabamas Auswaschungen am Strand. In Alabama verloren mehr als 600.000 Menschen infolge von Hurrikan Katrina ihr Hab und Gut, außerdem starben dort zwei Menschen bei einem Verkehrsunfall.
Entlang des nordwestlichen Floridas war die Sturmflut die meiste Zeit über etwa anderthalb Meter hoch; an der mittleren Westküste Floridas war sie mit etwa einem halben Meter deutlich niedriger. In der Stadt Pensacola wurden am 29. August Winde mit einer Geschwindigkeit von 90 Kilometern pro Stunde registriert. Die Winde verursachten einige Schäden an Bäumen und der Infrastruktur, außerdem wurde der Nordwesten Floridas geringfügig überflutet. Außerdem gab es im Walton County bei einem Verkehrsunfall, der sich infolge von Katrina ereignet hatte, ebenfalls zwei Todesopfer.
Der Norden und der mittlere Teil von Georgia wurden von schweren Regenfällen und heftigen Stürmen in Mitleidenschaft gezogen, da der Sturm sich in Richtung Inland bewegt hatte; in mehreren Gebieten betrugen die Regenfälle mehr als siebeneinhalb Zentimeter.

[Bearbeiten | Quelltext bearbeiten]


Hurrikane in den USA mit den meisten Toten


Rang

Hurrikan

Saison

Opfer


1

„Galveston“

1900

8000–120001


2

„Okeechobee“

1928

> 25001


3

Katrina

2005

1836


4

„Cheniere Caminada“

1893

1100–14001


5

„Sea Islands“

1893

1000–20001


6

„Florida Keys“

1919

778


7

„Georgia“

1881

7001


8

Audrey

1957

416


9

„Labor Day“

1935

408


10

„Last Island“

1856

4001


1geschätzt, gesamtQuelle: NOAA[21]

Hurrikan Katrina wurde allmählich schwächer, während er sich weiter ins Inland bewegte. Allerdings wurden selbst am 30. August auf der Höhe von Fort Campbell (Kentucky) noch tropische Windböen registriert, und die Stürme beschädigten sogar Bäume im Bundesstaat New York. Die Reste des Sturms bescherten weiten Gebieten im Osten der USA starke Regenfälle und in Teilen von insgesamt 20 Bundesstaaten stand das Regenwasser fünf Zentimeter hoch. Am 30. und 31. August bildeten sich infolge von Katrina 62 Tornados in acht Staaten, die allerdings nur kleinere Schäden anrichteten.
In Kentucky hatte am Wochenende zuvor ein Sturm Überflutungen angerichtet, die nun durch die Regenfälle von Katrina noch verstärkt wurden. Ernie Fletcher, der Gouverneur von Kentucky, erklärte drei Countys zu Katastrophengebieten und rief im gesamten Bundesstaat den Notstand aus. In Hopkinsville kam ein Mensch ums Leben und Teile einer High School stürzten ein. Überflutungen in West Virginia und Ohio führten dort zu einer Reihe von Evakuierungsmaßnahmen, die Regenfälle in Ohio führten zu zwei Todesfällen. Außerdem verursachte Katrina in vielen Gebieten, insbesondere in den Großräumen Memphis und Nashville Stromausfälle. Insgesamt waren mehr als 100.000 Verbraucher in Tennessee zeitweise ohne Strom.
Die Reste von Katrina kamen mit einem frontalen System über Ohio zusammen, aber die Feuchtigkeit zog nach Norden und tat am 31. August in Kanada ihr Übriges. In Ontario gab es vereinzelt Berichte über Regenfälle von zehn Zentimetern und ebenso einzelne Berichte über Schäden, die durch umgestürzte Bäume hervorgerufen worden waren. Überflutungen traten sowohl in Ontario als auch in Québec auf, dabei schnitten sie eine Reihe abgelegener Dörfer von der Außenwelt ab.


[Bearbeiten | Quelltext bearbeiten]
Im föderalistischen System der USA wird staatliche Macht grundsätzlich zunächst auf kommunaler Ebene, dann durch den Bundesstaat ausgeübt. Nur für bestimmte Aufgaben oder Notsituationen ist die Bundesregierung primär zuständig. Demnach war für die Notfallreaktionen in New Orleans zunächst die Stadtverwaltung unter Bürgermeister Ray Nagin verantwortlich. Der für Notfälle durch Hurrikane vorbereitete Comprehensive Emergency Management Plan wurde vom Bürgermeister jedoch nicht gestartet: Mehrere hundert Schulbusse standen schon bereit, geeignet zum Abtransport zehntausender Personen; sie wurden jedoch vom Bürgermeister nicht eingesetzt. Mehrere hundert kommunale Polizisten verließen ihre Posten und waren somit für den Zusammenbruch der Sicherheitslage mitverantwortlich, in Einzelfällen beteiligten sie sich sogar an Plünderungen. Auch die Gouverneurin Kathleen Blanco verhielt sich weitgehend passiv. Erst auf massiven politischen Druck des eigentlich unzuständigen US-Präsidenten Bush wurde die Evakuierung von New Orleans angeordnet.

[Bearbeiten | Quelltext bearbeiten]

Eine sogenannte Disaster-Recovery-Reaktion begann vor dem Sturm, als die Federal Emergency Management Agency Vorbereitungen traf. Als der Sturm das Land erreichte, leistete ein Netzwerk Freiwilliger sowohl Einheimischen als auch Menschen, die sich zu diesem Zeitpunkt in New Orleans aufhielten, Hilfe. Diese Hilfeleistungen dauerten noch mehr als sechs Monate nach dem Sturm an.
US-Präsident Bush überflog am 31. August auf der Rückreise von seiner Ranch, auf der er sich nach dem Abflauen des Hurrikans noch drei Tage aufgehalten hatte, nach Washington das Krisengebiet. In einer Rede versprach er, dass alle nötige Hilfe geleistet werde und dass jedes Ausnutzen der Notsituation, sei es Wucher bei Treibstoffpreisen oder Plünderungen, bestraft werde.[22] Die New York Times kritisierte, die Rede sei eine der schlechtesten in seinem Leben gewesen und nichts in seinem Verhalten deute darauf hin, dass er den Ernst der Lage begriffen hätte.[23] Erst am 2. September reiste Bush ins Katastrophengebiet, wo er verkündete, der Kongress habe 10,5 Milliarden US-Dollar Soforthilfe zur Verfügung gestellt.[24] Ray Nagin, Bürgermeister von New Orleans, hatte am Tag zuvor in einem Interview mit dem Radiosender WWL heftige Kritik an der Regierung in Washington geübt, deren Hilfe zu zögerlich komme.[25] Kathleen Blanco, Gouverneurin von Louisiana, schloss sich der Kritik an. Bush äußerte daraufhin, die Kritik sei „unangemessen und inakzeptabel“.
Nach heftiger Kritik hatte Bush am 9. September 2005 den Direktor der Bundesbehörde für den Katastrophenschutz (FEMA), Michael Brown, von seiner Vor-Ort-Koordinationsarbeit entbunden. Brown trat am 12. September 2005 von seinem Amt zurück. So überraschend, wie der Präsident sagte, war das Ausmaß der Katastrophe nicht. Bereits im Oktober 2001 brachte die Zeitschrift Scientific American einen Artikel, in welchem das Szenario exakt beschrieben wurde.[26][27]
Im Oktober 2006 wurde der Insurrection Act, der bis dahin nur bei Aufständen einen Militäreinsatz im Innern der USA erlaubte, auf Naturkatastrophen, terroristischen Anschläge, Epidemien und andere nationale Notständen ausgeweitet. Das United States Northern Command etablierte daraufhin die Joint Task Force (JTF) Katrina, die ihre Basis auf Camp Shelbey hatte. Bis zu 51.000 Angehörige der Nationalgarde wurden aktiviert,[28] um die Folgen des Sturms zu beheben, die Truppen kamen aus allen 50 US-Staaten. Präsident Bush bekam erneut Unterstützung der früheren Präsidenten Bill Clinton und seines Vaters George Bush, die auch schon 2004 nach dem Seebeben im Indischen Ozean für ein höheres Spendenaufkommen gesorgt hatten.

[Bearbeiten | Quelltext bearbeiten]

Im Golf von Mexiko befinden sich einige hundert Bohrtürme und Bohrinseln. Insgesamt 30 Bohrinseln wurden durch Katrina entweder beschädigt oder zerstört. Über ein Viertel des amerikanischen Erdöls und Erdgases wird in dieser Region gefördert. Die dortige Ölproduktion, die ungefähr 24 Prozent der jährlichen Produktion ausmacht, wurde für die folgenden sechs Monate nach Katrina eingestellt. Die dortigen Raffinerien stellen den Großteil der US-Kapazität dar. Große Ölkonzerne mussten einige von Katrina gefährdete Förderanlagen stilllegen. Acht Raffinerien bleiben weiterhin geschlossen, und eine weitere arbeitet nur mit geringer Kapazität. Viele Pipelines wurden ebenfalls zerstört. Dies führte zu Steigerungen des Rohölpreises an der New Yorker Börse auf historische Höchststände von über 70 Dollar pro Barrel.
Wegen der ausgefallenen Raffineriekapazitäten stiegen die Treibstoffpreise weltweit stark an, da ein globales Erhöhen der Förderkapazität nicht mehr möglich war (vgl. Peak-Oil). In den USA kletterte der Benzinpreis von gut $ 2/gal (ca. 0,43 €/l) auf rund $ 3/gal (ca. 0,65 €/l). An einigen Stellen stieg der Preis zeitweise auf bis zu $ 8/gal (1,72 €/l). Auch zwölf Monate nach dem Sturm waren 15 Prozent der Öl- und 11 Prozent der Gasfördermengen noch immer nicht wiederhergestellt. Grund dafür waren die immer noch nicht abgeschlossenen umfangreichen Reparaturmaßnahmen.
In den Wochen unmittelbar nach Katrina wurde Treibstoff vor allem im mittleren Süden stark rationiert. Fast alle Tankstellen mussten vorübergehend den Tankbetrieb einstellen, da Benzin- und Dieselkraftstoffe nur sporadisch an die Tankstellen geliefert werden konnten und pro Fahrzeug begrenzt abgegeben wurden (Ausnahmen bildeten Einsatz- und Rettungsfahrzeuge). Eine weitere Folge des knappen Kraftstoffangebotes war die vorübergehende Schließung zahlreicher Geschäfte, vor allem Fast-Food-Lokale in Louisiana, Mississippi und Alabama. Sowohl Personal als auch Produkte hatten kaum die notwendigen Transportmöglichkeiten. Eine Normalisierung setzte erst vier Wochen nach Katrina ein.
In Deutschland stieg der Benzinpreis binnen Tagen um 18 Cent/l und erreichte somit am 3. September einen Höchststand von rund 1,45 € (2,21 Fr.) pro Liter Superbenzin. In der Schweiz stiegen die Bleifrei-95-Preise um rund 14 Rappen/l, was je nach Region und Marke Rekordhöhen zwischen 1,69 und 1,83 Fr. (1,10 € – 1,20 €) pro Liter ausmacht. Das V-Power von Shell nähert sich an einigen Orten gar der 2-Franken-Grenze. In Österreich kostete das Normalbenzin rund 1,20 € (1,83 Fr.). Zumindest in den USA gab es durch den Hurrikan eine Energiekrise, bspw. konnten 13 % des täglichen Kerosinbedarfs wegen des Sturms nicht mehr gedeckt werden. Um die Energiekrise einzudämmen, hatte die US-Regierung die Vorschriften für die Sauberkeit von Benzin ausgesetzt, die den Schwefelgehalt im Benzin regulieren, da die Reinigung des Benzins dessen nutzbare Menge herabsetzt.

[Bearbeiten | Quelltext bearbeiten]
Katrina hatte tiefgreifende Auswirkungen auf die Umwelt. Die Sturmflut verursachte erhebliche Erosionen an den Küsten, und in einigen Fällen wurden diese komplett verwüstet. Auf Dauphin Island wurde der Sand, aus dem die dortige Sandbank besteht, ungefähr 150 Kilometer östlich der Stelle, an dem der Hurrikan das Festland erreichte, quer über die Insel in den Mississippi Sound transportiert, wodurch die Insel in Richtung Festland verschoben wurde. Die Sturmflut und die Wellen richteten auch substanzielle Verwüstungen auf den Chandeleur Islands an, die bereits im Jahr zuvor von Hurrikan Ivan in Mitleidenschaft gezogen worden waren.
Das verloren gegangene Land diente zum Teil auch als Brutstätte für Meeressäugetiere, Braunpelikane, Schildkröten und Fische sowie für Wandervögel wie die Rotkopfente. Insgesamt 20 Prozent der lokalen Marschen wurden als Folge des Sturms von Wasser überschwemmt. Katrina hatte auch zur Folge, dass 16 Naturschutzgebiete geschlossen werden mussten, unter denen das Breton National Wildlife Refuge den größten Schaden erlitten hatte, da allein die Hälfte des Gebiets fortgespült wurde. Ebenso wirkte sich der Hurrikan auf die Lebensräume der Meeresschildkröten, der Kanadakraniche, der Kokardenspechte und der Alabama-Küstenmäuse aus.
Als Teil der Reinigungsbemühungen wurden schließlich die Flutgewässer, die New Orleans heimgesucht hatten, in den Pontchartrain-See gepumpt, was insgesamt 43 Tage dauerte. Dieses Wasser enthielt eine Mischung aus Abwasser, Bakterien, Schwermetallen, Pestiziden, giftigen Chemikalien und etwa 6,5 Millionen Gallonen Öl, die Wissenschaftler befürchten ließen, dass massenhaftes Fischsterben folgen würde.

[Bearbeiten | Quelltext bearbeiten]
Kurz nachdem der Hurrikan am 30. August weiterzog, waren einige in der Stadt gebliebene Bewohner von New Orleans in ihrem Elend darauf angewiesen, in Geschäften nach Lebensmitteln und Wasser oder nach Dingen, die wegen der Zerstörungen nicht mehr erhältlich waren, zu suchen. Dabei nutzten selbst Polizisten die Situation auch für reine Plünderungen aus.
In den Sensationsmedien gab es fortlaufend Berichte über Autodiebstähle, Morde, Einbrüche und Vergewaltigungen; später wurde der Wahrheitsgehalt der meisten Meldungen in Frage gestellt. Tausende Angehörige der Nationalgarde und der Bundestruppen wurden zusammengesucht und zusammen mit einer Reihe Vollzugsbeamter aus dem ganzen Land nach Louisiana geschickt. Louisianas Gouverneurin Kathleen Blanco sagte laut Associated Press: „Sie haben M16-Gewehre, die gesichert und geladen sind. Diese Truppen wissen, wie sie schießen und töten sollen, und sie sind mehr als motiviert, das zu tun, und ich erwarte, dass sie es tun werden.“[29] Der demokratische Kongressabgeordnete William J. Jefferson aus Louisiana sagte in den ABC News: „Die Schießereien setzten sich fort. Die Heckenschützen trieben weiterhin ihr Unwesen. Erst in der ersten Septemberwoche hielten in der Stadt Recht und Ordnung allmählich wieder Einzug.“


Es gab mehrere Schießereien zwischen der Polizei und Bewohnern von New Orleans. Weiße Bürgerwehren erschossen nach Schätzungen von Bürgerrechtlern „mehrere Hundert der 1800 Katrina-Toten“. Leichen, die noch Wochen nach der Flut auf den Straßen lagen, wurden von einer Privatfirma im Auftrag der Regierung in Massengräbern beigesetzt. Staatsanwaltliche Ermittlungen, so die Bürgerrechtler, habe es nicht gegeben.[30]
Der Filmemacher Rasmus Holm dokumentierte in Welcome to New Orleans (2006)[31] das Verhalten weißer Bürgerwehren aus einem weißen Vorort, dem Stadtteil Algiers Point, die offen von ihrer Jagd auf Afroamerikaner erzählen. Emotional wurde hier der Vigilantismus von Gästen einer Grillparty zur Sprache gebracht: „Ich hätte mir niemals träumen lassen, dass ich eines Tages mit zwei .38-Revolvern in meinen Taschen und einer Schrotflinte über der Schulter durch die Straßen von New Orleans gehen würde (…) Das war groß[artig], das war wie Fasanenjagd in South Dakota. Wenn es sich bewegt, erschießt du’s (…)“[32] Die Polizei von Grentna und Bürgerwehren verhinderten mit der Schusswaffe die Flucht der Flutopfer vom jenseitigen überschwemmten Teil des Mississippis über die Brücke in das sichere Parish.[33] Insgesamt wurden zahlreiche Personen verhaftet, und am Bahnhof wurde zeitweise ein Gefängnis für etwa 700 Gefangene errichtet, das aus Käfigen aus Maschendraht bestand.
In Texas, wohin mehr als 300.000 Menschen ausgesiedelt worden waren, führten Beamte an 20.000 Ausgesiedelten Kontrollen durch, um die Vorbestraften auszusortieren. Auch Helfer, welche die Beamten unterstützten und Personen, die ihre Wohnungen zur Verfügung gestellt hatten, waren davon betroffen. Die meisten Kontrollen brachten für die Polizei allerdings keine besorgniserregenden Erkenntnisse.

[Bearbeiten | Quelltext bearbeiten]

Der Hurrikan führte zu einer radikalen Veränderung der Sozialstruktur in New Orleans. Vor allem wurden Mieter von Sozialwohnungen im Innenstadtbereich von ihren Wohnbezirken ausgesperrt und die sogenannten Public Housing Projects von privaten Immobiliengesellschaften mittlerweile abgerissen. Auf den lukrativen Grundstücken entstehen mit Subventionen geförderte Mustersiedlungen für Bürger mit einem gemischten Einkommen. Nur ein kleiner Teil der ehemaligen Mieter soll dort eine Wohnung erhalten.
Über 99 Prozent der betroffenen Bewohner sind Afroamerikaner und vor allem alleinerziehende Mütter, Leute mit einem Handicap und ältere Menschen.[16]
2008 hieß es in der Zeitschrift Geo: „Die Neubebauung und Renovierung dieser Anlagen würde nach offiziellen Schätzungen rund 400 Millionen Dollar kosten, ein Abriss hingegen etwa 700 Millionen Dollar. Dennoch lautet das offizielle Konzept für New Orleans: die Siedlungsdichte in diesen Vierteln senken.“[16]
Zu den betroffenen Public Housing Projects gehören:

Das nach dem Hurrikan Katrina abgeriegelte und später abgerissene St. Bernard Public Housing Development (1942–1943 erbaut, 2000: 1436 Wohneinheiten, nach Katrina für die Bewohner zugänglich gemachte Wohneinheiten: 0)
Das CJ Peete Public Housing Project (1941 erbaut, 2000: 1403 Wohneinheiten, nach Katrina für die Bewohner zugänglich gemachte Wohneinheiten: 0)
Das BW Cooper Project (1942–1943 erbaut, 2000: 1546 Wohneinheiten, nach Katrina für die Bewohner zugänglich gemachte Wohneinheiten: 261)
Das Iberville-Project
Das Tremé/Lafitte-Project (1941 erbaut, 2000: 896 Wohneinheiten, nach Katrina für die Bewohner zugänglich gemachte Wohneinheiten: 0)
Das BW Cooper Project (1954 erbaut, 2000: 1546 Wohneinheiten, nach Katrina für die Bewohner zugänglich gemachte Wohneinheiten: 0)
Das in 1990er Jahren sanierte St. Thomas Public Housing Development in New Orleans.





Die Hilfe für die Zeit nach dem Sturm lief bereits vor dem Sturm an. Insbesondere die FEMA traf Vorbereitungen, die von der Einlagerung von Hilfsgütern bis hin zur Mobilisierung einer mobilen Leichenhalle auf Kühllastwagen reichten. Mehr als 20.000 Soldaten der Nationalgarde und 7200 Soldaten im aktiven Dienst leisteten im Katastrophengebiet Hilfe.
Auf Anfrage von Präsident Bush bewilligte der Senat zunächst 10,5 Milliarden US-Dollar Soforthilfe. In den Abendnachrichten teilte NBC News am 1. September 2005 mit, dass die Vereinigten Staaten die Hilfsangebote anderer Staaten abgelehnt haben.

[Bearbeiten | Quelltext bearbeiten]
Zahlreiche Staaten boten internationale Hilfe an, darunter auch viele so genannte Entwicklungsländer oder Schwellenländer wie Indien und China, die beide jeweils fünf Millionen Dollar bereitstellten, Katar, das sogar 100 Millionen Dollar spendete. Darunter befanden sich auch ärmste Staaten wie Bangladesh (eine Million Dollar), Sri Lanka, das noch an den Folgen vom Seebeben von 2004 litt, sowie Afghanistan und sogar Iran, Kuba und Venezuela. Auch Kanada, Mexiko, Singapur und Deutschland lieferten Vorrat, Truppen, Schiffe und Wasserpumpen, um in den betroffenen Gebieten die Situation zu entschärfen. Nach anfänglichem Zögern waren die USA bereit, ausländische Hilfe anzunehmen. Jedoch lagerten die angebotenen Güter häufig tagelang noch auf den Flughäfen des anbietenden Staates oder der USA, da die Koordination der Hilfe mangelhaft verlief.[34] Russlands Angebot, zwei Strahlflugzeuge zur Verfügung zu stellen, lehnten die USA zunächst ab, akzeptierten es aber später. Auch die Hilfsangebote von Frankreich wurden zunächst zurückgewiesen, später aber ebenso akzeptiert.
Das Rote Kreuz und andere Organisationen riefen zu Spenden auf, die an amerikanische Partnerorganisationen weitergeleitet wurden. Deutschland hatte Helfer des Technischen Hilfswerkes nach New Orleans entsandt, die ab dem 9. September 2005 mit 15 großen Pumpen Hilfe leisteten. Begleitet und unterstützt wurde das THW von einem kleinen medizinischen Team der Johanniter-Unfall-Hilfe, welches sich um die medizinische und notfallmedizinische Versorgung der Einsatzkräfte des THW kümmerte. Angeblich wegen BSE-Gefahr verbot das US-Agrarministerium am 10. September 2005 die Einfuhr von Notrationen der Bundeswehr. Deutsche Hilfslieferungen durften damit nicht mehr verteilt werden.
Der europäische Luftfahrt- und Rüstungskonzern EADS N.V. unterstützte den Aufbau der medizinischen Versorgung in den vom Hurrikan Katrina verwüsteten Gebieten in den USA mit einer mobilen, klimatisierten Rettungsstation.[35] Die von der EADS ursprünglich entwickelte Rettungsstation, die von der Bundeswehr ausgeliehen werden konnte, wurde mit einem Transatlantikflug des Großraumtransporters Beluga bereitgestellt, der üblicherweise Komponenten der Airbus-Baureihe transportiert.

[Bearbeiten | Quelltext bearbeiten]
Die erste Mobilisierung der Nationalgardisten wurde behindert, weil zu der Zeit etwa ein Drittel der Nationalgarde Louisianas im Irak eingesetzt wurde, ebenso Ausrüstung wie hochwasserfeste Humvees, die in Überflutungsgebieten nützlich sind. Zum Ausgleich hat Louisiana schon in der Vorbereitungsphase zwischenstaatliche Hilfe in Form von Truppen und Gerät angefordert und erhalten. Seit Durchzug des Hurrikans wurden in Alabama, Mississippi, Florida und Louisiana mehr als 10.000 Gardesoldaten mobilisiert.

[Bearbeiten | Quelltext bearbeiten]
Die United States Coast Guard hatte so viele Helikopter wie möglich im Katastrophengebiet zusammengezogen. 500 Reservisten wurden einberufen, und aus dem ganzen Land wurden kleinere Boote zur Hilfe geschickt.

[Bearbeiten | Quelltext bearbeiten]
Die United States Navy begann ebenfalls schnell mit der Hilfeleistung. Mehrere Schiffe machten sich auf den Weg, darunter der Flugzeugträger USS Harry S. Truman, der als Kommandoposten für die Marineoperationen im Katastrophengebiet dienen sollte, und die amphibischen Angriffsschiffe USS Bataan und USS Iwo Jima mit ihren Unterstützungsgruppen. Diese Schiffe tragen Transporthelikopter der Typen CH-53 Sea Stallion und SH-60 Sea Hawk sowie Landungs- und Transportboote, welche an nahezu jedem Strand anlanden können und deshalb für Hilfeleistungen zugunsten zerstörter Küstenabschnitte geeignet sind, was sie bereits im Januar 2005 nach dem Tsunami in Sri Lanka unter Beweis gestellt hatten. Zwischenzeitlich lag die USS Bataan vor der Küste Mississippis vor Anker und die USS Iwo Jima als schwimmende Kommandozentrale am Pier im Hafen von New Orleans. Das mit 1000 Betten ausgestattete Lazarettschiff USNS Comfort wurde in die Region beordert und lag im Hafen von Pascagoula, Mississippi. Das Kommando über alle militärischen Hilfsoperationen hatte Lt. Gen. Russel L. Honoré von der United States Army in Camp Shelby, Mississippi.

[Bearbeiten | Quelltext bearbeiten]
Die Federal Emergency Management Agency (FEMA) schickte zehn Teams aus dem ganzen Land, die nach Überlebenden suchen sollten, sowie 23 medizinische Teams. Mit Hilfe des Verkehrsministeriums wurden 1700 Lastwagenladungen Wasser, Eis und Fertiggerichte herbeigeschafft. Weitere 390 LKW brachten Wasser, Zelte, Wohncontainer und Gabelstapler. Nach Durchzug von Katrina wurde mit Hochdruck daran gearbeitet, den Louis Armstrong New Orleans International Airport für Hilfsflüge wieder öffnen zu können.
Ein Kreditkartenprogramm für Flutopfer – nämlich die Abgabe von Karten, welche zum Bezug von 2000 US-Dollar pro Haushalt berechtigen – wurde gestoppt und wird nach anfänglichen Ankündigungen nur für die ausgesiedelten Personen im Astrodome weitergeführt.

[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Abschnitt „23. August 2005 – Hurrikan Katrina“ im Artikel Notfunk
Die Funkamateure, die sich in dem Salvation Army Team Emergency Radio Network (SATERN) und im West Gulf ARES Emergency Net zusammengeschlossen haben, nahmen den Notfunkbetrieb auf und stellten mit ihren Amateurfunkstellen zusätzliche Kommunikationswege zur Verfügung, um zügigen Informationsfluss zu ermöglichen. Lokalregierungen aus den ganzen USA schickten Hilfe in Form von Rettungswagen, Suchteams und Hilfsgütern. Bis hinauf nach Utah wurde Wohnraum für Flüchtlinge geschaffen.

[Bearbeiten | Quelltext bearbeiten]
Einer Vielzahl von unabhängigen Gruppen leistet seit der Flut in den nach fast einem Jahr noch immer vollständig zerstörten Gebieten Aufbauarbeit. Hervorzuheben ist für New Orleans das Common Ground Collective, eine Anfang September gegründete Graswurzel-Gruppe, in der seither kontinuierlich über 200 Freiwillige arbeiten (bis Juli 2006 insgesamt 10.000 Freiwillige). Die Arbeit von Common Ground umfasst ökologischen Wiederaufbau, Renovierung der Häuser und Schulen, medizinische Versorgung mit Stadtteilkliniken, Bildungsarbeit, Aufklärungsarbeit, aber auch politische Aktionen. Die Arbeit von Common Ground wird von der Polizei von New Orleans und von der Nationalgarde eingeschränkt, mehrere Common-Ground-Mitarbeiter wurden während Sanierungsarbeiten verhaftet.
An der Küste arbeiten Graswurzel-Gruppen wie Four Directions mit den Native Americans zusammen.[36][37]

[Bearbeiten | Quelltext bearbeiten]



Aufgrund der industriellen Nutzung des Feuchtgebiets östlich von New Orleans für Ölbohrungen wurde ein großer Teil der dortigen Zypressen abgeholzt, und große Flächen wurden durch Kanalverlegung unter Wasser gesetzt. Umweltschützer und Wissenschaftler gehen davon aus, dass der Hurrikan Katrina New Orleans bei einer weniger starken industriellen Nutzung dieses Gebiets mit geringerer Stärke erreicht hätte. Die optimistischsten Szenarien sprechen sogar davon, dass durch das Abbremsen des Hurrikans dieser gänzlich weniger Schaden angerichtet hätte.[38]
Am dritten und vierten Tag der Katastrophe wurde die Hilfeleistung der Regierung und besonders der nationalen Hilfe-Koordinationsstelle Federal Emergency Management Agency zunehmend kritisiert. Sie hatte z. B. laut Sprecher erst am 1. September erfahren, dass neben dem Superdome auch das Convention Center Ziel von ca. 15.000 Flüchtlingen gewesen war. Diese harrten dort tagelang ohne Unterstützung aus. Gewalt, Wassermangel, medizinische Unterversorgung und gesundheitsgefährdende hygienische Zustände forderten Todesopfer. Die kritisierte FEMA verwies auf die ungewöhnlich große Dimension der Katastrophe. Der Congressional Black Caucus, ein überparteilicher Ausschuss im US-Kongress zur Vertretung der Interessen der Schwarzen in den USA, äußerte sich am 2. September 2005 betroffen über die mangelnde Hilfe. In Not seien offensichtlich vor allem Arme, Alte und Bürger schwarzer Hautfarbe. Es könne nicht sein, dass diese Faktoren über das Schicksal der Opfer entschieden. Auch der Bürgermeister von New Orleans, Ray Nagin, wandte sich in einer emotionalen Ansprache an die Presse und klagte die unzureichenden Maßnahmen der Regierung und der Hilfsorganisationen scharf an. Der Rapper Kanye West nutzte eine Spendensammlungs-Sendung auf NBC zu unabgesprochenen, scharfen Angriffen auf die US-Regierung. Er sah Rassismus in den Darstellungen der Medien, die auf Bildunterschriften Weiße als „Personen, die sich mit dem Notwendigsten versorgen“, Schwarze dagegen als „Plünderer“ charakterisierten.
Die Medien diskutierten, ob es in den USA weiterhin eine unterschwellige Rassentrennung und eine ausgeprägte Klassentrennung gäbe. Während wohlhabende Menschen innerhalb kürzester Zeit aus dem Katastrophengebiet fliehen konnten, mussten die Mittellosen in der Stadt New Orleans bleiben. Eine erneute Diskussion über solche ungleichen Zustände und die damit verbundenen Folgen bei Katastrophen wird inzwischen von vielen Repräsentanten auf der politischen Bühne der USA eingefordert.
In Washington wurden am 4. September die Flaggen auf halbmast gesetzt, um den am 3. September an Krebs gestorbenen Vorsitzenden Richter des Supreme Court, William H. Rehnquist, zu ehren. Die Todesopfer des Hurrikans wurden nicht offiziell gewürdigt.
Die Presse hat für die Versäumnisse der Regierung Bush in Anlehnung an die Watergate-Affäre den Begriff Katrinagate geprägt und damit für Druck auf den Präsidenten gesorgt.
Die Überflutung von weiten Teilen New Orleans wurde nicht nur als Naturereignis diskutiert, sondern auch als Resultat politischer Fehleinschätzungen durch die US-Regierungen. Das Magazin National Geographic warnte bereits im Herbst 2004 in einem Artikel vor einer Katastrophe.[39][40] Der Wissenschaftler R. Burby zeigte anhand dieses Falles das „Safe-Development-Paradox“ auf. In den 1960–1970er Jahren wurden Feuchtgebiete im Umfeld von New Orleans durch Deiche geschützt und damit erst die Bebauung ermöglicht. In diesen Gebieten entstanden während des Hurrikans die größten Schäden.[41]
Die US-Katastrophenhilfsbehörde FEMA verklagte 2011 die Warren Buffett gehörende Firma Clayton Homes, weil in den Wohncontainern, die sie für die Unterbringung von Opfern der Katastrophe lieferte, erhöhte Mengen von Formaldehyd gemessen wurden, das Atemwegserkrankungen bei Kindern hervorrufen kann und in den USA als krebserregend eingestuft ist.[42]
Nach fast einem Jahr waren die Stadtteile, in denen vorwiegend die ärmere afroamerikanische Bevölkerung wohnte, immer noch vollständig zerstört. Von Seiten der Regierung wurde keine Wiederaufbauarbeit geleistet. Noch immer befanden sich mehrere hunderttausend Menschen aus New Orleans in anderen Bundesstaaten und warteten auf ihre Rückkehr. Siedlungen wie St. Bernhard, in denen über 3000 Menschen lebten, wurden von der Stadt eingezäunt und sollen durch eine Mischsiedlung ersetzt werden, was aber für viele der ehemaligen Bewohner nicht bezahlbar war. Stadtteile wie der 9th Ward waren ohne medizinische und schulische Versorgung. In diesen Stadtteilen wurden die Schulen nicht von der Regierung, sondern von Graswurzelgruppen saniert, obwohl hier Kinder bereits seit einem Jahr nicht mehr zur Schule gegangen sind.


Auf den Tag genau 16 Jahre nach Katrina traf der Kategorie-4-Hurrikan Ida ebenfalls in der Nähe von New Orleans mit Windgeschwindigkeiten von 240 km/h auf Land.[43]


Arjen Boin, Christer Brown, James A. Richardson: Managing Hurricane Katrina: Lessons from a Megacrisis. Louisiana State University Press, Baton Rouge 2019, ISBN 978-0-8071-7092-2.
Michael S. Falser: Der Wiederaufbau von New Orleans nach Hurricane Katrina. Gedanken zum Status der Zivilgesellschaft im Kontext von Natur- und Kulturkatastrophen. In: Hans-Rudolf Meier, Michael Petzet und Thomas Will (Hrsg.): Kulturerbe und Naturkatastrophen / Cultural Heritage and Natural Disasters. Risk Preparedness and the Limits of Prevention. TUDpress Dresden, 2008, ISBN 978-3-940046-64-2, S. 109–122.
Christian Jakob & Friedrich Schorb: Soziale Säuberung. Wie sich New Orleans seiner Unterschicht entledigt. Unrast Verlag, Münster 2008, ISBN 978-3-89771-484-7.
Christian Jakob & Friedrich Schorb: . In: analyse & kritik. Nr. 522, 16. November 2007.
, Pressemitteilung der Universität Bremen, 12. August 2008.
Dan Rather (Vorwort), Jenni Bergal, Sara Shipley Hiles, Frank Koughan, John McQuaid, Jim Morris, Katy Reckdahl, Curtis Wilkie: City Adrift – New Orleans Before And After Katrina, Louisiana State-University Press, Baton Rouge 2007, ISBN 978-0-8071-3284-5.
Eugenie L. Birch, Susan M. Wachter (Hrsg.): Rebuilding Urban Places After Disaster: Lessons from Hurricane Katrina. University of Pennsylvania Press, Philadelphia 2006, ISBN 978-0-8122-1980-7.
Ernest J. Gaines: Katrinas Erbe. Vor einem Jahr zerstörte der Hurrikan weite Teile der Südstaaten. Das Leid der Menschen dauert noch an. In: National Geographic Deutschland. August 2006, S. 84–107.
There Is No Such Thing as a Natural Disaster: Race, Class, and Hurricane Katrina, hrg. von Chester Hartman und Gregory D. Squires, Routledge 2006, ISBN 0-415-95487-8.
ACCENT Global Change Magazin für Schulen: . Sonderausgabe anlässlich des Hurrikans „Katrina“. September 2005.
John Brown Childs (Hrsg.): Hurricane Katrina. Response and Responsibilities. New Pacific Press, Santa Cruz 2005, ISBN 0-9712546-2-1.
Jerroldyn und Roland Hoffmann mit Christiane Landgrebe: Im Auge des Orkans. Wie der Hurrikan von New Orleans uns heimatlos machte. Bastei Lübbe, Bergisch Gladbach 2005, ISBN 978-3-404-61595-7.

When the Levees Broke: A Requiem in Four Acts. Regie: Spike Lee, 2006 ( bei Home Box Office)
BIG EASY to Big Empty – The Untold Story of the Drowning of New Orleans, Greg Palast 2006
Engineering Disasters: New Orleans, The History Channel (über das Versagen der Deiche, der Autobahnbrücke über den See und des Superdome-Daches)

Die Band Audioslave kritisiert mit dem Song Wide Awake aus dem Album Revelations (2006) das Verhalten der Regierung, insbesondere von George W. Bush.
Die Band Linkin Park half mit ihrem Projekt Music For Relief Opfern beim Aufbau von Häusern, außerdem handelt ihr Song The Little Things Give You Away über das fehlerhafte Verhalten der Regierung während der Katastrophe.
Die Band Rise Against widmete den Opfern das Video zu ihrem Song Help is on the Way von ihrem Album Endgame, das 2011 erschien.
Die Bands Green Day und U2 sangen für die Opfer The Saints Are Coming.
Das Elektro-Projekt Assemblage 23 bezog sich mit dem Song Madman’s Dream vom Album „Meta“ (2007) auf die Naturkatastrophe und ihre Folgen, vor allem das unzureichende Krisenmanagement der Regierung.
Der Jazztrompeter Terence Blanchard widmete den Opfern sein Album A Tale of Gods Will (Requiem for Katrina). Dies ist gleichzeitig die Filmmusik des Dokumentarfilms When the Levees Broke, in dem Blanchard selbst auch vorkommt.
Der Musiker und Schauspieler Mos Def verarbeitet die Wut der schwarzen Bevölkerung in seinem Song Dollar Day (Katrina Klap).
Der Musiker Prince spendete den gesamten Erlös seiner Single S.S.T. (2005) den Opfern des Hurrikans.

Liste der atlantischen Kategorie-5-Hurrikane


 Katrina archive
 von Richard D. Knabb, Jamie R. Rhome & Daniel P. Brown für das National Hurricane Center, 20. Dezember 2005 / 10. August 2006 (PDF; 3 MB)
 auf der Website Naturgewalten von Thomas Sävert (mit umfangreicher Linkliste)
 und  auf stern.de
, Report von William H. Frey, Audrey Singer und David Park für die Brookings Institution, September 2007 (PDF; 6,4 MB)




Die Artikel Liste von Hochwasser-Ereignissen, Flutkatastrophe, Jahrhunderthochwasser, Überschwemmung und Hochwasser überschneiden sich thematisch. Informationen, die du hier suchst, können sich also auch in den anderen Artikeln befinden.Gerne kannst du dich an der betreffenden Redundanzdiskussion beteiligen oder direkt dabei helfen, die Artikel zusammenzuführen oder besser voneinander abzugrenzen (→ Anleitung).


Als Überschwemmung bezeichnet man einen Zustand, bei dem eine normalerweise trockenliegende Bodenfläche vollständig von Wasser bedeckt ist. Flutkatastrophen waren neben besonders starken Erdbeben bislang die für Menschen folgenreichsten Naturkatastrophen.



Überschwemmungen sind meistens Naturereignisse:



Sturmfluten schieben Meerwasser über Flussmündungen dort, wo es keine Sperrwerke gibt, tief ins Binnenland hinein sowie über Deiche an der Küste und an küstennahen Flussabschnitten hinweg oder bewirken Deichbrüche; Tsunamis können auch hoch gelegene, nicht durch Deiche geschützte Küstenabschnitte überfluten;

Binnengewässer treten bei Hochwasser über die Ufer, wenn das Wasser nicht zügig genug „nach unten“ fließt (als Oberflächenwasser talwärts bzw. auf nicht versiegelten Böden ins Grundwasser versickernd). Das Hochwasser kann durch ergiebige Niederschläge, aber auch durch den Bruch von Dämmen oder Staumauern infolge zu hohen Wasserdrucks entstanden sein.
Gletscher hindern nachfließendes Wasser am Abfließen und bilden auf diese Weise einen Eisstausee.
Sich füllende Grundwasserreservoirs führen zu steigenden Wasserständen, wenn das Grundwasser über wasserundurchlässigen Bodenschichten liegt. Es findet dann von unten oder (unterhalb der Erdoberfläche) von den Seiten her seinen Weg in tiefliegende Teile von Bauwerken. Dies betrifft vor allem Gebiete mit einem ständig hohen Grundwasserpegel.
Der mangelhafte, teils auch ausbleibende Abfluss großer Wassermassen im Binnenland und auf Inseln kann (zumindest teilweise) von Menschen ausgelöst sein:

Die Versiegelung großer Flächen erschwert das Versickern von Oberflächenwasser, das ungehemmt in Bäche und Flüsse gelangt. Allerdings bewirkt Starkregen selbst eine Versiegelung tiefer gelegener Flächen, da er die Fähigkeit zur Aufnahme von Wasser auch in an sich nicht versiegelten Böden ab einem bestimmten Zeitpunkt unterbindet;[1]
Die Begradigung und Einengung von Flüssen führt zu einer Erhöhung der Fließgeschwindigkeit des Wassers, das schnell tiefer gelegene Gebiete erreicht und dort auf langsamer fließendes Wasser an Engstellen aufläuft. Es gibt vor allem in Ballungsräumen zu wenige Flächen, in denen sich das Wasser ausbreiten kann. Dies führt zwangsläufig zu Hochwasser bei starkem Wasserzustrom durch heftige Niederschläge und/oder in großen Mengen nachrückendes Oberflächenwasser.

Zusammengebrochene Konstruktionen oder Treibgut können sich an Brücken, Sperrwerken, Rechen oder Überläufen, bzw. Ablässen verkanten und dadurch einen Wasserstau auslösen (Verklausung);
Auch in großer Entfernung zu größeren Flüssen kann es zu (meist lokal begrenzten) Überschwemmungen kommen. Zumeist sorgen hier Starkregenfälle dafür, dass die Kanalisation und Entwässerungsgräben die Wassermassen nicht bewältigen können. Zur Zwischenlagerung von Wassermassen geschaffene Einrichtungen wie Regenrückhaltebecken oder geplante Überschwemmungsflächen erweisen sich oft als unterdimensioniert. In den genannten Fällen ist ein Hauptgrund für den Eintritt von Überschwemmungen, dass die Eintrittswahrscheinlichkeit und die Wirkung von Starkregenereignissen unterschätzt werden;[2]


Obwohl Wasserfluten eine Naturgewalt darstellen, handelt es sich bei einer Überschwemmung dann nicht um ein „Naturereignis“, wenn sie durch einen Wasserrohrbruch ausgelöst wurde oder wenn Gebiete (insbesondere im Zusammenhang mit Kampfhandlungen) absichtlich unter Wasser gesetzt werden.
Generell stellt sich die Frage, ob Schäden durch Überschwemmungen auf bebauten Grundstücken dann „schicksalhaft“ für Geschädigte sind, wenn eine Überschwemmung durch angrenzende Gewässer oder mangelhafte Entwässerungssysteme aufgrund der Lage der Schadensfläche vorhersehbar ist. Auch müssten sich Bauherren des Risikos bewusst sein, das sie eingehen, wenn sie in einem Gebiet mit einem hohen Grundwasserspiegel Anlagen unterhalb des Erdbodens errichten.


Überschwemmungen können unter Umständen erhebliche Wasserschäden am Eigentum von Menschen hervorrufen sowie die Gesundheit und das Leben von Menschen und Nutztieren gefährden. Besteht eine solche Gefahr, so sprechen Rettungskräfte von einem Wassernotstand. Zu unterscheiden sind temporäre Überschwemmungen, die durch das Ablaufen oder Hochpumpen des eingedrungenen Wassers enden, von dauerhaften Überschwemmungen. Letztere drohen insbesondere tiefgelegenen Küstengebieten infolge des  klimabedingten Anstiegs des Meeresspiegels.
Bei einer Überschwemmung in bergigem Gelände können Schäden auch unterhalb des eigentlichen Wasserspiegels ausgelöst werden, indem Grundstücke in Hanglage unterspült werden. Durch den Materialabtrag kann der Hang oberhalb des Wasserspiegels abrutschen und Gebäude oder deren Inhalt (z. B. ein Auto in einer Garage) nach unten stürzen.
Nicht jede Überschwemmung stellt jedoch für Menschen ein Problem dar. So gäbe es z. B. in Wüstengebieten ohne das regelmäßige Über-die-Ufer-Treten von Flüssen wie dem Nil abseits von Oasen kein fruchtbares Land für den Acker- und Gartenbau, und unter ökologischen Aspekten werden naturbelassene Feuchtgebiete, die regelmäßig überschwemmt werden, als überaus wertvoll bewertet.
Auch in Deutschland gibt es Kulturlandschaften, deren Bewohner ihren Wohlstand der Fruchtbarkeit ihres Landes verdanken, welche wiederum durch Sedimente zu erklären ist, die nach Überschwemmungen auf dem Boden zurückgelassen wurden. Dies trifft beispielsweise auf das Artland zu, welches großenteils im Hase-Binnendelta liegt.


Der Begriff der Überschwemmung als wirtschaftlicher Schaden ist zugleich ein Rechtsbegriff, der insbesondere im Zusammenhang mit der Gebäude-, Hausrats-, Kfz-Teilkasko- und Betriebsunterbrechungsversicherung relevant ist. Besteht nach diesen Versicherungen Schutz gegen Elementarschäden, so wird dabei üblicherweise auch das Überschwemmungsrisiko abgedeckt. Zum Zwecke der Risikoabschätzung und damit der Prämienkalkulation hat der Gesamtverband der Deutschen Versicherungswirtschaft ein geographisches Informationssystem erarbeitet: Das Zonierungssystem für Überschwemmung, Rückstau und Starkregen (ZÜRS).[3] Grundlage sind statistische Berechnungen des Softwareunternehmens IAWG (Ingenieurhydrologie, Angewandte Wasserwirtschaft und Geoinformatik) in Ottobrunn.[4]


→ Hauptartikel: Überschwemmungsgebiet
Überschwemmungsgebiete sind Gebiete, die bei Hochwasser eines oberirdischen Gewässers überschwemmt oder durchflossen werden.[5]


→ Hauptartikel: Hochwasserschutz

Der Begriff der Überschwemmung, also eine „Überflutung des Grund und Bodens, auf dem das versicherte Gebäude steht (Versicherungsgrundstück)“, ist nach Ansicht des Bundesgerichtshofes aus der Sicht eines verständigen Versicherungsnehmers auszulegen. Demnach ist die „Überflutung von Grund und Boden“ dann anzunehmen, wenn sich erhebliche Wassermengen auf der Geländeoberfläche ansammeln.[6] Einschränkend urteilte hingegen das Landgericht Dortmund:[7] Erforderlich sei es, dass die normalerweise trocken liegenden Fläche eine Bodenfläche im Sinne einer mit dem Erdboden niveaugleichen Fläche sei. Wegen fehlender Niveaugleichheit gelten Flachdächer oder Balkone nicht als „Bodenflächen“. Schäden, welche etwa durch das Eindringen von (Tau-)Wasser über das Dach hervorgerufen wurden, seien daher durch Gebäudeversicherungen nicht gedeckt. Es fehle bereits an einer Überflutung, sofern es nicht zu einer Ansammlung von Wasser auf der Geländeoberfläche gekommen ist. Aber auch eine Überschwemmung von Terrassen gilt nicht als Versicherungsschaden (trotz der Niveaugleichheit mit dem Erdboden). Den Begriff Überschwemmung fasst das LG Nürnberg-Fürth weiter.[8]


Vorregenindex


Christian Pfister:  In: Historisches Lexikon der Schweiz.
Gesamtverband der Deutschen Versicherungswirtschaft (GDV), 






Als Weltbevölkerung oder Erdbevölkerung bezeichnet man die Zahl der Menschen, die auf der Erde leben bzw. zu einem bestimmten Zeitpunkt gelebt haben (oder laut Hochrechnungen leben werden). Die Disziplinen Demografie und Bevölkerungsgeografie untersuchen den Stand, die historische Entwicklung, die räumliche Verteilung sowie die Dynamik der Weltbevölkerung und erstellen Prognosen.
Die Weltbevölkerung umfasste im November 2022 rund 8,03 Milliarden Menschen.[1] Nach dem Weltbevölkerungsbericht des Bevölkerungsfonds der Vereinten Nationen wurde die Acht-Milliarden-Menschen-Marke am 15. November 2022 überschritten.[2] Die Festlegung auf einen Tag ist dabei als symbolischer Akt zu verstehen, weil diese Schätzung der Weltbevölkerung mit einer Unsicherheit von bis zu ±5 % behaftet ist.[3] Die UNO rechnete für den Zeitraum 2015 bis 2020 mit einem Bevölkerungswachstum von rund 78 Millionen Menschen pro Jahr.[4]
Die Vereinten Nationen erwarten bis 2036 9 Milliarden und bis 2057 10 Milliarden Menschen auf dem Globus. Für das Jahr 2100 werden 10,9 Milliarden Menschen prognostiziert.[5] Eine andere Prognose der UNO geht davon aus, dass die Weltbevölkerung im 21. Jahrhundert mit etwa 10,4 Milliarden Menschen ihren Höchststand erreicht und zum Ende des Jahrhunderts schrumpft.[6]
Die Länder mit den meisten Einwohnern sind die Volksrepublik China und Indien mit jeweils ca. 1,4 Milliarden Menschen.




Der moderne Mensch (Homo sapiens) ist nach dem Aussterben der Neandertaler vor 30.000 Jahren und des Homo floresiensis vor 60.000 Jahren die einzige überlebende Art der Gattung Homo. Nach der Theorie des genetischen Flaschenhalses erlitt der moderne Mensch den für seine Existenz bedrohlichsten Rückgang seiner Bevölkerung vor 75.000 Jahren, als sich nach dem Ausbruch des Supervulkans Toba (heute der Tobasee auf Sumatra) weltweit nur 1.000 bis 10.000 Menschen retten konnten (siehe auch Toba-Katastrophentheorie). Danach verbreitete sich der moderne Mensch von Afrika aus über alle anderen Kontinente. Bis zum Ende der letzten Kaltzeit vor 10.000 Jahren lebten dann etwa 5 bis 10 Millionen Menschen weltweit.
Die Größe der Weltbevölkerung vor 2000 Jahren wird auf 170 bis 400 Millionen geschätzt, die UNO geht von 300 Mio. aus. Das Römische Reich soll zu Beginn unserer Zeitrechnung 57 Millionen Menschen gezählt haben, das Chinesische Reich 75 Mio. Einwohner. Vor 1000 Jahren lebten 250 bis 350 Millionen Menschen, die UNO nimmt 310 Mio. an. Nach diesem Stillstand der Bevölkerungsentwicklung im ersten Jahrtausend unserer Zeitrechnung begann das Wachstum im Hochmittelalter erneut, erlitt im Spätmittelalter jedoch Einbrüche durch Pest, Pocken und andere Seuchen.
Vor 500 Jahren betrug die Weltbevölkerung 425 bis 540 Millionen, die UNO geht von 500 Millionen aus. Im Laufe des 16. Jahrhunderts soll die amerikanische Bevölkerung (Indianer) durch eingeschleppte Seuchen von etwa 50 Millionen auf nur noch 5 Millionen zurückgegangen sein, während in Europa und Asien die Bevölkerung weiter zunahm. Das weltweite Wachstum stieg im 18. Jahrhundert dauerhaft über 0,5 % im Jahr und Mitte des 20. Jahrhunderts für einige Jahrzehnte sogar über 2 %, so dass man von einer Bevölkerungsexplosion sprechen kann.


Nach dem Jahr 1700 setzte ein rapides Bevölkerungswachstum ein. Erstmals in der Menschheitsgeschichte lag die Verdopplungszeit im Bereich von Jahrhunderten und schließlich Jahrzehnten. Um das Jahr 1804 überschritt die Weltbevölkerung die Anzahl von einer Milliarde Menschen. Innerhalb des 20. Jahrhunderts hat sich die Weltbevölkerung etwa verdreieinhalbfacht:

1804: 1 Milliarde
1927 (nach 123 Jahren): 2 Milliarden
1960 (nach 33 Jahren): 3 Milliarden
1974 (nach 14 Jahren): 4 Milliarden
1987 (nach 13 Jahren): 5 Milliarden
1999 (nach 12 Jahren): 6 Milliarden
2011 (nach 12 Jahren): 7 Milliarden
2022 (nach 11 Jahren): 8 Milliarden Menschen
Bei einem Bevölkerungswachstum von jährlich rund 80 Millionen Menschen steigt die Zahl der Erdenbürger jeden Tag um fast 220.000 und in jeder Minute um mehr als 150 Menschen.
Seit Ende der 1960er Jahre nimmt das jährliche Wachstum prozentual wieder ab: von damals 2,1 % auf 1,09 % im Zeitraum 2015–2020. Seit Ende der 1980er Jahre stagniert das jährliche Weltbevölkerungswachstum in absoluten Zahlen. Es liegt bei ca. 80 Millionen pro Jahr.[4]
Der überwiegende Anteil des Bevölkerungswachstums findet derzeit in den Entwicklungsländern bzw. in den wenig entwickelten und ärmeren Staaten der Welt statt. In einigen höher entwickelten Ländern – insbesondere den meisten ehemaligen Ostblock-Staaten – nimmt die Bevölkerungszahl ab.
Die Gesamtzahl der Kinder unter 15 Jahren liegt bei knapp unter 2 Milliarden. Sie stieg von 1960 (1,127 Milliarden) an, erreichte 2001 einen ersten Höhepunkt (1,847 Milliarden) und nahm danach wieder etwas ab (auf 1,834 Milliarden im Jahr 2005); diese Zahl wurde erst 2008 (1,851 Milliarden) wieder übertroffen. 2018 lag die Zahl bei 1,958 Milliarden.[7][8][8] Während die Gesamtzahl (absolute Zahl) sich von 1960 bis 2000 nahezu verdoppelte, ist ihr (relativer) Anteil in dieser Zeit deutlich gesunken. Von 37 % der Weltbevölkerung ab 1960 stieg ihr Anteil kurzzeitig an, erreichte 1966 einen Höchstwert von 38 % und fiel danach kontinuierlich bis auf 25,8 % ab (Stand: 2019).[9]




Von der Katastrophentheorie des Thomas Malthus im Jahre 1798 bis in die Gegenwart überschätzten Prognosen die tatsächliche Bevölkerungsentwicklung zumeist deutlich. Ein Hauptgrund sind Fehlprognosen für die Volksrepublik China. Dort sank das Bevölkerungswachstum stärker als erwartet. In den 1960er Jahren erregte die pessimistische Prognose eines Statistikers in den USA Aufsehen, der für den 21. Juni 2116 ankündigte, dass für jeden Mensch nur noch ein Stehplatz auf der Erde bleibe.[12]
Die UNO erwartete im Jahr 2010 bei mittlerer Projektion bis 2025 8,17 Milliarden und bis 2100 10,9 Milliarden Menschen.[13] 2019 prognostizierte die UNO einen Anstieg auf 8,5 Milliarden Menschen bis 2030 (10 % Anstieg), auf 9,7 Milliarden 2050 (26 %) und auf 10,9 Milliarden im Jahr 2100 (42 %). Die Bevölkerung in Subsahara-Afrika verdopple sich bis 2050 (99 %). Für Ozeanien ohne Australien/Neuseeland erwartete man von 2019 ausgehend bis 2050 einen Anstieg um 56 %, für Nordafrika und Westasien von 46 %, für Australien/Neuseeland um 28 %, für Zentral- und Südasien um 25 %, für Lateinamerika und die Karibik um 18 %, für Ost- und Südostasien um 3 % sowie für Europa und Nordamerika um 2 %.[14]
Das Institute for Health Metrics and Evaluation (IHME) der University of Washington in Seattle erwartet dagegen für 2100 nur 8,8 Milliarden Menschen, also 2 Milliarden weniger als die UNO im Jahre 2019.[15]
1975 erwartete die UNO für 2010 7,6 Milliarden Menschen (0,7 Mrd. zu hoch) sowie für 2100 12,3 Milliarden.[16]
2015 nahm man an, dass die mittlere Kinderzahl (Fertilitätsrate) von 2,5 Kindern pro Frau weltweit bis 2100 unter das sogenannte Ersatzniveau (2,1) auf zwei Kinder pro Frau sinkt.[17]
Läge die mittlere Kinderzahl um ein halbes Kind pro Frau höher, würde die Weltbevölkerung bis 2100 auf 16,6 Milliarden Menschen anwachsen (hohe Variante). Bei einem halben Kind weniger würden im Jahr 2100 nur 7,3 Milliarden Menschen auf der Erde leben (niedrige Variante).[17]
Neben der Fertilitätsrate sind auch die – als allgemein weiter steigend angenommene – Lebenserwartung und die Kindersterblichkeit bedeutsam. Bei der regionalen Verteilung spielen auch Wanderungsbewegungen eine wichtige Rolle.
Das Durchschnittsalter der Weltbevölkerung betrug im Jahr 2004 gemäß WHO 27,6 Jahre und wird nach UNO-Angaben bis 2050 voraussichtlich auf 38,1 Jahre steigen. Die UNO erwartet bis zum Jahr 2050 einen weltweiten Zuwachs bei den über 60-Jährigen von jetzt gut 10 % auf dann knapp 22 % bei gleichzeitigem Rückgang des Bevölkerungsanteils der Kinder bis 15 Jahre von jetzt knapp 30 % auf knapp 20 %.

[Bearbeiten | Quelltext bearbeiten]
Im Jahr 1975 schlug Sebastian von Hoerner eine Formel für das Bevölkerungswachstum vor, die ein hyperbolisches Wachstum mit einer unendlichen Bevölkerung im Jahr 2025 darstellte.[18] Das bis in die 1970er Jahre beobachtete hyperbolische Wachstum der Weltbevölkerung wurde später mit einer nichtlinearen positiven Rückkopplung zweiter Ordnung zwischen demographischem Wachstum und technologischer Entwicklung korreliert.
Diese Rückkopplung kann wie folgt beschrieben werden: technologischer Fortschritt → Erhöhung der Tragfähigkeit von Land für Menschen → demographisches Wachstum → mehr Menschen → mehr potentielle Erfinder → Beschleunigung des technologischen Fortschritts → beschleunigtes Wachstum der Tragfähigkeit → schnelleres Bevölkerungswachstum → beschleunigtes Wachstum der Anzahl potentieller Erfinder → schnellerer technologischer Fortschritt → somit schnelleres Wachstum der Tragfähigkeit der Erde für Menschen usw. Der Übergang vom hyperbolischen Wachstum zu langsameren Wachstumsraten hängt mit dem demographischen Übergang zusammen.[19]
Nach Angaben des russischen Demographen Sergej Kapiza wuchs die Weltbevölkerung zwischen 67.000 v. Chr. und 1965 nach folgender Formel[20]:





N
=


C
τ


arccot
⁡




T

0


−
T

τ




{\displaystyle N={\frac {C}{\tau }}\operatorname {arccot} {\frac {T_{0}-T}{\tau }}}


N ist die aktuelle Population
T ist das aktuelle Jahr
C = (1.86±0.01)·1011
T0 = 2007±1




τ


{\displaystyle \tau }

 = 42±1



Weltbevölkerung nach Kontinenten (in Mio.)[22]



2016
2030
2050


Asien
4437
4946
5327


Afrika
1203
1681
2527


Amerika
997
1117
1220


Europa
740
744
728


Ozeanien
40
51
66


Welt
7418

8539
9869

Die folgenden Bevölkerungszahlen und -projektionen sind dem DSW-Datenreport 2016[22] der Deutschen Stiftung Weltbevölkerung vom September 2016 entnommen und entsprechen der Publikation des Population Reference Bureau: 2016 World Population Data Sheet.[23]

[Bearbeiten | Quelltext bearbeiten]
[Bearbeiten | Quelltext bearbeiten]
Zur Zeitenwende lebten etwa 69 % der Weltbevölkerung in Asien (31 % in China, 21 % in Indien und circa 18 % im restlichen Asien), 18 % in Europa, 10 % in Afrika und 3 % in Amerika und dem Rest der Welt. Diese Anteilsverhältnisse blieben bis zum Jahr 1800 weitgehend konstant.[21]
Indien hatte im frühen Mittelalter seinen prozentual größten Anteil an der Weltbevölkerung mit 30 %. In dieser Zeit lag Europa mit 13 % auf einem historischen Minimum.[21]
China hatte drei Maxima um die Jahre 200, 1200 und 1800 mit Anteilen über 30 %, dazwischen Perioden um die 20 %.[21] Die Ein-Kind-Politik seit Beginn der 1980er-Jahre in China sorgte für eine sichtbare Abflachung der Bevölkerungs-Wachstumskurve. Aktuell (2019) liegt der Anteil an der Weltbevölkerung bei circa 18 %.
Der Anteil von Nord- und Südamerika blieb lange gering und hatte um 1700 ein historisches Tief mit nur 2 %. Er nahm jedoch seit 1800 stark zu und erreichte 1975 die 15 %-Marke.[21]
Afrika schwankte zwischen 7 und 13 %, wobei sein Anteil, um 1900 auf einem historischen Tief angekommen, im Verlauf des 20. Jahrhunderts wieder rasch aufholte.[21]
Um 1900 erreichte Europa sein Maximum mit 24 %, seither fiel es wieder ab. Zeitgleich befand sich Indien auf seinem historischen Minimum mit 18 %.[21]

[Bearbeiten | Quelltext bearbeiten]
Folgendes Diagramm zeigt die Entwicklung der Bevölkerung der Welt und ihrer Kontinente von 1950 bis 2019 in Millionen[24]



[Bearbeiten | Quelltext bearbeiten]
 
Die Angaben zu einer Weltbevölkerung sind dem "DSW-Datenreport 2022"[25] der Deutschen Stiftung Weltbevölkerung und dem "World Population Data Sheet 2022"[26] der Publikation des Population Reference Bureau  entnommen.

Welt: 7.963 Millionen im Jahr 2022
Asien: 4.730 Millionen (59,4 %) mit Türkei
Afrika: 1.419 Millionen (17,8 %) mit Ägypten
Amerika: 1.028 Millionen (12,9 %)
Europa: 742 Millionen (9,3 %) mit Russland
Ozeanien: 44 Millionen (0,6 %) mit Australien

Nebenstehende Karten und Tabellen:

Anteile der Kontinente an der Weltbevölkerung
Die Weltbevölkerung 2011
Bevölkerung der vier größten Staaten 2011
Bevölkerungstabelle 2011
bieten einen vollständigen Überblick zur Verteilung einer Weltbevölkerung von genau sieben Milliarden Menschen auf die in der Liste der Staaten der Erde (am Ende des Jahres 2011) angeführten 206 Staaten:

Karte: Anteile der Kontinente an der Weltbevölkerung – beinhaltet einen farblich gegliederten Überblick zur Bevölkerungsverteilung auf die Kontinente, wobei jedes Feld für ein Prozent der Weltbevölkerung steht.
Karte: Die Weltbevölkerung 2011 – beinhaltet die 136 größeren Staaten mit jeweils mehr als 0,05 % der Weltbevölkerung. In diesen 136 der 206 Staaten leben zusammen 99,2 % der Weltbevölkerung.
Karte: Staaten Bevölkerung 2011 – beinhaltet die Regionen der vier größten Staaten (China, Indien, USA, Indonesien) mit zusammen 45,0 % der Weltbevölkerung, sowie eine Auflistung der 70 kleineren Staaten mit zusammen 0,8 % der Weltbevölkerung.
Karte: Bevölkerungstabelle 2011 – beinhaltet die Bevölkerungszahlen der Kontinente und der 206 Staaten zum Zeitpunkt an dem sieben Milliarden Menschen auf der Welt lebten.
• Quellen der Bevölkerungszahlen nebenstehender Karten: DSW-Datenreport 2011 der Deutschen Stiftung Weltbevölkerung vom September 2011 (teilweise auf die nächste Million gerundet), sowie die Volkszählungsergebnisse in China, Indien, USA und Indonesien im Jahr 2010 bzw. 2011 (gerundet zur Angleichung an die Bevölkerungszahlen des DSW-Datenreport 2011)


Siehe auch: Liste von Staaten und Territorien nach Bevölkerung

Die Angaben sind dem DSW-Datenreport 2019 der Deutschen Stiftung Weltbevölkerung vom November 2019 entnommen und entsprechen der Publikation des Population Reference Bureau: 2019 World Population Data Sheet.

China Volksrepublik Volksrepublik China: 1398 Millionen (etwa 18,2 % der Weltbevölkerung)
Indien Indien: 1392 Millionen (18,1 %)
Vereinigte Staaten Vereinigte Staaten: 329 Millionen (5,1 %)
Indonesien Indonesien: 268 Millionen (3,7 %)
Pakistan Pakistan: 217 Millionen (2,8 %)
Brasilien Brasilien: 209 Millionen (2,7 %)
Nigeria Nigeria: 201 Millionen (2,6 %)
Bangladesch Bangladesch: 164 Millionen (2,1 %)
Russland Russland: 147 Millionen (1,9 %)
Mexiko Mexiko: 127 Millionen (1,7 %)
Japan Japan: 126 Millionen (1,7 %)
Athiopien Äthiopien: 112 Millionen (1,5 %)
Philippinen Philippinen: 108 Millionen (1,4 %)
Agypten Ägypten: 99 Millionen (1,3 %)
Vietnam Vietnam: 96 Millionen (1,2 %)
Deutschland Deutschland: 83 Millionen (1,1 %)
Anmerkung: Seit 2021 liegt Deutschland auf dem 19. Platz hinter 16. Kongo Demokratische Republik Demokratische Republik Kongo, 17. Turkei Türkei und 18. Iran Iran [27]
In diesen 16 bevölkerungsreichsten Staaten leben 5,076 Milliarden Menschen und somit rund zwei Drittel der gesamten Weltbevölkerung von 7,691 Milliarden. Die Europäische Union würde mit 446 Millionen Einwohnern (etwa 5,8 % der Weltbevölkerung) in 27 Mitgliedstaaten (nach dem Brexit) den 3. Rang einnehmen. In China, Indien, der EU und den USA lebt zusammen fast die Hälfte der Weltbevölkerung. Neben der jeweiligen Demografie wird die jeweilige Bevölkerungsentwicklung dabei mitunter stark von der Migration beeinflusst (vgl. Liste der Länder nach Nettomigrationsrate).




Gebiet
Bevölkerungs-dichte 2015 inEinwohner je km²


Welt insgesamt

054


Indien

400


Deutschland

230


Schweiz

200


Volksrepublik China

144


Europäische Union

116


Österreich

110


Afrika

040


Vereinigte Staaten

034


Südamerika

024


Russland

008


Kanada

004


Australien

003


Mongolei

002



Die Bevölkerungsdichte der Welt ist regional extrem unterschiedlich. Die höchste Bevölkerungsdichte eines Staates weisen die Stadtstaaten Monaco mit rund 19.000, Singapur mit fast 8.000 und Vatikanstadt mit 1.900 Einwohnern pro Quadratkilometer auf. Die größte Bevölkerungsdichte eines Flächenstaats hat Bangladesch mit etwa 1.100 Einwohnern pro Quadratkilometer. Deutschland hat 230, die Schweiz 200 und Österreich rund 110 Einwohner pro Quadratkilometer. Unter den deutschen Bundesländern ist Berlin mit rund 3.900 Einwohnern pro Quadratkilometer am dichtesten besiedelt. Bei den Flächenbundesländern ist es Nordrhein-Westfalen mit 520 Einwohnern pro Quadratkilometer. Der Staat mit der geringsten Bevölkerungsdichte ist die Mongolei mit nur etwa 2 Einwohnern pro Quadratkilometer. Die durchschnittliche Bevölkerungsdichte der Erde liegt bei etwa 54 Einwohnern pro Quadratkilometer Landfläche (ohne Antarktis).
Die UNO erwartet auch in der Zukunft eine weitere Zunahme der weltweiten Verstädterung. Im Jahr 2007 lebten erstmals in der Geschichte mehr Menschen in Städten als auf dem Land. Der Anteil der Stadtbevölkerung wird bis zum Jahr 2030 voraussichtlich auf über 60 % steigen und im Jahr 2050 rund 70 % erreichen. Im Jahr 1950 lag er noch bei 30 %, der Anteil der ländlichen Bevölkerung folglich bei 70 %. In absoluten Zahlen bedeutet dies eine Verdopplung der Stadtbevölkerung zwischen 2005 und 2050 von gut drei auf gut sechs Milliarden Menschen. In derselben Prognose aus dem Jahre 2007 erwartet die UNO[28] hingegen, dass die absolute Anzahl der auf dem Land lebenden Menschen zwischen 2010 und 2025 nahezu konstant sein und danach fallen wird.


[Bearbeiten | Quelltext bearbeiten]

Neben dem generellen Bevölkerungswachstum ist in den Bevölkerungspyramiden deutlich die Zunahme der Lebenserwartung zu erkennen. Diese zeigt sich in der Wandlung der verbreiterten Pyramidenform hin zu einer ausgeprägten Bienenstockform ab Mitte des 21. Jahrhunderts.

[Bearbeiten | Quelltext bearbeiten]
→ Hauptartikel: Geschlechterverteilung und Liste der Länder nach Geschlechterverteilung

Obwohl bei der Geburt das Geschlechterverhältnis bei 1,05 männlich zu 1 weiblich liegt, liegt es Stand 2018 in der Gesamtbevölkerung der Erde bei nur 1,01 zu 1. Dies ist vor allem auf die geringere Lebenserwartung von Männern zurückzuführen. In der Westlichen Welt liegt aus diesem Grund sogar fast überall ein leichter Frauenüberschuss vor. Besonders stark ist der Frauenüberschuss in Russland aufgrund der insbesondere in der Vergangenheit stark unterdurchschnittlichen Lebenserwartung russischer Männer. Auffallend ist der hohe Männerüberschuss in der Volksrepublik China, welcher mit häufigen Abtreibungen weiblicher Embryonen in Folge der Ein-Kind-Politik zusammenhängt. Noch stärker ist der Männerüberschuss aufgrund ihrer vielen männlichen Gastarbeiter in den Ländern der arabischen Halbinsel.


Die im Jahr 2011 lebenden sieben Milliarden Menschen waren über sechs Prozent der zu diesem Zeitpunkt rund 110 Milliarden jemals geborenen modernen Menschen; über 100 Milliarden waren somit in der Vergangenheit einschließlich der Steinzeit gestorben. Zur Berechnung der Zahl aller jemals geborenen Menschen gibt es verschiedene Quellen, so zum Beispiel einen Artikel des Population Reference Bureau aus dem Jahr 2002[29] mit rund 106 Milliarden jemals geborenen modernen Menschen.
Diese Hochrechnung beginnt mit zwei Menschen im Jahr 50.000 v. Chr., während man heute annimmt, dass die Menschwerdung bereits vor 200.000 Jahren oder früher in die Entstehung des modernen Menschen gemündet hat. Die frühen Menschen spielen in der Gesamtzahl jedoch nur eine untergeordnete Rolle. Trotz der langen Zeitspanne, der geringen Lebenserwartung und entsprechend hohen Geburtenraten entfallen auf die 42.000 Jahre bis zum Beginn der Sesshaftwerdung vor etwa 10.000 Jahren nur rund ein Prozent der Gesamtzahl, während mehr als die Hälfte allein auf die letzten 2000 Jahre entfällt.
Andere Arten der Gattung Homo, die in einem Zeitraum bis vor etwa 2,5 Millionen Jahren gelebt haben, sind in dieser Hochrechnung nicht enthalten. Beim Neandertaler wird teilweise davon ausgegangen, dass zeitweise nur wenige Tausend gleichzeitig gelebt haben.
Eine andere Hochrechnung stammt vom Mathematik-Department der Universität Hawaii aus dem Jahr 1999[30] und startet bereits vor einer Million Jahren mit zwei Personen. Bei ähnlicher Methodik kommt sie zu einer Gesamtzahl von etwa 96 Milliarden Menschen. Obwohl die Gesamtpopulation bereits zum Beginn der Sesshaftwerdung viel höher eingeschätzt wird, entfällt auch hier mit rund 20 Milliarden Menschen nur eine klare Minderheit auf die Zeit vor 8000 vor Christus. Ausgegangen wird dabei allerdings von einer über den ganzen Zeitraum konstanten Lebenserwartung von 25 Jahren.
Beide Hochrechnungen gehen für die gesamte Frühzeit von einem konstanten Bevölkerungswachstum aus, das sich aufgrund der Rahmenannahmen zu lediglich 0,035 bzw. 0,0015 Prozent pro Jahr errechnet (entspricht einer Verdopplung der Population innerhalb von ungefähr 2.000 bzw. 45.000 Jahren).


Am 11. Juli 1987 überschritt die Weltbevölkerung nach UN-Berechnungen die Zahl von fünf Milliarden Menschen. Um auf die damit verbundenen Probleme aufmerksam zu machen, wurde 1989 durch das Entwicklungsprogramm der Vereinten Nationen der 11. Juli eines jeden Jahres zum Internationalen Weltbevölkerungstag erklärt.[31]
Am 12. Oktober 1999 wurde nach UN-Berechnungen der sechsmilliardste Mensch auf der Erde geboren;[32] am 31. Oktober 2011 der siebenmilliardste Mensch.[33]
Am 15. November 2022 wurde die Schwelle von acht Milliarden Menschen erreicht.[34] Derzeit leben nach Angaben der Deutschen Stiftung Weltbevölkerung (DSW) 8.007.000.000 Menschen auf der Welt (Stand 28. Dezember 2022).


Überbevölkerung
Liste der Länder nach Bevölkerungswachstumsrate
Liste von Staaten und Territorien nach Bevölkerungsentwicklung
Liste von unterstaatlichen Verwaltungseinheiten nach Einwohnerzahl

Marc Frey:  In: Zeithistorische Forschungen/Studies in Contemporary History 4 (2007), S. 137–159.


Vereinte Nationen:
 (englisch)


Deutsche Stiftung Weltbevölkerung:
 – Einwohnerzahlen und Projektionen aller Länder und Regionen der Welt

 – die geschätzte aktuelle Weltbevölkerung
 – Geschätzte aktuelle Zahlen zum Bevölkerungswachstum, mit Daten zu Geburten und Toten

 (englisch)
 (englisch)
 (Website von D. Kemmer mit Links zu weiteren Quellen)
 – Das österreichische Wittgenstein-Zentrum legt eine von der UNO abweichende Berechnung vor. Die Forscher um Prof. Wolfgang Lutz rechnen für 2050 mit 9,5 Milliarden Menschen. In den Jahren danach wird eine rückläufige Entwicklung prognostiziert. , Wissen aktuell, ORF, 8. September 2015



Lebensstandard drückt das reale Niveau des Besitzes und Konsumierens von Gütern und Dienstleistungen aus und ist als quantitative Größe objektiv messbar. Demnach wird damit der materielle Wohlstand und das physische Wohlbefinden für einen Menschen, eine soziale Gruppe, einer sozialen Schicht, eines bestimmten Gebietes oder eines Staates vergleichbar gemacht.[1]
Nach Artikel 25[2] der Allgemeinen Erklärung der Menschenrechte hat jeder Mensch ein Recht auf „einen Lebensstandard, der seine und seiner Familie Gesundheit und Wohl gewährleistet“. Dabei sind Lebensmittel (Trinkwasser und Nahrungsmittel), Kleidung, Wohnung, ärztliche Versorgung und notwendige soziale Leistungen ausdrücklich eingeschlossen.



Der Systemwissenschaftler Ervin László und der Naturwissenschaftler Ernst Ulrich von Weizsäcker warnen davor, die Ideologie der Gegenwart – die einen ständig steigenden Lebensstandard anstrebt – von den Industriestaaten auf die übrige Welt zu übertragen. Die Ressourcen der Erde würden nicht ausreichen, um sowohl die Menschheit zu versorgen als auch die Stabilität der Ökosysteme zu erhalten.[3][4] Die internationale Studie Living Planet Report, die jährlich vom Global Footprint Network herausgegeben wird, bestätigt diese Befürchtungen: Wir bräuchten fünf Planeten wie die Erde, wenn alle Menschen so leben würden wie die US-Amerikaner heute (2014).[5] In Deutschland ist der ökologische Fußabdruck mehr als doppelt so groß wie die weltweit durchschnittlich verfügbare Biokapazität.[6] Da eine intakte Umwelt eine elementare Voraussetzung für einen hohen Lebensstandard ist, sieht Laszlo die Lösung in der Entwicklung neuer Wertvorstellungen jenseits der Wachstumsideologie: Lebensstandard müsste im Sinne von „Lebensqualität“ völlig neu und nachhaltig definiert werden, um der Forderung der Menschenrechte nachzukommen „und“ die Regenerationsfähigkeit der Biosphäre dauerhaft zu erhalten.[3]
Vor allem aufgrund seiner rein materiellen Betrachtung wird das Konzept von Vertretern nicht-westlicher Kulturen bisweilen als eurozentrisch eingestuft.[7][8][9]


In der Volkswirtschaft wird der (allgemeine) Lebensstandard mit Indikatoren gemessen. Hierbei werden je nach Methode wirtschaftliche und soziale Indikatoren berücksichtigt. Oft als Maßstab genommen werden:

durchschnittliches BIP pro Kopf der Bevölkerung[10]
das Bruttonationaleinkommen (früher Bruttosozialprodukt),
das Pro-Kopf-Einkommen und andere vergleichbare Indikatoren aus der Wirtschaftswissenschaft.
Seltener findet man:

Big-Mac-Index: Big-Mac-Preis im Land
Index der menschlichen Entwicklung: Eine Möglichkeit, mehr als das Bruttonationaleinkommen in den Lebensstandard miteinzubeziehen und dennoch mess- und vergleichbare Ergebnisse zu erhalten, ist der vom Entwicklungsprogramm der Vereinten Nationen veröffentlichte Index der menschlichen Entwicklung. Dieser enthält auch Daten zur Lebenserwartung, Alphabetisierungsrate und Bildung.
Anthropometrische Daten, Kalorienkonsum, Arbeits- und Freizeit sind neben Haushaltsein- und -ausgaben weitere Indikatoren des Lebensstandards.

Siehe auch: Wirtschaftswachstum und Wachstumskritik


Der allgemeine Lebensstandard in westlichen Ländern unterscheidet sich stark von dem in Entwicklungsländern. Eine hohe Dynamik und damit verbunden große Unterschiede zwischen Arm und Reich (d. h. hohem und niedrigem individuellen Standard) findet sich in den sogenannten Schwellenländern. Der allgemeine Lebensstandard ist unter anderem von der technischen Entwicklung abhängig. Beispielsweise zählte in Westeuropa in den 1950er Jahren eine – heute selbstverständliche – Waschmaschine nicht zum allgemeinen Standard. Als weiteres Beispiel ist in ländlichen Regionen entwickelter Länder ein Leben ohne Auto heute bereits mit starken Einschränkungen verbunden; der bisher nur individuelle Standard entwickelt sich hier langsam zum allgemeinen Standard, wobei arme Bevölkerungsgruppen davon ausgeschlossen sein können. Auch die Intaktheit der Umwelt hat Auswirkungen auf den Lebensstandard (z. B. Zersiedelung, Luft- und Bodenbelastung durch die Industrie).

[Bearbeiten | Quelltext bearbeiten]
Ein Industriearbeiter im 19. Jahrhundert musste typischerweise 12 Stunden täglich arbeiten, zuzüglich rund 2 Stunden häusliche Tätigkeiten. Demgegenüber wenden Jäger- und Sammlervölker – selbst in afrikanischen oder australischen Wüstengebieten – im Mittel nur 2,5 Stunden für die Nahrungsbeschaffung und 3,5 Stunden für alle weiteren Tätigkeiten auf. Beim einfachen Feldbau liegt der Wert bei knapp 7 Stunden; beim intensiven Bewässerungsfeldbau in Südostasien jedoch bereits bei fast 9,5 Stunden täglich. Wird der Lebensstandard an diesem Zeitaufwand für die täglichen Tätigkeiten für den Unterhalt, den Haushalt, die Kinder usw. gemessen, liegt ein US-amerikanischer Durchschnittsbürger heute mit 11 Stunden täglich am unteren Ende der Skala![11]



Der individuelle Lebensstandard bezeichnet das Niveau der Lebensbedingungen einer Person im Vergleich zu Anderen (zumeist derselben Gesellschaft). Auf individueller Ebene gelten insbesondere materielle Güter wie z. B. ein modernes Auto, schöne Kleidung, regelmäßige Flugreisen oder ein komfortabler Platz zum Wohnen als Ausdruck eines „angemessenen“ Lebensstandards (auch: des Lebensstils) in den Industrieländern.[12]
Jedoch weist schon der „komfortable Wohnort“ auch auf andere als materielle Dinge hin. Die modern mit allem Komfort ausgestattete Mietwohnung in sozialer Brennpunktlage hat erheblich andere Lebensqualität als ein rundum modernisiertes Fachwerkhaus in einer Altstadt. Der Verzicht auf ein Auto oder Flugreisen, der in den Augen vieler sicher einen Verlust an Lebensstandard darstellt, wird von manchen umweltbewussten Menschen als Gewinn an Lebensqualität empfunden.[13]
Lebensqualität und -standard werden außerdem von Möglichkeiten der Teilhabe an kulturellen Gütern beeinflusst – das Existenzminimum beispielsweise reicht nicht für Reisen, angemessenen Wohnraum, Zeitsouveränität, den Besuch von Gaststätten; Theater und kulturelle Veranstaltungen, Museen, Funk- und Fernsehen (Rundfunkgebühr), öffentliche Bibliotheken können auf dieser Basis nur mit hohen Ermäßigungsregelungen genutzt werden. Inwieweit hier jedoch ein „Fehlen“ von Teilhabemöglichkeiten festgestellt wird, hängt u. a. vom Bildungsstand ab. Auch Bildung gehört wie eine Reihe anderer Werte (Gesundheit, Gewaltfreiheit usw.) zum individuellen Lebensstandard. In einigen Industriestaaten lässt sich zurzeit beobachten, dass der Wohlstand zunimmt, gleichzeitig aber auch die soziale Ungleichheit (Anzahl der von Armut betroffenen) wächst. Familien mit minderjährigen Kindern und insbesondere Alleinerziehende sind dabei in der Gruppe mit niedrigem Lebensstandard überrepräsentiert.[14] (Siehe auch: Maslowsche Bedürfnishierarchie)


Auf das Individuum bezogen spricht man bei einer am bisherigen Einkommen orientierten sozialen Sicherung auch von einer Sicherung des Lebensstandards. Beispielsweise bezeichnet man die Sicherung des Lebensstandards im hohen Lebensalter als Alterssicherung. Die Sicherung des Lebensstandards ist einerseits Aufgabe des Einzelnen, andererseits Gegenstand der Politik (Sozialpolitik, Familienpolitik u. a.). Staatliche Rahmenbedingungen hierfür werden unter den Begriff Wohlfahrtsstaat gefasst.
In der Bundesrepublik Deutschland ist die Sozialversicherung an der Sicherung des bisherigen Lebensstandards orientiert. Die soziale Absicherung orientierte sich lange Zeit bei Arbeitslosigkeit (Bezug der ehemaligen Arbeitslosenhilfe) und bei Scheidung (Unterhalt) am Erhalt des bisherigen Lebensstandards durch eine am früheren Einkommen orientierte Absicherung. Von diesem Prinzip ist mit der Einführung des Arbeitslosengeldes II abgerückt worden: der Anspruch Langzeitarbeitsloser[15] hängt seitdem von einer Bedürftigkeitsprüfung ab und orientiert sich nunmehr am (sozio-kulturellen) Existenzminimum; es stellt damit keine Sicherung des früheren Lebensstandards mehr dar.[16] Von diesem Prinzip wurde ebenfalls durch die Unterhaltsreform (Gesetz zur Reform des Unterhaltsrechts) abgerückt: der Unterhalt orientiert sich nunmehr nicht dauerhaft am ehelichen Lebensstandard, sondern ist auf nacheheliche Eigenverantwortung ausgerichtet.[17]



Nach dem US-amerikanischen Ethnologen Marshall Sahlins begann die Entwicklung der Menschheit mit der „ursprünglichen Wohlstandsgesellschaft“, die von weitgehender Bedürfnisbefriedigung und reichlich arbeitsfreier Zeit für „alle“ Menschen geprägt war.[9] Erst mit der Entwicklung der verschiedenen Herrschaftsformen sowie der Arbeitsteilung und Spezialisierung kam es zu sozialer Ungleichheit mit einer oftmals drastischen Verschlechterung des Lebensstandards einzelner, rangniedriger Gesellschaftsschichten.
Auf den Lebensstandard dieser Menschen vor der Neolithischen Revolution schließt man anhand von Vergleichen mit heutigen lokalen Ethnien, die noch von traditionellen Subsistenzwirtschaften leben. Ein wichtiger Indikator ist die mittlere tägliche Energiezufuhr durch Lebensmittel. Diese unterscheidet sich erheblich zwischen Gesellschaften und beträgt etwa 6.280 kJ (= 1.500 kcal) bei den Yanomami bis zu etwa 15.900 kJ (= 3.800 kcal) bei den Aché.
Im vorindustriellen England konsumierte man täglich geschätzte 9.630 kJ (= 2.300 kcal). Die Yanomami haben dabei eine größere Abwechslung als es die Engländer hatten: Während die Engländer sich hauptsächlich von Brot und ein wenig Käse und Speck ernährten, standen auf dem Speiseplan der Yanomami zahlreiche Tier- und Pflanzenarten, unter anderem Wildschwein, verschiedene Vögel, Insekten und Fische, Früchte und Gemüse. Ein anderer Indikator des Lebensstandards ist die Körpergröße, wobei eine zunehmende Größe mit größerem Lebensstandard verbunden wird.[18] Sie deutet auf keinen Zuwachs des Lebensstandards vor der Industriellen Revolution hin. Jäger und Sammler waren nicht kleiner als Europäer im 18. Jahrhundert, und teilweise größer als Asiaten.[19]


Großen Einfluss auf die Arbeitswelt hatte die Industrielle Revolution. Uneinheitlich wird jedoch die Entwicklung des Lebensstandards zu dieser Zeit betrachtet. Wie die britische Wirtschaftsentwicklung der auf dem europäischen Kontinent um Jahrzehnte vorauslief, so auch die Veränderungen der Sozialstruktur und der proletarischen Existenzbedingungen. Deshalb stand auch zunächst die Entwicklung des Lebensstandards der britischen Arbeiterschaft im Zuge der Industriellen Revolution – wie bei Engels – im Mittelpunkt des Interesses der zeitgenössischen Beobachter. Eine Studie von Peter H. Lindert und Jeffrey G. Williamson aus dem Jahr 1983[20] schätzte die Entwicklung der Reallöhne zwischen 1755 und 1851 in mehreren Berufen und kam zu dem Ergebnis, dass Löhne von 1781 bis 1819 nur leicht anstiegen, im Zeitraum 1819–1851 sich hingegen verdoppelten. Diese Sicht wurde von anderen Ökonomen teilweise in Frage gestellt. Charles Feinstein verwendete einen anderen Preisindex als Lindert und Wiliamson und meinte, dass der Anstieg der Löhne deutlich geringer gewesen sein müsse. Untersuchungen zur Körpergröße stellen eine Abnahme dieser für den Beginn der industriellen Revolution im Europa des späten 18. Jahrhunderts fest, was John Komlos auf die große Ungleichheit zu dieser Zeit zurückführt.[18]
Die meisten Wirtschaftshistoriker stimmen darin überein, dass die Einkommensverteilung zwischen 1790 und 1840 ungleicher wurde. „Was die Anteile am Sozialprodukt betrifft, steht fest, dass die Steigerung der Kapital- und Renteneinkommen weit über und jene der Lohneinkommen weit unter der Steigerung des durchschnittlichen Pro-Kopf-Einkommens lag.“[21] Berücksichtigt man die Folgen von Arbeitslosigkeit, Umweltverschmutzung und Bevölkerungsdichte, erscheint eine zeitweilige Verschlechterung des Lebensstandards plausibel. Teilweise wird argumentiert, dass eine Reihe von Kriegen (Amerikanische Revolution, Napoleonische Kriege, Britisch-Amerikanischer Krieg) die positiven Effekte dämpften. Osterhammel resümiert: „Insgesamt verbesserte sich das Leben der arbeitenden Bevölkerung in England zwischen 1780 und 1850 nicht. Danach zogen die Löhne deutlich an den Preisen vorbei, und die Lebenserwartung begann allmählich zu steigen.“[22]
Im 20. Jahrhundert kam es, insbesondere nach dem Zweiten Weltkrieg, zu einem rapiden Wachstum des Lebensstandards in Industrieländern. Damit verbunden wuchs z. B. die Körpergröße bei Skandinaviern, Deutschen und Franzosen im Mittel um etwa 18 Zentimeter.[18] Es stiegen unter anderem auch die Lebenserwartung und der Bildungsstand, die Kindersterblichkeit nahm rapide ab. Die Ungleichverteilung des Lebensstandards in den USA nahm nach dem Zweiten Weltkrieg weiter ab, stieg jedoch seit Mitte der 1970er Jahre wieder an. Langfristige Entwicklungen bei Einkommensunterschieden folgten auch in den meisten westeuropäischen Ländern und westlichen Ablegern einer U‑Kurve: Die Ungleichheit im Einkommen ging gegen Ende des 19. Jahrhunderts bis etwa 1970 zurück und steigt seitdem in den OECD-Mitgliedsstaaten wieder an.[23][24]


Luxus

Hans-Jürgen Andreß und Gero Lipsmeier: Was gehört zum notwendigen Lebensstandard und wer kann ihn sich leisten? in: Aus Politik und Zeitgeschichte B31-32/95, 1995, S. 35–49
Hans-Jürgen Andreß, Anne Krüger, Bronia Katharina Sedlacek: , Köln 2004
Petra Böhnke und Jan Delhey:  (PDF; 226 kB), Berlin 1999
David Piachaud: Wie misst man Armut?, in: Stephan Leibfried und Wolfgang Voges (Hrsg.): Armut im modernen Wohlfahrtsstaat, Westdeutscher Verlag, Opladen 1992, 70-72
OECD: , OECD Framework for Statistics on the Distribution of Household Income, Consumption and Wealth, 2013.







Dieser Artikel behandelt Küsten. Für Küste als Bezeichnung für die Schiffbrücke (Flensburg) siehe dort. Zu weiteren Bedeutungen siehe Die Küste (Begriffsklärung).


Als Küste wird der Grenzraum der sich wechselseitig beeinflussenden Ökosysteme von Land und Meer bezeichnet. Abhängig von der Küstenform ist dieser Raum von unterschiedlicher Breite. Er kann sich an Flachküsten (z. B. der Nordseeküste) mitunter über mehr als 100 km erstrecken.
Der gemeinhin als Küstenlinie bezeichnete Ufersaum bestimmt sich durch die Linie des mittleren Wasserstands. Bei Gezeitenküsten ist dies die Linie des mittleren Tidehochwassers.
Über die Zeit gesehen, ist die Küste einem ständigen Wandel unterlegen. Die räumliche Lage wird von vielfältigen Faktoren beeinflusst. Hierzu zählen u. a. Veränderungen des Meeresspiegels, geänderte Strömungsverhältnisse, Änderungen der Salinität. Jede Änderung kann dabei natürlich bedingt sein, aber auch durch die räumliche Inanspruchnahme des Küstenraums durch den Menschen bewirkt werden. Zu den physischen Prozessen zählen einerseits eustatische Meeresspiegelschwankungen, aber auch isostatische Hebungen und Senkungen. Zu den anthropogen bedingten Faktoren zählen beispielsweise bauliche Veränderungen an Land (z. B. Deichbau), ebenso wie die beidseits des Ufers vollzogenen wirtschaftlichen Nutzungen. Hier sind u. a. zu nennen:

Fischerei in küstennahen Gewässern
Fremdenverkehr an Land und zu Wasser
industrielle Tätigkeiten (z. B. Offshore-Windparks)
Schiffsverkehr in den Küstengewässern



Eine eindeutige Klassifikation in Küstentypen ist schwierig. Küsten lassen sich nach verschiedenen Kriterien einteilen, beispielsweise 

nach dem Querschnitt: Flachküste und Steilküste
nach dem Verlauf: Ausgleichsküste und Buchtenküste
nach der Ausrichtung zum Gelände: Längsküste und Querküste
nach der geologischen Entstehung: z. B. Hebungsküste und Senkungsküste
Dabei kann es Überschneidungen geben. Einige Küstentypen werden nachfolgend kurz erläutert.

[Bearbeiten | Quelltext bearbeiten]

Buchtenküsten entstehen, wenn ein Meer weit in das Land hineingreift. Sie entstanden durch den Meeresspiegelanstieg nach der letzten Kaltzeit. Gute Beispiele dafür sind weite Strecken der Ostseeküste und der Nordseeküste.
Die Küstenformen der Ostsee sind hauptsächlich ein Resultat eiszeitlicher Gletscherbewegungen und nach-eiszeitlicher Geländehebung (Isostasie) im nördlichen und Absenkung im südlichen Bereich der Ostsee, die bis heute andauern. Des Weiteren werden die Küsten durch die Lage in der Westwindzone beeinflusst, wodurch über die Strömung von Westen her beständig Sedimente verdriftet werden. Prägende Küstentypen sind die Fördenküste, die Boddenküste, die Ausgleichsküste und die Fjord-Schärenküste.
Die Küste der Nordsee ist größtenteils beeinflusst durch nacheiszeitliche eustatische (Gletscherschmelzen) und isostatische (Landhebung) Meeresspiegelschwankungen, einzelne Sturmflutereignisse und die Gezeiten. Charakteristisch für die Nordseeküste ist die Wattküste mit ihren typischen Barriereinseln. Sie reicht von Westfriesland über Ostfriesland bis nach Nordfriesland, also von der niederländischen Insel Texel bis zum dänischen Fischereihafen Esbjerg. Landgewinnungs- und Küstenschutzmaßnahmen (Lahnungen, Deiche) prägen dabei die Küstenlandschaft. Eine weitere Form der Küste, die Steilküste, prägt beispielsweise die Insel Helgoland.

[Bearbeiten | Quelltext bearbeiten]
Gebirgszüge parallel zur Küste, buchtenreich. Sie entstanden nach Abbruch eines höherliegenden Gebietes zum Meer.

[Bearbeiten | Quelltext bearbeiten]
Eine tektonisch bedingte Form der Ingressionsküste, deren Strandlinie infolge tektonischer Absenkung der Landmasse unter den rezenten Meeresspiegel abgesenkt wurde. Die Unterscheidung von tektonisch bedingter Hebung und eustatischen Meeresspiegelschwankungen ist problematisch.


[Bearbeiten | Quelltext bearbeiten]

Eine Riasküste ist ein Küstentyp mit einer schmalen und langen, tief in das Land eindringenden Meeresbucht.
Die Riasküste entsteht durch den Anstieg des Meeresspiegels. Durch die Überschwemmung von Flusstälern entstehen tiefe Buchten. Im Gegensatz zu Fjordküsten sind die Riasküsten nicht glazial, sondern fluvial (durch einen Fluss) geprägt. Davor befinden sich häufig zahlreiche Inseln.
Riasküsten sind in Nordwestspanien (Galicien), Irland, Cornwall, in der Bretagne (Golf von Morbihan) und auf Korsika zu finden.

Siehe auch: Potamogene Küstenformen
[Bearbeiten | Quelltext bearbeiten]
Bei der Canaleküste handelt es sich um ein parallel zur Küste verlaufendes Gebirge, das durch den Meeresanstieg (Eustasie) im Meer versunken ist. Die Antiklinalen verlaufen parallel. Ein gutes Beispiel für die Canaleküste ist die dalmatinische Küste auf der Balkanhalbinsel.

[Bearbeiten | Quelltext bearbeiten]
Die Lagunenküste ist die vollendete Form der Haff- oder Nehrungsküste. Die Buchten sind endgültig zusammengewachsen. Die Nehrung nennt sich jetzt, vornehmlich im Italienischen, „Lido“. Die Lagune ist vom offenen Meer getrennt. Diese Küstenform findet sich überwiegend in Italien. Die Lagunenküste sieht aus wie eine Haffküste.

[Bearbeiten | Quelltext bearbeiten]

Schären entstanden während der Eiszeit, als Gletscher über felsige Landschaften verliefen und diese entweder abschliffen oder teilweise zermahlten. So lassen sich die beiden unterschiedlichen Formen der heute zu findenden Schären erklären. Die einen sind auf der Oberfläche relativ eben, haben teilweise Schleifspuren von Felsen, die der Gletscher über sie hinweggeschoben hat. Die anderen sind durch eine zerklüftete Oberfläche gezeichnet, die daher stammt, dass der Gletscher hier mechanische Zerstörungen verursacht hat, indem er ganze Teile des Felsens durch vorheriges Anfrieren herausgerissen hat (Detraktion). Schärenküsten findet man in Europa beispielsweise in Norwegen, Schweden und Finnland. An Dänemarks Küsten konnten aufgrund der vorhandenen Küstenform keine Schären entstehen. Der felsige Untergrund wie im übrigen Skandinavien fehlte.

[Bearbeiten | Quelltext bearbeiten]
Die Mangroveküste, quasi die „Wattenküste der Tropen“, gibt es ausschließlich im Bereich der Tropen. Charakteristisch ist ein starker Pflanzenbewuchs mit Stelzwurzeln, der hier durch einen größeren Tidenhub entstehen konnte.


Norbert Fischer, Susan Müller-Wusterwitz, Brigitta Schmidt-Lauber (Hrsg.): Inszenierungen der Küste. Reimer-Verlag, Berlin 2007, ISBN 978-3-496-02800-0 (Schriftenreihe der Isa-Lohmann-Siems-Stiftung 1).
Dieter Kelletat: Physische Geographie der Meere und Küsten. Eine Einführung. 2. neubearbeitete und erweiterte Auflage. Teubner, Stuttgart u. a. 1999, ISBN 3-519-13426-8 (Teubner-Studienbücher der Geographie).






Artenvielfalt – auch Artendiversität genannt – bezeichnet in der Biologie die Anzahl biologischer Arten innerhalb eines bestimmten Lebensraumes (Biotop, Biom oder Ökoregion) oder eines geographisch begrenzten Gebietes (beispielsweise Gebirge, Land, Rasterzelle). Häufig wird sie differenziert nach Flora oder Fauna oder noch konkreter nach den traditionellen biologischen Klassen (etwa Artenvielfalt der Pflanzen, der Bäume, der Insekten, der Fische, der Amphibien, der Reptilien, der Vögel, der Säugetiere usw.). Die Vielfalt der Arten ist ein Teil der Biodiversität und das wesentlichste Maß zu ihrer Charakterisierung.



Die „Artenvielfalt“ ist ein Teil der Biodiversität bzw. „biologischen Vielfalt“. Diese umfasst neben der Vielfalt der Arten auch die genetische Vielfalt und die Vielfalt der Ökosysteme. Artenvielfalt wird häufig synonym zu Biodiversität verwendet; Artenvielfalt ist die anschaulichste Form der Biodiversität.

[Bearbeiten | Quelltext bearbeiten]
Seit 1994 ruft die UNESCO jährlich zum „Internationalen Tag der biologischen Vielfalt“ (International Day for Biological Diversity) auf, zunächst für den 29. Dezember, der Tag an dem das Übereinkommen über die biologische Vielfalt (Convention on Biological Diversity) 1993 international in Kraft trat, seit 2001 für den 22. Mai,[2] der Tag wiederum, an dem das UN-Übereinkommen über Biodiversität am 22. Mai 1992 in Nairobi beschlossen wurde.[3] 2020 stand er international unter dem Motto „Our solutions are in nature“ („Unsere Lösungen liegen in der Natur“),[4] deutschsprachig „Unsere Artenvielfalt, unsere Ernährung, unsere Gesundheit“, womit auf einen direkten Zusammenhang zwischen dem Erhalt der Artenvielfalt sowie der menschlichen Ernährung und der Gesundheit hingewiesen werden sollte.[5] 2021 wurde er als virtuelles Global Biodiversity Festival ausgerufen, bei dem in einem über 72 Stunden dauernden Programm auf die fortschreitenden weltweiten Artensterben hingewiesen wurde.[6]
Seit 1999 wird auch ein von der deutschsprachigen Zeitschrift GEO jährlich für den Juni ausgerufener[7] „Tag der Natur“ begangen,[8][9] im deutschen Sprachraum wiederum „Internationaler Tag der Biodiversität“ bzw. „Internationaler Tag der Artenvielfalt“.[10][11]
Im deutschen Bundesland Baden-Württemberg veranstaltet seit 2022 der Landesnaturschutzverband (LNV) einen „Tag der Artenvielfalt in Baden-Württemberg“; für den Mitte Juni 2023 übernahm der dortige Ministerpräsident Winfried Kretschmann die Schirmherrschaft.[12]
Darüber hinaus gibt es Aktivitäten verschiedener Organisationen, die regelmäßig an die Artenvielfalt erinnern oder aktiv dazu aufrufen, die lokale Artenvielfalt zu erfassen, darunter etwa die „Stunde der Garten-“ oder „Stunde der Wintervögel“ des Naturschutzbundes Deutschland (NABU).



Im Global Biodiversity Assessment, im Auftrag der UNEP (United Nations Environment Programme) 1995 erstellt, wurde für die Erde insgesamt eine Zahl von rund 1,75 Millionen beschriebenen Arten angegeben.[13] Diese Zahl ist nur ein Schätzwert. Eine genaue Aufstellung existiert nicht. Heute rechnet man mit insgesamt über 2 Millionen beschriebenen Arten.[14] Die genaue Zahl beschriebener Arten anzugeben ist schwer möglich, da

viele Arten mehrfach beschrieben worden sind und die wissenschaftlichen Synonyme erst im Laufe der Zeit eliminiert werden und
viele vermeintlich einheitliche Taxa molekulargenetisch in mehrere Arten aufgetrennt werden, aber vielfach noch nicht mit einem Namen belegt sind (sogenannte kryptische Arten). Bei den Prokaryonten beruhen alle modernen Artkonzepte, und damit auch die sehr hohen in jüngerer Zeit genannten Artenzahlen, auf ausschließlich durch Genanalyse unterscheidbaren Formen. Inwieweit auch bei Tier- und Pflanzenarten molekulargenetisch unterscheidbare, aber morphologisch identische Taxa als Arten akzeptiert werden, hängt stark vom jeweiligen wissenschaftlichen Artkonzept ab.
Taxonomen unterscheiden daher häufig zwischen „nominellen Arten“ (Anzahl der Namen) und „validen Arten“ (Anzahl der realen Einheiten). So sind von den Fischen derzeit mehr als 50.000 nominelle Arten beschrieben; akzeptiert werden davon gegenwärtig gut 31.000 valide Arten (Stand: 2009).[15] Die meisten Synonyme gehen dabei auf die frühen Pioniertage der Taxonomie zurück. Von den seit ca. 1970 neu beschriebenen Arten erwies sich nur ein verschwindender Bruchteil als Synonym.
Derzeit sind rund 260.000 Gefäßpflanzenarten (möglicherweise auch 400.000: Govaerts 2001,[16]) rund 50.000 Wirbeltierarten und etwa 1 Million Insektenarten beschrieben (Schätzungen: Nielsen & Mound: 865.000 Arten[17]). Da die Gefäßpflanzen vergleichsweise viele Arten aufweisen und viel leichter zu erfassen sind als etwa Insekten und weil die globale Verteilung dieser Pflanzen weitgehend denen anderer Taxa entspricht, wird ihre Artenvielfalt gern für die Kartierung der globalen Biodiversität verwendet (siehe Weltkarte).[18]
Aus den Meeren sind zwischen 240.000 und 330.000 Arten bekannt (Schätzungen: 242.000 Arten im Global Biodiversity Assessment,[13] 230.000 Arten nach Bouchet,[19] 318.000 Arten nach Reaka-Kudla[20]). Etwa 51 Prozent aller heute beschriebenen Arten der Erde sind Insekten und etwa 14 Prozent gehören zu den Gefäßpflanzen. Den Rest von rund 35 Prozent (etwa 700.000 Arten) bilden die übrigen tierischen und pflanzlichen Organismen einschließlich aller Einzeller und aller Wirbeltiere.
Zurzeit sind 4.500 Prokaryontenarten (Bakterien und Archaebakterien) beschrieben, das heißt, sie haben einen wissenschaftlichen Namen gemäß den Nomenklaturregeln erhalten. Für viele Mikrobiologen erscheint aber fraglich, ob die von der Beschreibung von Pflanzen- und Tierarten abgeleitete Artdefinition auf Prokaryonten anwendbar ist (vgl. physiologisches Artkonzept bei Bakterien). Nach dem phylogenetischen Artkonzept gibt es keine Bakterienarten (Ernst Mayr).
Man kann die Artenzahl auch nach Lebensräumen aufteilen: Von den derzeit beschriebenen rund zwei Millionen Arten leben rund 78 Prozent auf dem Festland, 17 Prozent im Wasser und etwa 5 Prozent (rund 100.000 Arten) leben als Parasiten oder Symbionten in anderen Organismen (die letztgenannte Zahl hängt stark von der Definition von Parasitismus und Symbiose ab). Zur Artenvielfalt der Meere hat das Projekt Census of Marine Life wichtige neue Erkenntnisse erbracht.



Die globale Gesamtzahl aller Arten wurde in den vergangenen zwei Jahrzehnten sehr stark unterschiedlich zwischen 3,6 Millionen bis zu 112 Millionen geschätzt. Die Schätzgrößen wurden extrapoliert auf der Basis der Mitte der 1990er Jahre beschriebenen rund 1,75 Millionen Arten. Einen differenzierten Überblick über den damaligen Schätzstand gibt wiederum das Global Biodiversity Assessment von 1995, zu welchem in den letzten Jahren für viele Teilgruppen aktuellere Schätzwerte erarbeitet worden sind. Ein aktuellerer Gesamtüberblick wurde nicht mehr erarbeitet.
Einige weithin zitierte Schätzwerte:

Im Jahr 1982 publizierte Terry L. Erwin eine Studie über Käferarten, die er auf einer tropischen Baumart (Luehea seemannii) in Panama gefunden hatte. Er fand insgesamt ca. 1.200 Käferarten, von denen er 163 als wirtsspezifisch einschätzte (d. h., sie sollen nur auf L. seemannii leben). Durch Hochrechnen auf die (geschätzt) 50.000 tropischen Baumarten und den Anteil der Käfer an der Gesamtfauna extrapoliert er eine Gesamtsumme von 30 Millionen Arthropodenarten in den tropischen Baumkronen.[21] Die Arbeit von Erwin ist vielfach kritisiert worden. Viele Fachkollegen sind der Ansicht, dass er den Anteil der spezialisierten Arten zu hoch angesetzt hat. Mit demselben Ansatz kommen sie so zu 5 bis 7 Millionen Arten.
Grassle und Maciolek extrapolierten von der Zahl der bodenlebenden Arten aus Proben, die sie mit einem Greifer vom Tiefseeboden gewonnen hatten, auf die Artenzahl für bodenlebende Makroorganismen (z. B. Mollusken, Polychaeten, Krebstiere) am Meeresboden insgesamt. Sie kamen dabei auf 10 Millionen Arten.[22] Auch ihr Ansatz ist vielfach als überhöht kritisiert worden.
Hawksworth schätzte im Jahr 1991 die weltweite Zahl der Pilzarten durch Extrapolation der (sehr gut erforschten) britischen Zahlen auf die (meist mangelhaft erforschte) restliche Welt und kam so auf ca. 1,5 Millionen Pilzarten.[23] Hawksworth und Lücking veröffentlichten im Jahr 2017 neue Ergebnisse. Sie schätzten im Jahr 2017 die weltweite Zahl auf 2,2 bis 3,8 Millionen Pilzarten.[24] Tatsächlich beschrieben sind 2017 allerdings weltweit nur ca. 120.000 Pilzarten.
Stork und Gaston versuchten, die Artenzahl der Insekten aus der relativ gut erforschten Artenzahl der Schmetterlinge (Tagfalter) hochzurechnen. In England leben 67 Tagfalterarten und 22.000 andere Insektenarten. Bei weltweit 15.000 bis 20.000 Tagfaltern ergäben sich ca. 4,9 bis 6,6 Millionen Insektenarten insgesamt.
Zahlreiche Forscher, unter ihnen z. B. May, machen auf die weithin unbekannte, aber vermutlich sehr hohe Artenzahl der parasitischen Arten aufmerksam.[25] Wenn jede frei lebende Tierart einen spezifischen parasitischen Protozoen und einen Nematoden beherbergen würde, müsste man die Anzahl der anderweitig ermittelten Arten bereits verdreifachen.
Einer Studie von 2011 zufolge leben 8,7 Millionen Arten von Organismen auf der Erde. Davon leben 6,5 Millionen an Land und 2,2 Millionen in den Ozeanen. Diese Zahlen stammen vom „Census of Marine Life“, dessen Wissenschaftlern mit Hilfe einer neuen Methode der Stammbaumanalyse die genaueste jemals gemachte Schätzung der Artenzahl gelungen sei.[26]
Die Zahl der tatsächlich auf der Erde lebenden Arten ist allen seriösen Schätzungen nach weitaus höher als die Zahl der gegenwärtig beschriebenen. Fast alle Forscher stimmen aber darin überein, dass brauchbare Zahlenwerte zurzeit kaum anzugeben sind. Alle Schätzungen hängen in extremer Weise von den Schätzwerten für die tropischen Regenwälder ab, für die viel zu wenig belastbare Daten vorliegen. Gaston und May machen zum Beispiel darauf aufmerksam, dass in allen „Entwicklungsländern“ der Erde zusammen nur etwa 6 % der Taxonomen arbeiten.[27] Gleichzeitig werden auch in den reichen Nationen die Stellen für Taxonomen gestrichen, so dass, nur halb ironisch, manche den Taxonomen selbst zur bedrohten Spezies ausgerufen haben. Außerdem behindern gut gemeinte Regelungen über die Eigentumsrechte an Arten infolge der Biodiversitätskonvention die Erforschung, weil manche Staaten auch bisher unbekannte Arten als ihr Eigentum ansehen und die Erforschung behindern.[28] Für manche Tiergruppen existieren ernst zu nehmende Hinweise darauf, dass manche Schätzwerte unter Umständen weit überhöht sein könnten. Lambshead und Boucher vermuten etwa, dass die Zahl der marinen Nematoden, die zeitweise auf über 10 Millionen Arten geschätzt worden ist (man findet sogar vereinzelt Angaben von 100 Millionen), viel niedriger liegt (unter einer Million, eventuell deutlich darunter).[29] Tatsächlich beschrieben sind (im Jahr 2001) 26.646 Arten.[30]
Die nach den Insekten vermuteten nächstgrößten Gruppen bezüglich Artenzahlen sind die Pilze, die Algen und vielleicht die Fadenwürmer und Spinnentiere. Die Wirbeltiere fallen bei der Gesamt-Artenzahl überhaupt nicht ins Gewicht. Man schätzt die Gesamt-Artenzahl der Säugetiere auf etwa 4.000, die der Vögel auf 8.500 bis 9.500. Pro Jahr werden dabei ca. 3 Vogelarten neu beschrieben. Obwohl auch heute noch gelegentlich große Säugetierarten beschrieben werden (so noch 1991 eine Walart und 1993 mit dem Vu-Quang-Rind ein Großsäuger), sind wesentliche Neuentdeckungen hier kaum noch zu erwarten.
Heute geht man eher von Gesamt-Artenzahlen auf der Erde von rund 5 (bis vielleicht 20) Millionen Arten aus. Unter den renommiertesten Fachwissenschaftlern hat Nigel Stork eine Schätzung von 5 bis 15 Millionen vorgelegt.[31] Robert May schätzt – mit vielen Vorbehalten – es seien möglicherweise bis zu 20 Millionen.[25] Eine zentrale Datenbank für alle systematisierten Arten existiert bislang nicht. Die Gesamtzahl hängt auch sehr stark davon ab, was in den jeweiligen Organismengruppen als eine Art angesehen wird und hängt vom jeweiligen Artkonzept ab. Pro Jahr werden rund 12.000 bis 25.000 Arten neu beschrieben (der langjährige Durchschnitt liegt knapp über 13.000), viele von ihnen erweisen sich später häufig als Synonyme für schon beschriebene Arten. Insofern unterscheidet man auch zwischen sogenannten „nominellen Arten“ und „validen Arten“. Die letzteren sind die jeweils nach kritischer Überprüfung durch entsprechende Spezialisten akzeptierten „guten Arten“. Vielfach wird die Arttrennung heute mittels molekulargenetischer Untersuchungen vorgenommen oder zumindest durch sie ergänzt.
Ein eigenes Problem ist die Zahl der „Arten“ bei Prokaryonten. Die üblichen mikrobiologischen Methoden sind hier wertlos, da nach überschlägigen Untersuchungen sich weniger als 1 % der in natürlichen Proben (nach dem Genom) festgestellten Bakterienarten in den üblichen Nährmedien kultivieren und vermehren ließ. Durch eine Artendefinition, die Stämme mit einer genetischen Ähnlichkeit (nach dem Rekombinationsgrad) von kleiner 70 % als Arten definiert, und Hochrechnungen aus Bodenproben analog den oben genannten Beispielen, kam Dykhuizen 2005 auf eine Milliarde Bakterienarten.[32] Diese Zahl sollte vielleicht eher als das Ausmaß unseres Nichtwissens verstanden werden.

Siehe auch: DNA-Barcoding

[Bearbeiten | Quelltext bearbeiten]
Vom Gebiet der Bundesrepublik Deutschland sind 4.105 höhere Pflanzenarten (Gefäßpflanzen) bekannt.[33] Nach einer Abschätzung von Völkl und Blick 2004 sind 44.787 vielzellige Tierarten dokumentiert.[34] Davon sind 38.370 Arthropodenarten, unter denen die Insekten mit 33.305 Arten den größten Teil stellen. Aus Deutschland sind insgesamt nur 706 Wirbeltierarten belegt. Im internationalen Vergleich gilt die Flora und Fauna Deutschlands als sehr gut bekannt. Trotzdem werden auch in Deutschland nach wie vor jedes Jahr Arten neu gefunden oder sogar neu beschrieben.
Allerdings nimmt die Artenvielfalt in Deutschland besonders in den ackerbaulich genutzten Regionen wie z. B. Nordwestdeutschland im Zuge der Intensivierung der Landwirtschaft stark ab. Dies wird besonders an den Vögeln der Feldflur wie Rebhuhn, Feldlerche und Grauammer deutlich[35][36]. Forscher der Zoologischen Staatssammlung München fanden auf einer ökologisch bewirtschafteten landwirtschaftlichen Fläche die 2,6-fache Menge an Biomasse, im Vergleich zu einer konventionell bewirtschafteten.[37]

[Bearbeiten | Quelltext bearbeiten]
Die Gesamtzahl der Arten in der Schweiz wurde 2011 auf ca. 60.000 geschätzt. Eine Untersuchung im Zoo von Basel ergab auf dessen Gelände über 3.100 direkt bestimmbare Arten, mit den nicht direkt bestimmbaren wurde ihre Anzahl dort auf 5.500 geschätzt.[38] Allerdings nimmt die Artenvielfalt in der Schweiz, trotz den Anstrengungen der letzten Jahrzehnte, ab. Die Schutzmaßnahmen konnten mit den anhaltenden oder gar weiter zunehmenden Bedrohungen nicht Schritt halten.[39]


Nach der International Union for Conservation of Nature and Natural Resources (IUCN) galten 2007 rund 12 % der Arten der Vögel, 20 % der Säugetiere, 29 % der Amphibien und 33 % der Nacktsamer unter den Pflanzen als bedroht. Diese vier Gruppen sind zugleich die einzigen, deren Bedrohungsstatus auf der Evaluierung aller oder zumindest der meisten Arten beruht. Von den übrigen Gruppen (z. B. Fischen, Insekten, Bedecktsamer) ist nur ein relativ geringer Prozentsatz weltweit evaluiert worden, so dass sich die gefundenen Bedrohungszahlen statistisch nicht auf die Gesamtgruppe hochrechnen lassen. Zum Beispiel sind nur 1255 relativ auffällige Insekten-Arten von den insgesamt rund 1 Million beschriebenen (und zahlreichen unbeschriebenen) Insekten-Arten überprüft worden, so dass über den Bedrohungsstatus der Insekten als Gesamtheit aller Arten keine realistische Aussage machbar ist.
Der „Living Planet Index“ des WorldWildlifeFund (WWF) konstatierte 2014, dass die Artenvielfalt auf der Erde zwischen 1970 und 2010 um 52 Prozent gesunken ist. Lateinamerika erleidet mit durchschnittlich 83 Prozent den stärksten Verlust. Die Populationen der an Land lebenden Arten verkleinerten sich um 39 Prozent, Süßwasser-Arten um 76 Prozent und Arten in den Meeren um 39 Prozent.[40]
Vielfach wird das derzeitige Artensterben mit den großen Massenaussterben der Vergangenheit verglichen. Paläontologen unterscheiden traditionell während der vergangenen 600 Millionen Jahren fünf (teilweise auch mehr) große Artensterben, die laut neueren Erkenntnissen nach geologischen Maßstäben sehr rasch verliefen und teilweise innerhalb von wenigen 10.000 Jahren erfolgten. Diese biologischen Krisen wurden mitunter vorher und nachher von kleineren Aussterbe-Ereignissen flankiert und stellen nur die auffälligsten Auslenkungen der stets schwankenden Artenzahlen dar. Eine Schwierigkeit bei der Analyse ist dabei, dass die jeweilige Fossillage kein 1:1-Abbild der ehemaligen Artenvielfalt und des Artensterbens ist, sondern nur Informationen über die unter den jeweiligen Bedingungen fossilisierbaren ehemaligen Arten liefert. Weitere Probleme, die einen Vergleich mit der heutigen Situation schwierig machen, sind z. B. die vielfach merkmalsarmen fossilen Überreste, die es häufig nicht ermöglichen, wirklich einzelne Arten im biologischen Sinne definieren zu können; häufig entsprechen die Beschreibungen eher ganzen Gattungen oder noch höheren systematischen Einheiten. Der bedeutsamste Unterschied früherer Massensterben zur derzeitigen Situation ist aber der, dass das heutige Aussterben durch eine einzige biologische Art, nämlich den Menschen mit seinen Aktivitäten und seinem Raum- und Ressourcenanspruch verursacht wird, während frühere Ursachen wohl überwiegend geologische oder atmosphärisch-kosmische Ursachen hatten.


2019 wurde von der Intergovernmental Platform on Biodiversity and Ecosystem Services (IPBES) ein Bericht zur globalen Artenvielfalt veröffentlicht, in dem auf das gegenwärtige Massenaussterben hingewiesen wird.[41]



„Die Tatsache, dass der Wert der Ökosysteme und der Biodiversität bisher ökonomisch nicht wahrgenommen wird, ist eine entscheidende Ursache der alarmierenden Zerstörung der Natur.“


– Pavan Sukhdev, Generaldirektor Deutsche Bank (2011)[42]
Ökologische Werte finden bisher kaum Eingang in volks- oder betriebswirtschaftliche Rechnungen (siehe Ökologischer Fußabdruck).
Als wesentliche Ursachen des heutigen Artensterbens gelten:

Die Zerstörung natürlicher Lebensräume: Nach den Erkenntnissen der ökologischen Forschung hängt der Artenreichtum eines Lebensraums direkt von seiner Fläche ab. Wird ein Lebensraum durch menschliche Aktivitäten, beispielsweise durch Waldrodung, verkleinert, verliert er einen Teil seines Artenbestands. Wie viele und welche Arten aussterben, ist im Einzelnen schwer vorherzusagen (Beziehung über sogenannte Arten-Areal-Kurven, die zwischen verschiedenen Habitaten unterschiedlich sind). Vorhersagen des heutigen Artensterbens beruhen kaum jemals auf dem direkten Nachweis des Aussterbens einzelner bekannter Arten, sondern sind im Wesentlichen aus diesem Zusammenhang abgeleitet.
Übernutzung, z. B. Überfischung, Überweidung und unkontrolliertes Bejagen oder Sammeln: durch Übernutzung degradieren Ökosysteme. Wie stark sich Ökosysteme, die weithin als natürlich gelten, bereits verändert haben, zeigt zum Beispiel Jackson am Beispiel der atlantischen Küstengewässer.[43]
Verschmutzung: Während der letzten 4 Jahrzehnte hat sich z. B. der weltweite Pestizidverbrauch auf 2,5 Millionen Tonnen jährlich verdreifacht, 50.000 verschiedene Chemikalien sind im Einsatz. Rückstände dieser und anderer Chemikalien finden sich in natürlichen Ökosystemen.[44] Auswirkungen auf natürliche Lebensgemeinschaften sind schwer abschätzbar.
Klimaveränderung: Veränderungen von Artarealen infolge klimatischer Veränderungen sind im Prinzip ein natürlicher Vorgang. Bedrohlich am menschengemachten Klimawandel ist zum einen das (in natürlichen Zeiträumen betrachtete) extreme Tempo der Veränderung, das die Anpassungsfähigkeit vieler Arten überfordern könnte. Außerdem sind fatale Wechselwirkungen zwischen Klimaveränderungen und Habitatzerstörung anzunehmen. Mögliche Refugialräume stehen aufgrund menschlicher Nutzungen nicht zur Verfügung, oder sind durch Biotopzerschneidung nicht erreichbar. Außerdem passt das Netz der ausgewiesenen Schutzgebiete möglicherweise nicht mehr zu den veränderten Arealen der Arten.
Die Verdrängung einheimischer durch invasive Arten: Artenverluste durch eingeschleppte Arten haben in großem Umfang vor allem Inselökosysteme verwüstet. Pimm u. a.[45] weisen in einem klassischen Artikel zum Beispiel auf den Verlust von Vogelarten der polynesischen Inseln durch die einwandernden Polynesier und die mit ihnen eingeschleppten Ratten hin: Ein Verlust von etwa 2.000 Vogelarten (etwa 15 % der Weltfauna) ist anzunehmen. Lokal kann durch Neobiota die Artenvielfalt sogar ansteigen. So beobachtet man in Mitteleuropa und auch in der Nordsee das Eindringen zahlreicher wärmeliebender Arten, die sich infolge von Klimaänderung zunehmend etablieren. Im östlichen Mittelmeer steigen die Artenzahlen durch Einwanderung aus dem Roten Meer über den Suezkanal beständig an, was durch die Erwärmung des Mittelmeerwassers verstärkt wird. Diese Phänomene sind die Folge globaler Vermischungen bislang getrennter Faunen und Floren und führen weltweit zur Homogenisierung und damit Verarmung.
Aussterben durch eingeschleppte Pathogene. In den letzten Jahren wird diskutiert, dass ein weltweit zu beobachtendes Aussterben zahlreicher Amphibienarten unter anderem auf einen mit Krallenfröschen aus Afrika weltweit verschleppten Krankheitserreger, die Chytridiomykose, zurückgeht. Weitere bekannte Fälle betreffen nordamerikanische und eurasische Baumarten. Generell ist über diesen Faktor wenig bekannt.
Lokal und regional kann die Artenvielfalt derzeit durchaus zunehmen; dies ist kein Gegensatz zum Artensterben auf globaler Ebene und bedeutet nicht, dass das weltweite Artensterben zum Stillstand gekommen sei. Zahlreiche Wildpopulationen auf der Erde und in den Gewässern sind auf kleine und kleinste Populationsgrößen geschrumpft und unterliegen daher einer verstärkten Gefahr des Aussterbens.[46]


Um die Bedeutung der Artenvielfalt zu illustrieren, werden unterschiedliche Anschauungsmodelle propagiert, darunter die folgenden:

Nieten-Hypothese: Jede Niete eines Flugzeugrumpfs trägt zum Zusammenhalten bei und verhindert damit ein Abstürzen des Flugzeuges: Jede Art ist zum Aufrechterhalten eines Ökosystems mehr oder weniger wichtig.[47]
Passagier-Hypothese: Kein Fluggast ist für die Flugfähigkeit des Flugzeuges vonnöten, dafür umso mehr die Crew: es kommt demnach nur auf wenige Schlüsselarten an.[48]
Die Bedeutung der Artenvielfalt für die Stabilität von Ökosystemen ist in der ökologischen Wissenschaft ein Thema, das seit mehr als 80 Jahren kontrovers diskutiert wird, die sogenannte „Diversitäts-Stabilitäts“-Kontroverse (Übersicht in Bezug auf moderne Anwendungen z. B.[49][50][51]). Zur Klärung der Sachlage hat beigetragen, dass der Begriff „Stabilität“ schärfer definiert wurde (Grimm und Wissel fanden in einer Literaturstudie 163 verschiedene Definitionen von Stabilität, die sich auf 70 Konzepte bezogen.[52]) Heute wird (nach Pimm 1984[53]) meist unterschieden: Persistenz (man beobachtet wenig Veränderungen bei Beobachtungen über lange Zeit), Resilienz (Das System kehrt nach Störungen wieder in seinen Ausgangszustand zurück), Resistenz (Das System bleibt bei Störungen lange unverändert). Forschungsergebnisse deuten darauf hin, dass die zeitliche Stabilität (also die Persistenz) mit höherer Artenzahl ansteigt. Ob das auch nach Störungen gilt (also Resilienz) ist umstritten. Möglicherweise ist die Artenvielfalt für die Resilienz eines bestimmten Ökosystems nur von geringer Bedeutung oder sinkt sogar ab, dies könnte sich aber auf höherer Ebene umkehren.
Nach der Intermediate Disturbance Hypothesis (IDH) von Joseph H. Connell (University of California) reagieren manche Ökosysteme auf leichte, regelmäßige Störungen (z. B. Brände, Stürme, Überschwemmungen) mit einer wachsenden Artenvielfalt.[54] Von bestimmten Arten besetzte Gebiete werden frei, da sie aufgrund der Störung verschwinden. Dieser Raum kann von anderen (unter Umständen noch nicht anwesenden) Arten (u. a. sog. Pionierarten) neu besetzt werden. Als Resultat steigt die Artenzahl und somit die Artenvielfalt. Dieses Prinzip der mittleren Störungshäufigkeit gilt jedoch nicht uneingeschränkt für jedes System, das heißt: Nicht in jedem System steigt die Artenvielfalt aufgrund von Störung, sondern kann sich auch gegenteilig verhalten. Das heute von den meisten Ökologen akzeptierte Modell zum Zusammenhang von Artenvielfalt und Störungen ist das „dynamische Gleichgewichtsmodell“. Danach steigt in hochproduktiven Ökosystemen die Artenzahl mit zunehmender Störung (v. a. weil sie dem Konkurrenzausschluss entgegenwirkt). In wenig produktiven Systemen sinkt sie hingegen ab (weil die langsam wachsenden Arten sensibler reagieren). In höchstproduktiven Systemen (wie überdüngten Seen) ist die Artenvielfalt sogar bei hohem Störungsniveau minimal (das so genannte „Anreicherungsparadoxon“).


In der Vergangenheit konnten einige Arten durch Zoos und Wiederaufzuchtprogramme erhalten werden. Erfolgreiche Beispiele des 20. Jahrhunderts sind der europäische Wisent, der Davidshirsch, das Przewalski-Pferd und seit 2003 auch der Baumhummer.
Jedoch können Rettungsversuche zur Erhaltung von Arten außerhalb ihres natürlichen Lebensraumes (z. B. in Zoos und Botanischen Gärten oder Samenbanken) nicht alle Arten retten, da sich viele Tiere in Gefangenschaft nicht fortpflanzen und Kapazitäten zur Aufnahme weiterer Arten kaum vorhanden sind. Auch die Wiederansiedlung/Auswilderung ist aufwendig. Dagegen stellt die Ausweisung von Schutzgebieten (z. B. Naturschutzgebiete) eine gute Lösung dar (u. a. mit Hilfe des modernen Instruments der Gap-Analyse), wobei diese dann am erfolgreichsten sind, wenn alle Interessengruppen integriert werden können.
Ein Instrument für Naturschutzmaßnahmen und zum schonenden Umgang mit natürlichen Ressourcen in ärmeren Ländern ist die Global Environment Facility (GEF), in die die Industrieländer einzahlen. Auch das wirtschaftlich tragfähige nachhaltige Nutzen sichert Natur. So legt z. B. das Forest Stewardship Council (FSC) Kriterien für eine umweltverträgliche Waldnutzung fest, nach denen bereits 150.000 km² Wald in fast 30 Ländern ausgewiesen wurden. Bedingung für den weiteren Erfolg ist die Akzeptanz des Verbrauchers für zertifizierte (und eventuell teurere) Holzprodukte.
Seit 1973 regelt das Washingtoner Artenschutzübereinkommen (CITES) den internationalen Handel mit gefährdeten Arten freilebender Tiere und Pflanzen und ihrer Produkte.[55] Bei der 15. Tagung der Konferenz der Unterzeichnerstaaten (CoP15) in Doha, Katar, vom 13.–25. März 2010, konnten sich die Teilnehmer weder auf ein kurzzeitiges Verbot des Handels mit Blauflossen-Thunfischen zur Erholung der Bestände noch auf ein Handelsverbot mit Eisbärfellen oder den Schutz verschiedener Haiarten wie Hammerhaie und Dornhai einigen, von denen einige Produkte unter den Bezeichnungen Schillerlocke, Kalbsfisch, Seeaal oder Seestör auch in Europa im Handel sind. Hingegen wurde das Handelsverbot für Elfenbein verlängert.[56]
Die EU wollte seit den ersten Jahren des Jahrtausends eigentlich schon bis 2010 das Ziel erreichen, dass in Europa keine Tier- und Pflanzenarten mehr aussterben sollen.[57][58] Am 15. März 2010 verschoben die EU-Umweltminister dieses Ziel auf 2020 und starteten eine Biodiversitätskampagne.[59][60] Durch die Intensivierung der Landwirtschaft – beschleunigt durch die Förderungen des EEG – ist der Flächendruck in Teilen Deutschlands sehr groß geworden, so dass jede Fläche sehr intensiv genutzt wird.
2020 zeigten Forschende anhand von groben Modellen, wie die UN-Nachhaltigkeitsziele zur Artenvielfalt erreicht werden können, während eine Ernährung der Weltbevölkerung gewährleistet wird: Trends könnten bis 2050 durch eine integrative Strategie und sofort beginnende „Anstrengungen, die mit der umfassenderen Nachhaltigkeitsagenda konsistent sind, aber von beispielloser Ambition und Koordination sind“ – etwa durch nachhaltige Effizienz-Verbesserungen in der Landwirtschaft und mehr Pflanzen-basierter Ernährung – zum Positiven gewendet werden.[61][62]


→ Hauptartikel: „Vertragsstaaten-Konferenzen (COP CBD)“ im Artikel Biodiversitätskonvention

Die Generalversammlung der Vereinten Nationen (UN) hat im Dezember 2006 beschlossen, das Jahr 2010 zum International Year of Biodiversity zu erklären.[63] Sie tat dies aus Besorgnis über die sozialen, ökonomischen, ökologischen und kulturellen Konsequenzen des Biodiversitätsverlustes und mit der Hoffnung, dass die Staaten und anderen Akteure diese Gelegenheit nutzen würden, um das Bewusstsein für die Wichtigkeit der Biodiversität zu stärken und lokale, regionale und internationale Aktionen durchzuführen.[64] Koordiniert werden die Aktivitäten vom Sekretariat der Biodiversitätskonvention in Montreal, Kanada.[65]


Die UN-Dekade Biologische Vielfalt 2011–2020 ist eine nachdrückliche Initiative der Vereinten Nationen zum weltweiten Erhalt der biologischen Vielfalt: in einer Erklärung wurden alle Staaten aufgerufen, im Zeitraum der Dekade zusätzliche Aktivitäten zugunsten der Biodiversität und damit zur Umsetzung der CBD-Ziele zu leisten.[66]

→ Hauptartikel: UN-Dekade der Biodiversität

Anthropozän
Artenschutz
Liste der neuzeitlich ausgestorbenen Amphibien
Liste der neuzeitlich ausgestorbenen Fische
Liste der neuzeitlich ausgestorbenen Insekten
Liste der neuzeitlich ausgestorbenen Reptilien
Liste der neuzeitlich ausgestorbenen Säugetiere
Liste der neuzeitlich ausgestorbenen Tiere
Liste der neuzeitlich ausgestorbenen Vögel
Liste der neuzeitlich ausgestorbenen Weichtiere
Liste der neuzeitlich ausgestorbenen Pflanzen und Pilze
Millennium Ecosystem Assessment
Umweltprogramm der Vereinten Nationen (UNEP)
UNEP World Conservation Monitoring Centre

Bernhard Schmid: Die funktionelle Bedeutung der Artenvielfalt. In: Biologie in unserer Zeit. 33, Heft 6, 2003, S. 356–365.
Bruno Streit: Was ist Biodiversität? Erforschung, Schutz und Wert biologischer Vielfalt. C.H. Beck, München 2007.
Jonathan E. M. Baillie, Janine Griffiths, Samuel T. Turvey, Jonathan Loh, Ben Collen: Evolution Lost. Status and Trends of the World’s Vertebrates. The Zoological Society of London, 2010, ISBN 978-0-900881-41-1. (; PDF; 7,3 MB)


 im Katalog der Deutschen Nationalbibliothek
Aktionsgemeinschaft Artenschutz e. V.: 
 (englisch)
Biotop-Fonds der Jägerschaften Emsland / Grafschaft Bentheim e. V., 
Bundeszentrale für politische Bildung, 
deutschlandfunk.de, Forschung aktuell, 24. November 2017, Monika Seynsche: 


Ministerium für Umwelt, Klima und Energiewirtschaft Baden-Württemberg,  (Memento vom 9. Juli 2015 im Internet Archive)

, ORF.at, 8. Juli 2020



Man spricht von Überweidung, wenn Tiere durch Verbiss und/oder Vertritt die krautige Pflanzendecke einer Weide oder eines Biotopes schneller bzw. stärker beanspruchen, als diese sich regenerieren kann. Dies ist bei einem Viehbesatz der Fall, der der Ertragskraft der Fläche nicht angepasst ist.
Nimmt der Weidedruck (Zahl der Tiere bzw. Größe der Herden, Dauer der Beweidung) zu, kommt die ökologische Tragfähigkeit bald an ihre Grenzen: Die Folge sind Überweidung und Bodendegradation.[1][2]








In ursprünglich unbesiedelten Naturlandschaften kommt Überweidung durch Wildtiere nur temporär vor, da sich die Populationen aller Tier- und Pflanzenarten eines Ökosystems gegenseitig regulieren und die Zahl der Individuen sich somit dauernd auf die aktuelle Tragfähigkeit des Lebensraums einstellt. Insofern ist Überweidung grundsätzlich eine Folge anthropogener Weidenutzung. Seit der Entwicklung der traditionellen Viehwirtschaftsformen kam es überall zu mehr oder weniger deutlichen strukturellen Veränderungen der vormaligen Wildnis bis hin zu anthropogen beeinflussten Landschaften. So wird vermutet, dass große Teile der eurasischen Waldsteppe[7] (vergleichbar mit den mitteleuropäischen Heiden) erst durch die verstärkte Weidenutzung entstanden sind: Der Baumbewuchs wurde noch mehr eingeschränkt als durch die wilden Weidetiere. Aufgrund der geringeren Bevölkerungszahlen in der Vorgeschichte und der immer extensiven und häufig nomadischen Viehhaltung in Räumen, die schon vorher der Lebensraum von großen Pflanzenfressern waren, sind Überweidungsschäden bei diesen Konstellationen nicht anzunehmen.
Überweidung ist vor allem immer dann zu befürchten, wenn Viehwirtschaft in unangepasster Weise intensiviert wird: Voraussetzungen dafür sind vor allem ein starkes Bevölkerungswachstum, die Sesshaftwerdung vormals nomadisierender Gruppen oder der Übergang von der Subsistenz- zur Erwerbswirtschaft, der eine Überschussproduktion erforderlich macht. Dies alles sind Faktoren, die bereits in den alten Hochkulturen auftraten. Besonders empfindlich sind trockene (aride) Naturweiden (Pastoralismus), deren nachhaltige Nutzung nur durch den traditionellen Nomadismus oder ein ausgeklügeltes, modernes Weidemanagement möglich ist.[8] Doch auch in feuchten (humiden) Gebieten, die normalerweise von Wald bestockt sind, kam es seit dem Mittelalter zu Überweidungsschäden, wie die Entwicklung sandiger Heiden aus den mittelalterlichen Allmenden Mitteleuropas zeigt.[9]
Seit der industriellen Revolution haben Überweidung, Bodendegradation und Desertifikation weltweit drastisch zugenommen. Betroffen sind vor allem die Trockenräume der Erde (Wüsten, Steppen, Trockensavannen, Trockenwälder usw.). Verantwortlich ist in der alten Welt in erster Linie der Niedergang des vormals nachhaltigen Nomadismus, der sich seit Mitte des 20. Jahrhunderts durch staatliche Sesshaftmachungsprogramme und marktwirtschaftliche Einflüsse mehr und mehr in eine ungeregelte und intensivierte mobile Tierhaltung verwandelt hat.[10] Die Haltung überhöhter Tierbestände wurde – etwa in Afrika – erst durch den mit Fremdmitteln geförderten Bau von Brunnen für die Viehtränke möglich. In den Trockenregionen Amerikas, Südafrikas und Australiens hat sich seit der Kolonialisierung eine von den Europäern installierte, stationär-extensive Weidewirtschaft etabliert (Ranching), die von Anfang an marktwirtschaftlich orientiert war. Auch hier sind Überweidungsschäden in vielen Regionen, vor allem im „Wilden Westen“ der USA[11] und in Patagonien[12] eingetreten.

[Bearbeiten | Quelltext bearbeiten]
In der mediterranen Hartlaubzone mit seinen heiß-trockenen Sommern und Winterregen (Mediterranes Klima) führt die Überweidung durch Ziegen- und Schafherden zu erhöhter Bodenerosion; bei schon fortgeschrittener Erosion besteht die Gefahr der Bodendegradation. Durch anthropogenen und natürlichen Klimawandel kann es zur weiteren Ausdehnung solcher degenerierter Gebiete kommen.
In Kältesteppen können aufgrund der empfindlichen Vegetation und der sehr kurzen Wachstumsperiode Überweidungsschäden auftreten. Beispiele findet man bei der Schafzucht auf Island oder der intensivierten Rentierhaltung in Skandinavien.
Überweidung tritt nicht nur auf Naturweiden auf, sondern durchaus auch bei der Grünlandwirtschaft in gemäßigten Klimaten, die auf Flächen stattfindet, die vormals von Wald bestockt waren. Hier ist die Weidewirtschaft sachgerecht, wenn das „Grasland“ nachhaltig als Ersatzgesellschaft erhalten wird. Sowohl Überbeweidung, jedoch vor allem Unterbeweidung (die zur Verbuschung führt) können hier zum Verlust des Grünlandes führen. Überweidung auf Grünlandflächen führt durch die Nahrungspräferenzen des Viehs vor allem zur Ausbreitung von Weideunkräutern, die nicht als Futterpflanzen dienen. Durch Trittschäden kann sich außerdem die Artenzusammensetzung verändern. In Mitteleuropa ist eine Überbeweidung durch Rinder oft an dem vermehrten Auftreten von Trittzeigern (Wegerich), Nährstoff- und Säurezeigern, leicht regenerierenden Gräsern wie Einjähriges Rispengras Poa annua, Quecke A. repens und Weideunkräutern (z. B. Disteln) zu erkennen (Siehe auch Zeigerwerte nach Ellenberg). Auf feuchten Weiden Mitteleuropas können das auch Binsen sein.
Bei andauernder Haltung überhöhter Tierbestände werden langfristig die für die Tierernährung geeigneten Pflanzen so stark reduziert, dass die Pflanzendecke nur noch aus ungenießbaren oder wertlosen Pflanzenarten besteht. Besonders Berglagen oder trockene (aride Klimate), ertragsschwache Gebiete sind besonders betroffen. Der Bedeckungsgrad der Flächen sinkt durch Tritt im weiteren Verlauf, in Extremfällen stirbt die Pflanzendecke sogar partiell ab. Dies kann zur Erosion des Oberbodens führen, die eine Wiederbesiedlung durch Pflanzen erschwert, und im Extremfall zur Desertifikation (Wüstenbildung).
In geschädigten Trockengebieten erhöhen die Hirten nicht selten den Anteil der Ziegen, da diese Tiere besonders genügsam sind und auch in überweideten Regionen ihr Auskommen finden. Das setzt jedoch einen Teufelskreis in Gang, denn Ziegen weiden die Grasnarbe besonders tief ab, so dass die Erosion weiter verstärkt wird.


Hutewald

Joachim Radkau: Natur und Macht: eine Weltgeschichte der Umwelt. 1. Auflage, C.H. Beck, München 2002, ISBN 3-406-48655-X.




Bodenverflüssigung oder Liquefaktion kann infolge starker Erschütterungen wassergesättigter, meist sandiger Bodenschichten (Quickerde) durch ein Erdbeben stattfinden.
Wenn feuchte Böden locker gelagert sind und Grundwasser oberflächennah ansteht, kann es bei Erdbeben zu Bodenverflüssigung kommen. Küstengebiete mit Schwemmböden erfüllen diese Kriterien häufig. Prädestiniert sind Böden mit einer sehr gleichmäßigen Kornstruktur, insbesondere Sande, wie sie in Mündungsdeltas zu finden sind, sowie Löss- und Lehmböden. Besonders „junge“, erst in den letzten 10.000–15.000 Jahren abgelagerte, wassergesättigte Sedimente können sich durch die Druckwellen eines oberflächennahen Hochfrequenz-Erdbebens verflüssigen.
Locker gelagerte Böden enthalten – ähnlich wie bei Treibsand – einen hohen Porenanteil. Ihre Partikel berühren sich nur an einigen Kontaktpunkten. Wenn die Druckwelle (dynamische Belastung) eines Erdbebens dann den Porendruck im  Gefüge von wassergesättigten Böden erhöht, können die Haftreibung zwischen den Sandkörnern und somit die Scherfestigkeit des Bodens so stark abfallen, dass sich der Boden wie eine Flüssigkeit verhält.
Besonders stark verflüssigter Boden kann stellenweise an der Oberfläche austreten, unter anderem in Form von Schlammfontänen. Dadurch baut sich der entstandene Druck ab.
Auf verflüssigtem Boden befindliche Gebäude können ungleichmäßig absacken. Unterirdische Strukturen wie Abwasserkanäle, die Hohlräume enthalten, können nach oben gedrückt werden. 
Erdbeben, die mit großflächiger Bodenverflüssigung einhergingen, sind neben den Christchurch-Erdbeben (Februar 2011 und Juni 2011) beispielsweise das Erdbeben in Haiti 2010, das Loma-Prieta-Erdbeben in San Francisco von 1989 oder das verheerende Tangshan-Erdbeben im Jahre 1976 in China. Nachgewiesen wurde die Bodenverflüssigung auch für mehr als 1200 km² im Schwemmland der Po-Ebene in Norditalien nach den zwei Hauptbeben am 20. Mai 2012 (Mw ~ 6.1) und am 29. Mai 2012 (Mw ~ 6.0) sowie beim Sulawesi-Erdbeben 2018.[1]



Helmholtz-
 (Memento vom 8. März 2009 im Internet Archive)
 Bodenverflüssigung beim Erdbeben in Niigata 1964 (YouTube-Video, musikunterlegt, 2010)
 (englisch)
 (Memento vom 13. Februar 2008 im Internet Archive) (englisch)



Der Vulkanausbruch (Eruption) ist die bekannteste Form des Vulkanismus. Dabei leeren sich auf mehr oder weniger zerstörerische Weise die Magmakammer(n) eines Vulkans, oder Magma steigt durch Spalten und Bruchstellen mehr oder weniger direkt aus dem Erdmantel auf.
Der Grund für dieses Phänomen liegt in einer Tiefe um 100 km unter der Erdoberfläche, wo Temperaturen von 1000 bis 1300 °C herrschen. Das schmelzende Gestein dehnt sich aus, Magmakammern entstehen. Die entstehenden Gase erhöhen mit der Zeit den Druck innerhalb der flüssigen Masse; das Magma steigt auf. Überschreitet der Druck einen kritischen Punkt, bricht ein Vulkan aus.[1]
Eruptionen, etwa im Fall von Schildvulkanen, können auch durch Ruheperioden unterbrochen und in einzelne Eruptionsphasen unterteilt werden, sie können sich über Monate und Jahrzehnte hinziehen – vgl. Kilauea –, werden aber charakterisiert durch ein verbindendes Merkmal, das sie von der nächsten Eruption unterscheidet: den ganz speziellen chemischen Fingerabdruck, beweisbar durch genaue chemische Laboranalyse der Auswurfprodukte, und der auf eine ganz bestimmte, zeitlich und räumlich begrenzte Magmaquelle verweist.[2]
Laut der Geologin Elizabeth Cottrell vom Vulkanüberwachungsprogramm der Smithsonian Institution eruptieren auf der Erdoberfläche im Jahr durchschnittlich etwa 70 Vulkane. In jedem Augenblick sind 20 bis 30 Eruptionen im Gange. Nicht mitgezählt sind dabei die in ihrer großen Mehrzahl noch nicht bekannten Vulkane auf dem Meeresgrund.[3]



[Bearbeiten | Quelltext bearbeiten]
[Bearbeiten | Quelltext bearbeiten]

Explosive Ausbrüche produzieren vor allem Tephra.
Sie können im Allgemeinen entweder durch Überhitzung von Grund- und/oder Meerwasser über der Magmakammer des Vulkans (phreatische oder phreatomagmatische Eruptionen) oder durch besondere chemische Zusammensetzung von Magmen ausgelöst werden. Derartige Ausbrüche können schlagartig kubikkilometergroße Gesteinsmassen in die Luft sprengen. Auch die größeren Vulkanausbrüche unter Gletschern gehören zu dieser Kategorie (vgl. Subglazialer Vulkan).
Durch Einbruch der Magmakammer bei sehr explosiven Eruptionen entsteht dabei ein charakteristisch geformter weiter Krater, die Caldera, beispielsweise 1875 in der Askja, Ostisland. Wird die Caldera geflutet, bildet sich ein Kratersee, in dem Fall beispielsweise der See Öskjuvatn. Der verheerende Ausbruch des Krakatau 1883 in Indonesien war ebenfalls ein derartiger explosiver Ausbruch. Die Reste der Caldera sind heute als vier kleine Inseln in dieser bzw. um diese Kraterlagune angeordnet und befinden sich in der Sundastraße zwischen den indonesischen Inseln Sumatra und Java. Solche Ausbrüche können auch Flutwellen und Tsunamis hervorrufen, die auf Tausende von Kilometern wirken.
Falls bei derartigen Ausbrüchen das Vulkangebäude ganz oder teilweise in sich zusammenbricht, können sich heiße Glut- und Aschewolken oder auch Pyroklastische Ströme mit großer Geschwindigkeit lawinenartig hangabwärts bewegen und dabei alles mitreißen und unter sich begraben. Die berüchtigten Ausbrüche des Vesuv im Jahr 79 und des Mt. Pelé 1902 fallen unter diese Kategorie. Jeweils Tausende von Menschen wurden in kürzester Zeit von pyroklastischen Strömen überrascht und getötet.
Eine weitere Erscheinung des explosiven Vulkanismus sind die Lahare, die über viele Kilometer einen bis mehrere Meter hohen Schlammstrom bilden können, der sich mit einer Geschwindigkeit bis zu 100 km/h fortwälzen kann. Beispielsweise wurde die Stadt Armero in Kolumbien 1985 ein Opfer solcher Ströme.[4]
Generell neigen vor allem die Stratovulkane etwa des Pazifischen Feuerrings zu derartigem Verhalten, wie etwa 1980 am Mount St. Helens oder 1991 am Pinatubo beobachtbar.

[Bearbeiten | Quelltext bearbeiten]

 Lavasee im Krater des Nyiragongo
Die effusiven Ausbrüche hingegen produzieren vor allem flüssige und halbflüssige Laven. Bei diesen Vorgängen ist das Magma nicht so stark mit – explosiven – Gasen durchsetzt, viel heißer und flüssiger.
Besonders Spaltenvulkane und Schildvulkane neigen zu solchen Ausbrüchen, die sich in der Vergangenheit bis über mehrere hundert Jahre hingezogen haben (vor allem in den Warmperioden der Eiszeit), wobei sich langsam ein sehr flach ansteigender Vulkankegel aufgebaut hat.
Ein typisches Beispiel eines Schildvulkans wäre etwa der Skjaldbreiður in Island. Noch heute kann man solche Ausbrüche an den Vulkanen auf Hawaii oder La Réunion etwa am Piton de la Fournaise beobachten.[5]



Beispiele für Spaltenausbrüche waren in Island etwa die der Laki-Krater in den Jahren 1783–1784 oder die am Zentralvulkan Krafla 1975–1984. Inzwischen hat man allerdings in neueren Untersuchungen und Erfahrungen gesehen, dass auch solche gemischten oder effusiven Ausbrüche vulkanische Gase in beträchtlicher und gesundheitsschädlicher Menge freisetzen können. Dies ergab sich besonders aus Forschungen an der Gasfreisetzung des o. g. Laki-Ausbruchs[6] sowie am Ausbruch im Spaltensystem der Bárðarbunga 2014–2015.[7]
Flüssige Lava kann sich auch in einer Senke oder einem Krater als Lavasee ansammeln.

[Bearbeiten | Quelltext bearbeiten]
[Bearbeiten | Quelltext bearbeiten]
 Mount St. Helens 1980

Die Plinianische Eruption bezieht ihren Namen von dem Schriftsteller Plinius dem Jüngeren, der den Ausbruch des Vesuv im Jahre 79 n. Chr. beschrieben hat.
Es handelt sich um außerordentlich explosive Ausbrüche, die mit gewaltigen Aschenfällen verbunden sind. Der von Plinius beobachtete Ausbruch des Vesuv, der dieser Ausbruchsart zuzuordnen ist, zerstörte die Städte Pompeji und Herkulaneum.
Innerhalb weniger Stunden können bei solchen Ausbrüchen durch die Vulkanschlote einige Kubikkilometer Magma aufsteigen. Der gewaltige Druck und die vehement entweichenden Gase stoßen alte Reste des Pfropfs nach oben, wobei glühende Lavafetzen und Felsbrocken aus der Kraterwand mitgerissen werden. Der Materialstrom rast mit einer Geschwindigkeit bis zu mehreren hundert Metern pro Sekunde im Schlot empor und bildet oberhalb des Kraters eine Eruptionssäule, die bis in die Stratosphäre reicht. Stürzt die Staub- und Aschewolke in sich zusammen, bildet sie den Ausgangspunkt eines pyroklastischen Stroms. Den zurückbleibenden Einsturzkrater nennt man Caldera.[8]
Auch die Eruption des Vulkans Hekla in Island im Jahre 1104 gehörte diesem Eruptionstyp an.[9] Weitere Beispiele sind die Eruption des Mount St. Helens im Jahre 1980, die des Pinatubo 1991 sowie die des Laacher-See-Vulkans.[10]

[Bearbeiten | Quelltext bearbeiten]

 Vulkan Montagne Pelée einige Tage nach dem großen Ausbruch 1902
Dieser Eruptionstyp ist benannt nach dem Ausbruchsverhalten des Vulkans Montagne Pelée auf Martinique.[11]
Diese Art des Vulkanausbruchs zeichnet sich durch eine sehr hohe Viskosität des aufsteigenden Magmas aus. Dieses kann oftmals noch während des Aufstiegs erhärten und den Hauptschlot für nachfolgende Ausbrüche in Pfropfenform verschließen. In der Folge suchen sich die vulkanischen Fluide und Gase Seitenschlote und Risse im Gestein und brechen oftmals unter hohem Druck auf lateralem Wege in Form von Glutwolken durch die Flanken des Berges. Diese Pelée-Dynamik zählt zur Gruppe der an Gase gebundenen Dynamiken (im Gegensatz zu den an Wasser gebundenen Dynamiken) und kann auch dahingehend wirken, dass dickflüssige Lava unmittelbar abgelagert wird, sobald sie die Erdoberfläche erreicht und an den Austrittsstellen halbstabile Lavadome bildet.[12] Wenn diese kollabieren, bilden sich an den Berghängen pyroklastische Ströme.

[Bearbeiten | Quelltext bearbeiten]
 Vulkanianische Eruption 1998 am Tavurvur in Papua-Neuguinea.

→ Hauptartikel: Vulkanianische Eruption
Die Vulkanianische Eruption ist benannt nach der Vulkaninsel Vulcano, einer der Äolischen Inseln vor Italien.
Das Eruptionsmuster besteht aus kurzen, kanonenschussartigen Explosionen (mit entsprechenden Stoßwellen), die einzeln oder in Serien bis zu einigen Stunden vorkommen können. Die Stärke der Eruption liegt im Schnitt zwischen einer strombolianischen und einer plinianischen Eruption.
In der Hauptsache wird hochfragmentierte vulkanische Asche erzeugt, die in einer Eruptionssäule bis zu 20 km aufsteigen kann. Daneben werden auch oft vulkanische Bomben ausgeworfen, die in einem Umkreis bis zu 5 km niedergehen können. Typisch ist höher viskoses Magma von andesitischer bis dacitischer Zusammensetzung.
Als Ursache wurden verschiedene Prozesse identifiziert:[13] a) eine plötzliche Druckentlastung gasreichen, hochviskosen Magmas im oberflächennahen Förderschlot[14] und b) eine spontane Freisetzung von Gasakkumulationen aus einer Magmakammer in der oberen bis mittleren Erdkruste.[15]
Vulkane, die vulkanianische Eruptionen zeigen sind z. B. der Ngauruhoe in Neuseeland, Galeras in Kolumbien und Soufrière Hills auf Montserrat.

[Bearbeiten | Quelltext bearbeiten]
 Stromboli

Die Bezeichnung Strombolianische Eruption bezieht sich auf den Vulkan Stromboli, der sich auf einer weiteren der Äolischen Inseln in Süditalien befindet.
Der Stromboli ist ständig aktiv, im Altertum bezeichnete man ihn daher als Leuchtturm des Mittelmeeres. In unregelmäßigen Abständen (wenige Minuten bis stündlich) kommt es an mehreren Krateröffnungen zu größeren und kleineren Eruptionen. Das ausgeworfene Material fällt meist in den Krater zurück oder es rollt teilweise über die Sciara del Fuoco ins Meer.
Dieser regelmäßige Auswurf von Lavafetzen, Schlacken und Aschen ist so typisch für Stromboli, dass der Begriff Strombolische oder Strombolianische Aktivität allgemein für Vulkanaktivität dieser Art verwendet wird. Diese kontinuierliche Aktivität ist durch die so genannte Zwei-Phasen-Konvektion begründet. In einer gewissen Höhe des Schlotes ist der Dampfdruck der Gase größer als der Druck der sich über den Gasen befindenden Flüssigkeit. Die dadurch gebildeten Gasblasen steigen auf und reißen durch ihr Zerplatzen an der Oberfläche Magmafetzen mit sich. Diese Ausgasung bringt eine Erhöhung der Dichte der betroffenen Schmelze mit sich, die nun wiederum absinkt und somit einen stetigen Kreislauf darstellt.[5]

[Bearbeiten | Quelltext bearbeiten]

 Schildvulkan Mauna Kea
 AA-Lavastrom 1984 am Mauna Loa
Die Hawaiische Eruption bezeichnet die Ausbrüche von Schildvulkanen, wie man sie derzeit nur auf dem hawaiischen Inselarchipel im Pazifik beobachten kann.
Die hawaiischen Vulkane sehen aus wie umgedrehte Schilde, daher erklärt sich die Bezeichnung Schildvulkan.
Die Ursache für die typische Form ist das Ausfließen sehr dünnflüssiger und damit schnell fließender, gasarmer Lava. Diese ist üblicherweise von basaltischer Zusammensetzung und enthält meist weniger als 52 % Siliziumdioxid (SiO2). Beim Austritt ist sie ca. 1000 °C bis 1250 °C heiß. Entstehungsort des geförderten Magmas ist der obere Erdmantel.
Beim Austritt bilden sich auf Hawaii bis zu 500 m hohe Lavafontänen.[5]
Die Böschungswinkel von Schildvulkanen betragen aufgrund der hohen Fließgeschwindigkeit der Lava (bis zu 60 km/h) nur etwa 5°, das heißt, es handelt sich durchweg um sehr flach abfallende, dafür ausgedehnte Kegel.
Diese Laven treten normalerweise über Jahre, Jahrzehnte, teilweise sogar Jahrhunderte durch dieselben Krateröffnungen aus und bauen so die flachen Vulkanschilde auf. Z. B. findet man auf Island sehr zahlreiche Schildvulkane wie etwa den Skjaldbreiður, die einen Bodendurchmesser von etlichen Kilometern aufzuweisen haben und in Zwischeneiszeiten oder direkt nach dem Ende der Eiszeit entstanden sind.[16]

[Bearbeiten | Quelltext bearbeiten]

 Phreatische Explosionen am Spirit Lake, 1980
Phreatische Ausbrüche sind Wasserdampf-Explosionen, bei denen überhitztes, externes Wasser infolge einer plötzlichen Druckentlastung in Dampf verwandelt wird. Der dabei entstehende Wasserdampf hat ungefähr das 1000fache des Wasservolumens[17] und sprengt einen Krater in den Untergrund. Das Gestein, das sich vorher im Krater befand, wird dabei zertrümmert. Das ausgeworfene Gestein wird rings um den Krater als Wall abgelagert. Phreatische Eruptionen enthalten nur zersprengtes „Alt“gestein, kein juveniles Gestein (also Pyroklasten s. str.).
Eine phreatische Explosion findet statt, wenn entweder externes Wasser infolge seiner Fließ- bzw. Sickerbewegung in die Nähe vom Magma kommt (jedoch keinen direkten Kontakt hat!) und stark aufgeheizt wird, oder aus der Tiefe aufsteigende Gase überhitzen das Wasser über den Siedepunkt. Wird nun das überliegende Gestein etwa durch zersetzende Solfataren-Tätigkeit rissig oder durch ein Ereignis (z. B. Erdbeben) plötzlich durchlässig und kann etwas Dampf entweichen, kommt es infolge der Druckentlastung zur explosionsartigen Verdampfung des überhitzten Wassers und damit zur phreatischen Explosion.
Solche Explosionen können auch im Untergrund stattfinden, aufsteigendem Magma den Weg freimachen, und wenn dieses in direkten Kontakt mit dem Grundwasser kommt, können sich phreatomagmatische Explosionen ereignen.

[Bearbeiten | Quelltext bearbeiten]

 Eyjafjallajökull 2010

Bei der subglazialen Eruption handelt es sich um einen Ausbruch unter einem Gletscher.
Solche Eruptionen sind i. A. explosiv oder phreatisch, sobald das Magma die Oberfläche des Gletschers erreicht. Oft werden sie begleitet vom Phänomen des Gletscherlaufs, da die Hitze des Magmas sehr große Eismengen auftauen lässt und sich dieses Wasser-Eis-Sediment-Gemisch in Form einer mehr oder minder großen Flutwelle einen Weg in die Ebenen unterhalb der Gletscher oder ins Meer sucht.
Wenn das Magma durch eine Spalte oder einen Schlot die Erdoberfläche erreicht, wird es eine Höhle in den Gletscher schmelzen. Gleichzeitig erkennt man die Vorgänge durch Veränderungen an der Gletscheroberfläche, wo sich große Spalten oder Senken bilden. Es bildet sich ein anfangs unter dem Gletscher verborgener See, unter dem sich wiederum Kissenlaven anhäufen. Wenn der Druck des Wassers auf das Magma nachlässt, etwa weil sich der gebildete Gletschersee – wie etwa bei Ausbrüchen des Grímsvötn-Vulkans in Island zu beobachten – entleert, findet ein Phasenwechsel statt. Die Eruption wird phreatisch oder explosiv und große Mengen an Tephra können produziert werden.
Die Aschen und anderen Lockermaterialien werden dann auf den Kissenlaven abgelagert. Die Ergebnisse sind ein Palagonitkegel über einem Ausbruchsschlot, wie etwa Keilir, oder ein Palagonitrücken über einer Ausbruchsspalte, wie z. B. Sveifluháls, beide in Südwestisland.
Hält die Eruption noch weiter an, bilden sich an der freien Luft Laven und ein Tafelvulkan, wie etwa Herðubreið in Island oder The Table in British Columbia, Kanada, entsteht.[18]

[Bearbeiten | Quelltext bearbeiten]
 Surtsey

Die Surtseyanische Eruption ist benannt nach der Insel Surtsey in Island, die ab 1963 durch Vulkaneruptionen im Meer entstand.
Gemeint sind Vulkane, die zunächst ihren Ursprung unter der Wasseroberfläche des Meeres haben.
Zu Anfang der Eruptionsserie ereignen sich Ausbrüche unter der Meeresoberfläche, wie es etwa bei der Insel Surtsey der Fall war. Es werden in dieser Anfangsphase Kissenlaven gebildet, aus denen sich nach und nach ein Vulkangebäude über bis zu Hunderten von Metern aufbaut, bis es die Meeresoberfläche erreicht.
Dann findet durch den Einfluss des Sauerstoffs der Luft ein Phasenwechsel statt. Die Eruption geht in eine explosive Phase über, bei der große Mengen an Tephra ausgeschüttet werden. Das Zusammentreffen von Magma, Wasser und Luft erzeugt phreatomagmatische Explosionen. Diese Phase hält solange an, bis das Vulkangebäude die Meeresoberfläche derart überragt, dass das Wasser nicht mehr in den oder die Ausbruchsschlote eindringen kann.
In diesem Stadium findet ein weiterer Phasenwechsel statt, nämlich ein Übergang in eine effusive Eruption. Laven beginnen zu strömen und bauen den Vulkan weiter auf.[19]

[Bearbeiten | Quelltext bearbeiten]
 Ausbruch am submarinen Vulkan West Mata

Ein Großteil aller auf der Erde vorhandenen Vulkane befindet sich unter der Meeresoberfläche. Allerdings sind bisher nur wenige von ihnen genauer untersucht worden, darunter etwa der Marsili vor der süditalienischen Küste im Mittelmeer.
Die Eruptionen der submarinen Vulkane finden also unter der Meeresoberfläche, vor allem an den mittelozeanischen Rücken, statt.
Bei diesem Eruptionstyp erhebt sich das Vulkangebäude nicht über die Meeresoberfläche.
Allerdings kann in späteren Ausbrüchen oder Ausbruchsphasen dieser Eruptionstyp in eine Surtseyanische Eruption übergehen.
Die submarine Eruption ähnelt in vieler Hinsicht der subglazialen Eruption. Zunächst bilden sich unter dem Wasserdruck über Vulkanschloten oder -spalten Hügel und Berge von Kissenlaven. Erst knapp unter der Wasseroberfläche findet ein Phasenwechsel statt und eine explosive Phase mit der Bildung von Tephra beginnt.[20]


Inzwischen hat die Wissenschaft zahlreiche Methoden gefunden, um die Vorhersage von Vulkanausbrüchen zu verbessern. Damit befassen sich vor allem die Vulkanobservatorien, aber auch die jeweiligen geologischen bzw. vulkanologischen Institute diverser Universitäten, die meteorologischen Institute, die manchmal die Erdbebenüberwachung übernehmen oder auch die Vorhersage der Zugrichtung von Aschewolken, die ihrerseits aber auch die Luftraumüberwachung betrifft (vgl. VAAC).

[Bearbeiten | Quelltext bearbeiten]
Eine der wichtigsten Methoden bleibt die Beobachtung und Erforschung des bisherigen Verhaltens des jeweiligen Vulkans, da sich dadurch auch Rückschlüsse auf künftiges Verhalten ziehen lassen.[21]

[Bearbeiten | Quelltext bearbeiten]
Am genauesten kann man sich vorbereitende Vulkaneruptionen durch das Erfassen von Schwarmbeben feststellen, also durch viele kleinere Beben, die sich innerhalb einer kurzen Zeit in einem bestimmten Gebiet ereignen. Man unterscheidet zwischen Erdbeben des Typs A und B.
Bei den Typ-A-Beben schwenkt das Seismometer (Erdbebenmessgerät) ruckartig aus, beruhigt sich jedoch schnell wieder und zwar ebenso ruckartig. Das bedeutet, dass sich Magma auf dem Weg nach oben befindet und harte Gesteinsmassen durchbricht, wobei es die kurzzeitig anhaltenden, heftigen Beben verursacht.
Anders bei den Typ B-Beben: Das Seismometer schlägt auch schnell aus, das Beben wird aber nur langsam und gleichmäßig immer schwächer. Das bedeutet, dass der Vulkan unter sehr hohem Druck steht. Wenn sich die Typ-B-Beben in immer kürzeren Abständen wiederholen, kann der Vulkan jeden Moment eruptieren.
Ein Beispiel dafür ist der Vulkan Galeras in Kolumbien. Vier Tage nachdem sich 1992 das erste Typ-B-Beben ereignet hatte, brach der Vulkan aus.

[Bearbeiten | Quelltext bearbeiten]

Neben der Messung von Erdbeben, die auch die sehr niedrigfrequenten, d. h. den sog. vulkanischen Tremor erfasst, setzt man die Geodäsie ein, Messungen, die ein Aufblähen des Vulkans feststellen. Zu diesem Zwecke verwendet man inzwischen z. B. GPS-Systeme und Satellitenbeobachtung.
Eine andere Vorhersagemethode bietet das Tiltmeter. Es misst ebenfalls den Steigungswinkel der Flanken eines Vulkans. Wenn die Magmakammer sich mit flüssigem Gestein füllt, wird der Vulkan an seinen Flanken etwas steiler. Dann ist es wahrscheinlich, dass sich demnächst eine neue Eruption ereignet.
Satelliten dienen zudem der Beobachtung und zur Frühwarnung bzgl. Anzeichen von Ausbrüchen sehr abgelegener Vulkane wie etwa auf dem Aleuten oder der Halbinsel Kamtschatka, in deren Umgebung zwar nur wenige Menschen leben, die aber z. B. den Flugverkehr bedrohen könnten.

[Bearbeiten | Quelltext bearbeiten]
Zudem beobachten Geologen die Anzahl und das Verhalten von heißen Quellen, die zum Vulkan gehören. Wenn sich deren Anzahl und Größe – bei Thermalquellen wie Geysiren auch die Aktivität – erhöhen, kann dies ein Anzeichen eines bevorstehenden Ausbruchs sein. Genauso achtet man auf deren Wassertemperatur, auch hier können Veränderungen Hinweise auf gestiegene vulkanische Aktivität darstellen.[22]

[Bearbeiten | Quelltext bearbeiten]
Schließlich werden die chemischen Zusammensetzungen von Ausgasungen, aber auch die aller Gewässer rund um den betreffenden Vulkan auf das Auftreten und die enthaltene Menge bestimmter Gase wie Kohlendioxid, Fluor und Schwefeldioxid überwacht.

[Bearbeiten | Quelltext bearbeiten]
Auch die elektrische Leitfähigkeit von Gewässern wird überprüft, da erhöhte Leitfähigkeit auf gestiegene vulkanische Aktivität im Gebiet hinweisen kann.

[Bearbeiten | Quelltext bearbeiten]
vergrößern und Informationen zum Bild anzeigenVulkanobservatorium auf dem Colima, Mexiko
Die Auswertung und Zusammenschau derartiger Daten vermittelt ein immer genaueres Bild vom gegenwärtigen Zustand eines Vulkans. Gleichzeitig ist auch wichtig, dass im zuständigen Vulkanobservatorium die Charakteristika jedes einzelnen Vulkans in möglichst vielen Details bekannt sind, welche sich aus der Erforschung seiner jeweiligen Ausbruchsgeschichte ergeben. Aus dieser lassen sich etwa auch Zusammenhänge zwischen Erdbeben und bevorstehenden Ausbrüchen erschließen, die wichtige Informationen zur jeweiligen Vorwarnzeit und damit Zeit für Evakuierungen am einzelnen Berg geben können.[23]
Von besonderer Wichtigkeit zur Verhütung von Vulkankatastrophen sind allerdings auch die Aufklärung der Bevölkerung und eine gute Kooperation zwischen den Wissenschaftlern und den örtlichen Behörden.[24]


Liste großer historischer Vulkanausbrüche
Vulkanexplosivitätsindex
Liste von Vulkanen
Eruptionsgewitter

Hans-Ulrich Schmincke: Vulkanismus. 2. Auflage. Wiss. Buchgesellschaft, Darmstadt 2000, ISBN 3-534-14102-4.
Ari Trausti Guðmundsson: Lebende Erde. Facetten der Geologie Islands. Mál og Menning, Reykjavík 2007, ISBN 978-9979-3-2778-3.
Þorleifur Einarsson: Geology of Iceland. Rocks and Landscapes. Mál og Menning, Reykjavík 2005, ISBN 9979-3-0689-0.


[Bearbeiten | Quelltext bearbeiten]


 Ein Film über Vulkanismus in Island, besonders Gjálp/Grímsvötn 1996 (explosiver Ausbruch mit Gletscherlauf) und Kraflaeldur 1975–84 (effusive Ausbrüche), (Video mit isländischem Kommentar)


[Bearbeiten | Quelltext bearbeiten]

, Smithsonian Inst., Weekly Reports (englisch)
[Bearbeiten | Quelltext bearbeiten]
 (englisch)
 (englisch)
 (englisch/isländisch)
 (englisch)
 (englisch, italienisch)
 (portugiesisch)
 (englisch)
 (spanisch)
[Bearbeiten | Quelltext bearbeiten]
Wissenschaftliche Beiträge zur Vulkanologie

 San Diego State University. (Zum Vulkanismus allg.) (englisch)
Vic Camp:  Dept. of Geological Sciences, San Diego State University. (englisch)
Vic Camp:  Dept. of Geological Sciences, San Diego State University. (englisch)
Erik Sturkell:  – enthält viele Information zur Eruptionsvorhersage (englisch)
 In: geology.com, (englisch)
Erik Klemetti:  In: Eruptions, Wired science blogs. 1. November 2011. (englisch)
 MIT, Open source, Spring 2010. (englisch)
Stephen Self:  In: Phil. Trans. R. Soc. A. vol. 364, no. 1845, Royal Society, London 15. August 2006, S. 2073–2097. doi:10.1098/rsta.2006.1814 (englisch)
Reportagen

Monika Seynsche:  In: Deutschlandfunk. Wissenschaft im Brennpunkt 21. August 2010





Dieser Artikel behandelt eruptiertes Magma. Zu weiteren Bedeutungen siehe Lava (Begriffsklärung).



Lava ist die Bezeichnung für eruptiertes Magma, das flüssig an die Erdoberfläche ausgetreten ist. Sowohl auf der Erdoberfläche fließende Lava als auch die aus der Bewegung heraus erstarrte Lava wird als Lavastrom bezeichnet.
Lava ist ein vulkanisches Förderprodukt und gehört zur Gruppe der Vulkanite. Andere vulkanische Förderprodukte sind die Pyroklastika und die gasförmigen und damit flüchtigen Bestandteile (Volatile) wie Kohlenstoffdioxid, Wasser, Schwefeldioxid, Ammoniak, Edelgase, die das Magma durch Druckentlastung verloren hat. Magmen treten vergleichsweise selten direkt an die Oberfläche aus, da dazu erhebliche Kräfte erforderlich sind. Häufiger sind sogenannte Intrusionen, bei denen Magma in der Erdkruste erstarrt.
Die Temperatur von Lava beträgt beim Austritt zwischen 800 °C (rhyolithische Lava) und 1200 °C (basaltische Lava). Erstarrte Lava bildet vulkanisches Gestein.



Laven sind in der Regel Silikatschmelzen mit einem Gewichtsanteil von 45–70 % SiO2, es gibt allerdings selten auftretende Laven, die geringere Anteile an Silikaten enthalten, so zum Beispiel die Karbonatit-Laven des Ol Doinyo Lengai. Neben den Silikaten können Magnesium- und Eisen-Verbindungen enthalten sein. Man unterscheidet zwischen saurer oder rhyolithischer Lava (SiO2-Gehalt > 65 %, hochviskos) und basischer oder basaltischer Lava (SiO2-Gehalt < 52 %, niederviskos). Dazwischen finden sich die intermediären oder andesitischen Laven (SiO2-Gehalt zwischen 52 % und 65 %). Beim Aufstieg des Magmas finden verschiedene Prozesse statt, die Einfluss auf die Zusammensetzung der austretenden Lava haben (Magmatische Differentiation), so dass diese von der des primären Magmas abweichen kann. Da Lava beim Austritt an die Oberfläche schnell abkühlt, ist ihr Gefüge in der Regel feinkörnig oder glasig. Durch den Austritt von Gasen durch die Druckentlastung beim Aufstieg können sich in der Lava kleinere oder größere Gasblasen bilden.


Abhängig von den Bedingungen beim Aufstieg und der Abkühlung bildet Lava unterschiedliche Erscheinungsformen, die ganz entscheidend von der Viskosität der Lava abhängen. Die bekanntesten Formen sind:





Erstarrte ʻAʻā-Lava, Krafla, Island






Lavastrom, Island






Pāhoehoe- und ʻAʻā-Lava auf Hawaii






Kissenlava, Askja, Island






Gesteine, die aus flüssigem und mit Gasen angereichertem Magma entstehen, werden in der Geologie als Krotzen bezeichnet.

[Bearbeiten | Quelltext bearbeiten]
Pāhoehoe-Lava [pa:ˌhoeˈhoe] ist eine dünnflüssige (d. h. niedrigviskose) basaltische Lava, die als Lavastrom hangabwärts fließt. Sie bildet glasige Oberflächen. Erscheinungsformen von Pāhoehoe-Lava sind Stricklava, Fladenlava oder Schollenlava.

[Bearbeiten | Quelltext bearbeiten]
ʻAʻā-Lava [ˈʔɑʔɑː] – auch Brockenlava – ist eine zähflüssige basaltische Lava, die zu scharfkantigen Brocken und Klumpen erstarrt. Ein Lavastrom kann in seinem oberen Teil aus Pāhoehoe-Lava bestehen, während in seinem unteren Teil ʻAʻā-Lava dominiert (aufgrund der steigenden Viskosität durch Abkühlung und Ausgasung).


[Bearbeiten | Quelltext bearbeiten]
Flutbasalte entstehen aus extrem dünnflüssiger basaltischer Lava, die in ebenem Gelände geringmächtige vulkanische Decken bildet. In Einzelfällen reichen die Fördermengen aber auch aus, um mächtige Tafeln zu erzeugen, die früher auch als Trapp, heute eher als magmatische Großprovinz bezeichnet werden. Beispiele sind das 160.000 km² große Columbia River Plateau (Oregon, Washington und Idaho) in den USA, die über 250.000 km² ausgedehnten Karoo-Basalte Südafrikas oder das 500.000 km² große Dekkan-Plateau in Indien (Dekkan-Trapp).

[Bearbeiten | Quelltext bearbeiten]
Pillow- oder Kissenlava besteht aus Anhäufungen von im Querschnitt runden oder elliptischen, schlauchartigen Basalt-Strukturen von ca. 1 m Durchmesser oder mehr. Sie entsteht bei der sehr schnellen Abkühlung von Lava im Wasser. Durch Hebung von Gesteinskörpern, die ursprünglich unter der Meeresoberfläche lagen, können Pillow-Laven auch auf dem Festland gefunden werden.

[Bearbeiten | Quelltext bearbeiten]
Typisch für zähflüssige andesitische und dazitische Laven ist die Bildung von kurzen, gedrungenen Lavaströmen, deren Oberfläche sich durch Autobrekziierung in kompakte, porenarme Blöcke mit verschiedenartigsten Oberflächenformen aufgelöst hat.

[Bearbeiten | Quelltext bearbeiten]
Brotkrustenbomben bestehen aus Lava, die noch während des Austritts in der Flugphase erkaltet und die Form von Brotlaiben annimmt.

[Bearbeiten | Quelltext bearbeiten]
Eine besondere Erscheinung sind Lavaseen, wie am Erta Ale oder Nyiragongo.
Manche Lavaseen entstehen, indem Krater durch oberirdische Lavaströme mit Lava gefüllt werden, sie werden dann Sekundäre Lavaseen genannt. Solche Lavaseen können Tiefen von bis zu 100 Meter haben. Die Lava kühlt in einem solchen See langsam ab (über mehrere hundert Tage) und bietet dadurch die Möglichkeit, die Erstarrungsprozesse von Lava zu untersuchen.



Beim Abkühlen von dünnflüssigen Lavaströmen können große Hohlräume dadurch entstehen, dass die erkaltete Oberfläche bereits erstarrt ist, während darunter die flüssige Lava noch weiter abfließen kann. Stürzt die Decke einer solchen Lavaröhre ein, entsteht eine Lavarinne.



Ist die Lava beim Austritt bereits so zäh, dass sie nicht abfließen kann, so entsteht ein Lavadom. Darunter versteht man einen kurzen und dicken, oft pfannkuchenartigen Lavastrom. Häufig füllen Lavadome auch in fingerartiger Form einen Kraterschlund auf, der sich zuvor durch eine explosive Eruption entleert hatte.
Die Bildung von Lavadomen zieht sich über einen längeren Zeitraum hin und ist daher ein von Wissenschaftlern gut dokumentierter Vorgang. Berühmt sind etwa die Lavadome am Mount St. Helens, wo sich vor dem Ausbruch von 1980 einer bildete und seither schon wieder die Bildung eines neuen Lavadoms begonnen hat. Weitere bekannte Beispiele sind die Lavadome des Unzen und des Usu auf der Insel Hokkaidō in Japan, wo man überhaupt wohl das erste Mal mitverfolgt hat, wie sich ein Vulkan vor einem Ausbruch aufbläht und verformt. Ein Beispiel für europäische Lavadome stellt der Puy de Dôme in Südfrankreich dar.






Lavabombe aus dem Vulkan Hekla






Lavadom auf dem Mount St. Helens






Lavahöhle in Westisland






Pāhoehoe-Lavafontänen








Basaltsäulen entstehen bei Abkühlung der Lava unter bestimmten Bedingungen. Lava zieht sich zusammen und zerspringt während des Abkühlungsprozesses. Dieses Phänomen ist jedoch nicht auf basaltische Gesteine (Basaltoide) begrenzt, sondern tritt u. a. auch bei Rhyolith oder Phonolith (siehe z. B. Devils Tower) auf.
Wenn v. a. Pāhoehoe-Lavaströme schnell abkühlen, werden die Lavasäulen nicht so auffallend und sind unregelmäßig geformt. Allerdings erklärt sich dadurch, dass die Lavafelder i. A. für Erosion sehr anfällig sind.
Schön ausgebildete Basaltlavasäulen hingegen bilden sich bei langsamerer Abkühlung. Dabei stehen die Säulen immer senkrecht zur Abkühlungsfläche. Daher findet sich in Lavaschichten und flach liegenden Intrusionen eine vertikale Ausrichtung der Säulen, wie etwa im Lava-Keller in Mendig in Deutschland, bei Gerðuberg im Hnappadalur in Island, der Giant’s Causeway bei Bushmills in Irland oder bei St. Flour in der Auvergne in Südfrankreich; hingegen sind Lavasäulen in steilen Gängen horizontal ausgerichtet.
Lava kühlt nicht gleichmäßig ab, sondern an der Oberfläche schneller und in der Tiefe langsamer; daher sind obere Säulen oft dünner als untere.
Fächermuster und Rosetten bilden sich hingegen in Lavagängen und -höhlen. Dergleichen Formationen findet man z. B. im Barranco de Agaete auf Gran Canaria oder bei Hljóðaklettar im Jökulsárgljúfur-Nationalpark in Island.
Die meisten dieser Basaltsäulen sind sechseckig, es finden sich aber auch fünfeckige wie etwa am Dvergasteinn bei Kirkjubæjarklaustur in Südisland, und siebeneckige.


Hans-Ulrich Schmincke: Vulkanismus. Primus-Verlag, Darmstadt 2010, ISBN 978-3-89678-690-6.




Mineralienatlas:Lava Geologie, Bilder, Lavaformen etc.
 (englisch)
 (englisch)


Vulkanische Ablagerungen




    Zusammen-setzung    

            

    Anteil anPyroklasten    

              
           
Pyroklastika> 75% Tuffite75–25% Epiklasten< 25%

             
     
    Verfestigt?    

Ja        Nein
      
  pyroklast.Gestein Tephra  

  Tuff, Lapillistein,pyroklast. Brekzie,Agglomerat Asche, Lapilli,Blöcke und Bomben  

           

    Transport-weg    

            

              
      
  pyroklast. Fließ-Ablagerung pyroklast. Fall-Ablagerung  



Der Begriff vulkanische Asche bezeichnet in der Vulkanologie sehr kleine Pyroklasten beliebiger Form (< 2 mm), die bei einem explosiven Ausbruch eines Vulkans entstehen. Vulkanasche bildet zusammen mit den vulkanischen Lapilli (> 2 mm), den vulkanischen Bomben (> 64 mm, gerundet, ursprünglich geschmolzen) und den vulkanischen Blöcken (> 64 mm, eckig, zum Zeitpunkt des Auswurfs bereits fest) die pyroklastischen Sedimente. Diese werden auch Tephra genannt, wenn sie noch unverfestigt sind bzw. nach ihrer Verfestigung pyroklastische Gesteine.
Vulkanische Asche hat positiven Effekt auf die Bodenverbesserung, als Aschewolke jedoch negativen auf die Gesundheit, das Klima und die Sicherheit des Flugverkehrs.
Die allgemein bekannte Asche, die aus mineralischen Verbrennungsrückständen organischen Materials besteht (Zigarettenasche, Holzasche), hat mit Asche im vulkanologischen Sinn nichts zu tun.





Vulkanische Asche ist ausschließlich über die Korngröße definiert, d. h. die chemisch-mineralogische Zusammensetzung und die Form der Komponenten spielt keine Rolle. Der Begriff Asche im vulkanologischen Sinn bezeichnet einfach Pyroklasten, die kleiner als 2 mm sind. Vulkanische Asche besteht aus feinen Lava-Fetzen, Glasfragmenten, klein zerriebenem vulkanischem Gestein oder auch aus Einzelkristallen. Sie wird nach der Definition der IUGS (International Union of Geological Sciences) in

grobe Asche (1/16 mm bis 2 mm) und
feine Asche oder Aschenstaub (< 1/16 mm)
unterteilt.
Nach der älteren Unterteilung von Sohn und Cough (1989)[1] kann auch eine Dreiteilung der Aschefraktion vorgenommen werden in:

grobe Asche (1/2–2 mm)
mittelfeine/mittelgrobe Asche (1/16–1/2 mm)
feine Asche (feiner 1/16 mm)
Sie wird derzeit zum Teil noch parallel zur obigen Empfehlung der IUGS benutzt.



Vulkanische Aschen sind Bestandteile pyroklastischer Sedimentabfolgen. Die lockeren pyroklastischen Sedimente werden auch als Tephra bezeichnet. Wenn diese verfestigt sind, spricht man von pyroklastischen Gesteinen. Der Anteil vulkanischer Asche innerhalb einer pyroklastischen Abfolge wächst mit zunehmendem Abstand zum Herkunftsort, d. h. zum entsprechenden Vulkan. Ab einer bestimmten Entfernung zum Vulkan bestehen die pyroklastischen Sedimente eines Ausbruches ausschließlich aus Asche.
Wird vulkanische Asche zu einem pyroklastischen Gestein verfestigt (lithifiziert), wird dieses als Tuff oder genauer Aschentuff bezeichnet sofern es mehr als 75 % Aschepartikel enthält. Die Bezeichnung „Tuff“ ist bzw. war in der Literatur jedoch mehrdeutig, weshalb die Bezeichnung „Aschentuff“ vorzuziehen ist. Aschentuff kann weiter in Groben Aschentuff und Feinen Aschentuff (oder auch Staubtuff) unterteilt werden.
Ein Lapilli-Tuff ist hingegen insgesamt grobkörniger und enthält bis zu 25 % vulkanische Bomben und Blöcke und mehr als 75 % Lapilli und Asche. Insgesamt muss ein Gestein aus mehr als 75 % Pyroklasten bestehen, damit es überhaupt als „Tuff“ bezeichnet werden darf. Eine Ablagerung, die weniger als 75 % Pyroklasten enthält, wird Tuffit genannt.




Bei einer Vulkaneruption können gewaltige Mengen an vulkanischer Asche freigesetzt werden. Ein Beispiel dafür ist der Inselvulkan Krakatau, der in der Sundastraße zwischen Java und Sumatra liegt. Als er am 27. August 1883 ausbrach, lieferte er 18 km3 Aschenpartikel, die bis zu 25 km hoch in die Erdatmosphäre geschleudert wurden und drei Jahre lang die Erde umkreisten. Vielerorts riefen sie Trübungsschleier, Dämmerungserscheinungen und Himmelsverfärbungen hervor. Hinzu kommen außerdem „Gewitter“ innerhalb der Aschewolken: Die Ascheteilchen werden durch die Reibung elektrostatisch aufgeladen, dadurch kommt es zu Blitzen und gewitterähnlichen Erscheinungen, bei denen sich die Ladungsunterschiede abbauen.
Noch extremere Auswirkungen hatte die Explosion des Tambora im Jahre 1815. Dabei wurde so viel Asche und Aerosol in die Atmosphäre geschleudert, dass weltweit auf Jahre hinaus das Klima beeinflusst wurde. Das darauf folgende Jahr 1816 ging sogar als das Jahr ohne Sommer in die Geschichte ein.
Ähnlich langanhaltende Trübungen der Erdatmosphäre traten mehrmals in der Erdgeschichte durch große Meteoriteneinschläge auf, die auch zum Massenaussterben vieler Arten geführt haben.


Vulkanische Aschen besitzen dank ihres Mineralgehalts einen hohen bodenverbessernden Wert. In günstigen Klimata können sie bereits nach wenigen Jahren landwirtschaftlich genutzt werden.


Vulkanische Asche enthält teilweise große Mengen für Menschen und Tiere giftige Substanzen. Außerdem können sich die Aschepartikel in der Lunge ansammeln und dort zu Husten, Luftnot und Lungenvernarbungen führen. Dazu muss die Konzentration aber erheblich sein. Beim Ausbruch des Eyjafjallajökull 2010 in Island wären nur Personen in Island selber von dieser Gefahr betroffen gewesen, diese wurden aber rechtzeitig evakuiert. Im übrigen Europa war die Konzentration der Partikel zu klein, um gefährlich zu werden.[2]


Sehr feinkörnige Vulkanasche, die während einer Eruption in die höheren Schichten der Atmosphäre aufsteigt, stellt – zumindest in größeren Konzentrationen – eine gravierende Gefahr für die Luftfahrt dar. Für den Zeitraum zwischen 1973 und 2000 sind ca. 100 Begegnungen von Luftfahrzeugen mit Aschewolken dokumentiert.[3][4] Schäden an den Flugzeugen traten dabei innerhalb eines Radius von maximal 3300 km (1800 mi) um den entsprechenden Vulkan auf.[5] In sieben dieser Fälle, in Abständen von ca. 270 bis 1100 km (150 bis 600 mi) zum entsprechenden Vulkan, traten Triebwerksausfälle während des Fluges auf, in drei Fällen sogar ein kurzzeitiger Ausfall aller Triebwerke.[3][5] Jedoch führte bisher noch kein solches Ereignis zu einem Absturz.[3] Der finanzielle Gesamtschaden aller Ereignisse wird mit einer Viertelmilliarde Dollar beziffert.[6]S. 1[5]
Über die tatsächliche Gefahr, die von Vulkanasche für Flugzeuge ausgeht, herrschte lange Zeit Unklarheit. Einerseits sind Aschewolkendurchflüge mit fast katastrophalem Ausgang bekannt, andererseits auch solche ohne Auffälligkeit. Kontrovers war dahingehend das über weite Teile Europas verhängte Flugverbot im Zusammenhang mit der Eruption des Eyjafjallajökull 2010. Nachträgliche Betrachtungen ergaben, dass das umfassende Flugverbot so nicht zu rechtfertigen war, weil die im entsprechenden Zeitraum gemessenen Aschekonzentrationen überall deutlich unter dem von der britischen Zivilluftfahrtbehörde und Herstellern als kritisch erachteten Grenzwert von 2 Milligramm pro Kubikmeter lagen.[7][8] Der Grenzwert war allerdings erst nach dem Vorfall eingeführt worden.
Folgende gefährliche Wirkungen von Vulkanasche insbesondere auf Verkehrsflugzeuge werden angeführt:

[Bearbeiten | Quelltext bearbeiten]
Durch die hohe Fluggeschwindigkeit wirken Aschepartikel aufgrund ihrer relativ großen Mohshärte (5,5–7) und ihrer Scharfkantigkeit wie ein Sandstrahlgebläse.[2]  Dies gilt vor allem für die größeren Partikel, die allerdings wegen ihres Gewichts relativ schnell zu Boden fallen und nicht in größere Höhen getragen werden.

Scheiben: Durch den Aufprall von Aschepartikeln können die Glasscheiben des Cockpits so weit undurchsichtig werden, dass keine Sicht mehr besteht.[2] Dieses ist während des Reisefluges weniger problematisch als während der Landung.
Tragflächen: auch eine aerodynamische Beeinträchtigung der durch die Aschepartikel aufgerauten Tragflächen mit Auswirkung auf die Sicherheit wird teilweise für möglich gehalten.[9]
[Bearbeiten | Quelltext bearbeiten]
Beim Durchfliegen von vulkanaschehaltiger Luft können Triebwerke beschädigt werden und zeitweise oder vollständig ausfallen, abhängig von der Art und Dichte der Aschewolke und der Dauer des Durchflugs. Folgende Effekte können auftreten:

Ablagerungen geschmolzener Aschepartikel an Teilen der Brennkammer und der Turbinen sowie teilweiser Verschluss der Treibstoffdüsen: Die Aschepartikel typischer explosiver zirkumpazifischer Stratovulkane beginnen bei etwa 1100 °C zumindest teilweise zu schmelzen,[10] und ähnliche Werte wurden auch für den isländischen Vulkan Eyjafjallajökull ermittelt.[2] Demgegenüber herrschen in der Brennkammer eines modernen Strahltriebwerks bis zu 2500 °C, wobei die Temperatur auf Reiseflughöhe typischerweise 1450 °C beträgt[11]. Daher schmelzen in die Brennkammer geratene Aschepartikel und erstarren bei Kontakt mit kühleren Maschinenteilen wieder, wodurch sich u. a. auf den Schaufeln der Hochdruckturbine und vor allem an den vorgeschalteten Leitblechen (engl.: nozzle guide vanes) glasartige Krusten bilden.[12] Zudem entstehen an den Treibstoffeinspritzdüsen kohlige Ablagerungen, die zwar nicht die zentrale Öffnung aber die Drallflügel der Einspritzdüsen verstopfen, was dafür sorgt, dass der Treibstoff nicht mehr ausreichend zerstäubt wird.[12]
Erosion an den Kompressor- und Turbinenschaufeln und anderen dem Gasstrom ausgesetzten Triebwerksteilen (Sandstrahleffekt):[6]S. 2, 16 Noch intensiver als an der Außenhaut und den Cockpitscheiben des Flugzeugs wirkt die Materialabrasion durch Aschepartikel an den schnell rotierenden Teilen der Triebwerke. Zumindest das Phänomen der Erosion durch Sand- und Staubpartikel, die z. B. während des Start- und Landevorganges oder beim Flug durch sturminduzierte Sand- und Staubwolken in die Triebwerke gelangen, ist seit langem bekannt, und die Antriebsaggregate von Hubschraubern und Flugzeugen werden bereits während der Entwicklungsphase auf entsprechende Auswirkungen getestet („Arizona road-dust test“).[13][14][15] Jedoch haben Versuche gezeigt, dass die erosive Wirkung von Vulkanasche 4-mal höher sein kann als die von Quarzsand.[15] Besonders nachteilig auf die Triebwerksleistung wirkt sich die Erosion der Hochdruckkompressorschaufeln aus, da dadurch keine optimale Verdichtung der einströmenden Außenluft mehr erreicht wird.[15]
Teilweiser oder vollständiger Verschluss der Kühlluftbohrungen der Leitbleche und Hochdruckturbinenschaufeln: Die Kühlluft hält die Temperatur der Turbinenschaufeln möglichst niedrig (ca. 420 °C). Ein Ausfall der Kühlung hat keinen unmittelbaren Einfluss auf die Triebwerksleistung, verkürzt aber die Lebensdauer der Hochdruckturbinenschaufeln auf etwa 100 Betriebsstunden – im Vergleich zu mehreren 1000 Betriebsstunden normal gekühlter Schaufeln.[6]S. 2, 13
Akut gefährlich sind besonders die Ablagerungen im heißen Bereich (engl.: hot section) des Triebwerksinneren. Krusten auf den Leitblechen vor der Hochdruckturbine führen zu einem Anstieg des Druckes in der Brennkammer und des Kompressor-Enddruckes, wodurch es in größerer Flughöhe zu einem Strömungsabriss im Triebwerk (engl.: engine surge) und damit zu einem Flammabriss (engl.: flame-out) kommen kann, was wiederum einen kompletten Triebwerksausfall bedeutet.[12] Verminderte Leistung des Kompressors durch Erosion und mangelnde Zerstäubung des Treibstoffes in der Brennkammer infolge der Verstopfung der Drallflügel der Treibstoffdüsen kann zusätzlich zum Triebwerksausfall beitragen. Nach Absinken im Gleitflug in dichtere Luftschichten kann, sofern die Treibstoffdüsen nicht zu stark zugesetzt sind, das Triebwerk in aller Regel wieder gestartet und der Flug normal fortgesetzt werden. Möglich wird dies auch, da der passive Luftstrom (engl.: ram air) im ausgefallenen, abgekühlten Triebwerk bis dahin wieder eine gewisse Menge der spröden Krusten von den Maschinenteilen der „hot section“ fortgerissen hat.[12]

[Bearbeiten | Quelltext bearbeiten]
Es besteht die Gefahr, dass durch die Asche die Sensoren für Geschwindigkeit und Höhe verstopfen,[9] was unmittelbar gefährlich werden kann,[16] da Flugzeuge außerhalb eines definierten Geschwindigkeitsbereichs in unkontrollierbare Flugzustände geraten, wobei dieser sichere Bereich mit steigender Höhe immer kleiner und zur so genannten Coffin Corner wird.

[Bearbeiten | Quelltext bearbeiten]
Es wird vermutet, dass unter Umständen, wo von Vulkanen ausgestoßene Asche von viel Wasser begleitet wird, dies dazu führt, dass die Aschepartikel als Kondensationskeime in entsprechender Höhe weitgehend von Eis umhüllt sind. Dies wurde beim NASA-Flug im Jahr 2000 als mögliche Erklärung dafür angesehen, warum zwar (nachträglich entdeckte) sehr kostenintensive Triebwerksschäden zu verzeichnen waren, jedoch keine Beschädigungen der Flugzeughülle oder Scheiben.[6]S. 17

[Bearbeiten | Quelltext bearbeiten]
Der erste schwerwiegende Vorfall war der vorübergehende Ausfall eines Triebwerks an einer Lockheed C-130 am 25. Mai 1980 bei einem Erkundungsflug über dem Mount St. Helens in Washington (USA) in der Folge des Ausbruchs des Mount St. Helens vom 18. Mai 1980. Sieben weitere Flugzeuge wurden in den Wochen nach der Eruption durch Abrieb äußerlich und an den Triebwerken beschädigt.[17]
Am 24. Juni 1982 geriet eine Boeing 747-200 auf dem British-Airways-Flug 9 über dem Indischen Ozean in einer Flughöhe von 37.000 ft (ca. 11.300 m) südlich der indonesischen Insel Java in eine Wolke aus Asche des Vulkans Gunung Galunggung. Dies führte zu einem Ausfall aller vier Triebwerke. Erst nach einem Sinkflug in dichtere Luftschichten in etwa 4000 Metern Höhe gelang es der Besatzung, die Triebwerke wieder in Gang zu setzen und auf dem Flughafen Jakarta/Halim Perdanakusuma notzulanden.[5][18]
Am 15. Dezember 1989 passierte Vergleichbares mit KLM-Flug 867 über dem Mount Redoubt in Alaska. Alle vier Triebwerke der Boeing 747-400 fielen für fast eine volle Minute aus. Die Maschine ging in den Sinkflug und erst nach einem Höhenverlust von rund 3000 m konnten die Triebwerke außerhalb der Wolke neu gestartet werden. Die Maschine landete anschließend in Anchorage, Alaska, dem ohnehin vorgesehenen Zielflughafen.[5][18]
Von der NASA wurde ein Flug dokumentiert,[6] bei dem im Februar 2000 ein Messflugzeug 7 min lang durch eine Aschewolke flog. Hierbei wurde von den Piloten keinerlei technische Auffälligkeit registriert. Allein die Messinstrumente zeichneten in diesem Zeitraum das Vorhandensein von Vulkanasche auf. Im Bericht ist beschrieben, dass für diesen Zeitraum der Sternenhimmel nicht sichtbar war.[6]S. 11, 19 Jedoch wurden bei späteren Inspektionen Beeinträchtigungen entdeckt, die zur Überholung aller vier Triebwerke führten. Der hierbei entstandene Schaden betrug 3,2 Millionen US$.
Der Ausbruch des Vulkans Eyjafjallajökull ab dem 14. April 2010 führte ab dem 15. April zu einer mehrtägigen, weitgehenden Einstellung des Flugverkehrs über Nordeuropa und weiten Teilen Mittel- und Osteuropas und somit zu volkswirtschaftlichen Schäden in Höhe von mehreren Milliarden Euro. Am 16. April 2010 waren in der Bundesrepublik Deutschland erstmals in der Geschichte alle zivilen Flughäfen für den Flugbetrieb nach Instrumentenflugregeln gesperrt.

[Bearbeiten | Quelltext bearbeiten]
Ab dem Jahr 1993 wurden durch die Internationale Zivilluftfahrt-Organisation (ICAO) neun Volcanic Ash Advisory Center eingerichtet, die weltweit den Luftraum auf Vulkanasche überwachen und falls notwendig den Luftverkehr warnen.

[Bearbeiten | Quelltext bearbeiten]
Zwar sind die Vulkanaschewarnzentralen seit Jahren aktiv, jedoch wurden offenbar nie verbindliche Aussagen getroffen, in welchen Konzentrationen aschehaltige Luft eine konkrete Gefahr für Verkehrsflugzeuge darstellt. Stattdessen ging man immer von ‚der Aschewolke‘ aus. Diese Situation galt noch bis zum Ausbruch des Vulkans Eyjafjallajökull im April 2010, was zu umfangreichen, im Nachhinein kritisierten, Sperrungen von Lufträumen und tagelangen Komplettausfällen im Luftverkehr führte.
Am 20. April 2010 wurde daraufhin von der britischen Civil Aviation Authority erstmals ein verbindlicher Grenzwert verkündet. So gelten Einschränkungen für den britischen Luftraum nur noch da, wo ein Wert von 2 Milligramm Vulkanasche pro Kubikmeter Luft überschritten wird.[7] Dieser Wert wurde über Mitteleuropa durch den Ausbruch des Eyjafjallajökull zu keiner Zeit auch nur annähernd erreicht.


Drei-Zonen-Modell der Europäischen Flugsicherung Eurocontrol


Zone
Konzentration
Regelung


3

>2 mg/m³
Flugverbot im Umkreis von 110 km


2

0,2–2 mg/m³
erhöhte Wartungsintervalle


1

<0,2 mg/m³
keine Einschränkungen

Am 4. Mai 2010 einigten sich die EU-Verkehrsminister auf eine 3-Zonenregelung. Flugverbote gelten hierbei für Bereiche mit über 2 Milligramm Vulkanasche pro Kubikmeter einschließlich eines Sicherheitsabstandes von 110 km (Zone 3). Zwischen 2 und 0,2 mg/m³ gelten verschärfte Wartungsintervalle (Zone 2). Unterhalb von 0,2 mg/m³ gibt es keine Einschränkungen (Zone 1).[19]

[Bearbeiten | Quelltext bearbeiten]
Zurzeit sind Detektoren, mit denen Vulkanasche aus dem Cockpit heraus erkannt werden kann, praktisch nicht verfügbar. Das eingebaute Wetterradar kann die Aschepartikel nicht erkennen, da sie zu klein sind.[6]S. 3


Roger Walter Le Maitre: Igneous rocks: IUGS classification and glossary; recommendations of the International Union of Geological Sciences, Subcommission on the Systematics of Igneous Rocks. 2. Auflage. Cambridge University Press, New York, NY 2002, ISBN 0-521-66215-X. 
Hans Pichler: Italienische Vulkangebiete III, Lipari, Vulcano, Stromboli, Tyrrhenisches Meer. In: Sammlung geologischer Führer. Band 69. Gebrüder Bornträger, Stuttgart 1981, ISBN 3-443-15028-4. 




 (englisch)




Ein pyroklastischer Strom (von altgriechisch πῦρ pyr, deutsch ‚Feuer‘ und κλαστός klastós, deutsch ‚zerbrochen‘) ist eine Feststoff-Gas-Dispersion, die in Begleitung explosiver vulkanischer Eruptionen auftreten kann und sich sehr schnell hangabwärts bewegt.



Pyroklastische Ströme treten in Zusammenhang mit felsischen, also quarz- und feldspatreichen, seltener intermediären, aber in jedem Falle gasreichen Magmen und Asche auf. Der Begriff (ausgehend von nuée ardente, das im Französischen synonym mit coulée pyroclastique ‚pyroklastischer Strom‘ ist) wurde erstmals im Zusammenhang mit dem Ausbruch des Pelée 1902 verwendet.
Wenn Magma in einem Vulkan aufsteigt, dann sinkt der Druck, und die Gaslöslichkeit im Magma nimmt damit ab. In der Folge entstehen Gasblasen, welche aber aufgrund der Zähigkeit des Magmas vorerst nicht entweichen können. Durch den ansteigenden Gasdruck verfestigt sich das um die Blase liegende Magma breiförmig und kann bei einem Austritt des Gases nicht mehr zusammenfließen, wodurch ein Hohlraum entsteht. Das dickflüssige Magma schiebt sich übereinander und bildet eine so genannte Staukuppe (auch als Lavadom oder, bei spitzeren Formen, als Lavanadel bezeichnet). Ab einer bestimmten Höhe (etwa ab 40 Metern) wird das zähflüssige, halbstarre Gebilde instabil und kann kollabieren.
Beim Austritt aus dem Schlot kann das im Magma gelöste Gas entweichen. Ein pyroklastischer Strom entsteht, wenn dabei Gesteinsbrocken und das Magma zu besonders feiner vulkanischer Asche zerrissen werden und sie zusammen mit den austretenden Gasen mit bis zu 700 km/h[1] den Hang hinab gleiten, wobei eine enorme Zerstörungskraft entfaltet wird. Selbst große Wasserflächen (z. B. offene Meerwasserflächen) werden mühelos überwunden. Beim Ausbruch des Soufrière Hills auf Montserrat konnten erstmals Ströme beobachtet werden, die sich über das Meer ausbreiteten. Im Inneren des Stroms können Temperaturen zwischen 300 und 800 °C herrschen, abhängig von der Größe des Stroms. Pyroklastische Ströme zerstören alles auf ihrem Weg, auch Gebäude. Asche und Staub sind auch in der Nähe dieser Ströme eine tödliche Gefahr.



Plinius der Jüngere beobachtete im Jahr 79 den Ausbruch des Vesuvs und beschrieb eine Plinianische Eruption. Seine Darstellungen einer sich in das Tal stürzenden schwarzen Wolke[2] wurden erst spät als pyroklastischer Strom identifiziert. Die Ablagerungen zeigen, dass beim Ausbruch des Vesuvs mehrere pyroklastische Ströme entstanden. Einer davon erreichte Herculaneum und tötete viele Menschen, die in Bootshäusern Schutz gesucht hatten. Ein weiterer erreichte 18 Stunden nach Beginn des Ausbruchs das weiter vom Vesuv entfernte Pompeji. Seine Temperatur von 300 Grad Celsius tötete zwar die Menschen, ließ aber deren Kleidung weitgehend unbeschädigt.
Nach 1812 wurde der indonesische Vulkan Tambora sehr aktiv und erreichte sein Maximum 1815 (VEI-Stärke 7). Bei diesem Ausbruch wurden 160 Kubikkilometer Pyroklastika ausgeworfen, die in der Folge für eine weltweite Klimakatastrophe mit drastischen Temperaturabsenkungen (bis 5,5 °C) sorgten („Jahr ohne Sommer“).[3]
Am 8. Mai 1902 kam es in der Karibik am Montagne Pelée zum verlustreichsten Ausbruch des 20. Jahrhunderts, der schätzungsweise 29.000 Menschen das Leben kostete.
Am 18. Mai 1980 brach in den USA der Vulkan Mount St. Helens mit einem horizontalen Flankenaufbruch aus und setzte einen pyroklastischen Strom frei, der ein 37 Kilometer breites und 30 Kilometer langes fächerförmiges Areal verwüstete. Dabei wurde neben 56 weiteren Personen auch der Vulkanologe David A. Johnston getötet. Neun Personen überlebten schwer verletzt. Die United States Geological Survey hatte nicht mit einem direkten, so gewaltigen pyroklastischen Strom gerechnet, der 1080 km/h und möglicherweise kurzzeitig sogar Schallgeschwindigkeit erreichte, und daher eine zu kleine Schutzzone ausweisen lassen.
Besonders berüchtigt für seine pyroklastischen Ströme ist der Unzen in Japan. Während seiner letzten Aktivphase (1990–1995) schickte er über 175 von ihnen ins Tal. Am 3. Juni 1991 starben dort neben 41 weiteren Personen die berühmten Vulkanologen Katia und Maurice Krafft bei Filmaufnahmen, als überraschend ein pyroklastischer Strom niederging. Auch der Soufrière auf der Karibikinsel Montserrat ist bekannt dafür; ab dem 25. Juni 1997 führten zahlreiche pyroklastische Ströme, zu denen es bis in den Dezember 1997 kam, zur Zerstörung der südlichen Inselhälfte.
Am 29. September 2014 wurden Bergwanderer auf dem Vulkan Ontake-san in Japan von einem pyroklastischen Strom überrascht. Es wurden mehrere Verletzte gerettet und über 55 Tote geborgen.[4]



Eine Glutlawine ist eine Variante des pyroklastischen Stromes, die mit 300–1000 km/h und Temperaturen von 350 bis 1000 °C die Vulkanhänge hinabrasen und sich kilometerweit ausbreiten kann.
Ein Lahar ist eine durch Lava ausgelöste Schlammlawine. Er ist mit bis zu 100 °C deutlich kälter als ein pyroklastischer Strom und erreicht Fließgeschwindigkeiten von weniger als 100 km/h.
Pyroklastische Ströme werden grundsätzlich von den Lavaströmen unterschieden. Pyroklastische Ströme entstehen durch explosive Eruptionen bzw. Eruptionsphasen von Vulkanen, Lavaströme hingegen durch effusive Eruptionen oder in effusiven Eruptionsphasen.
In der Vulkanologie werden pyroklastische Surges und pyroklastische Ströme (im engeren Sinn) unterschieden. Ströme und Surges unterscheiden sich durch ihre Dichte (Gasgehalt), bei Surges kann man daher von Glutwolken sprechen.

Jens Edelmann: Vulkane besteigen und erkunden. Vulkantouren, Vulkanismus, Eruptionsformen, Verhalten beim Vulkanausbruch, Gesteine und Minerale, interessante Vulkangebiete, Touren mit Kindern: Planung, Kosten, Ausrüstung, Sicherheit, Fotografieren, Informationsquellen. 2., aktualisierte Auflage. Reise Know-How Rump, Bielefeld 2007, ISBN 978-3-8317-1625-8, S. 78.
Anke Fischer: Naturkatastrophen. Compact, München 2007, ISBN 978-3-8174-6091-5, S. 22 ff.
Hans Füchtbauer (Hrsg.): Sedimente und Sedimentgesteine. In: Sediment-Petrologie. Teil 2, 4., ergänzte und neubearbeitete Auflage, Schweizerbart, Stuttgart 1988, ISBN 3-510-65138-3.
Hans-Ulrich Schmincke: Vulkanismus. 2., überarbeitete und erweiterte Auflage, Wissenschaftliche Buchgesellschaft, Darmstadt 2000, ISBN 3-534-14102-4.
Martin Rietze: Vulkane. Einführung in die Welt der Vulkane. Primusverlag, Darmstadt 2010, ISBN 978-3-89678-836-8.



 (englisch)
 (englisch)





Dieser Artikel beschäftigt sich mit dem geologischen Phänomen Supervulkan, für den gleichnamigen Fernsehfilm siehe Supervulkan (Film).


Supervulkane sind die größten bekannten Vulkane, die im Gegensatz zu „normalen“ Vulkanen auf Grund der Größe ihrer Magmakammer bei Ausbrüchen keine Vulkankegel aufbauen, sondern riesige Calderen (Einbruchskessel) im Boden hinterlassen. Als Supereruption werden Ausbrüche mit dem Vulkanexplosivitätsindex-Wert 8 (VEI-8) bezeichnet, wobei gelegentlich auch Ausbrüche der Stärke VEI-7 dazu gerechnet werden. Eine wissenschaftlich exakte Definition gibt es allerdings nicht. Den Begriff Supervulkan hat die Fachliteratur erst kurz nach der Jahrtausendwende aus Medienberichten übernommen.
Der letzte Ausbruch eines Vulkans mit VEI-8 oder stärker geschah im Gebiet des Lake Taupō (Neuseeland) vor etwa 26.500 Jahren. Der letzte Vulkanausbruch mit VEI-7 oder stärker (und schwächer als VEI-8) war der Ausbruch des Tambora 1815 („Jahr ohne Sommer“). Die Zeit zwischen vollständiger Auffüllung der Magmakammer und dem darauf folgenden Ausbruch eines solchen Supervulkans wird auf einige hundert bis wenige tausend Jahre geschätzt.[1][2]




Supervulkane besitzen eine besonders große Magmakammer unter dem Vulkangebiet. Sie stoßen bei Ausbrüchen typischerweise eine Auswurfmenge (Lava, Pyroklastika, Staub etc.) von mindestens 1.000 km³ aus.[3] So liegt unter dem Yellowstone-Vulkan eine Magmakammer mit einem Volumen von rund 10.000 km³ über einem auf 46.000 km³ geschätzten Magmareservoir. Während sich das teilgeschmolzene Magma über tausende von Jahren mit Gas anreichert, hebt sich das Gebiet über der Magmakammer. Wird das Magma durch die Gasanreicherung kritisch, bricht es an mehreren weitverteilten Stellen durch das Deckgestein. Typischerweise geschieht das durch die beim Heben des Gebietes über der Magmakammer entstehenden Risse im Boden ringförmig. Der auf diese Weise gebildete Deckel aus Gestein sinkt in die sich leerende Magmakammer und bildet so die charakteristische Caldera (Kessel). Die Wucht eines solchen Ausbruches wird mit dem Vulkanexplosivitätsindex-Wert 8 (VEI-8) und höher beschrieben. Dabei werden Hunderte oder Tausende Kubikkilometer Lava aus der Magmakammer mit Überschallgeschwindigkeit bis zu 50 km hoch in die Stratosphäre geschleudert und „regnen“ im Umkreis von mehreren 100 km nieder. Vulkanischer Staub wird um den ganzen Globus getragen.



Extrem heiße pyroklastische Ströme bedecken ein großes Areal um die Ausbruchstelle; sie können bis zu 200 km weit reichen und eine bis zu 200 m dicke Schicht bilden. Bei einem Ausbruch in Küstennähe sind Tsunamis möglich. Noch Jahre nach dem Ausbruch besteht das Risiko von Schlammlawinen (Lahar), die u. a. Flussläufe blockieren und Fluten auslösen können. Ein Gebiet von der Größe eines Kontinents kann mit Asche bedeckt werden.[4][5]
Die Zahl der Opfer ist abhängig vom Standort des Supervulkans. In einem Umkreis in der Größenordnung von 100 km wird jedes Leben durch den Ausbruch vernichtet. Im Umkreis von mehreren hundert Kilometern kann die Last von Ascheschichten, besonders wenn Feuchtigkeit hinzu kommt, Dächer zum Einsturz bringen. Wasser- und Abwasseranlagen, Flugverkehr und Stromversorgung wären gefährdet.[5] Auch in größerer Entfernung ist die Sterblichkeit hoch. Sehr feiner Vulkanstaub mit einem Durchmesser von weniger als 4 µm kann durch Einatmen in die Lunge gelangen und kurzfristig Asthma- und Bronchitisanfälle, langfristig Silikose, Lungenkrebs und COPD verursachen.[6] Die Ascheschicht behindert die Photosynthese von Pflanzen, sie kann – je nach Dicke und Verweilzeit der Tephraschicht – ihren Wuchs beeinträchtigen, bis hin zum Absterben. Vor allem Bäume und Sträucher können durch die Last der Tephra brechen. Bildet sich durch Regen oder Tau eine zementartige Schicht, so wird die Verweilzeit der Tephra verlängert und die Wiederbesiedlung der Flächen verzögert.[7]
Neben den primären Schäden einer Supervulkanexplosion kommt es zu einer globalen Klimakatastrophe, auch als Vulkanischer Winter bezeichnet, bei welchem die Temperaturen weltweit um mehrere Grad sinken. Durch massenhaftes Absterben von Pflanzen und Tieren droht eine jahrelange Nahrungsknappheit.[5]
Man vermutet, dass Supervulkane bei den bekannten Ausbrüchen für Artensterben verantwortlich waren. Nach der umstrittenen Toba-Katastrophentheorie wurde die Menschheit auf einige tausend Menschen reduziert, als vor 75.000 Jahren der Toba-Vulkan auf Sumatra (Indonesien) ausbrach. Relikt des Ausbruchs ist der aus der Caldera gebildete Tobasee.[8]


Aktuell werden Supervulkane weltweit wissenschaftlich erfasst, ihre Gesamtzahl steht allerdings noch nicht abschließend fest. Bekanntester Vertreter dieses Typus ist der Yellowstone im Yellowstone-Nationalpark. Weitere Beispiele sind die Phlegräischen Felder in Italien, der Taupō in Neuseeland und die La-Garita-Caldera im südwestlichen Colorado, USA.
Als bisher stärkster Vulkanausbruch im Quartär gilt der des Toba auf der indonesischen Insel Sumatra vor rund 74.000 Jahren, für den eine Magnitude von 8,8 errechnet wurde und der in der Folge über einen Zeitraum von etwa zehn Jahren massive weltweite Temperaturabsenkungen bewirkte. Nach der umstrittenen Toba-Katastrophentheorie des Anthropologen Stanley Ambrose soll es durch die Folgen dieses Ausbruchs zu einem „genetischen Flaschenhals“ bei den damals lebenden Hominiden gekommen sein, was die geringe genetische Vielfalt der heute lebenden Menschen erklären könnte.
Verheerende Vulkansysteme sind auch die Trapps (aus dem Skandinavischen für „Treppe“), die über längere Zeit aktiv waren und dabei geologische Hochebenen ausbildeten, die sich in Stufenform deutlich voneinander abheben. Am bekanntesten ist der „Dekkan-Trapp“, der auch mit dem Aussterben der Dinosaurier in Verbindung gebracht wird. Als größter seiner Art gilt der „Sibirische Trapp“, der mit dem Massenaussterben im Perm in Zusammenhang gebracht wird und über rund eine Million Jahre aktiv war. Der „Etendeka-Trapp“ erstreckte sich einst über die damals zusammenhängenden Kontinente von Westafrika und Südamerika.
Hoch aktiv ist auch der Altiplano–Puna-Vulkankomplex im Dreiländereck zwischen Chile, Bolivien und Argentinien mit dem aktiven Uturuncu[9], wobei vier weiteren Calderen (z. B. Vilama-Caldera) belegt sind.
Kaum erforscht ist das Lazufre-Vulkanfeld (Ojos del Salado, Cerro de Azufre Lastarria und San Román[10]), das nach der Region zwischen Lastarria und Cordón del Azufre an der Grenze zwischen Chile und Argentinien benannt ist. Die Lazufre-Region hebt sich auf einer Fläche von 1.750 km², im Zentrum um 3 Zentimeter pro Jahr.[10] Die Region ist seismisch wesentlich aktiver als zum Beispiel die Yellowstone-Region. Die  Lazufre-Region ist jedoch wissenschaftlich nur unzureichend erforscht und aufgrund der Höhe nur für Bergsteiger zugänglich.


Einer von Forschern der University of Bristol Anfang November 2017 in den Earth and Planetary Science Letters veröffentlichten Studie[11] zufolge brechen Supervulkane mit einer Explosion bzw. Eruption mindestens der Stärke Mag 8 alle 5.200 bis 48.000 Jahre aus, also ca. 10-mal häufiger als in der früher angenommenen Spanne von 45.000 bis 714.000 Jahren. Grundlage ist eine geologische Datenbank über die vergangenen 100.000 Jahre; ein letzter derartiger Ausbruch liegt demzufolge ca. 20.000 Jahre zurück.[12]


Die Daten stammen z. T. aus der Datenbank der Volcano Global Risk Identification & Analyse Project (VOGRIPA)[13] unter Angabe der Quellen, wobei die Wissenschaftler oft unterschiedlicher Auffassung sind.



Vulkan

Ort

Staat

Zeit des Ausbruchs

Tephra Ablagerung

Mag

Quellen


Vulkanexplosivitätsindex 8


San-Juan-Vulkanfeld
(La-Garita-Caldera)


Colorado

USA

27.800.000!vor etwa 27,8 Mio. Jahren

5.000 km³

9,2

Lemma


Toba (Tobasee)
(Young Toba Tuff)


Sumatra

Indonesien

74.000!vor etwa 74.000 Jahren

2.800 km³

8,8

[13]


Toba (Tobasee)
(Old Toba Tuff)


Sumatra

Indonesien

788.000!vor etwa 788.000 Jahren

820 km³

8,4

[13]


Yellowstone Caldera
(Lava Creek Eruption)


Wyoming

USA

640.000!vor etwa 640.000 Jahren

1.000 km³

8,4

[13]


Yellowstone Caldera
(Huckleberry Ridge Eruption)


Wyoming

USA

2.100.000!vor etwa 2,1 Mio. Jahren, Serie mehrerer Ausbrüche mit 1340 km³, 820 km³ und 290 km³

2.500 km³

8,8

[13]


Altiplano–Puna Vulkan Komplex (APVC)
(Vilama-Caldera)


El Tatio, Puna-Region, Anden

Chile

8.400.000!vor etwa 8,4 Mio. Jahren

2.000 km³



Lemma


Altiplano–Puna Vulkan Komplex (APVC)
(Guacha-Caldera)


Sol de Mañana, Puna-Region, Anden

Bolivien

5.700.000!vor etwa 5,6–5,8 Mio. Jahren

1.300 km³



?


Altiplano–Puna Vulkan Komplex (APVC)
(La Pacana Caldera)


Región de Antofagasta, Santa Cruz Region, Anden

Chile

3.700.000!vor etwa 3,5–3,6 Mio. Jahren

2.500 km³



?


Long Valley Caldera
(Bishop Tuff)


Kalifornien

USA

760.000!vor etwa 760.000 Jahren

1.380 km³

8,3

[13]


Taupō
(Oruanui-Ausbruch)


Nordinsel

Neuseeland

26.500!vor etwa 26.500 Jahren

1.170 km³

8,1

[13]


Taupō
(Whakamaru-Eruption)


Nordinsel

Neuseeland

254.000!vor etwa 254.000 Jahren

1.170–2.000 km³



?


Corbetti
(Awasa Caldera)


Awasasee

Äthiopien

1.000.000!vor etwa 1 Mio. Jahren

1.000 km³

8,0

[13]


Vulkanexplosivitätsindex 7


Altiplano–Puna Vulkan Komplex (APVC)
(Pastos Grandes Caldera)


Departamento Potosí, Anden

Bolivien

2.890.000!vor etwa 2,89 Mio. Jahren

820 km³



?


Yellowstone Caldera
(Mesa Fall Eruption)


Wyoming

USA

1.400.000!vor etwa 1,2 Mio. oder 1,6 Mio. Jahren

280–300 km³

7,8

[13]


Valles-Caldera
(Lower Bandelier)


New Mexico

USA

1.613.000!vor etwa 1,6 Mio. Jahren

690!690 km³

7,8

[13]


Aso
(Jigoku-Eruption)


Kyūshū

Japan



600!600 km³

7,7

[13]


Aso

Kyūshū

Japan



150!150 km³

7,2

[13]


Aso

Kyūshū

Japan



100!100 km³

7,0

[13]


Aso
(Hirose-3 Eruption)


Kyūshū

Japan



100!100 km³

7,0

[13]


Atitlán
(Los Chocoyos Asche)


Zentralamerika

Guatemala



420! 420 km³

7,8

[13]


Kapenga
(Waiotapu)


Fidschi-Insel

Fidschi



460! 460 km³

7,7

[13]


Taupō
(Reporoa-Eruption)


Nordinsel

Neuseeland

230.000!vor etwa 230.000 Jahren

340 km³



?


Taupō
(Maroa-Eruption)


Nordinsel

Neuseeland

230.000!vor etwa 230.000 Jahren

140 km³



?


Taupō
(Rotorua-Eruption)


Nordinsel

Neuseeland

220.000!vor etwa 220.000 Jahren

100 km³



?


Kos-Nisyros
(Kos-Nisyros Eruption)


Kos und Nisyros

Griechenland

161.000!vor etwa 161.000 Jahren
Trennte Kos und Nisyros, Kos-Plateau-Tuff


110 km³

7,1

[13]


Changbaishan
(Tianchi eruption)


Changbai-Gebirge

China



76–116 km³

7,4

Lemma


Changbaishan
(Oga eruption)


Changbai-Gebirge

China

448.000! vor etwa 448.000 Jahren

70–100 km³

7,0

[13]


Maipo
(Diamante Eruption)


San Carlos (Mendoza)

Chile/Argentinien

450.000!vor etwa 450.000 Jahren

450 km³

7,7

[13]


Bruneau-Jarbidge

Idaho

USA

11.000.000!vor etwa 10–12 Mio. Jahren

250!250 km³



?


Sabatini Vulkankomplex

Latium

Italien

374.000!vor etwa 374.000 Jahren

200!200 km³

7,3

[13]


Tambora

Sumbawa

Indonesien

135!1815 „Jahr ohne Sommer“

110–160 km³

7,0

Lemma


Samalas
(Ausbruch des Samalas 1257)


Lombok

Indonesien

693!1257, „Jahr ohne Sommer“

100 km³

7

Lemma


Kikai
(Akahoya Eruption)


Ōsumi-Inseln

Japan

6.300!um 4350 v. Chr.

200 km³

7,2

[13]


Corbetti
(Corbetti Caldera)


Awasasee

Äthiopien

500.000!vor 500.000 ± 60.000 Jahren

103 km³



[13]


Mount Mazama

Crater Lake, Oregon

USA

7.627!um 5677 ± 150 v. Chr. (oder 5724 ± 20 v. Chr.)

150 km³



Lemma


Kurilensee
(Ilinsky Eruption)


Kamtschatka

Russland

8.400!um 6440 ± 25 v. Chr.

155 km³

7,2

[13]


Aira

Kyūshū

Japan

28.000!vor etwa 28.000 Jahren

456 km³

7,7

[13]


Aira

Kyūshū

Japan

456.000!vor etwa 456.000 Jahren

100 km³

7,0

[13]


Santorin
(Minoische Eruption)


Kykladen

Griechenland

3.613!1613 ± 13 v. Chr.

100 km³



Lemma


Taupō
(Hatepe-Eruption)


Nordinsel

Neuseeland



85–100 km³



Lemma


Phlegräische Felder

Kampanien

Italien

39.000!vor etwa 39.000 Jahren

320 km³

7,1

[13]




Ereignis

Ort

Staat

Alter(Mio. Jahre)

Bedeckte Fläche(Mio. km²)

Lava-Volumen(Mio. km³)


Sibirien-Trapp

Putorana-Gebirge bei Norilsk, Sibirien

Russland

250!251–250

1,5–3,9

0,9–2,0


Dekkan-Trapp
(Mahabaleshwar–Rajahmundry Trapp)


Dekkan-Plateau

Indien



0,5–0,8

0,5–1,0


Etendeka-Trapp
(Serra-Geral-Formation)


Paraná-Becken und Etendeka-Plateau

Brasilien und Namibia/Angola

128! 134–128

1,5

1


Emeishan-Trapp

Emei Shan, Sichuan

China

259!263–259

0,25

0,3


[Bearbeiten | Quelltext bearbeiten]
Ilya N. Bindemann: Die Urgewalt der Supervulkane. Spektrum der Wissenschaft, S. 38–45, August 2006, ISSN 
Clive Oppenheimer: Eruptions that Shook the World. („Eruptionen, die die Welt erschütterten“), Cambridge University Press, 2011, ISBN 978-0-521-64112-8
[Bearbeiten | Quelltext bearbeiten]
Supervulkan, USA 2005

Liste von Vulkanen
Liste großer historischer Vulkanausbrüche


 Städtisches Theodolinden-Gymnasium, 4. Mai 2014, abgerufen am 8. September 2014 (englisch). 
scinexx.de:   21. November 2014
 (PDF, englisch; 992 kB)
Peter L. Ward:  In: Thin Solid Films. 517, 2009, S. 3188, doi:10.1016/j.tsf.2009.01.005. (Liste von Vulkaneruptionen mit Einfluss auf das Weltklima)
Ben G. Maso, David M. Pyle, and Clive Oppenheimer: The size and frequency of the largest explosive eruptions on Earth. In: Bulletin of Volcanology. Band 66, Nr. 8, 2004, S. 735–748, doi:. 
 bei Quarks


 Karte mit allen verlinkten Seiten: OSM | WikiMap Als vulkanischer Winter wird die Abkühlung der unteren Erdatmosphäre nach einem Vulkanausbruch bezeichnet. Asche und Schwefeldioxid (SO2), aus denen sich Aerosole aus Schwefelsäure bilden, werden bei einer größeren Eruption bis in die Stratosphäre geschleudert und verteilen sich dort wie ein Schleier über den gesamten Erdball. Die Sonnenstrahlen werden dadurch teilweise absorbiert oder zurückgestreut. In der Stratosphäre verursacht dies eine Erwärmung. Am Boden kommt es im Mittel zu einer Abkühlung des Weltklimas, regional und abhängig von der Jahreszeit kommt es gleichzeitig aber auch zu Erwärmungen. Ein dem vulkanischen Winter vergleichbarer Effekt, der durch einen Atomkrieg ausgelöst würde, wird nuklearer Winter genannt.
Erdgeschichtlich werden großflächige und länger andauernde vulkanische Aktivitäten (z. B. die Bildungen des Sibirischen Trapps, des Emeishan-Trapps und des Dekkan-Trapps) mit verschiedenen Massenaussterben in Verbindung gebracht.
Maß für die Verringerung der Strahlungsdurchlässigkeit der Atmosphäre ist der sogenannte Trübungsindex, der für den Ausbruch des Krakatau von 1883 auf 1000 festgelegt wurde. Der Trübungsindex hat nur einen geringen Zusammenhang mit dem Vulkanexplosivitätsindex. Grund hierfür sind die stark unterschiedlichen Schwefelfreisetzungen gleich explosiver Vulkanausbrüche. Die Trübungswirksamkeit der Schwefelgase ist jedoch wesentlich stärker als die der Asche, die nur in wesentlich geringerem Umfang die Stratosphäre erreicht.



[Bearbeiten | Quelltext bearbeiten]

Nach dem Ausbruch des Pinatubo mit einer Explosivität von 6 bei einer Trübung von 1000 auf der Insel Luzon im Jahr 1991 registrierten die Meteorologen einen Temperaturrückgang von durchschnittlich 0,5 K (Kelvin).[1] Der Eintrag von Aerosolen in die Stratosphäre durch den Pinatubo wurde im 20. Jahrhundert durch kein anderes Ereignis übertroffen.[2]
Folgenschwer war der Ausbruch des Tambora auf Sumbawa im Jahr 1815, der bei Stärke 7 auf dem Vulkanexplosivitätsindex (VEI) einen Trübungsindex von 3000 erreichte. Er wirkte sich durch einen Rückgang der Durchschnittstemperatur um 2,5 K aus, und in Europa gab es Frost im Juli, weshalb das Jahr 1816 auch das Jahr ohne Sommer genannt wird. Bis 1819 führte die Kälte zu Missernten und dadurch zu Auswanderungswellen von Europa nach Amerika.
Die Gründe für die Klimapessimum der „Kleinen Eiszeit“ vom Beginn des 15. bis zur 1. Hälfte des 19. Jahrhunderts sind zum Teil noch unklar, verschiedentlich wurde neben einer verringerten Sonnenaktivität und einer Abschwächung des Golfstroms eine Reihe von vulkanischen Eruptionen als Mitursache vermutet.[3]
Weltweite Wetterveränderungen mit begleitenden Missernten traten nach dem Ausbruch des Kuwae im Jahre 1453 und nach dem Ausbruch des Samalas 1257 auf.
Die dem vulkanischen Winter vergleichbare Klimaanomalie ab 536 wurde wahrscheinlich durch zwei dicht aufeinander folgende Vulkanausbrüche verursacht, von einem in hohen Breiten der Nordhemisphäre, gefolgt vier Jahre später von einer Eruption in den Tropen.[4] Bei dem tropischen Vulkan könnte es sich um den Ilopango in El Salvador gehandelt haben.[5]
Um das Jahr 10.930 v. Chr.[6] wurden innerhalb weniger Tage ca. 16 km³  vulkanischer Asche und Bims bei einer Eruption in der Vulkaneifel ausgeschleudert[7], als deren Folge die Caldera des Laacher Sees entstand. Die feineren Ablagerungen der Explosion sind noch bis nach Schweden in quartären Sedimenten als schmaler Bimshorizont (bekannt als Laacher-See-Tephra, LST) zu finden.

[Bearbeiten | Quelltext bearbeiten]
Zu einer Abkühlung um mehrere Kelvin und einer dramatischen Klimaänderung führte auch der letzte Ausbruch des Supervulkans Toba auf Sumatra während der letzten Kaltzeit vor etwa 74.000 Jahren. Nach der kontrovers diskutierten Toba-Katastrophentheorie soll sich dadurch die Population des Homo sapiens auf wenige tausend Individuen reduziert haben. Das könnte die geringe genetische Vielfalt der heutigen Menschen erklären („Genetischer Flaschenhals“ genannt). Für die jüngere Erdgeschichte seit dem Oligozän wurden bisher über vierzig Supervulkan-Ausbrüche nachgewiesen.[8]
Vor ca. 66 Millionen Jahren an der Kreide-Paläogen-Grenze (gleichzeitig Übergang vom Erdmittelalter zur Erdneuzeit) starben bis zu 75 Prozent aller Tierarten aus, darunter auch die Dinosaurier. Als Ursache kommen zwei Ereignisse in Frage: Der Einschlag eines Asteroiden (KP-Impakt; übersetzt etwa Kreide-Paläogen-Einschlag) nahe der Halbinsel Yucatán und der kontinentale Ausbruch eines Plume in der Dekkan-Trapp in Vorderindien. Die Staubaufwirbelung durch den Asteroideneinschlag entspricht ebenfalls dem eines vulkanischen Winters, eventuell verstärkt durch eine atmosphärische Schicht aus Sulfataerosolen in Verbindung mit einem globalen Dauerfrostklima über mehrere Jahre.[9]
Das Massenaussterben am Ende der Trias vor 201 Millionen Jahren führte zu einem Artenschwund von etwa 70 Prozent und betraf in erheblichem Umfang auch viele Landwirbeltiere. Ein direkter Zusammenhang mit den umfangreichen Magmafreisetzungen der Zentralatlantischen Magmatischen Provinz vor dem Auseinanderbrechen des Superkontinents Pangaea gilt in der Wissenschaft als sehr wahrscheinlich.[10]
Vor ca. 252 Millionen Jahren starben innerhalb einer Zeitspanne von maximal 30.000 Jahren 95 Prozent aller meeresbewohnenden Arten sowie ca. 66 Prozent der Landfauna aus.[11] Als Auslöser und Hauptursache für den Zusammenbruch der Ökosysteme gilt der großflächige Flutbasalt-Ausstoß des Sibirischen Trapps, der während seiner Aktivitätszyklen  eine Fläche von 7 Millionen Quadratkilometern mit magmatischen Gesteinen bedeckte. Allerdings bewirkten die Ereignisse an der Perm-Trias-Grenze und am Trias-Jura-Übergang keine globale Abkühlung, sondern führten im Gegenteil durch hohe Emissionen von Treibhausgasen zu extrem starken Erwärmungen.[12]


Das derzeit größte Gefahrenpotenzial eines vulkanischen Winters weist der Supervulkan Yellowstone im Yellowstone-Nationalpark (USA) auf. Sein Ausbruch könnte zu mehreren Jahrzehnten eiszeitartigen Klimas führen, was weltweite Missernten und Hungersnöte zur Folge hätte. Die Phlegräischen Felder in der italienischen Region Kampanien, etwa 20 km westlich des Vesuvs, gelten ebenfalls als potenzieller Supervulkan.


Vulkankatastrophen
Magmatische Großprovinz
Trübung der Atmosphäre
Impaktwinter

Keith Briffa et al.: Influence of volcanic eruptions on Northern Hemisphere summer temperature over the past 600 years. In: Nature. Band 393, 1998, S. 450–455. doi:10.1038/30943
M. R. Rampino, S. Self, R. B. Stothers: Volcanic Winters. In: Annual Review of Earth and Planetary Sciences. Band 16, 1988, S. 73–99. doi:10.1146/annurev.ea.16.050188.000445
William J. Humphreys: Volcanic dust and other factors in the production of climatic changes, and their possible relation to ice gases. In: Journal of the Franklin Institute. 1913, S. 131–172.

 (Memento vom 14. Oktober 2006 im Internet Archive) In: Jahresbericht 2002. des Max-Planck-Instituts für Meteorologie.
H. Graf: Klimaänderungen durch Vulkane. In: promet – Meteorologische Fortbildung. 28. Jahrgang, Heft 3/4, 2002 (; 1,8 MB).



Als Gletscherlauf (veraltet: Gletscherseeausbrüche) bezeichnet man das plötzliche durch natürliche Vorgänge hervorgerufene Entleeren eines unter einem Gletscher befindlichen Sees in Form von Flutwellen.



Der Begriff Gletscherlauf ist eine wörtliche Übersetzung des isländischen Begriffs jökulhlaup. Isl. jökull bedeutet im Deutschen Gletscher[1], isl. hlaup bedeutet Lauf; Gerinnsel[2][3]. Dieser Begriff ist in Island sehr geläufig, da man v. a. im Süden des Landes zahlreiche, oft katastrophale Gletscherläufe erlebt hat, die dort von unter Gletschern gelegenen Vulkanen ausgelöst wurden.


[Bearbeiten | Quelltext bearbeiten]
In vulkanischen Gegenden entstehen Gletscherläufe entweder durch stetiges Auftauen des Gletschers über einem Hochtemperaturgebiet oder wenn ein von einem Gletscher bedeckter Vulkan ausbricht.
Unter Gletschern gelegene Hochtemperaturgebiete schmelzen kontinuierlich den über ihnen befindlichen Gletscher ab. Das Wasser sammelt sich in Becken oder auch in Blasenform an. Wenn sein Volumen eine bestimmte Grenze übersteigt, durchbricht es die Eisbarriere davor und eine meist nicht sehr bedeutende Flutwelle ergießt sich in regelmäßigen Abständen durch niedriggelegene Täler bis ins Meer, z. B. etwa alle 2 bis 3 Jahre im Fluss Skaftá in Island,[4] wobei etwa Flussraten von 2.000 bis 5.000 m³/s produziert werden, ebenso wie von regelmäßigen Auftauvorgängen über dem Geothermalgebiet der Grímsvötn alle 4 bis 5 Jahre.[5]
Viel bedeutender und unberechenbarer sind dagegen die durch Vulkanausbrüche entstandenen Gletscherläufe.
Durch die Wärme des Ausbruches schmilzt ein Teil der Eiskappe über dem Vulkan. Das Wasser sammelt sich oftmals in einem See unter der nun dünneren Eisdecke. Durchbricht die aus Wasser, Eisstücken diverser Größenordnung und Sedimenten bestehende Flutwelle die vorgelagerte Eisbarriere, entleert sich der See in kurzer Zeit und die Fluten ergießen sich über tiefer gelegene Täler und Ebenen ins Meer.
Das Gletscherwasser läuft dabei durch Tunnel unter der Eisdecke ab oder es verteilt sich unter dem Eis auf bedeutendere Flächen, bis es dann an den Rändern des Gletschers ins Freie tritt. Der genaue Verlauf wird mit beeinflusst durch Faktoren wie Eisdicke, Hangneigung und Wassertemperatur.[6]
Das Phänomen ähnelt den Laharen bei nicht von Eis bedeckten Oberflächen von Vulkanen.

[Bearbeiten | Quelltext bearbeiten]
Der Begriff wird auch für andere Überflutungsereignisse, die im Zusammenhang mit Gletschern stehen, verwendet, etwa wenn eine Endmoräne den aufgestauten Wassermassen nicht mehr standhält, oder wenn das Eis das Entleeren eines an den Gletscher angrenzenden Sees verhindert und durch den Wasserdruck bricht.[7]
Ein Beispiel wäre etwa der 2002 erfolgte Bruch des Hubbard-Gletschers, der den Russell-Fjord von der Disenchantment Bay abgeschnitten hatte. Dies war der bis dahin zweitgrößte von Menschen dokumentierte Gletscherlauf.[8] Ein weiteres Beispiel sind die regelmäßigen Entleerungen der Gletscherseen am Tulsequah-Gletschers in British Columbia, Kanada.[9]



[Bearbeiten | Quelltext bearbeiten]
Der letzte große Gletscherlauf ereignete sich 1996 am Fluss Skeiðará wegen eines Ausbruchs im Vulkansystem der Grímsvötn. Der 10 km vom Zentralvulkan entfernte Vulkan Gjálp war im Oktober ausgebrochen und hatte viel Eis geschmolzen. Das Schmelzwasser floss in die unterhalb gelegenen subglazialen Seen Grímsvötn, die sich über dem Zentralvulkan selbst befinden.
Man hatte den Wasserstand der Grímsvötn-Seen genau gemessen und so konnte man den Zeitpunkt der Flutung darunter gelegener Ebenen relativ genau voraussagen. Die über diese Ebenen verlaufende südliche Ost-West-Verkehrsverbindung, die Ringstraße 1, konnte rechtzeitig gesperrt werden, so dass keine Menschen zu Schaden kamen. Der Gletscherlauf von 1996 erreichte immerhin eine Flussrate von bis zu 45.000 m³ Wasser pro Sekunde (das ist mehr als der durchschnittliche Abfluss des zweitwasserreichsten Flusses der Erde, dem Kongo) und riss Teile der Ringstraße sowie eine Brücke mit sich fort. Bis zu 10 m hohe Eisblöcke wurden mittransportiert und lagen nach dem Ende des Gletscherlaufes in der Sanderebene Skeiðarársandur.[10]
Ebenfalls für seine Gletscherläufe bekannt ist der im äußersten Süden Islands gelegene Gletscher Mýrdalsjökull mit dem darunter befindlichen Vulkan Katla.[11] Er wird kontinuierlich überwacht.[12]

[Bearbeiten | Quelltext bearbeiten]
In allen Gegenden, wo Vulkanismus und Gletscher aufeinandertreffen, gibt es auch die Gefahr von Gletscherläufen, z. B. auch in Alaska, Neuseeland, Chile, auf der Kamtschatka-Halbinsel usw.


[Bearbeiten | Quelltext bearbeiten]
 (englisch)

[Bearbeiten | Quelltext bearbeiten]
  (englisch)
 Paper,  (PDF) (englisch)
V. Manville, e.a.: , The Geological Society of America Bulletin, v. 111, no. 10, S. 1435–1447; doi: (Ähnliches Ereignis: Flut aus einem Calderensee und Eruptionen von Lake Taupo, Neuseeland) (englisch)
 (PDF-Datei; 402 kB) (englisch)
 (PDF-Datei) (englisch)
 (PDF-Datei; 5,9 MB) (isländisch/englisch)
 Spektrum, 18. November 2020.
[Bearbeiten | Quelltext bearbeiten]
 (englisch)
, Skaftárhlaup 2015, RÚV vom 4. Oktober 2015 (isländisch)
 (unten)


Ein Lahar ist ein Schlamm- und Schuttstrom, der von einem Vulkan ausgeht. Das Wort kommt aus dem Javanischen. Dabei mischt sich eruptives Material aus zum Teil metergroßen Blöcken mit Lockersedimenten und Wasser. Je nach Geländeneigung können Lahars durch die Schwerkraft eine Geschwindigkeit bis zu 100 km/h erreichen, über 100 km weit fließen und große Gebiete überschwemmen. Sie können durch einen Vulkanausbruch ausgelöst werden, aber auch völlig unabhängig davon entstehen. Je nach Art ihrer Entstehung können Lahars bis zu 100 °C heiß sein.



Die Definition ist in der Literatur nicht ganz einheitlich. Die Encyclopedia of Volcanoes beschränkt den Begriff auf Schlammströme im weiteren Sinne, die einen Sedimentanteil zwischen 20 % und 90 % haben und von einem Vulkan ausgehen. Das entspricht in sedimentologischen Begriffen einem Debris Flow (Sedimentanteil ca. 50–60 % bis ca. 90 %) und einem hyperkonzentrierten Strom (Sedimentanteil zwischen 20 % und 50–60 %). Schlammströme mit niedrigeren Sedimentkonzentrationen transportieren Sediment wie Flüsse, entweder in Suspension oder als Bodentransport. Die Encyclopedia of Volcanoes empfiehlt zudem, den Begriff Lahar auf den Prozess zu beschränken und nicht auf die Ablagerung anzuwenden, obwohl der Begriff in der Literatur inzwischen auch zum Teil auf die Ablagerungen ausgedehnt worden ist („fossile Lahars“).



Lahars können bei oder kurz nach einem Vulkanausbruch entstehen. Sie können aber auch völlig unabhängig von einem Vulkanausbruch ausgelöst werden.
Voraussetzung für die Entstehung von Lahars sind:

ein großes Wasserreservoir in Form von Schnee, Eis oder sonstigen Gewässern
große Mengen unverfestigten Materials, z. B. pyroklastische Strom- oder Fall-Ablagerungen, glaziale Ablagerungen, Böden oder Kolluvium
steile Hänge und gewisses Relief des Liefergebietes
ein Auslöser, der die richtige Mischung (siehe oben) für einen Lahar produziert
Typische Auslösemechanismen:

Vulkanische Aktivität oberhalb der Schneegrenze. Schnee und Eis werden schnell aufgeschmolzen (siehe auch Gletscherlauf) und mischen sich mit Lockersedimenten. Dieser Prozess kann sehr große Lahars auslösen.
Tauwetter
Starke Regenfälle, die auf vulkanisches Lockersediment treffen. Starkregen sind infolge von Eruptionsgewittern häufige Begleiter des Vulkanismus, wenn viel Wasserdampf aus der glutflüssigen Schmelze freigesetzt wird, in der schon wasserhaltigen Erdatmosphäre aufsteigt, abkühlt und um die feinsten Aschepartikel kondensiert. Meist werden hierdurch nur kleinere, aber zahlreiche Lahars ausgelöst.
Infolge vulkanischer Aktivität können Seen, die zuvor durch vulkanische Ablagerungen aufgestaut wurden, durch den Bruch dieser natürlichen Dämme plötzlich in tieferliegendes Gebiet abfließen. Auch dieser Mechanismus kann sehr große Lahars produzieren.
Kollaps-induzierte Lahars. Durch die Instabilität von vulkanischen Lockermassen können Hänge oder kleinere Teile eines Vulkangebäudes kollabieren. Enthält das Sediment genügend Porenwasser, kann dieses das Sediment verflüssigen. Flache Intrusionen von Magma in ein Vulkangebäude sind hierbei die häufigsten Ursachen. Meist werden dadurch aber nur kleinere Lahars ausgelöst.

Lahars können auf ihrem Weg talwärts stark erosiv wirken, vor allem in vulkanischen Lockermassen. Dabei werden Böschungen unterspült und Hänge untergraben, auch können sekundär kleinere Erdrutsche ausgelöst werden. Generell ist die Erosion umso höher, je mehr Wasser die Schlammströme enthalten. Entscheidend für die Erosion ist jedoch, dass in kurzer Zeit sehr große Mengen Wasser bzw. eines Schlamm/Wasser-Gemischs abfließen. Eine Flutwelle erodiert stärker als ein kontinuierliches Abfließen.



Flutströme, also Wasserströme mit weniger als 20 % Sedimentführung, die von Vulkanen ausgehen, können sich durch Aufnahme von Sediment auch zu Lahars verändern. Dies verlangsamt die Fließgeschwindigkeit, kommt aber eher selten vor. Lahars können auch durch die weitere Aufnahme von Wasser „verdünnt“ und damit zu „normalen“ Flutströmen werden. Meist aber nehmen Lahars Sediment und Wasser auf und verändern sich bis zur Ablagerung in ihrem Fließverhalten nicht wesentlich. Beim Abfließen „sammeln“ Lahars buchstäblich alles auf, was auf ihrem Weg liegt.


Während die direkte Umgebung von Vulkanen, die am meisten von Ausbrüchen bedroht ist, in der Regel ohne Besiedlung bleibt, ist die weitere Umgebung der Vulkane wegen der fruchtbaren Böden oft dicht besiedelt. Die Bedrohung durch die Vulkane wird dort als gering eingeschätzt. Lahars haben deshalb vor allem durch ihre weite Fließreichweite ein beträchtliches Zerstörungspotential.

Am 24. Dezember 1953 ereignete sich Neuseelands schwerstes Eisenbahnunglück, als ein Lahar eine Eisenbahnbrücke bei Tangiwai wegschwemmte. Kurz nach dem Einsturz erreichte der Nachtzug Wellington-Auckland die Stelle und stürzte in den Schlammstrom. 151 Menschen kamen ums Leben, viele der Opfer wurden niemals gefunden.
In den südlichen Anden Chiles grub ein Lahar des Vulkans Villarrica (2847 m) am 29. Dezember 1971 noch in einer Entfernung von 14 km eine Fließrinne, die an ihrer Oberkante 128 m breit und 8 m tief war.
Ein Lahar beim Ausbruch des Mount St. Helens im Süden des Bundesstaates Washington in den USA am 18. Mai 1980 trug zum Ausmaß der verheerenden Katastrophe bei.
Am 13. November 1985 verursachte ein Lahar des Vulkans Nevado del Ruiz in Kolumbien die zweitgrößte Zahl von Todesopfern durch einen Vulkanausbruch im 20. Jahrhundert. Der bis zu 5 m hohe Schlammstrom erreichte die 47 km entfernte Stadt Armero etwa zweieinhalb Stunden nach dem Ausbruch und kostete zwei Drittel der 28.700 Einwohner das Leben.
Im März 2007 ergoss sich wie 1953 ein Lahar vom neuseeländischen Vulkan Ruapehu. Menschenleben waren diesmal nicht zu beklagen, da die Behörden entlang des Flusses Whangaehu rechtzeitig Maßnahmen getroffen hatten.

Die Ablagerungen eines Lahars unterscheiden sich in den Sedimentstrukturen nicht von denen eines Debris Flow und eines hyperkonzentrierten Stroms. Es entstehen je nach Ausgangszusammensetzung Debrite, Diamiktite, Parakonglomerate und Brekzien. Sie unterscheiden sich von „normalen“ Schutt- und Schlammströmen im Grunde nur durch das vulkanogene Material, aus dem sie überwiegend bestehen. Es gibt Übergänge zu „normalen“ Schlammströmen.
Durch die plötzliche Bedeckung mit Schlammmassen können unter Umständen auch viele Lebewesen fossilisiert werden. Es kann eine Fossillagerstätte entstehen.



Vor ungefähr 5600 Jahren entstand am Mount Rainier im US-Bundesstaat Washington ein riesiger Lahar. Das Volumen wurde auf etwa 3,8 km³ berechnet. Er verfüllte Täler mit bis zu 200 m Sediment, legte eine Strecke bis zu 120 km zurück und floss noch 20 km unter Wasser am Grund des Puget Sound weiter.
An den Monts Dore in der französischen Auvergne legte ein Lahar im Tertiär mehr als 30 km zurück.


Hans Füchtbauer: Sedimente und Sedimentgesteine, Teil 2. In: Sediment-Petrologie. 4., gänzlich neubearbeite Auflage, Schweizerbart, Stuttgart 1988, ISBN 3-510-65138-3.
Christopher G. Newhall, Raymundo S. Punongbayan (Hrsg.): Fire and Mud. Eruptions and Lahars of Mount Pinatubo, Philippines. University of Washington Press, Seattle 1997, ISBN 0-295-97585-7
Haraldur Sigurðsson, Bruce F. Houghton et al. (Hrsg.): Encyclopedia of Volcanoes. Academic Press, San Diego 2000, ISBN 0-12-643140-X



[Bearbeiten | Quelltext bearbeiten]
 (englisch)
 (englisch)
[Bearbeiten | Quelltext bearbeiten]
 (englisch, mit Fotos)
Eine Massenbewegung, Hangbewegung oder Rutschung ist ein geomorphologischer Prozess, bei dem eine gewisse Masse an Böden, Regolith und Felsen samt darauf stehenden Lasten unter dem Einfluss der Gravitation durch die antreibende Wirkung einer Komponente der Schwerkraft hangabwärts in Bewegung kommt. Typisch ist das Auftreten einer Gleitebene zwischen ruhend bleibendem Untergrund und darüber sich abgleitend bewegenden Massen. Start und Erhalt der Bewegung erfolgt unter Überwindung von Kohäsion, Reibungskraft und Strömungswiderstand.
Feste Barrieren, geringer werdendes Gefälle, das Erreichen einer Ebene oder Gegenhangs bremsen den Vorgang vorne. Je nach Geschwindigkeit – proportional zur Bewegungsenergie – kann die Massenträgheit ein Zusammenschieben und Übereinanderlaufen der Massen bewirken. Am Ende des Abklingvorgangs kann die aktuelle Gleitfläche im Material höhersteigen und in Bewegungsrichtung zuletzt sogar bergauf verlaufen.
Massenbewegungen können in Form von Kriechen, Gleiten, Fließen, Schießen, Kippen oder Fallen auftreten – jeweils mit ihren eigenen charakteristischen Eigenschaften – und können in ihrem Ablauf zwischen Sekunden und Jahren dauern. Massenbewegungen finden sowohl an der Landoberfläche als auch in submarinem Terrain statt und wurden außer auf der Erde auch auf dem Mars und der Venus beobachtet.




Wenn die Gravitationskraft auf einen Hang einwirkt und die Reibungskraft überschreitet, kommt es zur Massenbewegung. Die Festigkeit und Kohäsion des Hangmaterials und die Höhe der internen Reibung helfen, die Hangstabilität aufrechtzuerhalten. Man spricht in diesem Zusammenhang auch von der Scherkraft. Der steilste Winkel, den ein kohäsionsloser Hang aufweisen kann, ohne seine Stabilität zu verlieren, wird als Reibungswinkel bezeichnet. Besitzt ein Hang diesen Winkel, hält die Scherkraft die einwirkende Gravitation genau im Gleichgewicht.
Massenbewegungen können sehr langsam ablaufen, insbesondere in Gebieten, die sehr trocken sind oder in denen ausreichend Niederschlag gefallen ist, sodass sich eine stabilisierende Vegetationsdecke bilden konnte. Sie können aber auch mit einer sehr hohen Geschwindigkeit ablaufen, in Form von Felsstürzen oder Erdrutschen etwa, die verheerende Konsequenzen haben können, welche entweder sofort oder verzögert auftreten (etwa in Form eines Abdämmungssees).
Faktoren, die das Potential von Massenbewegungen verändern können, sind: Änderung der Hangneigung, Schwächung des Materials durch Verwitterung, Erhöhung des Wasseranteils, Veränderung der Vegetationsbedeckung.




Massenbewegung gehört zu den Prozessen der flächenhaften Erosion (Denudation). Hinsichtlich ihrer Dynamik können verschiedene Typen von Massenbewegung unterschieden werden:

Sturzdenudation und Rutschungen haben eine hohe Geschwindigkeit. Die Massenbewegungen finden entweder durch Stürzen, Gleiten, Fließen oder Kriechen statt. Dementsprechend werden verschiedene schnelle Massenbewegungen unterschieden:
Stürzen
Steinschlag, Blocksturz
Felssturz
Bergsturz
Gleiten
Slump (Rotations-Block-Rutschung)
Erdrutsch, Bergrutsch
vulkanische Trümmerlawine
Fließen
Schuttstrom:
Murgang, Mure, Rüfe
Lahar, Schlammstrom in vulkanischen Ablagerungen
Körnerstrom (grain flow): Sandrutschung u. a.
Solifluktion (Bodenfließen)
Kriechen
Bodenkriechen, unter anderem mit der Bildung von Plaiken
Hangkriechen, beispielsweise ein Talzuschub
Bewegung von Schutt- und Blockhalden
Blockgletscher
Kriechdenudation ist eine sehr langsame Hangabwärtsbewegung von Lockermaterial. Kriechvorgänge können als kontinuierliche Bewegung, durch das fortlaufende Versetzen des Materials aufgrund von Expansions- und Kontraktionsvorgängen von Ton und Wasser oder durch Regen induziertes Splash-Kriechen ausgelöst werden.
Sedimentationsfolgen, geologisch betrachtet:

Turbidit (im Wasser)
Lamina (Feinstschichtungen)



Wasser kann die Stabilität eines Hanges vergrößern oder verringern, abhängig von der vorhandenen Wassermenge. Geringe Mengen von Wasser können aufgrund der Oberflächenspannung des Wassers Böden stärken, da dem Boden so eine erhöhte Kohäsion zukommt. Dies erlaubt dem Boden, erosionsresistenter zu sein, als wenn er trocken wäre.
Ist jedoch zu viel Wasser vorhanden, fungiert es als eine Art Gleitmittel und beschleunigt somit Erosionsprozesse, die in verschiedenen Arten von Massenbewegungen resultieren (z. B. Muren, Erdrutsche,…). Gut vorstellen kann man sich dies, wenn man an eine Sandburg denkt. Der Sand muss mit Wasser vermischt werden, um seine Form zu halten. Fügt man dem Sand zu viel Wasser hinzu, rinnt der Sand davon; verwendet man zu wenig Wasser, fällt der Sandhaufen zusammen, da er nicht in Form gehalten werden kann.
Bei Rutschungen unter Wasser kann Energie aus der Rutschung in einen Tsunami übergehen, wie es z. B. für den Neufundlandbank-Tsunami von 1929 festgestellt wurde.


Böden und Regolith verweilen auf einem Hang, solange die Gravitationskraft nicht die Reibungskraft übersteigt, die das Material an Ort und Stelle hält. Faktoren, die diesen Reibungswiderstand verringern, können sein:

seismische Aktivität
Überlastung durch Bebauung
erhöhter Anteil an Bodenfeuchte
Verringerung der Wurzeldichte, welche die Erde im Untergrund festhält
Verwitterung durch Frosthebung
Bioturbation
submarine Gashydrate

Trümmerlawine
Sackung
Murgang
Lahar
Rutschhang
Bergzerreißung
Schuttstrom
Bodenfließen
Setzungsfließen


 im Katalog der Deutschen Nationalbibliothek
 Landesamt für Geologie und Bergbau Rheinland-Pfalz; abgerufen am 20. Februar 2022 

Monroe, Wicander: The Changing Earth: Exploring Geology and Evolution. Thomson Brooks/Cole, 2005, ISBN 0-495-01020-0. 
M. J. Selby: Hillslope Materials and Processes, 2e. Oxford University Press, 1993, ISBN 0-19-874183-9. 
A. H. Strahler und A. N. Strahler: Physische Geographie. 3. Auflage. UTB, Stuttgart, 2005, ISBN 3-8252-8159-0.
Sebastian Krastel: Submarine Hangrutschungen: eine (unterschätzte) Naturgefahr? IFM Geomar, Leibniz-Institut für Meereswissenschaften an der Universität Kiel, 15. März 2011, 



Dieser Artikel erläutert das Sturzereignis. Siehe auch: Steinschlag (Sachschaden) bzw. Steinschlagspitze.



Unter Steinschlag versteht man meist den Niedergang von Steinen an einem Hang oder einer Felswand.
Steinschlag kann unterschiedliche Ursachen haben:

Erosion und Verwitterung
Regenwasser oder Schmelzwasser kann Gestein bewegen
Durch Tiere, unachtsame Wanderer oder Kletterer können Steine losgetreten werden
Wenn größere zusammenhängende Felspartien abbrechen, spricht man nicht mehr von Steinschlag, sondern von einem Felssturz. Einen umfangreicheren, meist rutschenden und eher lawinenähnlichen Abgang von Fels und Erdmassen bezeichnet man hingegen als Erdrutsch oder Bergrutsch.



Steinschlag ist eine Form der geodynamischen Massenbewegung (Geologie).
Grund für Steinschlag ist, neben Sekundärwirkungen anderer Bewegungen, im Allgemeinen Frostsprengung. Aber auch zuvor frostgebundene Steine können bei Temperaturen oberhalb des Gefrierpunktes in Bewegung geraten. Daher bergen sowohl die ersten Stunden der Abkühlung durch Beschattung (Nachmittagsstunden im Winterhalbjahr und Höhenlagen), wie auch die ersten Stunden der Erwärmung durch Sonneneinstrahlung (Vormittagsstunden im Sommerhalbjahr) besonderes Steinschlagrisiko.



Auch Verkehrswege in Bergregionen können von Steinschlag betroffen sein. In diesem Fall muss der Benutzer damit rechnen, dass mehr oder weniger große Steine im Weg liegen, die unter Umständen ein gefährliches Hindernis darstellen können. Straßen sind daher in solchen Fällen mit dem Gefahrenzeichen Achtung Steinschlag gekennzeichnet.
Sowohl „natürlicher“ als auch vom Menschen verursachter Steinschlag stellt ein erhebliches Risiko im Alpinismus dar. Auch wenn Felsbeschaffenheit (brüchiger Stein), Witterung (Regen, Tauwetter), Tageszeit, Himmelsrichtung (durch Sonneneinstrahlung verursachte Erwärmung) und die lokale Geländegliederung (Schluchten, Rinnen) Rückschlüsse auf das Ausmaß der Steinschlaggefahr zulassen, zählt Steinschlag zu den großen, oftmals unberechenbaren Gefahren im Bergsport. In steinschlaggefährdeten Gebieten sind Steinschlaghelme dringend angeraten.


Erdrutsch
Lawine
Mure
Bergsturz

 Johannes-Gutenberg-Universität Mainz, August 2004, abgerufen am 11. Januar 2010, urn:
 der Eidgenössischen Forschungsanstalt WSL (Wald – Schnee – Landschaft), Birmensdorf, Schweiz, abgerufen am 10. November 2013

 im Katalog der Deutschen Nationalbibliothek




Im folgenden Absatz fehlen noch folgende wichtige Informationen: Bezeichnung der physischen Erscheinungsformen der Erdrutsche, Bezeichnungen der entstandenen Morphologien. Hilf der Wikipedia, indem du sie recherchierst und einfügst.


Ein Erdrutsch ist das Abgleiten größerer Erd- und Gesteinsmassen, meistens ausgelöst durch starke Niederschläge (langandauernder Regen oder Starkregen) und das dadurch bedingte Eindringen von Wasser zwischen vorher gebundene Bodenschichten. Durch die Schwerkraft und die Verminderung der Haftreibung zwischen den Bodenschichten rutscht der Hang (bei ausreichend großer Hangneigung) ab. Ein großer Erdrutsch wird auch Bergrutsch genannt; wenn kleine Flächen betroffen sind, auch Hangrutsch oder Hangrutschung.
Ein Erdrutsch unterscheidet sich vom Bergsturz durch die geringere Geschwindigkeit.





Die häufigste Ursache ist, dass der Erdboden am Hang zu große Mengen an Wasser, beispielsweise infolge heftiger Gewitterregen oder durch Schneeschmelze, aufgenommen hat. Wegen zu geringer innerer Haftreibung folgt daraus ein Verlust der Stabilität entlang einer sich ausbildenden Gleitfuge.
Andere mögliche Ursachen sind:

Erdbeben
ganz allgemein tektonische Bewegungen
Erosion durch Wind und Frost
Starke Abholzung des bestehenden Waldes (Absterben und Verrottung von den Boden stabilisierenden Wurzeln)
Auftauen des Permafrostbodens im Hochgebirge oder von Methanhydrat (Storegga-Effekt) an Kontinentalhängen wegen der Klimaerwärmung
Schädigung des Erdbodens durch ausgedehnten Bergbau
Das Risiko eines Erdrutsches ist abhängig von:

der Wasserdurchlässigkeit und Wasseraufnahmefähigkeit der Bodenschichten,
dem Gefälle des Geländes,
dem Vorhandensein oder Fehlen einer schützenden Vegetation, deren Durchwurzelung die Bodenkrume zusammenhält,
dem Vorhandensein rutschiger Grenzflächen, beispielsweise entlang von Tonschichten.

Ein Erdrutsch bewegt sich meist in komplexer, rotierender Bewegung nach unten. Je nach Entstehungsort können auch Bäume, Eis- oder Schneemassen oder Bestandteile menschlicher Bauwerke zum Materialstrom beitragen.
Besondere Formen des Erdrutsches sind:

Der Erdschlipf oder die Rutschung, bei der Erdmaterial entlang einer Schwächezone als Block abrutscht
Die Sackung oder Rotationsrutschung, bei der ein Bodenkörper in einer kreisförmigen Bahn um eine zum Hang orthogonale Achse abgleitet
Die Hangmure, bei der als Folge von starken Niederschlägen Wasser gesättigtes Erdmaterial spontan abrutscht und in Form eines Murgangs relativ weite Strecken zurücklegt
Der Schuttstrom, bei dem Wasser und Schutt plötzlich und kanalisiert (z. B. in einem Bachbett) freigesetzt werden (Murgang)



Typ

Datum

Ort

Ursache / Auslöser

Schäden


Erdrutsch

1920

Gansu, China

Erdbeben

Beim Erdbeben von Gansu gab es insgesamt mehr als 200.000 Tote


Erdrutsch

22. April 1980

Thanheimer Steige am Albtrauf zwischen Bisingen und Albstadt-Onstmettingen, Baden-Württemberg, Deutschland



Durch das Zusammentreffen von Schneeschmelze und starken Regenfällen zerstörte ein starker Erdrutsch auf einer Fläche von rund 16 Hektar den kompletten Straßenverlauf. Der Albaufstieg musste über drei Jahre gesperrt und vollständig erneuert werden.


Steinrutschung

12. April 1983

am „Hirschkopf“ am Albtrauf bei Mössingen, Baden-Württemberg, Deutschland



Auf einer Fläche von rund 50 Hektar brachen fünf bis sechs Millionen Kubikmeter Gestein ab und rutschten samt Wald und Waldweg in die Tiefe, ein Vorgang, der schon seit Jahrtausenden den Trauf der Schwäbischen Alb, der einstmals bis in die Nähe von Stuttgart reichte, immer weiter zurückweichen lässt.


Bergrutsch

Abend des 11. Dezember 2004[1]

Steinbruch Steinbergen, Steinbergen, Niedersachsen, Deutschland

Ein etwa 300 m langer und bis zu 50 m breiter keilförmiger Block rutschte aus dem Kamm des Messingberges (Wesergebirge/Niedersachsen) nach Norden ab.

Felsmassen in der Größenordnung von ca. einer Million Tonnen stürzten lawinenartig bis zu 300 m weit in den vorgelagerten Steinbruch. Tiefe Risse und Spalten haben sich auch auf der Südseite des Berges gebildet. Weitere Klippenformationen (Mönch und Nonne), die den Kamm bilden, sind gefährdet ebenso abzurutschen. Negative Auswirkungen auf wertvolle Wald- und Naturbereiche dieses touristisch genutzten Erholungsraumes im Weserbergland sind zu erwarten.


Erdrutsch

Morgen des 18. Juli 2009 gegen ca. 4:40 Uhr

Concordiasee im Harzvorland in Sachsen-Anhalt



Ein etwa 350 mal 150 Meter breiter Landstreifen rutschte in den entstehenden See beim großen Erdrutsch am Concordiasee.


Erdrutsch

22. November 2015

Kachin-Staat, Myanmar

Raubbau – statische Mängel einer Abraumhalde

Bei einem Erdrutsch der Abraumhalde einer Jade-Mine Norden Myanmars kamen 114 Menschen ums Leben. Ein circa 300 Meter hoher Abraumhügel rutschte ab und begrub knapp 50 Häuser. Der Großteil der Toten waren Dorfbewohner, welche die riesige Halde der Jade-Mine durchsuchten.[2]


Erdrutsch

20. Dezember 2015

Shenzhen, Gewerbegebiet Neu-Guangming, China

Anhaltende Regenfälle

Aus einem künstlichen ca. 100 Meter hohen Abfallberg löste sich eine Schlammlawine, die eine Fläche von über 380.000 Quadratmetern bedeckte; über 85 Menschen wurden seither vermisst.


Erdrutsch

25. Dezember 2015

Kachin-Staat, Myanmar

Raubbau – Statische Mängel einer Abraumhalde

Nach dem schweren Erdrutsch des Abraumhügels einer Jade-Mine am 22. November 2015 kamen bei einem weiteren Erdrutsch mindestens 50 Menschen ums Leben.[3]


Erdrutsch

16. Mai 2015

Salgar, Kolumbien

Anhaltende Regenfälle

Nach einem Erdrutsch mit Schlammlawine und Überschwemmung starben 58 Menschen, weitere 37 Personen wurden verletzt. Bei einem gleichgelagerten Erdrutsch im Jahre 1966 kamen in Salgar über 100 Menschen ums Leben.[4][5]


Erdrutsch

24. Juni 2017

Xinmo, Diexi, Sichuan, China

Anhaltende Regenfälle

Nach einem Erdrutsch mit Schlammlawine und Überschwemmung wurden alle 62 Häuser des Dorfes Xinmo verschüttet. Stand 26. Juni 2017 wurden 15 Leichen geborgen und weitere 118 Menschen vermisst.[6][7]



Hangrutschungen lassen sich kaum verhindern, aber bei nicht allzu großen Erdmassen oder langsamer Bewegung in ihrer Wirkung mildern. Wichtigster Punkt dabei ist, das Wasser aus dem Hang zu entfernen. Dabei gibt es unterschiedliche Maßnahmen, unter anderem:

Einbauen von Drainagen, entweder oberflächenhaft oder tief in den Untergrund hinein (z. B. Drainageanker);
vorbeugende Einbauten in den gefährdeten Untergrund – analog zur Wildbach- und Lawinenverbauung;
kurzfristige Stabilisierung bewegter Hänge durch Beton- und Stahlbewehrung (z. B. Panzerigel);
bei kleinen Ausmaßen auch Stabilisierung durch Sandsäcke;
großflächiges Abdecken kritischer Hangbereiche durch Planen, um weiteres Eindringen von Regenwasser zu verhindern.
Ein Schutzwald bietet häufig eine wirksame Sicherung. Die Wurzeln der Bäume verfestigen den Boden und regulieren den Wasserhaushalt (siehe auch Durchwurzelung).
Auch Rasensaaten stabilisieren den Hang mit ihren feinen und stark verzweigten Wurzeln.
Abflachen des Hangs.
Diese Maßnahmen sind jedoch machtlos gegen Erdrutsche, bei denen sich Millionen Kubikmeter Erde lösen. Die beste Maßnahme gegen diese Erdrutsche ist die Vorbeugung.

Verbote hindern Menschen daran, in gefährdeten Gebieten zu siedeln.
Aufmerksamkeit kann eine Vorwarnzeit bis zum tatsächlichen Erdrutsch gewährleisten und eine rechtzeitige Evakuierung ermöglichen.

Ein Erdrutsch ist eine häufig vorkommende, aber in der Regel lokale Naturkatastrophe. Auf das betroffene Ökosystem wirkt er als Störung und öffnet Rohboden für die Wiederbesiedelung sowie einen Neustart der Sukzession.
Erdrutsche im Meer oder in Seen, insbesondere von oberhalb des Wasserspiegels in diese Gewässer hinein, können dagegen Tsunamis auslösen und dadurch auch in größerer Entfernung Zerstörungen verursachen. Bei entsprechender Größe des Erdrutsches kann die Flutwelle an benachbarten Küstenhängen Höhen von mehreren hundert Metern erreichen (Megatsunami).[8]
Vor den Inseln Hawaiis befinden sich große Schuttfächer, die durch Flankenabbrüche der Vulkane entstanden sind. Flankenabbrüche mit gefährlichen Tsunamis gibt es dort nach Schätzungen von Wissenschaftlern etwa alle 100.000 Jahre.[9]
Erdrutsche mit Tsunamis sind in der Liste von Tsunamis, andere sind in der Liste von Lawinen und Erdrutschen, Bergstürzen angegeben.


Liste von Rutschungen im Bergbau

Massenbewegung (Geologie)

Kyoji Sassa, Badaoui Rouhban, Sálvano Briceño (Hrsg.): Landslides : global risk preparedness. Springer, Berlin/Heidelberg 2013, ISBN 978-3-642-22086-9.



 im Katalog der Deutschen Nationalbibliothek

, Geowissenschaften-Portal planeterde
, hitec (3sat) vom 12. April 2010


Informationsplattform zum Umgang mit Naturgefahren in der Schweiz: 



Ein Bergsturz ist eine großvolumige, schnell vonstattengehende Fels- und Schuttbewegung aus steilen Bergflanken. Auch stabil erscheinende Felswände können betroffen sein, wenn sie von Klüften durchzogen sind. Bei Bergstürzen verhält sich das Gestein großräumig „wasserähnlich“, kann auf einer geneigten Gleitbahn eine Geschwindigkeit von über 100 km/h erreichen und sogar an gegenüberliegenden Hängen „aufbranden“, wie beispielsweise im Oberinntal mehrfach zu sehen ist.
Die Untersuchung von Bergstürzen und ihrer Ursachen ist ein interdisziplinäres Thema zwischen mehreren Fachgebieten, v. a. Geologie, Felsmechanik, Ingenieurvermessung und Geomorphologie, während zugehörige Warnsysteme in jüngst entstandenen Kooperationen zwischen Geotechnik und Geodäsie entwickelt werden.
Die Ablagerungsgebiete können Volumina von Millionen Kubikmetern und Flächenausdehnungen von mehr als 10 Hektar erreichen. Eine umfassende Definition von Bergstürzen stammt vom Geografen Gerhard Abele (1974): Bergstürze sind „Fels- und Schuttbewegungen, die mit hoher Geschwindigkeit in Sekunden oder Minuten aus Bergflanken niedergehen und im Ablagerungsgebiet ein Volumen oberhalb von einer Million Kubikmeter besitzen, sowie eine Fläche von über 10 Hektar bedecken. Kleinere Ereignisse bezeichnet man als Felsstürze“.[1]
Frank Ahnert definiert sie im Lehrbuch Geomorphologie (1996) stattdessen auf der subjektiven Ebene: „Die von der Bewegung erfasste Hangfläche und die bewegte Gesteinsmasse (bzw. Volumen) muss groß genug sein, um der Bezeichnung „Bergsturz“ in der Auffassung der umwohnenden Bevölkerung und der das Ereignis untersuchenden Geomorphologen gerecht zu werden“.[2]
Bergstürze sind demnach groß dimensionierte Felsstürze mit teils verheerenden Auswirkungen. In den zurückbleibenden Schuttmassen können sich zudem kleinere Stauseen bilden, bisweilen auch größere Abdämmungsseen. Eine Sonderart von Felssturz ist der Eissturz mit weit überhöhter Schadensfläche, da das Eis (zusammen mit Schutt) weiter transportiert wird, das Eis, auch Sturzeis genannt,[3][4] dabei durch die Reibungshitze schmilzt oder gar verdampft und damit ein Effekt ähnlich dem bei einem Luftkissenfahrzeug entstehen kann.




Bergstürze entstehen in der Regel an der Grenze zweier oder mehrerer Gesteinsschichten und an tektonischen Störungslinien, wenn derartige Grenzflächen durch Erdbeben, extreme Wetterereignisse (heftige Niederschläge oder Temperaturschwankungen) geschwächt werden oder auch wenn ein Gletscher abschmilzt und dessen Gegendruck fehlt. Zunehmende Steinschlagaktivität kann ein Hinweis auf bevorstehende Bergsturzereignisse sein. Eingriffe des Menschen in die Natur (Hangrodung, zu breite Forstwege, Rohstoffabbau) können diese Vorgänge beschleunigen, wie exemplarisch beim Bergsturz von Elm 1881.
Fels- und Bergstürze stellen neben Muren und Lawinen die Hauptgefahr natürlicher Phänomene im Gebirge dar.
Man unterscheidet zwischen den häufiger vorkommenden Schlipfstürzen und den selteneren Fallstürzen. Ein Schlipfsturz beginnt mit einer Gleitbewegung, bei der die rutschende Masse weitgehend im Verband bleibt oder völlig in Kleinteile zerfällt. Durch eingeschlossene Luft, die wie ein Luftpolster zwischen dem festen Untergrund und der abrutschenden zerfallenden Gesteinsmasse wirkt, können Schlipfstürze selbst in Gesteinspartien ohne größeren Wassergehalt auftreten. Beim Fallsturz hingegen erfolgt praktisch unmittelbar ein Abbruch, bei dem sich das Gestein im freien Fall befindet.[5]
Der mit dem Klimawandel verbundene Temperaturanstieg und das damit einhergehende Auftauen des bis anhin stabilisierenden Permafrosts erhöht die Gefahr von Bergstürzen. Die historische Geologie kennt Bergstürze mit diesen Ursachen bereits aus früheren Warmzeiten.
Das bei Bergstürzen zurückbleibende Material bildet eine Sturzhalde, in der Schweiz „Bergsturzkegel“ genannt; zur Orientierung in solchen Blockhalden (etwa bei Vermessungen oder Umweltprojekten) werden größere Felsblöcke oft mit roten Nummern markiert.
Nach längeren Zeiträumen können durch Bergstürze auch reizvolle Landschaften entstehen. Typisch für das Ablagerungsgebiet ist ein kleinhügeliges Relief (sogenannte Tomahügel) mit meist deutlicher Abgrenzung zur Umgebung.
Die Geschwindigkeit eines Bergsturzes beim Auftreffen aufs Gelände kann – abhängig von der Fallhöhe – 100 km/h übersteigen. Auf einer stark geneigten Gleitbahn kann die Geschwindigkeit der Gesteinslawine weiter auf 200 km/h anwachsen, auf einem Gletscher auch noch mehr. Sie hängt von der Gesamtmasse, vom Material und dessen Verdampfen sowie von der Gleitreibung des Untergrunds ab.


Ein Bergsturzereignis bewirkt sowohl im Abbruchgebiet als auch im Ablagerungsgebiet markante Änderungen. Im Abbruchgebiet kann es zum Beispiel zu Nachstürzen und zu Sackungsbewegungen am oberen Rand der Abrisswände kommen. Weitere Folgen von Bergstürzen können sein:

Bildung von Bergsturzseen, Verlagerung von Wasserläufen und Wasserscheiden
Bildung von Schuttkegeln
Entstehung einer eigenen Bergsturzvegetation
Epigenesen.
Besonders in dichter besiedelten Gebieten werden auch Kulturbauten und Menschenleben gefährdet, insbesondere durch

Verschüttung von Siedlungsgebieten und Verkehrswegen (Straßen, Eisenbahnlinien)
direkte Flutwellen, wenn Gesteinsmassen in größere Gewässer stürzen
instabile Aufstauung von Flüssen und Bächen, welche später zu Flutwellen führen kann, insbesondere bei Ausbrüchen von Bergsturzstauseen.

Zur Einschätzung der Größe und Auswirkung von Berg- und Felsstürzen werden in der Regel Angaben zu den Volumina der umgelagerten Gesteinsmassen und zur Flächenausdehnung ihrer Ablagerungsgebiete gemacht. Bei Bergstürzen geht es dabei um Volumina im Bereich von Millionen bis zu Milliarden Kubikmetern und Ablagerungsflächen von einem Dutzend bis zu über tausend Hektar. Bei mittelgroßen bis großen Felsstürzen betragen die Volumina einige tausend bis zu einigen hunderttausend Kubikmetern mit Ablagerungsflächen im Hektar-Bereich.
Für Sturzmassen, die bis in den Talgrund gelangt sind und ggf. ein Fließgewässer aufgestaut haben, finden sich häufig Angaben, auf welcher Länge und bis zu welcher Höhe über dem Talboden das Tal verlegt wurde und bis zu welcher Höhe die Gesteinsmasse am gegenüberliegenden Prallhang emporgebrandet ist.
Für die Einschätzung der bei einem Berg- bzw. Felssturz umgesetzten Energie (von Lageenergie in Wärme, Verformungsarbeit und im abgelagerten Gestein gebundene chemische Energie) sind Angaben zur mittleren Sturzhöhe erforderlich, die über die Höhe und Massenverteilung im Abriss- und Ablagerungsgebiet geschätzt werden können. Für die größten bekannten Bergsturzereignisse wie den Flimser Bergsturz kommen vorsichtige Abschätzungen zu umgesetzten Energien jenseits von 100 Petajoule (1017 Joule).
Die Umrechnung zwischen verschiedenen Einheiten und die damit verbundenen Größenordnungsunterschiede geben die folgenden Tabellen wieder.


Größenordnungen für Volumenangaben zu Sturzmassen


Größenordnung

Umrechnung in kleinere Einheit

Anschauliche Entsprechung


tausend Kubikmeter (1.000 m³)



Rauminhalt eines Würfels mit

10 m Kantenlänge


1 Million Kubikmeter (1.000.000 m³)



100 m Kantenlänge


1 Kubikkilometer (1 km³)

1 Milliarde Kubikmeterbzw. 1000 Millionen Kubikmeter

1 km Kantenlänge


Größenordnungen für Flächenangaben zu Ablagerungsgebieten


Größenordnung

Umrechnung in kleinere Einheit

Anschauliche Entsprechung


1 Hektar (1 ha)

10.000 Quadratmeter (10.000 m²)

Flächeninhalt eines Quadrates mit
100 m Kantenlänge


1 Quadratkilometer (1 km²)

100 Hektar (100 ha)bzw. 1 Million Quadratmeter (1.000.000 m²)

1 km Kantenlänge


Prähistorische Bergstürze können aufgrund der geologischen Beschaffenheit des Bodens und der Oberflächenformen im Abbruchgebiet und im Ablagerungsgebiet erkannt werden.



Undatiert

Dobratsch, Kärnten, A: Ca. 0,9 km³ Gesteinsmassen stürzten in das Gailtal.
Hocharn im Raurisertal, Salzburg, A: Die Ostflanke des Hocharn (Grieswies-Schwarzkogel) stürzte in den Talschluss von Kolm-Saigurn und brandete auf die Ostflanke Richtung Filzenalm wieder hinauf. Der unregelmäßige und von Lacken durchsetzte Hügel des Durchgangwalds (Rauriser Urwald) repräsentiert die Sturzmasse.[6]
Datiert, chronologisch

Pyhrnpass, Oberösterreich, A: ein möglicherweise durch das 300 km entfernte Ries-Ereignis (vor etwa 15 Millionen Jahren) ausgelöster Bergsturz leitet den nach Norden gerichteten Lauf der Ur-Enns nach Süden, ins Grazer Becken, um.[7]
Langtang-Tal, Nepal: Vor 40.000 Jahren stürzten wahrscheinlich infolge eines Erdbebens an der Himalaya-Hauptstörung 10 bis 15 km³ Gestein eines vormals bis zu 8000 m hohen Berges im Himalaya-Hauptkamm zu Tal. Hiervon wurde der Großteil bis auf einen Rest von 2 bis 3 km³ bereits durch nachfolgende Gletschertätigkeit ausgeräumt. Der noch erhaltene Abrisskamm läuft über bis zu 7000 m hohe Gipfel und Grate. Im Bereich des 24 km² umfassenden Ablagerungsgebietes befindet sich heute der 4984 m hohe Tsergo Ri, mit dessen Namen das Ereignis häufig verbunden wird, dessen Gipfel aber selbst Teil der Bergsturzmasse ist. Es gilt als weltweit größtes Bergsturzereignis im Kristallingestein.[8]
Seymareh-Bergsturz, Zāgros-Gebirge, Iran: Vom an dieser Stelle bis zu 2340 m hohen Bergkamm Kabir Kouh südlich von Pol-e Dochtar brachen vor etwa 10.000 Jahren etwa 30 km³ Gestein ab, bedeckten den Talboden bis fast zum heutigen Pol-e Dochtar und staute den Seymareh-Fluss auf.[9][10][11][12]
Almtal, Oberösterreich, A: Von der Nordabdachung des Toten Gebirges stürzte vor etwa 15.000 Jahren eine große Felsmasse in die Hetzau hinab, wo möglicherweise der Rest eines späteiszeitlichen Gletschers oder auch ein See oder Sumpf lag. Durch die Reibungshitze glitt die Felsmasse auf einem Wasser- oder gar Dampf-Teppich weit hinaus ins Almtal, wo sie erst in Heckenau unmittelbar südlich von Grünau im Almtal zum Stillstand kam. Die Tomahügel von den Ödseen bis zum Cumberland Wildpark sind auf diesen Sturzstrom zurückzuführen.[13]
Flimser Bergsturz, Graubünden, Schweiz: Ca. 12 bis 15 km³, vor etwa 10.000 Jahren.
Köfels, Tirol, A: Über drei Kubikkilometer Gestein stürzten vor etwa 8700 Jahren vom Westhang in das mittlere Ötztal bei Umhausen und blockierten die Ötztaler Ache, die sich später eine Schlucht (Maurach) durch den Schutt fressen musste. Durch die Reibungshitze kam es bei dem Bergsturz zu einer Umwandlung von Gneis in ein glasiges Gestein, das als Köfelsit bezeichnet wird.
Storegga, Europäisches Nordmeer, vor Mittelnorwegen: Unter Wasser und mit einem Tsunami als Folge. Etwa vor 8000 Jahren, die Sturzmasse muss mehr als hundertmal größer gewesen sein als in Flims. Sie hatte Auswirkungen auch in Schottland und Island.
Davos, Graubünden, Schweiz: Weit über 0,3 km³ stürzten von der Totalp im Parsenngebiet und bildeten so den Wolfgang-Pass und den Davosersee. Datierung: jünger als 8000 Jahre.
Wildalpen, Steiermark, A: Vom Ebenstein und Brandstein (Hochschwabgruppe) stürzten etwa 4000 v. Chr. (= vor etwa 6020 J.) gewaltige Felsmassen nach Norden und brandeten als Sturzstrom bis ins Salzatal hinaus.
Vom Schafberg, Oberösterreich, A: geschätzt 50–100 Millionen m³, trennte Attersee und Mondsee und könnte um 3200 v. Chr. (= vor 5220 J.) durch die Binnentsunami die Pfahlbausiedlungen der Mondseekultur ausgelöscht haben
Marocche di Dro, Italien: Ergebnis mehrerer Bergstürze im unteren Sarca-Tal, deren erster sich frühestens zwischen 2950 und 2600 v. Chr. (= frühestens vor 4970 J.) und deren letzter (die frana di Kas) sich frühestens zwischen 400 und 200 v. Chr. ereignete. Das Volumen der Bergstürze betrug zusammen etwa 1 km³.
Fernpass, Nordtirol, A: Entstand durch einen Bergsturz des Westhangs vor etwa 4000 Jahren.
Hochkaltermassiv, Bayern, D: Ein Bergsturz von ca. 15 Millionen Kubikmetern aus dem Blaueistal vor rund 3500 bis 4000 Jahren staute die Ramsauer Ache zum Hintersee auf und schuf den Zauberwald. Er bedeckt eine Fläche von 0,75 km², die sich zwischen dem Hintersee und der Marxenklamm befindet. 4 viel kleinere Bergstürze 1908–1959.
Zugspitze, Bayern, D: Vor rund 3750 Jahren brachen rund 200 Millionen Kubikmeter Fels aus der Nordflanke der Zugspitze. Teile davon durchquerten den gesamten Eibsee und rutschten auf der gegenüberliegenden Seite wieder etwa 100 Meter den Hang hinauf. Dabei wurden deutlich mehr Gesteinsmassen abgelagert, als heute an der Ausbruchstelle zu fehlen scheinen. Geologen gehen deshalb davon aus, dass das überzählige Material aus dem Gipfelbereich stammt und die Zugspitze vor dem Ereignis ein Dreitausender gewesen sein könnte.[14][15]
Tschirgant, (Nord-)Tirol, A: 240 Millionen Kubikmeter Gesteinsmasse stürzten vor etwa 3000 Jahren in das Inntal und vordere Ötztal, nachdem die Flanke des Berges zuerst durch den Rückgang von stützendem Gletschereis und später durch eine außergewöhnlich intensive Erdbebenaktivität destabilisiert wurde.[16] Die Geröllmassen hinterließen ein Ablagerungsgebiet von 13 Quadratkilometern.



2.-3. Jahrhundert – Dritter von drei Pletzachbergstürzen bei Kramsach, Tirol, A: Vom Pletzachkogel ins Inntal. Menschen nutzen das im Tal gebrochen liegende Gestein für Bauten. Es bildeten sich hier Verwaltungsgrenzen aus.[17]
1137 (?), siehe: 3. April 1595: Bergsturz in Reurieth
1172: Ein großer Bergsturz geht auf den Moränenwall zwischen Königssee und Obersee in den Berchtesgadener Alpen nieder.[18]
24. November 1248: Mont Granier im Chartreuse-Massiv bei Chambéry im Savoyen: Bergsturz in der Nacht auf den 25. November von ca. 150 Millionen m³ Felsmasse mit einer Gerölllänge von sieben Kilometern, Ort Saint-André mit etwa 3000 Menschen total verschüttet, ferner 16 Dörfer begraben, insgesamt geschätzt bis zu 5000 Tote.[19]
1348 – Dobratsch (2100 m) bei Villach in Kärnten: Ausgelöst durch das Friaul-Erdbeben stürzten im selben Gebiet, in dem auch ein prähistorischer Bergsturz stattgefunden hatte, geschätzte 150 Millionen m³ Gesteinsmassen in das Gailtal. Das Abbruchgebiet an der südöstlichen Felswand ist als Rote Wand noch gut sichtbar. Sein Ablagerungsgebiet reicht 3 km bis zur Gail, trägt den Namen Die Schütt und steht unter Naturschutz. Zwischen dem Schütter Wald und dem Fluss wurde die neue Ortschaft Oberschütt gegründet (Im Januar 2015 stürzten nochmals fast 2.000 m³ Gestein aus der Roten Wand auf den darunterliegenden Wald. Die Abbruchstelle und der neue Schuttkegel sind von der Aussichtsplattform beim Alpengarten gut zu beobachten).
30. September 1512: Bergsturz Buzza di Biasca im Valle di Blenio nördlich Biasca. Die Gesteinsmassen stauten einen See auf; der Damm brach 1515 und verwüstete das Tal des Tessin bis zum Lago Maggiore.
3. April 1595: Bergsturz in Reurieth vom so genannten „Reuriether Felsen“. Davor soll bereits 1137 ein Bergsturz das Dorf verschüttet haben.
24. August 1598: Bergsturz von Wartha oberhalb der Glatzer Neiße in Bardo Śląskie, Polen.

4. September 1618 (julianischer Kalender: 25. August) – Bergsturz von Plurs (bei Chiavenna an der Straße zum Malojapass, damals Drei Bünde, heute Italien): Hier wurde eine ganze Stadt samt dem Ortsteil Scilano (Schilan) verschüttet, nach zeitgenössischen Quellen starben zwischen 930 und 1200 Menschen. Forschungsgeschichtlich bedeutend ist auch die Vorher-nachher-Dokumentation von Matthäus Merian.
16. Juli 1669 – Felssturz von 1669 in der Stadt Salzburg, Österreich: Zwei Felsstürze vom Mönchsberg, der aus lockerem Nagelfluh besteht, kostete in der Gstättengasse 230 Menschen das Leben. Seitdem werken hier Bergputzer.
1714 und 1749: Zwei Bergstürze an den Les Diablerets, einer von ihnen schuf den Stausee Lac de Derborence.
2. September 1806 – Bergsturz von Goldau, Schweiz: Ein ganzes Dorf wurde von 40 Millionen m³ Fels verschüttet, 457 Menschen starben.
10. März 1876 – Bergsturz von Kaub am Rhein: acht Häuser wurden verschüttet, 25 Menschen starben.
11. September 1881 Elm, Glarus, Schweiz: zehn Millionen Kubikmeter: Der Bergsturz von Elm wurde durch den jahrelangen, rücksichtslosen Abbau von Schiefer verursacht. 115 Menschen starben.
29. April 1903 – Bergsturz in Frank (Frank Slide), Alberta (Kanada): 30 Millionen m³, eine Klippe brach über eine sehr steile Flanke von rund 1000 Metern Höhendifferenz ab. Einer der bekanntesten Bergstürze.
18. Februar 1911 – Saressee/Pamir, Tadschikistan: ein Erdbeben verursachte einen Bergsturz von 2,2 km³, der den höchsten Damm der Welt und den 55,8 km langen Saressee bildete.
10. April 1939: Der Bergsturz von Fidaz ereignete sich östlich des Dorfes Fidaz in der Gemeinde Flims im schweizerischen Kanton Graubünden. Es stürzten 100'000 Kubikmeter Fels zu Tal. 18 Menschen fanden den Tod.
10. Juli 1949: Ein durch ein Erdbeben ausgelöster Bergsturz im Pamir traf den oberhalb des tadschikischen Ortes Chait gelegenen See Chaus-Chait. Die resultierende Mure überrollte den Ort und begrub rund 18.000 Bewohner unter einer zwanzig bis dreißig Meter hohen Schicht aus Schlamm und Geröll.[20][21]
9. Juli 1958: Ein Erdrutsch, der mit geschätzt 90 Mio. t Gestein und Eis in die Meeresbucht Lituya Bay, Alaska hineinlief und eine Tsunami erzeugte, die zumindest über einen 520 m hohen Hügel schwappte.
9. Oktober 1963: Katastrophe von Vajont (Longarone), 90 km nördlich von Venedig im Friaul/Italien: Felssturz von 260 Millionen m³ in Stausee, rund 2000 Menschen verloren ihr Leben.
9. Januar 1965: Bergsturz von Hope (Hope Slide) bei Hope in British Columbia, Kanada: 46 Millionen m³ Gestein und Geröll ergossen sich zu einer Halde von 70 m Höhe und 3 km Länge zu Tal. Dabei wurde ein See vollständig zugeschüttet, vier Menschen starben.
11. Jänner 1965 – Ein Reisezug prallte in der Dunkelheit gegen die Trümmer eines Felssturzes, der zwischen Egg und Lingenau/Hittisau auf das Gleis der Bregenzerwaldbahn niedergegangen war. Die Lok stürzte 30 Meter tief über einen Steilhang ab.[22] Der Lokführer wurde schwer verletzt, die anderen Insassen des Zuges kamen mit dem Schrecken davon. Die in sehr schwierigen Gelände erbaute Bahntrasse war vielmals durch Felsstürze und Hangrutschungen beschädigt und deshalb in den 1980er Jahren großteils stillgelegt worden.
30. August 1965 – Mattmark, Saas-Almagell, Wallis, Schweiz: Eissturz 500.000 m³, 88 Tote.
31. Mai 1970: Yungay, Peru[23]: Infolge eines Erdbebens der Stärke 7,8 stürzten vom Nevado Huascarán etwa 60 Millionen m³ Eis und Fels ab und töteten über 70.000 Menschen im Tal Callejón de Huaylas, wobei etwa 150.000 verletzt und weit über 500.000 obdachlos wurden. Die Stadt Yungay mit rund 5000 Einwohnern wurde komplett zerstört, nur etwa 400 überlebten. Heute leben wieder etwa 10.000 Bewohner neben der Gedenkstätte.
18. März 1971 – Chungar, Peru: 100.000 m³ Gestein lösten sich 400 m über dem See Lago Yanawayin aus anstehendem Kalkstein und verursachten eine bis zu 30 m hohe Flutwelle, die das gegenüberliegende Ufer unter sich begrub, nahezu die gesamte Minensiedlung zerstörte und (nach unterschiedlichen Schätzungen) 400–600 Menschen tötete.
28. Juli 1987 – Morignone im Val Pola in der Provinz Sondrio, Italien (Veltlin): 40 Millionen m³
April und Mai 1991 – Randa, Wallis, Schweiz: 30 Millionen m³.
22. September 1993 – Bischofsmütze im Land Salzburg: ein mehr als 200 m hoher Pfeiler aus der Felswand stürzte in den Abgrund. Seither kommt es immer wieder zu kleineren Felsstürzen.
23. September 1995 – Breitachklamm im Allgäu: Um 6:00 Uhr lösten sich etwa 50.000 m³ Fels und Geröll, wodurch 300.000 m³ Wasser bis zu einer Höhe von 30 m angestaut wurden. Am 23. März 1996 erfolgte um 11:30 Uhr der Durchbruch, der die Klamm total verwüstete.
10. Juli 1999 – Schwaz in Tirol: Im Bergbaugebiet des Eiblschrofen stürzten etwa 150.000 m³ Gestein in den darunter liegenden Bergwald und bedrohten einen Ortsteil. 250 Einwohner mussten evakuiert werden und konnten erst nach mehreren Wochen und umfangreichen Sicherungsmaßnahmen wieder in ihre Häuser zurückkehren.


14. Oktober 2000 – Gondo am Simplonpass, Wallis/Schweiz; Grenzort zu Italien: Bergmure mit ungeheurer Geschwindigkeit und einem Volumen von etlichen 10.000 m³, elf Tote und zwei Verschollene (kein eigentlicher Felssturz).
15. Juli 2003 – Matterhorn: ca. 1.500 m³, Auftakt für das Projekt PermaSense
31. Mai 2006 – Gurtnellen: Felssturz auf Autobahn A2 (Schweiz) mit zwei toten Autofahrern.
13. Juli 2006 – Eiger: 500.000 m³ Gestein stürzten auf den Unteren Grindelwaldgletscher ab.
30. Oktober 2006 – Dents du Midi: Vom Berg Dents du Midi im Val d’Illiez (Wallis/Schweiz) stürzten ca. 1 Million m³ Gestein ins Tal. Personen- und Sachschäden gab es keine. Als Grund für den Felssturz wurde der ungewöhnlich warme Sommer vermutet.
12. Oktober 2007 – Sexten: Vom Einserkofel oberhalb des Fischleintals bei Sexten-Moos stürzten ca. 60.000 m³ Fels und Geröll ins Tal. Staub hüllte das Tal ein, Verletzte gab es nicht.
4. Januar 2010: Bergsturz in den Fluss Hunza im Sonderterritorium Gilgit-Baltistan in Pakistan
2011: Ein Felssturz in der Rappenlochschlucht riss eine Straßenbrücke, auf der sich niemand befand, mit in die Tiefe. Die Auflager einer Behelfsbrücke wurden 2020 durch einen erneuten Felssturz so destabilisiert, dass sie demontiert werden musste.
Dezember 2011 und 23. August 2017: Bergstürze von Bondo mit rund 1 und 4 Millionen m³ Gesteinsvolumen. Letzterer Bergsturz führte über eine Mure zu großen Schäden im Dorf.
5. Mai 2012 – Annapurna IV (Nepal): Bei einem Felssturz fielen große Mengen Gestein (geschätzt 32 Millionen m³) und Eis aus ca. 7000 m Höhe in 2 Schritten über 4000 m in die Tiefe, wobei das enthaltene Eis durch Reibungshitze schmolz und der entstehende Schlammstrom in den tiefen unzugänglichen Einschnitt des Seti Gandaki Flusses vordrang. Nachdem diese Engstelle den Schlammstrom zunächst abgebremst hatte, beschleunigte er sich unterhalb wieder, und die entstehende Flutwelle zerstörte das Dorf Kharapani, es starben ca. 70 Menschen. Eine andere Erklärung ist, dass es zuvor bereits einen kleinen aus einem vorangegangenen Felssturz aufgestauten Stausee gegeben habe, in den der Felssturz vom 5. Mai gestürzt sei.[24][25][26][27][28] Der Pilot eines Besichtigungs-Rundfluges filmte den Felssturz.[29]
24. Dezember 2017 – Vals (Tirol): 117.000 m³ Gestein verschüttete die Landesstraße, 3 Häuser wurden evakuiert, ein Notweg wurde gebaut.
12. Oktober 2019 – Trossingen: Felssturz nachts auf die Autobahn 81. Ein Pkw fährt mit hoher Geschwindigkeit in den Felsbrocken und fängt Feuer. Der Fahrer findet dabei den Tod.
25. Oktober 2020 und Folgejahre – Dachstein/Dirndln: Einem Abbruch folgen zwei Felstürme darüber mit insgesamt 20.000 m³. Höhlen werden eröffnet.
29. und 30. Januar 2021 – Raron: 300.000 bis 500.000 m³[30]
15. März 2021 – Kestert: Ein Felssturz nahe der Loreley führt zu einer mehrwöchigen Sperrung der vor allem im Güterverkehr wichtigen rechten Rheinstrecke. Lockeres Schiefergestein musste mit mehreren Sprengungen beseitigt werden. Gesamte Schuttmasse ca. 15.000 bis 20.000 m³[31]


Im Jahr 1895 wurde der Ötztaler Pfarrer Adolf Trientl, der auch Naturkundler war, darauf aufmerksam, dass Zimmerleute zum Holzschleifen heimischen Bimsstein verwendeten, dessen Herkunft der angefragte Innsbrucker Geologieprofessor Adolf Pichler auf die Tätigkeit eines örtlichen Vulkans zurückführte. Diese Theorie ließ sich aber ebenso wenig erhärten wie die Idee eines großen Meteoriteneinschlages. Der an Meteoriteneinschlägen besonders interessierte Mineraloge und Petrologe Ekkehard Preuss[32] aus Regensburg erforschte ab 1962 die Bimssteinfundstellen und die Oberflächenform des Bergsturzes genau und kam zu dem Schluss, dass die für die Theorie nötige Reihenfolge – erst Meteoriteneinschlag, dann Bergsturz – nicht stimmen könne.
Aufgeklärt wurde das Phänomen der Bimssteinvorkommen dann von Theodor H. Erismann, dem damaligen Direktor der Eidgenössischen Materialprüfungs- und Versuchsanstalt in Dübendorf bei Zürich. Als vor ca. 8000 Jahren 3 km3 Gestein vom Köfels in das Ötztal rutschten, erreichten die Rutschmassen Geschwindigkeiten von 150 bis 200 km/h. Die Reibung im Bereich der Gleitfläche führte unter dem hohen Gewichtsdruck zu einer so großen Hitzeentwicklung, dass der Gneis schon nach 100 m Wegstrecke zu schmelzen begann. Am Köfels überschritten die Temperaturen 1700 °C. Während der Gneis schmolz, wurde der darin in geringen Mengen enthaltene Calcit durch die Hitze in Branntkalk und Kohlendioxid zerlegt. Das so entstandene Gaspolster und die Gesteinsschmelze bildeten ein ausgezeichnetes Gleitmittel für die ganze Masse. Der „Bimsstein“ aus dem Ötztal wird heute nach seinem Fundort Köfels als Köfelsit bezeichnet.
Ein ähnliches Szenario fand der bereits erwähnte Preuss 1973 nach Hinweisen früherer Himalaya-Expeditionen im nepalesischen Langtang-Tal vor, ca. 60 km nördlich der Hauptstadt Kathmandu und am Himalaya-Hauptkamm gelegen, wo vor ungefähr 40.000 Jahren im Bereich des heutigen Tsergo Ri 10–15 km3 Gestein abgerutscht waren. Eine so große Massenbewegung setzte gemäß einer Berechnung der Wissenschaftler genug Energie frei, um eine Masse von der Größe der Cheops-Pyramide in eine Erdumlaufbahn zu schießen. Es wird vermutet, dass das Massiv um Yala Peak und Tsergo Ri die Überreste eines durch den Bergsturz zusammengebrochenen 8000ers sind. Als wahrscheinlicher Auslöser wird ein starkes Erdbeben an der zentralen Hauptstörung (engl. Main Central Thrust) des Himalayas vermutet.[8]


Bergzerreißung
Erdrutsch, Rutschhang
Geomorphologie
Glaziologie
Permafrostboden

Katrin Hauer: Der plötzliche Tod. Bergstürze in Salzburg und Plurs kulturhistorisch betrachtet (= Kulturwissenschaft. Bd. 23). Lit, Wien u. a. 2009, ISBN 978-3-643-50039-7.
Albert Heim: Bergsturz und Menschenleben (= Beiblatt zur Vierteljahresschrift der Naturforschenden Gesellschaft in Zürich. Jg. 77, Beiblatt No. 20, ZDB-ID ). Komm. Beer & Co, Zürich 1932.
Melchior Neumayr:  In: Zeitschrift des deutschen und österreichischen Alpenvereins. Bd. 20, 1889, ZDB-ID , S. 19–56.
Welsch, Walter (1984) Bergstürze durch Erdbeben. Geowissenschaften in unserer Zeit; 2, 6; 201–207; doi:10.2312/geowissenschaften.1984.2.201.

 im Katalog der Deutschen Nationalbibliothek



 ()

 Seite des Deutschen Alpenvereins e.V zum Ereignis von Bondo 2017





Mure ist eine Weiterleitung auf diesen Artikel. Zu weiteren Bedeutungen siehe Mure (Begriffsklärung).


Ein Murgang (auch Mure, Gisse oder Rüfe genannt, in den Medien oft umgangssprachlich Schlammlawine) ist ein Erdrutsch, bei dem ein Strom aus Schlamm und gröberem Gesteinsmaterial im Gebirge schnell talwärts fließt, physikalisch vergleichbar mit einer sehr groben Suspension. Murgänge haben einen hohen Feststoffgehalt und dadurch bedingt eine hohe Dichte (bis 2,6 g/cm3).[1] Ein Murgang kann einige hunderttausend Kubikmeter Material transportieren. Durch seine Energie kann er große Verwüstungen anrichten. Die meist klar ausgeprägte Front kann eine Geschwindigkeit von bis zu 60 km/h erreichen.



Ein Murgang entsteht, wenn im steilen Gelände wenig verfestigtes Material (Geröll, Schutt und Erdmaterial) wasserübersättigt wird und, meist allein durch Einwirkung der Schwerkraft, in Bewegung gerät. Ausgelöst wird die Durchnässung meistens durch starke oder lang anhaltende Niederschläge oder die Schneeschmelze, zunehmend jedoch auch durch das Abschmelzen von Gletschern oder Permafrostböden durch die Erderwärmung. Murgänge folgen meist bestehenden Bachbetten oder Rinnen und erweitern sie stark, sie können aber auch eine neue Rinne erodieren. Grobe Korngrößen (Steine, Blöcke) konzentrieren sich an der Murenfront, die Material bis hin zu metergroßen Felsblöcken und Baumstämmen mitreißen kann. Schon entlang des Fließweges wird einiges von dem transportierten Material in Randwällen (Levées) wieder abgelagert. Die Bewegung endet meist am Hangfuß, wo das Gefälle nachlässt. Dort lagert sich das Material zungenförmig ab. Durch wiederholte Murgangereignisse bilden sich Ablagerungskegel (Murkegel oder Murenhalde). Wegen des hohen Feststoffgehalts und der damit verbundenen Zähigkeit des abgehenden Gemischs findet bei der Akkumulation eine Sortierung kaum statt.[2]




Ein Murgang hat deutlich mehr Energie als ein Hochwasser und richtet erheblich höheren Schaden an. Ein mit voller Wucht auftreffender Murgang kann Häuser, Verkehrswege und Brücken zerstören. Oft werden Straßen und die Erdgeschosse von Häusern meterhoch mit dem Schlamm-Geröllgemisch verschüttet. Dies geschieht unter anderem, wenn Bachläufe in Ortschaften zu eng kanalisiert sind, mitgerissene Baumstämme Brücken oder Durchlässe verklausen und der Murgang dort über die Ufer tritt. Wegen der oft langen Zeiträume zwischen einzelnen Murgängen ist sich die Bevölkerung dieser Gefahr oft nicht bewusst.
Zur Vorbeugung gegen Murgänge und Murgangschäden gehören:

Gefahrenzonenplanung
Bauliche Schutzmaßnahmen wie Geröllsperren, Rückhaltedämme oder Ablenkbauwerke
Verbreitern kanalisierter Bäche und Vermeidung von Engpässen (besonders bei Brücken), damit der Murgang nicht über die „Kanalufer“ tritt (in Brig wurde zum Beispiel nach der Katastrophe von 1993 eine automatische Hubbrücke gebaut)
Säuberung der Gebirgsbäche von losem Material (Bäume, Äste und Geröll), das einen Murgang auslösen oder nähren kann
Murgangwarnungen (noch in einem experimentellen Stadium)
Wegen des Klimawandels wird für die nächsten Jahrzehnte mit einer Zunahme an Murgängen gerechnet. Wenn hochalpine Permafrostböden und Blockgletscher auftauen, entsteht mehr mobilisierbares Material, das dann als Mure abgehen kann.


Bleiben die Ablagerungen von Murgängen als Murzungen und Murkegel erhalten, können sie auf verschiedenen Wegen datiert und so der ungefähre Zeitpunkt eines einzelnen Murgangs bestimmt werden. Die systematische Erfassung von möglichst vielen Murgangereignissen kann so Informationen über die generelle Muranfälligkeit sowie über die Klimageschichte eines Gebiets liefern. Häufig wird das Alter der Bäume bestimmt, die auf Murzungen und -kegeln wachsen. Möglich sind auch sedimentologische Untersuchungen. So wurde am Pragser Wildsee die Beziehung zwischen Murgängen und den daraus resultierenden Ablagerungen auf dem Seegrund untersucht. Durch Auswertung der See-Sedimente war es möglich, einen Mur-Kalender zu erstellen. Hierbei sind über Jahrhunderte deutliche Unterschiede in der Häufigkeit von Murgängen festzustellen. Ein Zusammenhang zwischen Mur-Aktivität und Großklima konnte jedoch nicht festgestellt werden, so dass anthropogene Ursachen vermutet werden.[3]



 im Katalog der Deutschen Nationalbibliothek
 nach dem Bergsturz von Bondo 2017





Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Lawine (Begriffsklärung) aufgeführt.


Als Lawinen werden Massen von Schnee, Eis oder Schlamm bezeichnet,[1] die sich von Berghängen ablösen und zu Tal gleiten oder stürzen.  Abgänge von Steinen oder ganzen Hängen werden demgegenüber als Muren bezeichnet. Lawinen, die große Sach-, Personen- oder Umweltschäden verursachen, werden zu den Naturkatastrophen gezählt.



Das Wort «Lawine» geht auf alpinromanisch lavīna beziehungsweise lateinisch labīna ‚Erdrutsch‘ zurück; diesem zugrunde liegt das lateinische Verb lābi ‚gleiten‘.[2] Im Altoberdeutschen des 8./9. Jahrhunderts diente lewina, lewin oder louwin als Übersetzung für lateinisch torrēns ‚Wildbach‘;[3] in den hoch- und höchstalemannischen Mundarten, wo aus alpinromanisch lavīna Laut- und Formvarianten wie Lauwene, Laubene, Lauene und ähnlich wurden (mit Betonung je auf der ersten Silbe), erlangte das Wort im Laufe des Mittelalters in erster Linie die Bedeutung ‚Schneerutsch‘.[4] Die Schweizer Humanisten versuchten das für sie nicht mehr durchsichtige Wort hingegen an „Löwin“ anzuschließen.[4]
Im 18. Jahrhundert wurde das schweizerdeutsche Lauwene, Laubene, Lauene durch die Reiseliteratur im ganzen deutschen Sprachraum bekannt. Dass sich dabei die relatinisierte Form Lawine (mit Betonung auf der mittleren Silbe) durchsetzte, ist im Wesentlichen auf Friedrich Schillers 1804 uraufgeführtes Drama Wilhelm Tell zurückzuführen.[5]
Die Herkunft des ähnlich klingenden, ebenfalls ‚Schneerutsch, Lawine‘ bedeutetenden bairisch-österreichischen Lahn, Lähn und ähnlich ist umstritten. Gemäß einer Herleitung stammt es wie Lawine aus dem Alpinromanischen,[6] gemäß einer anderen ist es mit Lawine zwar urverwandt, aber nicht wie dieses ein Lehnwort aus dem Romanischen, sondern ein deutsches Erbwort, das germanisch *lanō(n)- fortsetzt.[3] Der Grund für letztere Annahme ist, dass bairisch Lahn Parallelen mit der Bedeutung ‚Reihe, Gang, Weg‘ in mitteldeutschen und niederdeutschen Mundarten sowie im Englischen, Schwedischen, Norwegischen und Isländischen hat.[3]



Spätestens seit der Mensch den alpinen Lebensraum erschlossen hat, ist er von Lawinenabgängen bedroht. Aus der Literatur sind vor allem Heerzüge, die die Alpen überquerten, als betroffen bekannt. So verlor Hannibal auf seiner Alpenüberquerung im Jahre 218 v. Chr. angeblich rund die Hälfte seiner Soldaten (etwa 20.000 Mann) und eine unbekannte Anzahl von Elefanten durch Lawinen.


Abhängig von der Art ihres Abgangs unterscheidet man zwei grundsätzliche Arten von Schneelawinen, und zwar nach der Art ihres Anrisses Schneebretter und Lockerschneelawinen, daneben teilt man sie auch nach ihrem Umfang und Ausmaß ein.
Eine Dachlawine ist eine Schneelawine im Kleinen, die von Gebäuden abgeht.
Zu unterscheiden sind Lawinen vom Eissturz.

[Bearbeiten | Quelltext bearbeiten]

Kennzeichen für Schneebrettlawinen ist ein linienförmiger Anriss quer zum Hang. Ausgedehnte Schichten der Schneedecke – oft aus Triebschnee – rutschen auf einer Gleitschicht zunächst zusammenhängend ab. Im Verlauf des Abgangs kann sich eine Schneebrettlawine zu einer Staublawine entwickeln. Eine solche Gleitschicht kann beispielsweise durch den Nigg-Effekt entstehen.
Sie stellen die klassische Gefahrenlawine für Schneesportler und Bergsteiger dar. Ein sogenanntes Schneebrett kann sich spontan lösen oder durch die zusätzliche Belastung im Gelände ausgelöst werden. Dabei können auch bergseitig über dem Geländegänger ausgedehnte Schneeschichten abreißen und abfahren. Gefahren für Opfer einer Schneebrettlawine sind Ersticken, Verletzungen durch Aufprall an Felsen, Absturz oder der Druck der oft tonnenschweren Schneemassen.
Schneebrettlawinen treten in der Regel bei Hangneigungen zwischen 30° und 50° auf. Sie sind aber auch schon bei geringeren Hangneigungen möglich, ab etwa 25°. Bei Hangneigungen über 50° sind Schneebrettlawinen selten, bei diesen Hangneigungen treten in der Regel vorher Lockerschneelawinen auf.
Der Ausdruck Schneebrett lässt zunächst an eine harte Beschaffenheit denken. In der Realität kommen jedoch auch in sehr weichem, schwer erkennbarem Triebschnee flächige Lawinenauslösungen vor: Der Begriff beschreibt lediglich, dass eine ganze Schneemasse „wie ein Brett“ auf einmal losfährt, auch ohne dabei zwingend einen festen Körper zu bilden. In wissenschaftlichen Studien wird untersucht, wie sich in Schwachschichten Brüche ausbreiten, sodass ein ganzer Hang auf einmal abbricht. Mit der Bewegung zerbricht das Brett dann in kleinere Teile, die sich im Auslauf übereinander schieben, verdichten und als eine verfestigte Ablagerung (oder ein Lawinenkegel) liegen bleiben.
Es wird zwischen trockenen und nassen Schneebrettlawinen unterschieden.

[Bearbeiten | Quelltext bearbeiten]

Eine Lockerschneelawine ist durch einen punktförmigen Anriss gekennzeichnet. Durch eine Kettenreaktion wächst die Lawine. Solche Lawinen kommen vor allem in unverfestigtem Schnee vor. Es wird weiter in trockene Lockerschneelawinen und in nasse Lockerschneelawinen (oberflächliche Nässung) unterteilt. Lockerschneelawinen verlangen – wegen der zur Fortpflanzung der Bewegung notwendigen Energie – eine etwas höhere Hangneigung als Schneebrettlawinen. Ein häufiges Auftreten wird bei etwa 40–60° Hangneigung beobachtet.

[Bearbeiten | Quelltext bearbeiten]

Staublawinen entstehen, wenn eine große Schneemasse einen steilen Hang hinabstürzt und dabei weiteren Schnee aufnimmt. Der Schnee wird aufgewirbelt, sodass ein Schnee-Luft-Gemisch (Aerosol) entsteht. Eine Staublawine kann eine Geschwindigkeit von über 300 km/h erreichen.[7]
Einher mit der Staublawine gehen gewaltige Luftdruckschwankungen (Druck vor der Front, dahinter Sog), die sehr gefährlich sind. Durch diese Druckschwankungen, die den Bedingungen in einem Wirbelsturm gleichen können, kommt es zu den großen Zerstörungen. Bäume werden abgeknickt, Hausdächer weggerissen und Fenster eingedrückt, wodurch Schnee in das Haus eindringt. Gelangt das Schnee-Luft-Gemisch in die Lunge von Menschen oder Tieren, so kann dies nach kurzer Zeit zum Tode durch Ersticken führen. Zudem ist der Fließanteil von Staublawinen gefährlich, da er zu Verschüttungen führen kann.

[Bearbeiten | Quelltext bearbeiten]
Eislawinen sind eine Folge der langsamen Gletscherbewegungen. Das Eis bewegt sich bis zum Rand eines Abbruchs und stürzt in einzelnen Brocken darüber hinaus. Dies gleicht zunächst mehr einer Steinlawine als den bekannten Schneelawinen, doch dann werden die herabstürzenden Eisbrocken beim Aufprall in feine Schneepartikel zerschlagen und sind kaum mehr von einer Fließlawine zu unterscheiden.

[Bearbeiten | Quelltext bearbeiten]
Sind berechenbare Grundlawinen, die vor allem im Frühjahr bei Tauwetter losbrechen. Der weiche Schnee verliert schneller an Haftung und rutscht den Berg herunter.

[Bearbeiten | Quelltext bearbeiten]

Die oben genannte Einteilung kann noch verfeinert werden:

Von einer Oberlawine spricht man, wenn die obere Schneeschicht auf der darunter liegenden abrutscht.
Gleitet dagegen die gesamte Schneedecke talwärts, sodass freigelegter Boden sichtbar wird, bezeichnet man die Lawine als Grundlawine, (seltener als Bodenlawine).
[Bearbeiten | Quelltext bearbeiten]
Hanglawinen erreichen im Gegensatz zu Tallawinen nicht den Fuß des Hangs (bzw. das Tal), sondern kommen im Hang zum Stillstand.



An der Entstehung einer Lawine sind viele Faktoren beteiligt, die sich gegenseitig verstärken oder abschwächen können. Man kann die Entstehung einer Lawine nicht unabhängig von der Art der Lawine betrachten, da es sich z. B. bei Schneebrettern und Nassschneelawinen um ziemlich unterschiedliche Prozesse handelt. Auch die Gefahrenbeurteilung erfolgt darum je nach Lawinenart unterschiedlich. Das Verständnis dieser Entstehungsfaktoren ist die notwendige Grundlage für die Risikobeurteilung und für die Erstellung eines Lawinenbulletins.

[Bearbeiten | Quelltext bearbeiten]
Eine große Menge Neuschnee innerhalb kurzer Zeit erhöht die Lawinengefahr. Während bei sehr günstigen Verhältnissen bis zu 50 cm Neuschnee fallen können, bevor die Lawinengefahr ansteigt, können bei ungünstigen Verhältnissen schon 10 cm Neuschnee gefährlich werden. Unter ungünstigen Verhältnissen versteht man sehr tiefe Temperaturen, starken Wind und eine bestehende instabile Schneedecke.

[Bearbeiten | Quelltext bearbeiten]

Die Gefahr eines Lawinenabgangs besteht vor allem bei Hangneigungen zwischen 30° und 50°, wobei eine stärkere Hangneigung einen Lawinenabgang im Allgemeinen begünstigt – vergleiche hierzu die Kräfte an der Schiefen Ebene. Maßgeblich ist die steilste – ungefähr 10 m × 10 m große – Stelle im Hang. Unter 25° Hangneigung entstehen Lawinen nur sehr selten, beziehungsweise nur unter besonderen Umständen. Bei 60° Hangneigung oder mehr sind Lawinen fast unmöglich, da der Schnee schon früh und spontan abrutscht; bedeutende Schneemengen können sich daher gar nicht ansammeln.
Die Neigung des Geländes ist auch bezüglich der Sonneneinstrahlung relevant: Fällt das Licht mehr oder weniger rechtwinklig auf den Boden, dann nimmt der Schnee mehr Wärme auf, als wenn die Sonne in flachem Winkel auf den Schnee scheint. Dies spielt zum Beispiel bei Nassschneelawinen eine Rolle.

[Bearbeiten | Quelltext bearbeiten]
Eine wesentliche Rolle spielt die Hanglage. Nord-Hänge sind (in nördlichen Breiten) der Sonneneinstrahlung am wenigsten ausgesetzt, wodurch sich die Stabilisierung der Schneedecke verlangsamt und Gefahrenstellen länger konserviert werden. Umgekehrt sind Südhänge im späten Winter heikler, da größere Wärme Nassschneelawinen begünstigt.
Je nach Windsituation sammelt sich Triebschnee auch an spezifischen Hanglagen.

[Bearbeiten | Quelltext bearbeiten]
Die Bodenbedeckung ist ein weiterer Faktor, der die Entstehung von Lawinen beeinflusst. Dichter Wald kann den Abgang von Schneebrettern erschweren, umgekehrt begünstigt Altgras u. ä. den Abgang von Grundlawinen, eingeschneiter Reif oder Eisschichten begünstigen Oberlawinen. Der Wald kann das Anreißen von Lawinen verhindern, aber große Staublawinen nicht stoppen.

[Bearbeiten | Quelltext bearbeiten]
Schnee kann durch den Wind verfrachtet werden. Dieser so genannte Triebschnee lagert sich auf der windabgewandten Seite von Graten, in Rinnen und Mulden oder am windzugewandten Fuß von Hängen ab. An Graten bildet er leeseitig Schneewehen und Schneewechten. Dieser verfrachtete Schnee ist instabil, und bereits kleinste Störeinflüsse können zu einer Schneebrettlawine führen. Triebschnee kann sowohl hart als auch weich sein und ist somit nicht einfach zu erkennen. Auch nach dem Einschneien durch nachfolgenden Neuschnee behält er sein Gefahrenpotenzial. Triebschnee ist gefährlich, weil die Eiskristalle abgeschliffen sind und sich wenig ineinander verzahnen. Der Zusammenhalt von Triebschnee ist somit viel geringer als jener von Neuschnee. Sogenannte Windgangeln oder Sastrugi können auf Verfrachtungen von Triebschnee hinweisen.

[Bearbeiten | Quelltext bearbeiten]
Wenn viel Schnee in kurzer Zeit auf einem Hang zu liegen kommt, wächst die Belastung der Schneedecke durch das zusätzliche Gewicht schneller, als die Setzung und Verfestigung voranschreiten kann. Der Druck auf die unteren Schichten wird so groß, dass diese der Belastung nicht mehr standhalten. Bereits geringe Zusatzbelastung, z. B. das Gewicht eines Skifahrers, kann dazu führen, dass die Schneeschichten ins Rutschen geraten und es zu einem Lawinenabgang kommt. Besonders instabil sind Schneedecken mit großen Festigkeitsunterschieden zwischen den abgelagerten Schichten oder eine schwache Schneedecke, die das erste Mal durchfeuchtet wird. In die Schneedecke eingelagerte Zwischenschichten – beispielsweise aus Triebschnee, Schwimmschnee, Raureif oder Eislamellen – tragen zur Verschärfung der Situation bei und bilden die Gleithorizonte, auf denen die darüber liegende Schneedecke abrutscht.

[Bearbeiten | Quelltext bearbeiten]
Je tiefer die Temperatur, desto länger dauert es, bis sich der Neuschnee verfestigt. Lawinengefährdete Hänge behalten so ihr Gefahrenpotenzial lange bei. Bei einem raschen Temperaturanstieg kann die Lawinengefahr zunehmen – wegen der Durchfeuchtung bis auf den Boden, beziehungsweise durch die Umwandlung von Schneekristallen. Auf diese Weise entstehen insbesondere Nassschneelawinen. Grundsätzlich hat jeder Temperaturwechsel eine Veränderung der Lawinensituation zur Folge. Die Lawinengefahr ist am geringsten, wenn milde Temperaturwechsel die Verfestigung des Schnees beschleunigen. Letztlich gilt auch wegen der Mittagswärme die bergsteigerische Faustregel, dass man den Gipfel am Mittag oder vorher erreicht haben sollte, um rechtzeitig mit dem Abstieg zu beginnen.


Früher glaubte man, Lawinen würden von Hexen oder Geistern ausgelöst oder wären eine Strafe Gottes. Im Spätmittelalter kam natürlichen Ereignissen als Auslöser von Lawinen größere Aufmerksamkeit zu, wie z. B. laute Geräusche oder das Werfen von Objekten (Schneebällen) auf einen lawinengefährdeten Hang.
Heute werden Lawinen wissenschaftlich erforscht, und zwar durch Modellversuche im Labor und Gelände, Computersimulationen oder durch künstlich ausgelöste Lawinen (z. B. am WSL-Institut für Schnee- und Lawinenforschung SLF in Davos).
Um die Lawinengefahr möglichst korrekt einschätzen zu können, müssen Feldversuche unternommen werden. Dazu gehört z. B. das Erstellen von Schneeprofilen, um die verschiedenen Schichten und Formen der Schneekristalle zu analysieren, oder das Anlegen von Rutschblöcken. Lawinenforscher stützen sich auch auf meteorologische Daten, um so eine Aussage über die Art des Schnees machen zu können, was wiederum Einfluss auf die Lawinenbildung hat.
Ungefähr seit dem Jahr 2000 versucht man, Satellitenbilder in die Lawinenforschung zu integrieren. Aus dem Vergleich von Bildern, die in verschiedenen Wellenlängen des elektromagnetischen Spektrums aufgenommen wurden, kann man auf die Art der Schneekristalle schließen, weil jede Schneeart das Licht unterschiedlich stark reflektiert. Somit kann man die Schneedichte sowie Temperatur, Wasser- und Luftgehalt bestimmen. Der Nachteil der Satellitenbilder ist, dass sie nur die oberste Schneeschicht zeigen, was eine eingehendere Analyse der Lage erschwert.
In der Forschung werden noch viele weitere Methoden eingesetzt, um die Schneedecke, ihre Wechselwirkung mit der Atmosphäre sowie die Entstehung und Dynamik von Lawinen zu untersuchen und Maßnahmen zum Lawinenschutz bzw. Risikomanagement zu entwickeln. Dazu gehören z. B. Messinstrumente wie Radar, SnowMicroPen oder Nahe-Infrarot-Kameras, mit denen die Schichtung der Schneedecke analysiert wird, sowie seismische, akustische und optische Sensoren, mit denen Lawinenabgänge detektiert werden. Ebenso werden Computermodelle verwendet, die die Schneedecke simulieren (Snowpack, bzw. Alpine 3D) oder Lawinenabgänge berechnen (RAMMS) und wichtige Informationen für die Lawinenwarnung oder die Berechnung von Lawinengefahrenzonen liefern.



In den Alpenländern, den USA, Kanada und Japan wird ein großer Aufwand betrieben, um die Bevölkerung vor Lawinenabgängen zu schützen.

[Bearbeiten | Quelltext bearbeiten]
Die aktuelle Lawinengefahr für ein bestimmtes Gebiet wird in den Gefahrenstufen 1 bis 5 in der europäischen Lawinengefahrenskala angegeben. Diese aktuelle Lawinenwarnstufe wird in den Alpenländern von den Lawinenwarndiensten jeden Tag bekanntgegeben. Örtliche Lawinenkommissionen beraten die Behörden hinsichtlich der Erforderlichkeit von Schutzmaßnahmen für Siedlungen, Skigebiete und Verkehrswege.
Die Lawinengefahr kann jeweils nur anhand der lokalen Gegebenheiten an einem potentiellen Lawinenhang beurteilt werden. Der Beurteilung liegen

das Lawinenbulletin,
eigene Beobachtungen,[8]
meteorologische Entwicklungen,
der Schneedeckenaufbau,[9]
…
zu Grunde.

[Bearbeiten | Quelltext bearbeiten]

Lawinenschutz kann aufgrund der Eingriffsart in aktive und passive Maßnahmen eingeteilt werden:

[Bearbeiten | Quelltext bearbeiten]
Passive Schutzmaßnahmen dienen größtenteils der Prävention. So können in lawinengefährdeten Gebieten Baugenehmigungen entzogen werden oder Evakuierungen angeordnet werden. Zu den passiven Maßnahmen gehören auch Lawinengalerien sowie Umlenk- und Bremsverbauten zum Schutz von Straßen, Brücken und Bauwerken.


[Bearbeiten | Quelltext bearbeiten]
Aktive Schutzmaßnahmen sollen dem Entstehen von Lawinen vorbeugen. Den kostengünstigsten Schutz bieten Wälder. Deshalb gibt es besondere Aufforstungsprogramme (siehe dazu Schutzwald). Sind keine Bäume vorhanden, werden künstliche Schutzbauten (Lawinenverbauungen) erstellt. Dazu werden in Hängen, aus denen Lawinen abgehen können, Netze, Gitter oder windbrechende Barrieren aus Holz, Beton oder Stahl montiert. Dadurch wird die Schneedecke entweder unterteilt, so dass sich keine großen Schneebretter ablösen können, oder Schneeanhäufungen an kritischen Punkten werden verhindert. Auch künstliche Lawinenauslösungen gehören zu dieser Maßnahmengruppe. Mit Hilfe von Hubschraubern, Kanonen oder Seilbahnsystemen etc. wird Sprengstoff an kritische Stellen befördert, von fest installierten Masten abgeworfen oder die Schneedecke wird durch Zündung eines explosiven Gasgemisches destabilisiert,[10] um kleine kontrollierte Lawinen auszulösen. Dadurch wird die Schneedecke entlastet und man kommt unkontrollierten Lawinenabgängen zuvor.
Lawinenschutzmaßnahmen können im Hinblick auf die Wirkungsweise auch in permanente und temporäre Schutzmaßnahmen eingeteilt werden.

[Bearbeiten | Quelltext bearbeiten]


Temporäre Lawinenschutzmaßnahmen werden kurzfristig eingesetzt und auf Zeitpunkt, Ort und Ausmaß der Lawinengefahr abgestimmt. Dabei entscheiden auf Basis von Lawinenwarnung, Lagebeobachtung, -prognose und -berichten örtliche Lawinenkommissionen oder andere Gremien über

Sperren (Straßen, Skigebiete)
Evakuierungen
Künstliche Lawinenauslösung
Handsprengung, mit Hubschrauber, mit Sprengschlitten oder Gratausleger
DaisyBell (Hubschrauber)
Sprengseilbahn
Lawinensprengmast /-sprengturm
Lawinenwächter
Lawinenpfeife, Lawin Locker, Avalancheur
militärische Geräte (z. B. Minenwerfer, RAK-Rohr oder Haubitze)[11]
[Bearbeiten | Quelltext bearbeiten]
Unter permanentem Lawinenschutz versteht man technische, forstlich-biologische und raumplanerische Maßnahmen sowie die Aufklärung von betroffenen und interessierten Personenkreisen über Schnee- und Lawinenvorgänge.

Lawinenschutzbepflanzungen
Stützverbauungen (Schneebrücken, Netze)
Gleitschneeschutz (Holzböcke)
Verwehungsverbauten
Bremsbauwerke (Höcker, Keile)
Ablenk-, Leit-, Auffangdämme
Lawinengalerien
Lawinenschanzen bei Gebäuden
Schneekragen (historischer Bergbau)
[Bearbeiten | Quelltext bearbeiten]
Durch temporäre und passive Maßnahmen wird zum Zeitpunkt der Gefahr und innerhalb eines begrenzten Zeitraums durch Maßnahmen die Auswirkungen des Lawinenabganges auf Personen und Sachen zu vermeiden versucht.
Durch temporäre und aktive Lawinenschutzmaßnahmen wird die Steuerung des Ablaufs und die Auswirkungen des Lawinenabganges zu regeln versucht.
Durch permanente und passive Maßnahmen werden, ohne in den Prozess einzugreifen, durch bauliche Maßnahmen die Auswirkungen eines Lawinenabganges verringert. Durch Raumplanungsvorgaben werden Gefährdungsbereiche ausgewiesen und Bau- oder Besiedelungsverbote vorgegeben.
Durch permanente und aktive Lawinenschutzmaßnahmen wird versucht, den Prozess der Lawinenbildung und des Lawinenabganges zu verhindern, zu bremsen oder abzulenken.[12]
[Bearbeiten | Quelltext bearbeiten]

Warnsysteme können Lawinen erkennen, welche sich langsam entwickeln, z. B. Eislawinen bei Eisabbrüchen von Gletschern. Mittels interferometrischen Radaren, hochauflösende Kamerasystemen oder Bewegungssensoren kann ein instabiles Gebiet über einen langen Zeitraum von einigen Tagen hin zu Jahren beobachtet werden. Durch die Interpretation der Daten können Experten bevorstehende Abbrüche erkennen und Maßnahmen veranlassen. Mittels solchen Systemen (z. B. die Gletscherüberwachung am Weissmies in der Schweiz[14]) können Ereignisse einige Tage im Voraus erkannt werden.

[Bearbeiten | Quelltext bearbeiten]
Moderne Radartechnologie erlaubt es, große Gebiete zu überwachen und Lawinen bei allen Witterungsbedingungen bei Tag oder Nacht zu lokalisieren. Komplexe Alarmsysteme können in kürzester Zeit die Lawine detektieren und so ein gefährdetes Gebiet unmittelbar und automatisch sperren (z. B. Straßen und Bahnen) oder evakuieren (z. B. Baustellen). Ein solches Projekt befindet sich beispielsweise in der Schweiz auf der einzigen Zufahrt nach Zermatt.[13] Zwei Radare überwachen eine Bergflanke unter welcher die Zufahrtsstraße durchführt. Im Fall einer Lawine wird die Straße mit mehreren Barrieren und Ampeln automatisch und innerhalb von Sekunden gesperrt, so dass keine Personen zu Schaden kommen können.

[Bearbeiten | Quelltext bearbeiten]

Lawinen bedrohen nicht nur Siedlungen, sondern auch den Menschen, der sich in der Natur bewegt. Vor allem durch Schneebrettlawinen werden regelmäßig Skitourengeher, Snowboarder, Schneeschuhgeher und andere Wintersportler erfasst. Allein in der Schweiz sterben jeden Winter durchschnittlich 22 Personen in Lawinen.[15] Die meisten Opfer waren allerdings zu beklagen, wenn große Lawinen Dörfer trafen und wie im Lawinenwinter 1950/51 die Leute in ihren Häusern überraschten.

[Bearbeiten | Quelltext bearbeiten]

Im verschneiten alpinen Gelände ist eine potentielle Lawinengefahr gegeben. Das gesicherte Skigebiet zu verlassen bedeutet ein gewisses Risiko in Kauf zu nehmen. Viele alpine Wintersportarten nutzen aber gerade den Naturraum als Handlungsfeld. Das erfordert eine präventive Auseinandersetzung mit dem Risikofaktor durch strategische Entscheidungssysteme, auch bezeichnet als strategische Lawinenkunde. Strategische Lawinenkunde ist der systematische Umgang mit dem Lawinenrisiko innerhalb eines Risikomanagements. Als wegweisend zu ihrer Entwicklung war die Anfang der 1990er Jahre entwickelte Formel 3×3 und elementare Reduktionsmethode nach Munter.
Die Komplexität der Faktoren, die zur Lawinenbildung führen (speziell in der Schneedecke), überfordern die kognitiven Fähigkeiten des Menschen. Trotzdem muss eine „JA-oder-NEIN“ Entscheidung für die Begehung eines Hanges getroffen werden. Wichtig ist dabei, dass nicht nur Experten, sondern auch laienhafte Winterbergsteiger solche Entscheidungen treffen müssen. Je komplexer eine Entscheidung, desto wichtiger ist es, einfache Entscheidungs- und Handlungskonzepte parat zu haben. Dies geschieht durch die Anwendung von Risikomanagement-Systemen und Entscheidungsstrategien, die wahrscheinlichkeitsorientiert arbeiten. Um das Risiko entsprechend einschätzen zu können, sind ausreichendes Wissen, Kompetenz und Erfahrung nötig. Eine gute körperliche Kondition ermöglicht es, entsprechende Entscheidungen auch umsetzen zu können.
Weiterhin zählt zur Notfallprävention eine ausreichende, zweckmäßige und erprobte Sicherheitsausrüstung. Dabei haben sich folgende Geräte als Mindeststandard für jeden Winterbergsteiger etabliert:

LVS-Gerät
Lawinenschaufel
Lawinensonde
Erste-Hilfe-Ausrüstung
Kommunikationsmittel zur Verständigung der Bergrettungsdienste (Funkgerät, Handy, Trillerpfeife, Leuchtmittel)
Ergänzend dazu existieren der Avalanche-Ball, Lawinenairbag und die Avalung. Durch Einhalten von Sicherheitsabständen, gute Spuranlage und vorsichtige Fahrweise bei der Abfahrt in einem Hang kann das Risiko weiter minimiert werden. Halteriemen von Stöcken und Ski sollten vor einer Abfahrt gelöst werden, da sie im Verschüttungsfall den Sportler nach unten ziehen können.
Von behördlicher Seite können Präventionsmaßnahmen wie zunächst die Sperrung einzelner Gebiete, später auch kontrolliertes Auslösen von Lawinen durch Sprengung (Lawinen-Sicherungstrupps) in Betracht kommen.

[Bearbeiten | Quelltext bearbeiten]

Wenn man von einer Lawine erfasst zu werden droht, kann man auf mehrere Handlungsoptionen zurückgreifen, die allerdings keine Erfolgsgarantie beinhalten. Es erhöht jedenfalls die Überlebenschancen, wenn der Wintersportler möglichst wenig tief verschüttet wird und eine Atemmöglichkeit hat. Eine früher häufig empfohlene „Schussflucht“ (also das schnelle Fahren in der Falllinie, um der Lawine zu enteilen) scheint nur selten erfolgreich gewesen zu sein, da Lawinen generell sehr schnell sind und oft der komplette Hang aufbricht. Falls man sich am Rand eines Lawinenhangs befindet, kann man versuchen, durch schnelle Fahrt weg von den Schneemassen das Verschüttungsrisiko zu mindern. Auch ein geschicktes „Reiten“ mit Ski auf der Lawine dürfte nur wenigen Personen geglückt sein. Ebenfalls empfohlene „Schwimmbewegungen“ in den Schneemassen sind nach Aussagen von Verschütteten sinnlos. Erfolgversprechender ist, mitgeführte Rettungsmittel sofort zu aktivieren. Dies sind zum Beispiel ein „Lawinen-Airbag“ (durch Ziehen am Auslösegriff wird eine Gaspatrone gezündet, welche einen oder mehrere Luftkissen am Rucksack aufbläst), der eine tiefe Verschüttung verhindern kann oder die „Avalung“ (man nimmt eine Art Schnorchel in den Mund und kann so auch unter dem Schnee in der Regel atmen – die Ausatemluft wird am Rücken abgeleitet), welche die Erstickungsgefahr verringert. Ski, Snowboard und Stöcke wirken wie ein Anker innerhalb einer Lawine und können eine Person tiefer in die Schneemassen hinein ziehen. Deswegen sollte der Sportler versuchen sein/e Ski/Snowboard zu lösen und die eventuell vorhandenen Stöcke wegzuwerfen. Das Verwenden von Fangriemen ist in diesem Kontext zu vermeiden, da sie wie eine Ankerkette wirken können.
Oft sind weitere Personen vor Ort, die nicht vom Lawinenabgang betroffen sind. Da die Überlebensrate von Lawinenverschütteten schnell abnimmt, kann die „Kameradenhilfe“ durch Anwesende lebensrettend sein. Die organisierte Bergrettung benötigt schon aufgrund der Alarmierungs- und Ausrückezeiten meist länger als eine Viertelstunde bis zur Ankunft. Die Hilfe vor Ort beginnt mit einer möglichst genauen Beobachtung der Verschüttung. Die Registrierung von Erfassungspunkt und Verschwindepunkt ermöglicht Rückschlüsse auf den primär abzusuchenden Bereich. Parallel sollte ein korrekter Notruf abgesetzt werden.

[Bearbeiten | Quelltext bearbeiten]

→ Hauptartikel: Lawinenverschüttetensuche
Unter Beachtung des Eigenschutzes (Nachlawinen) muss dann zügig die Rettung eingeleitet werden. Man sucht die Lawinenoberfläche nach dem Stillstand zuerst nach Kleidungsstücken oder Ausrüstungsteilen ab. Mancher Teilverschüttete kann so gefunden werden. Gleichzeitig sucht man mit elektronischen LVS-Geräten. Es ist sicherzustellen, dass alle Teilnehmer vor der Suche ihre LVS von Senden auf Empfangen umschalten, um sich nicht gegenseitig zu orten. Nach der Ortung des Verschütteten setzt man Lawinensonden ein, um den Standort noch genauer zu lokalisieren. Da man mit der Lawinensonde auch die Verschüttungstiefe feststellt, kann man unterhalb der Sonde zu graben beginnen und sich waagrecht zum Verschütteten vorarbeiten. Man achtet darauf, ob eine Atemhöhle vorhanden war und beginnt mit Maßnahmen der Ersten Hilfe. Falls der Patient unterkühlt ist, muss er vorsichtig geborgen werden. Wird er zu stark bewegt und dadurch der Kreislauf angeregt, fließt unterkühltes und äußerst sauerstoffarmes Blut in Richtung der inneren Organe. Es droht der sog. Bergungstod. Der Bergrettungsdienst kann neben den oben genannten Hilfsmitteln auch – falls vorhanden – das RECCO-System und Lawinensuchhunde einsetzen. Der Einsatz von Lawinenhunden wäre am sinnvollsten gleich zu Anfang, bevor noch ein Mensch den Lawinenkegel betreten hat, was aber in den seltensten Fällen zu verwirklichen ist.

[Bearbeiten | Quelltext bearbeiten]
„Die Wahrscheinlichkeit, eine Verschüttung länger als zwei Stunden zu überleben, liegt bei drei bis zehn Prozent.“ (erhoben im Alpenraum). Versorgung mit Sauerstoff, der etwa durch lockeren Schnee von unten nachsickert, ist eine gute Voraussetzung, dem Verschütteten zu helfen, seine Körpertemperatur möglichst lange möglichst wenig absinken zu lassen. Rückatmung von ausgeatmetem Kohlenstoffdioxid in einer abgeschlossenen Atemhöhle führt zu Bewusstlosigkeit. Unter 32 °C Körpertemperatur kommt es zu Herzrhythmusstörungen, unter 24 °C erlöschen Lebensfunktionen meist dauerhaft. Wiedererwärmen einer tief (unter 30 °C) unterkühlten Person ist ein intensivmedizinischer Prozess, der stunden- bis tagelang dauern kann. Am längsten überlebte eine Frau, die 1974 in der Lombardei 48 Stunden verschüttet war.[16]


In den letzten 100 Jahren gab es in den Alpen im Schnitt jährlich 100 Tote durch Lawinenabgänge. Einige besonders schwere Unglücke weltweit sind hier verzeichnet.

16. Oktober 2014: Im Zusammenhang mit dem Zyklon «Hudhud» kommt es zu Schneefällen im Himalaya. Mindestens 21 Bergsteiger kommen ums Leben.
April 2014: 16 Nepalesen sterben in einem Eisfall am Mount Everest.
23. September 2012: Nach dem Abgang zweier Lawinen am Manaslu auf das Lager III in 7000 m Höhe um 5 Uhr morgens sterben 11 von ca. 30 Bergsteigern.[17]
7. April 2012: Eine Lawine begräbt auf einem pakistanischen Militärstützpunkt nahe dem Siachengletscher im Bezirk Gayari 124 Soldaten und 11 Zivilangestellte. Trotz Rettungsaktion überlebt niemand.[18][19]
3. Januar 2010: Eine Skitourengruppe löste im Diemtigtal eine Lawine aus, durch die eines der Mitglieder verschüttet wurde. Während der Bergung wurden zwölf Personen bei einer Nachlawine aus dem Gegenhang verschüttet, von denen sieben das Ereignis nicht überlebten.
20. September 2002: Bei einem Lawinenunglück in der Karmadon-Schlucht in Nordossetien kommen 150 Menschen ums Leben.
28. Dezember 1999: Bei einem Lawinenunglück im Jamtal (Gemeindegebiet von Galtür, Österreich) sterben neun Teilnehmer einer geführten DAV-Summit-Club-Gruppe.[20]
23. Februar 1999: Die Lawinenkatastrophe von Galtür (Tirol) fordert 38 Menschenleben.
21. Februar 1999: Das Lawinenunglück von Evolène im Kanton Wallis in der Schweiz fordert 12 Tote.
Januar 1998: Bei einer Wanderung in den französischen Alpen kommen neun Schüler und zwei Lehrer ums Leben.
Februar 1991: Auf der italienischen Seite des Mont Blanc begräbt eine Eislawine sieben Skifahrer unter sich.
1991: Eine Lawine in Bingöl (Türkei) verwüstet mehrere Ortschaften, 200 Menschen sterben.
1972: Die Überlebenden des Uruguayan-Air-Force-Flug 571 vom 13. Oktober wurden am 29. Oktober in ihrem als Schutzbehausung dienenden Flugzeugwrack von einer Lawine überrascht. Von den bis dato 27 Überlebenden des Flugzeugabsturz starben acht Menschen durch die Lawine.
April 1970: Auf dem Plateau d’Assy in den Savoyer Alpen sterben 74 Menschen, darunter 56 Kinder, in einer Lawine.
24. Februar 1970: Eine Lawine in Reckingen im Wallis reißt 30 Menschen in den Tod.
10. Februar 1970: Lawinenunglück in Val-d’Isère, 39 Tote.
15. Mai 1965: Eine Lawine, die über die Sonnenterrassen des Hotels Schneefernerhaus und die Liftanlagen am Zugspitzplatt hinwegging, forderte 10 Tote und 21 Verletzte. Dieses Ereignis gab den Anstoß zur Einführung eines staatlichen Lawinenwarndienstes und lokaler Lawinenkommissionen in Bayern.
11. Januar 1962: Eine Lawine löst sich vom Huascarán, dem höchsten Berg von Peru. Die Stadt Yungay wird zerstört, weitere Ortschaften werden von einer Flutwelle erreicht, die durch in einen Fluss gefallene Schneemassen hervorgerufen wurde. Insgesamt sterben etwa 4.000 Menschen (nach anderen Quellen 12.000 bis 20.000 Menschen), damit ist es das schlimmste jemals von Schnee verursachte Unglück.
11. Januar 1954 – Vorarlberg – Als eine Lawine den Ort Blons (Vorarlberg) zerstört, werden 118 Menschen in ihren Häusern verschüttet. Eine zweite Lawine neun Stunden später begräbt einen Großteil der Rettungsmannschaften unter sich. 55 Menschen können schließlich nur noch tot geborgen werden, die sterblichen Überreste von zwei weiteren Opfern bleiben verschollen.
11. Januar 1954: Große Lawinenkatastrophe in der Schweiz. 23 Einheimische und 10 Touristen sterben.[21]
1950/1951 (Lawinenwinter 1951) – 265 Menschen verlieren in den Alpen ihr Leben durch Lawinenabgänge.
7. Februar 1945: Lawinenunglück auf der Eppzirler Alm, 18 Gebirgsjäger finden im Ski-Aufstieg zur Eppzirler Scharte den Tod.[22]
5. Dezember 1935: 88 Tote und 42 Verletzte bei einem Lawinenunglück in Kukiswumtschorr in den Chibinen (nahe Kirowsk).
9. Januar 1918: Das schwerste Lawinenunglück Japans ereignet sich, als das halbe Dorf Mitsumata (heute Teil von Yuzawa) von einer Lawine begraben wird und 158 Menschen umkommen.[23]
1915 bis 1918: Im Alpenkrieg des Ersten Weltkriegs sterben mindestens 10.000 Soldaten an der österreichisch-italienischen Front in den Dolomiten durch Lawinenabgänge. Viele Lawinen werden vorsätzlich vom Gegner ausgelöst. Im Winter 1916 sind die Verluste durch Lawinen und Erfrierung höher, als durch die Kampfhandlungen (→ Lawinenkatastrophe vom 13. Dezember 1916).
Bei einem Lawinenabgang im März 1916 am Vršičpass (heute Slowenien) starben 170 bis 300 russische Kriegsgefangene und 10 bis 80 österreichische Soldaten.[24]
1. März 1910: In Wellington, WA (USA) wurden zwei Züge durch eine Lawine zu Tal gerissen, wobei 96 Menschen starben. → Hauptartikel: Eisenbahnunfall von Wellington
24. Februar 1844: In Neukirch im Schwarzwald wird der Königenhof durch eine Lawine verschüttet. 17 Menschen sterben.
Lawinenjahr 1720 in der Schweiz: Rund 300 Tote.[25]

Auch bei anderen Phänomenen spricht man von lawinenartigen Vorgängen, wenn die Vorgänge selbstverstärkend sind. Diese Vorgänge haben wie Schneelawinen, Eislawinen oder Schlammlawinen gemeinsame Verhaltenstypen („Universalität“, „Selbstorganisation“). Zur Auslösung solcher Vorgänge reichen schwer zu kontrollierende kleine Ursachen.
Quantitative physikalische Theorien dazu hat der dänische Physiker Per Bak aufgestellt.


Bergsturz, Geröllstrom
Murgang (Rüfe), Schlamm- oder Gesteinsstrom
Lahar, vulkanischer Schlamm- oder Schuttstrom

In Österreich besteht seit Mitte Dezember 2011 ein eigenes technisches Regelwerk[26], in dem der "Stand der Technik im Lawinenschutzbau zusammengefasst wurde.

ONR 24805 – Permanenter technischer Lawinenschutz – Benennung und Definitionen sowie statische und dynamische Einwirkungen;
ONR 24806 – Permanenter technischer Lawinenschutz – Bemessung und konstruktive Ausgestaltung;
ONR 24807 – Permanenter technischer Lawinenschutz – Überwachung und Instandhaltung.

Europäische Gefahrenskala für Lawinen
Lawinenkommission, Lawinenbulletin
Liste von Lawinenunglücken
Lawinenauslösung durch Sprengstoff

Martin Engler, Jan Mersch: Die weiße Gefahr – Schnee und Lawinen. Verlag Martin Engler, Sulzberg 2001, ISBN 978-3-9807591-1-3.
Michael Falser: . In: kunsttexte.de 3/2010 (PDF; 7,8 MB).
Paul Föhn:  In: Historisches Lexikon der Schweiz.
Hans Haid: Mythos Lawine: Eine Kulturgeschichte. Studienverlag, Innsbruck 2008, ISBN 978-3-7065-4493-1.
Rudi Mair, Patrick Nairz: Lawine. Die 10 entscheidenden Gefahrenmuster erkennen. Tyrolia, Innsbruck 2010, ISBN 978-3-7022-3086-9.
Werner Munter: 3×3 Lawinen. 4. völlig neubearbeitete Auflage. Verlag Pohl & Schellhammer, Garmisch-Partenkirchen 2009, ISBN 978-3-00-010520-3.
Sergio Pistoi: Lawinenschutz aus dem All? In: Spektrum der Wissenschaft 1/06, S. 84 ff.
Florian Rudolf-Miklau / Siegfried Sauermoser (Hrsg.): Handbuch Technischer Lawinenschutz. Ernst, Wilhelm & Sohn, Berlin 2011, ISBN 978-3-433-02947-3.



 im Katalog der Deutschen Nationalbibliothek
Glossar Lawinen


Lawinenforschung:


Lawinengefahr:

 SLF-Merkblatt (PDF; 1 MB)
 SLF-Merkblatt (PDF; 1,3 MB)
Lawinenschutz:

  SLF-Merkblatt (PDF; 1,1 MB)
  SLF-Merkblatt (PDF; 2,3 MB)
  SLF-Merkblatt (PDF; 1,7 MB)
  (Memento vom 18. Februar 2015 im Internet Archive). lawinen-warn-dreieck.de
 (PDF-Datei; 424 kB)
. Niederösterreichischer Zivilschutzverband – ein Überblick
Lawinen und Recht:

  SLF-Publikation (PDF; 2,5 MB)
 


Unter einer Anomalie versteht man in der Meteorologie die Abweichung einer meteorologischen Größe wie der Jahresmitteltemperatur oder der Niederschlagsmenge von ihrem Mittelwert. Meist handelt es sich dabei um einen zeitlichen Mittelwert, doch auch bei Abweichungen von räumlichen Mittelwerten spricht man von Anomalie. Eine Anomalie kann unvermittelt auftreten und über mehrere Jahre anhalten.[1]
Beispielsweise kann die Hitzewelle 2003 als Anomalie bezeichnet werden.[2]


Singularität (Meteorologie)
Hitzewelle
Kältewelle
Unwetter

Der Brockhaus. Wetter und Klima. Brockhaus, Leipzig/Mannheim 2009, ISBN 978-3-7653-3381-1



Unwetter, auch Extremwetterereignis oder  Wetteranomalie ist ein Sammelbegriff für extreme Wetterereignisse. Diese Wetterereignisse bewirken oft hohe Sachschäden, Katastrophen und Lebensgefahr für viele Menschen.




[Bearbeiten | Quelltext bearbeiten]
Extremereignisse[1] im Sinne der Meteorologie sind Wetterlagen, die in ihrem Verlauf (dargestellt in Wetterelementen) signifikant vom Durchschnitt abweichen. Als Basis dient eine klimatologische Normalperiode, ein geographischer Bezug zu einer Klimaklassifikation, als Maß der Ausnahmeerscheinung die Jährlichkeit der Wetterelemente und anderer Wirkungsfaktoren (wie die Hochwasserpegel), wie auch der Versicherungsschaden oder der gesamtwirtschaftliche (versicherter und unversicherter Direktschaden, Folgeschäden und Wiederherstellung, einschließlich der Opfer). Dem Begriff liegt keinerlei präzise Definition zugrunde, sondern ist ein pragmatischer Ausdruck der Dokumentation von Klima und Wetter in der Klimafolgenforschung oder Versicherungswesen: „Extremereignisse sind Ereignisse, die stark vom Durchschnitt abweichen und dadurch außergewöhnlich sind. Es hängt nur von der konkreten Anwendung ab wie stark diese Abweichung tatsächlich sein muss, um ein Ereignis als extrem einzustufen.“[2]
Extremereignisse sind von besonderer historischer und wirtschaftlicher Bedeutung. Als klimatologische Indikatoren sind sie aber ungeeignet: zum einen treten sie sehr unregelmäßig ein, und zum anderen muss der Mittelwert einer Normalperiode bekannt sein, um eine Wetteranomalie als solche klassifizieren zu können. Der aktuelle langfristige Mittelwert setzt sich aber genau aus den eintretenden Wetterereignissen zusammen, aktuelle Extremereignisse können also nur mit abgelaufenen Bemessungszeiträumen verglichen werden / in Kontexte gesetzt werden.[3]

[Bearbeiten | Quelltext bearbeiten]
Der Deutsche Wetterdienst definiert folgende Ereignisse als Unwetter (Stufe 3 der Kriterienskala im Bereich 0–4), wenn die genannten Schwellen überschritten werden:[4]



Bezeichnung

Kriterien zu Unwetterwarnungen


Gewitter

mit Hagel (Körner größer als 1,5 cm) oder mit Starkregen oder mit Sturm oder Orkan.


Sturm

Orkanartige Böen von 11 Bft. (in 10 m Höhe gemessen)


Orkan

mind. 12 Bft. (in 10 m Höhe gemessen)


Schneeverwehung

lockere Schneedecke (größer als 10 cm) oder Neuschnee mit Böen über 8 Bft


Starkregen

mehr als 25 l/m² in 1 Stunde oder mehr als 35 l/m² in 6 Stunden


Dauerregen

mehr als 40 l/m² in 12 Stunden oder mehr als 50 l/m² in 24 Stunden oder mehr als 60 l/m² in 48 Stunden


Glatteis

verbreitete Bildung von Glatteis oder auch überfrierender Nässe mit Einfluss auf den Verkehr


Schneefall

mehr als 10 cm in 6 Stunden oder mehr als 15 cm in 12 Stunden


Tauwetter

Dauerregen bei einer Schneedecke von mehr als 15 cm

Folgende Ereignisse werden noch für Unwetterwarnungen seitens der meteorologischen Dienste herangezogen:

Hagelschlag
Nebel
Extrem hohe Temperatur (Hitzewelle, Hitzeanomalien) extrem niedrige Temperatur (Kältewelle, Kälteanomalien)
Dürre (auch mit der Folge von Waldbrandgefahr, zum Beispiel: Dürre und Hitze in Europa 2018)
Lawinengefahr
Folgende Ereignisse werden allgemein noch als speziellere Unwetter angesehen:

Schneesturm
Sandsturm
Wirbelsturm (Kleintrombe, Tornado, Tropischer Wirbelsturm – die Bezeichnungen Sturm/Orkan stehen als Name für die Stärke parallel dazu)
Darüber hinaus wurden seit dem Jahr 1993 von der Internationalen Zivilluftfahrt-Organisation (ICAO) neun Volcanic Ash Advisory Center eingerichtet, die weltweit den Luftraum auf Vulkanasche überwachen und gegebenenfalls den Luftverkehr warnen. Diese gehören wegen der meteorologischen Prognose der Zugbahnen der Aerosolemissionen zum Themenfeld.


→ Hauptartikel: Liste nationaler und internationaler meteorologischer Dienste
amtlich:

Deutscher Wetterdienst (DWD)
Meteoalarm der EUMETNET
Bundesamt für Meteorologie und Klimatologie (MeteoSchweiz)
Zentralanstalt für Meteorologie und Geodynamik (ZAMG, Österreich)
privat:

KATWARN (Warn- und Informationsdienst)
Österreichische Unwetterzentrale (UBIMET)
Skywarn, ehrenamtliches Beobachtungsnetz
Unwetterzentrale Deutschland
Wetter-Alarm, kostenloser Unwetterwarndienst von den Kantonalen Gebäudeversicherungen, Mobiliar und SF Meteo
WIND Unwetterwarnsystem “Weather Information on Demand”

Zwischen 1980 und 2016 haben sich z. B. in Deutschland nach dem Versicherungskonzern Münchener Rück die durch Extremwetter (Gewitter) verursachten Schäden von durchschnittlich rund 580 Mio. auf über 2 Mrd. Euro praktisch vervierfacht.[5]
Bis zum Jahr 2100 könnten laut einer in der Fachzeitschrift The Lancet Planetary Health veröffentlichten Studie des Joint Research Centre der Europäischen Kommission jährlich bis zu zwei Drittel der europäischen Bevölkerung durch Wetterextreme betroffen sein, ohne weitere Anpassungsmaßnahmen an den weltweiten Klimawandel zwischen 2071 und 2100 in der EU, Schweiz, Norwegen und Island pro Jahr 80.000 bis 240.000 Menschen sterben. Zwischen 1981 und 2010 sind hiernach jährlich rund 3.000 Europäer durch Wetterkatastrophen um ihr Leben gekommen. 99 % der Wetter-Todesopfer zwischen 2070 und 2100 könnten aufgrund von Hitze sterben.[6]
Anfang September 2017 brachte mit über 6 Mio. Betroffenen im US-Bundesstaat Florida der Hurrikan Irma eine der größten Evakuierungsaktionen mit sich.[7][8]
Neben Schäden, Verletzten und Toten, sorgen Unwetter auch für Vertreibung von Menschen. 2016 waren fast 24 Millionen wegen Wetterextremen auf der Flucht und das vor allem in armen Gebieten. In reicheren Ländern waren dagegen nur knapp eine Million Menschen im Jahr betroffen.[9]


Liste historischer Katastrophen (weltweit, unter anderem auch Wetterereignisse)
Liste von Wetterereignissen in Europa
Hochwasser und Naturkatastrophen in Sachsen
Liste der Sturmfluten an der Nordsee
Hochwasser: Siehe bei den einzelnen Flüssen, zum Beispiel Rhein#Hochwasser, Elbe; siehe auch
Donauhochwasser 2002,
Hochwasser in Mitteleuropa 2013,
Hochwasser in West- und Mitteleuropa 2021
Omegalage, mit einer Liste der hochstabilen Hochs in Europa (Hitzeanomalien, Dürren)
Vb-Wetterlage, mit einer Liste typischer Südstau-Starkniederschlagsereignisse im Alpen- und Karpatenraum
Bedeutende Tornadoereignisse (Beispiele auch für Europa)

Hyperkan
Liste von Wetterereignissen in Europa
Wetterrekorde
Anomalie (Meteorologie)

Karl W. Steininger, Christian Steinreiber, Christoph Ritz (Hrsg.): Extreme Wetterereignisse und ihre wirtschaftlichen Folgen. Anpassung, Auswege und politische Forderungen betroffener Wirtschaftsbranchen. 2. Auflage. Springer, Berlin / Heidelberg 2005, ISBN 3-540-23477-2. 
Christian Rohr: Extreme Naturereignisse im Ostalpenraum: Naturerfahrung im Spätmittelalter und am Beginn der Neuzeit. In: Umwelthistorische Forschungen. Band 4. Böhlau, 2007, ISBN 978-3-412-20042-8. 



: Informationen über Unwetter weltweit
: WDR-Doku (YouTube-Kanal)
Ben Clarke, Friederike Otto: Über Extremwetter und den Klimawandel berichten: Ein Leitfaden für Medien. World Weather Attribution 2022. ( PDF).





Dieser Artikel behandelt das Wetterereignis. Zu weiteren Bedeutungen siehe Sturmflut (Begriffsklärung).


Eine Sturmflut ist ein durch Sturm mit auflandigen Winden erhöhter Tidenstrom.



DIN 4049-3 (2005) definiert eine Sturmflut als ein „durch starken Wind verursachtes Ansteigen des Wassers an der Meeresküste und in den Flussmündungen im Küstengebiet, wenn die Wasserstände einen bestimmten Wert überschreiten.“[1]
Die in Deutschland weitgehend anerkannte Klassifikation von Nordseesturmfluten für Emden, Bremen und Hamburg vom Bundesamt für Seeschifffahrt und Hydrographie (BSH) bezeichnet das Erreichen von 1,5 bis 2,5 m über dem mittleren Hochwasser (MHW) als „Sturmflut“; von 2,5 bis 3,5 m über dem MHW als „schwere Sturmflut“, und bei über 3,5 m als eine „sehr schwere Sturmflut“.[1][2] Das mittlere Hochwasser ist eine Bezeichnung für den aus einer hinreichend langen Beobachtungsreihe abgeleiteten mittleren Hochwasserstand.



Sturmfluten treten an der deutschen Küste verstärkt im Frühjahr und im Herbst auf. Die Deutsche Bucht ist nach Ansicht des Bundesamts für Seeschifffahrt und Hydrographie (BSH) eines der am stärksten von Sturmfluten bedrohten Gebiete weltweit. Bedingt durch die Geographie der Nordseeküste und den Trichtereffekt der Elbmündung tritt dieses Phänomen dort häufiger auf als anderswo.
Sturmfluten bedeuten eine Gefahr für die betroffenen Küstenregionen durch Überschwemmungen, soweit sie die von Menschen geschaffenen Deiche durchbrechen. Sturmfluten verleihen Wellen eine erhebliche Energie. Im Mittelalter veränderten im Nordseebereich Sturmfluten den Küstenverlauf und schufen großräumige Meeresbuchten wie den Jadebusen und den Dollart.



Sturmfluten und ihre Wirkungen sind seit der Römerzeit bekannt. Zuverlässige Angaben gibt es dabei – bis in die neuere Zeit hinein – allenfalls für das Ausmaß der jeweiligen Landverluste. Welche Sturmflut im Hinblick auf die Zahl der Toten die verheerendste war, ist nicht bekannt. Die früheren Angaben zur Zahl der Toten sind sehr widersprüchlich; es ist zu vermuten, dass einige Zahlen im Hinblick auf die mittelalterliche Siedlungsdichte an der Nordsee deutlich zu hoch angesetzt wurden.
Auf um 340 v. Chr. wird die große Cimbrische Flut datiert. Um 120 bis 115 v. Chr. scheinen in Jütland durch eine Sturmflut viele Menschen umgekommen zu sein. Es bestehen aber große Zweifel, dass dies einer der Faktoren für die Völkerwanderung der Kimbern und Teutonen gewesen sein könnte, da gewichtigere Gründe notwendig sind, dass ganze Völker ihren Lebensraum aufgeben, als eine Sturmflut an der Küste.[3]
Um 1134 ereignete sich eine Sturmflut in Flandern. Als Folge davon entstand ein Seearm (Zwin), der sich bis nach Brügge erstreckte und der Stadt später über das kanalisierte Flüsschen Reie den Zugang zum Meer bot. Bei der Julianenflut starben im Jahre 1164 im Gebiet der Weser und Elbe und in Ostfriesland um die 20.000 Menschen.[4][5]
Die bedeutendsten Sturmfluten des Mittelalters sind die Erste Marcellusflut des Jahres 1219 und die Zweite Marcellusflut oder Grote Mandränke von 1362. In beiden Fluten veränderte sich der Küstenverlauf drastisch: Inseln wurden zerstört, geteilt oder geschaffen und große Landstriche des Festlands gingen über Nacht verloren. Es gab Zehntausende von Toten und Dutzende verlorene Dörfer. In der Ersten Marcellusflut wurde die Zuidersee, das heutige IJsselmeer, geschaffen, wobei etwa 36.000 Menschen starben. Bei der Groten Mandränke gehen die – vielleicht etwas hoch gegriffenen – Schätzungen bis 100.000 Todesopfer. Sicher ist, dass 30 Dörfer in einer Nacht vernichtet wurden, infolge der Sturmflut durch die zerstörten Deiche insgesamt 44 Dörfer. Viele andere Dörfer wurden für viele Jahre von der Umgebung abgeschnitten und wurden zu Inseln, so auch Asel bei Wittmund.
Seit dem Mittelalter hat sich auf niederländischem Gebiet in jedem Jahrhundert eine Flutkatastrophe ereignet, bei der hoher Schaden entstand und viele Opfer zu beklagen waren:

1347 und 1376 rissen die Sturmfluten weite Landesteile weg und vernichteten hunderte Dörfer mit ihren Bewohnern, der Dollart entstand und der Jadebusen wurde um ein Vielfaches vergrößert.
Im 15. Jahrhundert war es die Elisabethenflut 1421,
im 16. Jahrhundert die Allerheiligenflut 1570,
im 17. Jahrhundert die Burchardiflut vom 11. Oktober 1634. Durch das nahende Ende der Kleinen Eiszeit wurden die wirtschaftlichen Verhältnisse stabiler; nach der Burchardiflut fand eine wichtige Wende im Deichbau statt, siehe Geschichte des Deichbaus.
Im 18. Jahrhundert folgte die Weihnachtsflut von 1717,
im 19. Jahrhundert die Februarflut von 1825.
Die Flutkatastrophe von 1953 gilt als die schwerste Sturmflut des 20. Jahrhunderts in den Niederlanden und England. Vom niederländischen Wetteramt wird nur diese zur Kategorie der schweren Sturmfluten im 20. Jahrhundert gezählt, während sich die in Deutschland besonders verheerende Flut vom 17. Februar 1962 in den Niederlanden lediglich als mittlere Sturmflut äußerte.
Die Opfer der Sturmfluten von 1953 (vor allem in den Niederlanden) und der Sturmflut 1962 (vor allem in Deutschland und Dänemark) waren Anlass für umfangreiche Küstenschutzmaßnahmen wie die Deltawerke. Diese enormen Investitionen in den Küstenschutz, insbesondere durch Deichbau und Sperrwerke, haben dafür gesorgt, dass die jüngsten Sturmfluten weitaus weniger Schäden verursachten als frühere, niedrigere Sturmfluten.

Siehe auch: Liste von Sturmfluten an der Nordsee

1304: Allerheiligenflut an der Ostsee, 271 Tote
1824: Sturmhochwasser in Sankt Petersburg, 10.000 Tote
1872: Ostseesturmhochwasser, 271 Tote. Die Düne, die Wustrow mit Alt-Gaarz verband, wurde weggespült, Wustrow wurde zur Insel.
12. November 1970: Ein Zyklon mit Windgeschwindigkeiten von bis zu 230 km/h und meterhohen Flutwellen trifft Bangladesch (damals Ostpakistan): 300.000 Tote.
29. April 1991: Wirbelsturm Gorky drückt mit Windgeschwindigkeiten bis zu 250 km/h in Bangladesch eine bis zu sechs Meter hohe Flutwelle weit in das Land. Nach offiziellen Quellen starben dabei 138.000 Menschen.
vergrößern und Informationen zum Bild anzeigenWeihnachtsflut 1717 (wahrscheinlich)



Für die Nordsee gibt es erst seit 1840 regelmäßige Aufzeichnungen über Wasserstände; nach Einführung automatischer Pegelschreiber entstanden ab 1880 kontinuierliche Aufzeichnungen. Aus solchen hinreichend langen Beobachtungsreihen werden durchschnittliche Wasserstände berechnet und Eckdaten abgeleitet, die für die Wasserstandsvorhersage verwendet werden, wobei meteorologische Daten die Vorhersagen erleichtern.
Als Wasserstand (WS) wird die aktuelle Höhe eines natürlichen oder künstlichen Wasserspiegels in Bezug auf einen Referenzpegel zur Wasserstandsmessung bezeichnet, wobei länderabhängig unterschiedliche Höhensysteme und Referenzpunkte benutzt werden. Für die Nordsee ist dabei der Amsterdamer Pegel (NAP; Normaal Amsterdams Peil) der wichtigste Bezugspunkt.
Mittelwasser (MW) stellt bei der Wasserstandsmessung den mittleren Stand des Wassers während eines längeren Zeitraums dar, der als arithmetisches Mittel gleichabständiger, meist stündlicher Wasserstände über diesen Zeitraum berechnet wird. Dieser Begriff wird grundsätzlich nur im Binnenland verwendet, wo kein oder nur ein geringer Einfluss durch den Tidenstrom besteht. Mittleres Hochwasser (MHW) ist der abgeleitete mittlere Hochwasserstand beziehungsweise die mittlere Hochwasserhöhe (MHWH). Tidenhub (TH) ist dabei der Höhenunterschied des Wasserstandes im Wechsel der Gezeiten. Besonders hohe Tiden bei Voll- und Neumond werden Springhochwasser (SpHW) beziehungsweise umgangssprachlich Springflut genannt;[6] sie können sich durch Gezeitenwellen und Wind (Driftstrom) zu einer Sturmflut entwickeln.
Steigt das Wasser an der Nordseeküste um mehr als 1,5 m über den mittleren Hochwasserstand (MHW), spricht man von einer Sturmflut, ab 2,5 m von einer schweren und ab 3,5 m von einer sehr schweren Sturmflut.[7] Sie entsteht durch das Zusammenspiel von Wind und Gezeiten, wobei sowohl die Windstärke als auch ihre Dauer eine Rolle spielen. Stehen Mond und Sonne in einer Achse zur Erde, addieren sich bei Neumond die Gezeitenkräfte zu einer Springtide, bei der es zu besonders hohen Wasserständen kommt.[8]
Sturmfluten sind an der Nordseeküste keine seltene Erscheinung. Sie sind ab 1000 n. Chr. überliefert, sie veränderten den Küstenverlauf und schufen großräumige Meeresbuchten. Sie bedeuten eine Gefahr für die relativ flachen Küstenregionen durch Überschwemmungen, soweit sie über die Deichkronen schwappen oder die Deiche sogar brechen. Die Bewohner der Küstengebiete haben aber gelernt, sich mit der Anlage von Warften, Deichen, Schleusen, Sturmflutwehren und Windmühlen (als Schöpfmühlen zur Entwässerung) zu schützen.
Heutzutage werden Sturmfluten nach der Höhe ihres Wasserstandes in leichte, mittlere und schwere Fluten eingeteilt. Solange es noch keine exakte Statistik der Wasserstände gab, wurden sie nach den durch sie verursachten Schäden bewertet.[9] Durchschnittlich alle zwei Jahre tritt an der niederländischen Nordseeküste eine Sturmflut auf, die als leicht kategorisiert wird und in der Regel ohne größere Schäden verläuft. Gefährlicher, aber auch seltener sind mittlere Sturmfluten, die statistisch nur alle 10 bis 100 Jahre beziehungsweise schwere Sturmfluten, die alle 100 bis 1000 Jahre auftreten.[10]


Die folgende Tabelle enthält die bei Sturmfluten gemessenen Pegelstände ab 5 m über NN am Beispiel des Pegels von Hamburg-St. Pauli und im Vergleich dazu die Pegelstände in Cuxhaven.

(N = Neumond; V = Vollmond; Diff. = Differenz)


Datum
St. Pauli
Cux­haven
Diff.
Bemerkungen


3. Jan. 1976 N
6,45
5,10
1,35
Höchster bisher gemessener Pegelstand


6. Dez. 2013 N
6,09
4,64
1,45
zweite von drei Sturmfluten durch Orkan Xaver[11]


28. Jan. 1994 V
6,02
4,50
1,52



10. Jan. 1995 V
6,02
4,48
1,54



3. Dez. 1999 V
5,95
4,50
1,45



19. Feb. 2022 V
5,88
4,38
1,50
hervorgerufen durch Orkan Zeynep


24. Nov. 1981 V
5,81
4,75
1,06



23. Jan. 1993 N
5,76
4,34
1,42



28. Feb. 1990 N
5,75
4,44
1,31



5. Feb. 1999 V
5,74
4,50
1,45



17. Feb. 1962 V
5,70
4,95
0,76
siehe Sturmflut 1962


9. Nov. 2007 N
5,40
4,41
0,99



28. Jan. 2002 V
5,26
3,84
1,42



4. Feb. 1825 V
5,24
4,66
0,58



30. Jan. 2000 N
5,16
3,94
1,22




Im Zuge der globalen Erwärmung durch einen verstärkten Treibhauseffekt wird von Wissenschaftlern mit einer Erhöhung der Sturmflutgefahren durch drei Effekte gerechnet: erhöhte Sturmwahrscheinlichkeit, Erhöhung der Sturmintensitäten und genereller Anstieg des Meeresspiegels.

→ Hauptartikel: Globale Erwärmung

Im Rahmen der vom deutschen Bundesamt für Bevölkerungsschutz und Katastrophenhilfe (BBK) durchgeführten Risikoanalysen im Bevölkerungsschutz wurde im Jahr 2014 die Risikoanalyse Sturmflut veröffentlicht.[12]
Das analysierte Sturmflut-Szenario geht von einem zwei Tage anhaltenden Wintersturm aus, der zu einer sehr schweren Sturmflut führt und auf die gesamte deutsche Nordseeküste, die Niederlande und Dänemark trifft. Die höchsten Wasserstände treten in Hamburg, Bremerhaven und Husum auf. Die Wasserstände übersteigen zwar nicht die Deichhöhen, es kommt aber zu Wellenüberlauf, was punktuell Deichbrüche und damit Überflutungen des Hinterlandes verursacht, mit teils erheblichen Schäden. Durch den Sturm kommt es bundesweit zu langanhaltenden Stromausfällen.

Der Wintersturm trifft auf 30 Mio. Einwohner und verursacht 110 Tote.
Die Überflutung betrifft 150.000 Einwohner und verursacht > 150 Tote.
Die langanhaltenden Stromausfälle betreffen mehr als 6 Mio. Personen und verursachen ca. 1.000 Tote.
Die Eintrittshäufigkeit wird mit 1× in >10.000 Jahren ermittelt.


Sturmfluten wurden auch Gegenstand literarischer Werke wie beispielsweise in der Novelle Der Schimmelreiter von Theodor Storm, der darin außerdem recht interessant die Entwicklung im Deichbau an der Nordsee im 19. Jahrhundert beschreibt. Die Sturmflut wird dabei in der deutschen Literatur sowie in Liedertexten oft auch als Blanker Hans bezeichnet.



Windstau, Erhöhung des Wasserspiegels unter Windeinfluss
Ostseesturmhochwasser
Liste von Sturmfluten an der Nordsee
Deichschart, Öffnung in einem Deichkörper für einen Verkehrsweg
Dammbruch

Georg Eilker: Die Sturmfluten in der Nordsee. Verlag W. Haynel, 1877.
E. Drägert: Weihnachtsflut 1717 in Ritzebüttel. In: Männer vom Morgenstern, Heimatbund an Elb- und Wesermündung e. V. (Hrsg.): Niederdeutsches Heimatblatt. Nr. 216. Nordsee-Zeitung, Bremerhaven Dezember 1967, S. 1 ( [PDF; 3,9 MB; abgerufen am 4. Juli 2019]). 
Marcus Petersen, Hans Rohde: Sturmflut. Die großen Fluten an den Küsten Schleswig-Holsteins und in der Elbe. Karl Wachholtz Verlag, Neumünster 1977, ISBN 3-529-06163-8. 
Norbert Fischer: Wassersnot und Marschengesellschaft. (= Schriftenreihe des Landschaftsverbandes der ehemaligen Herzogtümer Bremen und Verden Band 19) Stade 2003, ISBN 3-931879-12-7.
Heie Focken Erchinger, Martin Stromann: Sturmfluten – Küsten- und Inselschutz zwischen Ems und Jade. Norden 2004, ISBN 3-928327-82-8.
Rudolph, Elisabeth (2018): Sturmfluten in den Ästuaren der Elbe, Jade-Weser und Ems. In: Die Küste 86. Karlsruhe: Bundesanstalt für Wasserbau. S. 311–320. 
Rodewald, Martin (1962): Zur Entstehungsgeschichte der Sturmflut-Wetterlagen in der Nordsee im Februar 1962. In: Die Küste 10, 2. Heide, Holstein: Boyens. S. 1–54. 



 (PDF; 1,4 MB)




 THW
 Welt der Physik
 im Katalog der Deutschen Nationalbibliothek
 In: Deutsche Digitale Bibliothek
 im Online-Katalog der Staatsbibliothek zu Berlin – Preußischer Kulturbesitz (Achtung: Die Datenbasis hat sich geändert; bitte Ergebnis überprüfen und SBB=1 setzen)

22. Juli 2021, Zurich-Versicherungen,  ("Die drei üblichen Hochwasserarten")





Dieser Artikel behandelt den Zustand von Gewässern. Zur Fernsehserie siehe Hochwasser (Fernsehserie).




Die Artikel Liste von Hochwasser-Ereignissen, Flutkatastrophe, Jahrhunderthochwasser, Überschwemmung und Hochwasser überschneiden sich thematisch. Informationen, die du hier suchst, können sich also auch in den anderen Artikeln befinden.Gerne kannst du dich an der betreffenden Redundanzdiskussion beteiligen oder direkt dabei helfen, die Artikel zusammenzuführen oder besser voneinander abzugrenzen (→ Anleitung).



Hochwasser (wissenschaftlich/mathematische Abkürzung HQ aus „Hoch“ und Abfluss-Kennzahl Q) wird der Zustand von Gewässern genannt, bei dem ihr Wasserstand deutlich über dem Pegelstand ihres Mittelwassers liegt. Gegenstück ist „Niedrigwasser“.
Bei der Begriffsverwendung ist zu unterscheiden, woher entsprechendes Wasser hauptsächlich stammt:

Gezeitenunabhängig (Tide): Aufgrund von Starkregen ("pluvial") oder Schneeschmelze (Wasser von oben), bei fließenden oder stehenden Gewässern ("fluvial"),[1]
Tideabhängig (In der Regel an maritimen Gewässerküsten):
Normalfall: Zustand zwischen Nipp- und Springflut
Extremfall Sturmflut: Durch Stärke und Richtung von Wind bzw. Sturm bis Orkan erhöhtes normales periodisches Hochwasser



[Bearbeiten | Quelltext bearbeiten]
Bei Flüssen und kleineren Fließgewässern spricht man von Hochwasser wenn ihr Wasserstand für längere Zeit (mehrere Tage) ihren normalen Pegel deutlich übersteigt. Sie haben meist – je nach Art des Einzugsgebietes – eine jahreszeitliche Häufung, etwa bei der Schneeschmelze oder nach sommerlichen Starkregen. Bei starkem Hochwasser muss zunächst die Flussschifffahrt eingestellt werden, bei weiterem Ansteigen kann es zu Überschwemmungen kommen. Anschwellende Wildbäche können Brücken mitreißen und Muren oder Erdrutsche auslösen. Bei besonders schnellen Hochwässern spricht man von Sturzflut.


In Meeren und von Gezeiten („Tiden“) abhängigen Gewässern bezeichnet „Hochwasser“ den periodischen Eintritt des höchsten Wasserstands nach Eintreten der Flut und vor dem Übergang zur Ebbe („Scheitelpunkt“). Hoch- und Niedrigwasser wechseln sich durchschnittlich alle 6 bis 6½ Stunden ab, verursacht durch die Gravitation der Sonne und vor allem des Mondes. Besonders hohe Tiden bei Voll- oder Neumond werden als „Springtide“ auch „Springflut“ oder „Springhochwasser“ bezeichnet. Normale Hochwasser können durch Wind (Driftstrom) zu einer Sturmflut verstärkt werden, die an einer Flachküste kilometerweit ins Landesinnere vordringen kann. Bei Gewässern ohne merkliche Gezeiten kann es so auch zu reinen Sturmhochwässern kommen.







Grundsätzlich sind Hochwasser Bestandteile des natürlichen Geschehens. Zur Katastrophe (Flutkatastrophe) werden sie, wenn menschliche Werte betroffen sind. Man kann unterscheiden zwischen regelmäßig wiederkehrenden Hochwassern, ausgelöst etwa durch Gezeiten oder Schneeschmelze (Frühjahrshochwasser), und unregelmäßigen oder einmaligen Ereignissen wie Tsunamis, Sturmfluten und sogenannte „Jahrhundertfluten“ (als solche wurde das Elbehochwasser 2002 sowie das Hochwasser in Mitteleuropa 2013 bezeichnet;[2] inzwischen gab es einige weitere Hochwasser, die diese Bezeichnung relativieren). Bei derartigen, besonders starken Hochwassern wird von „Jahrtausendhochwassern“ gesprochen (z. B. Magdalenenhochwasser 1342 oder Oderhochwasser 1997).[3]
Der Beitrag der globalen Erwärmung zum Hochwassergeschehen ist nicht klar zu benennen und von den örtlichen Verhältnissen abhängig (Steigerung von Extremereignissen, Verschiebung von Schnee zum Regen etc.). Für manche Regionen prognostiziert man eine Steigerung des Jahresniederschlages, für andere eine Verminderung oder eine andere Verteilung. Dennoch geht das IPCC davon aus, dass Hochwasserrisiken künftig zunehmen werden.[4]
Länder mit geringen Reliefhöhen wie die Niederlande, Deutschland (vor allem im Norden) und Dänemark versuchen, sich durch massive Deichbaumaßnahmen und Sperrwerke (zum Beispiel das Emssperrwerk bei Emden) vor Meereshochwasser zu schützen. Wird kein intensiver Hochwasserschutz betrieben, kann es wie in Bangladesch am Mündungsdelta des Ganges häufiger zu Katastrophen mit vielen tausend Toten kommen.
Hochwassersituationen entstehen auch im Landinneren durch das Anschwellen der Flüsse und Seen sowie durch die Gefahren des Wildbaches. Ebenso können durch Eisstau oder Windeinstau (zum Beispiel Hamburger Sturmflut) Hochwasser entstehen.
Die Hochwasser(scheitel) eines Flusses und eines Nebenflusses können zusammenwirken. Beispiel: Wenn in Koblenz eine Mosel- und eine Rhein-Hochwasserwelle zeitnah zusammentreffen, erhöht sich ab da das Rheinhochwasser. Beim Rheinhochwasser Ende 1993 wirkten Fluten aus Neckar, Main, Nahe und Mosel zusammen.
Traditionell werden feste Markierungen an Gebäuden oder anderen Befestigungen in Form von Hochwassermarken oder Flutmarken angebracht, um den Höchststand zu dokumentieren.




Im Zuge der fortschreitenden Landnutzung wuchsen auch die genutzten Flächen, die Hochwassergefahren ausgesetzt sind. Mancherorts kann dies durch baulichen Hochwasserschutz kompensiert werden.
Die menschliche Flächennutzung und meist damit verbundene Flächenversiegelung sowie der nicht sachgerechte Ausbau von Gewässern (lineare Regulierung, Verminderung der Retentionsräume) können verschärfend auf Hochwasserstände wirken. Eine Erweiterung des Abflussquerschnitts vermindert die Überflutungsgefahr lokal, kann sie aber flussabwärts erhöhen (siehe #Deutschland). Durch Bewuchs und Anlandungen kann sich der Abflussquerschnitt wieder verringern.[5][6]
Das Hochwasserrisiko kann anhand von vier Faktoren ermittelt werden:

(Stark-)Regenfälle in der historischen Vergangenheit und deren Dauer,
Geomorphologie des vom Regen betroffenen Gebiets,
die Verwundbarkeit, das heißt die Empfindlichkeit der betroffenen Einrichtung oder Nutzungen gegenüber Überflutungen und
das Ausmaß und die Häufigkeit der Überflutung in jüngerer Zeit.
[Bearbeiten | Quelltext bearbeiten]
In Kriegssituationen kann eine vorsätzliche Überflutung als Angriffs- oder als Verteidigungswaffe gegen Angreifer eingesetzt werden. Unter anderem hat den Niederlanden diese Strategie oft Erfolg gegen Angreifer gebracht. Siehe: Achtzigjähriger Krieg, Alkmaar, Inundierung.
1943 zerstörte die britische Luftwaffe einige deutsche Talsperren. Weitere Angriffe auf Staumauern gab es an der Dnjeprostroj- und der Supung-Talsperre.
1945 öffneten Soldaten der Wehrmacht die Rurtalsperre; am 10. Februar 1945 sprengten sie die Verschlüsse des Kermeterstollens am Kraftwerk Heimbach, worauf die Talsperre bis zum Niveau des Kermeterstollens leer lief.[7] Sie sprengten auch die Verschlüsse der Grundablassstollen der Staumauer Schwammenauel (Rursee). Beides zusammen erzeugte flussabwärts ein wochenlanges Hochwasser, das die Flussaue verschlammte und den Westalliierten den Vormarsch erschweren sollte. Die Rur wurde von einem kleinen Flüsschen zum reißenden Gewässer; dies verzögerte den Beginn der Operation Grenade (Übersetzen der 9. US-Armee über die Rur).
Ab dem 2. Dezember 1944 sprengte die Wehrmacht am Niederrhein Deiche, um die vorrückenden Westalliierten am Übersetzen zu hindern.[8] Auch die Operation Veritable (8. – 21. Februar 1945) geriet dadurch ins Stocken, zumal der Winter 1944/45 sehr kalt war.
Dithmarschen im Mittelalter: Im Februar des Jahres 1500 besiegten die Dithmarscher unter Wulf Isebrand in der Schlacht bei Hemmingstedt ein dänisch-schleswig-holsteinisches Heer unter König Johann. Die anrückende dänische Streitmacht bestand vor allem aus einer im Marschenkrieg spezialisierten Infanterietruppe, der aus Landsknechten zusammengesetzten Schwarzen Garde, sowie einigen adligen Reitereinheiten, war aber schlecht geführt. Die Bauern konnten dieses Heer überraschend vernichten. Sie vermieden zunächst eine offene Schlacht, öffneten im Marschland die Deiche und ließen das anrückende Heer auf dem engen Damm der Straße von Meldorf nach Heide an der Dusenddüwelswarft in der Nähe von Hemmingstedt in eine nasse Falle tappen.

[Bearbeiten | Quelltext bearbeiten]


Hochwasser werden zumeist mit einer statistischen Bewertung versehen. Grundlage sind langjährige Messreihen an Pegeln. Aus diesen werden die Jahreshöchstwerte ausgewählt und Überschreitungswahrscheinlichkeiten ermittelt. Deren Kehrwert ist die Jährlichkeit. Diese Jährlichkeiten bezeichnen das statistische Wiederkehrintervall.
An Fließgewässern ist ein einzelner Pegel wenig aussagekräftig für allgemeine Verhältnisse (er hängt von der örtlichen Gestalt des Gewässerbetts ab), daher errechnet man hier die Durchflussmenge am Pegel, die über den ganzen Flussabschnitt weitgehend gleich ist und über das jeweilige Flusssystem aufsummiert werden kann.
Diese Durchflussmenge (bzw. Abflussmenge unterhalb einer Pegelstelle) bezeichnet man in der Hydrografie mit „Q“ (aus lateinisch quantitas ‚Menge‘), den Wasserstand mit „W“, Hochwasser mit „H“, daher hat sich für Abflusskenngrößen und damit für die Bezeichnung der Hochwasser selbst die Notation „HQ“ bzw. an Seen und Küsten „HW“ eingebürgert. „HQ100“ oder „HW100“ (auch HQ100 notiert) beispielsweise bezeichnet ein statistisch gesehen alle 100 Jahre auftretendes Hochwasserereignis, ein „Jahrhunderthochwasser“.
Die typischen Referenzwerte an Flüssen sind:

 Mittlerer Hochwasserabfluss (MHQ): Das arithmetische Mittel aus den höchsten Abflüssen (HQ) gleichartiger Zeitabschnitte für die Jahre des Betrachtungszeitraums. Der Zeitabschnitt und der Betrachtungszeitraum der Angabe ist im Zweifelsfalle hinzuzufügen, so ist zum Beispiel „HQ 1971/1980“ der höchste Abfluss aus den Jahren 1971 bis 1980, „SoHQ 1971/1980“ das höchste in den Sommern 1971 bis 1980, „JulHQ 1971/1980“ der höchste in den Julimonaten der Jahre 1971 bis 1980 aufgetretene Abfluss.
 Höchster jemals gemessener Hochwasserabfluss (HHQ, „Höchstes jemals gemessenes Hochwasser“): Historisch belegtes Höchsthochwasser
 Rechnerisch höchster Hochwasserabfluss (RHHQ): Die wasserbauliche Berechnungsgröße des Höchsthochwassers
Dabei verdrängen zunehmend Werte aus der Modellierung („Niederschlags-Abfluss-“, „NA-Modelle“) die gemessenen Werte, da man im Kontext der globalen Erwärmung nicht mehr sicher ist, inwieweit die bekannten – und vergleichsweise kurzen – Messintervalle aussagekräftig sind, und die Modelle gut angepasst werden können.
Älter ist eine phänomenologische Klassifizierung anhand der Ausmaße der jeweiligen Auswirkung wie Ausuferungen, Überströmen von Sperrwerken oder Ausmaß der Überflutungen. Diese Hochwasserwarnstufen sind heute meist an die Abflusskenngrößen gekoppelt (ähnlich der Beaufort-Skala für Windstärken, die nach Windgeschwindigkeiten eingeteilt ist):

das deutsche länderübergreifende Portal hochwasserzentralen.de beispielsweise verwendet ein vierstufiges System, das den Warnstufen der einzelnen Länder entspricht, in den Grenzen HQ2, HQ10, HQ20, HQ100:[9]
„Kleines Hochwasser → Mittleres Hochwasser → Großes Hochwasser → Sehr großes Hochwasser“
dabei werden die Binnenhochwasser- und die Sturmflutwarnungen zunehmend korreliert
in Österreich sind aktuelle Daten allgemein auf die Periode 1981–2010 hydrologisches Jahr (30-jähriges Mittel) bezogen. Üblich ist:[10]
„Extremes Hochwasser“ / extrem selten: HQ100–RHHQ (100-jährliches bis rechnerisch höchstes Hochwasser)
„Sehr großes Hochwasser“ / sehr selten: HQ30–HQ100 (30- bis 100-jährliches Hochwasser)
„Großes Hochwasser“ / selten: HQ10–HQ30 (10- bis 30-jährliches Hochwasser)
„Mittleres Hochwasser“ / selten–häufig: HQ5–HQ10 (5- bis 10-jährliches Hochwasser)
„Kleines Hochwasser“ / häufig: HQ1–HQ5 (1- bis 5-jährliches Hochwasser)
„Erhöhtes Mittelwasser“ (Erhöhte Wasserführung) / sehr häufig: MQ–HQ1 (Mittel- bis 1-jährliches Hochwasser)
Verbreiteter sind heute aber die Hochwasserwarnstufen (Abflusskategorien) 1–3, in den Grenzen >HQ1, >HQ10 und >HQ30, wie das etwa der hydrographische Dienst des Bundes, eHYD, verwendet (Stufe 1 entspricht also kleinen und mittleren Hochwassern).[11] Die besonders aufwendige Rheinaufweitung auf Höhe Vorarlberg wird für ein 300-jährliches Hochwasser HQ300 konzipiert.
die Schweiz verwendet das BAFU, ein Gefahrenstufen-System:
für Flüsse in den Grenzen HQ2, HQ10, HQ30, HQ100
für die Seen das Verhältnis „Sommerkote“ (SK) zu Hochwassergrenze (HWG) in den Grenzen SK+1⁄3, SK+2⁄3, HWG und HWG+25 cm[12]
Eine Bezeichnung „mittleres Hochwasser“ für eine der Stufen ist dort unüblich.


→ Hauptartikel: Hochwasserschutz

Maßnahmen zum Hochwasserschutz können folgende Aspekte umfassen:

Anpassung der Nutzung an die Hochwassergefährdung (Absiedelung, Änderung der landwirtschaftlichen Nutzung, sichere und schadensarme Gestaltung von Bauwerken)
Schutz vor dem Hochwasser durch
Rückhalt des Niederschlagswassers in der Fläche, oder durch Regenrückhaltebecken
Buhnenbauwerke, Wiederherstellung der natürlichen Flussgeometrie (eine große Uferlänge durch viele Bögen)
Schutz betroffener Gebiete oder Objekte durch Deiche (in Österreich auch als Hochwasserschutzdämme bezeichnet)
Erhöhung der Abfuhrkapazität der Gewässer durch Querschnittserweiterung und Flutmulden
Rechtzeitige Warnungen und Alarmierung durch automatische Pegelmessstationen und Hochwasserwarndienste
Zwischen den einzelnen Maßnahmen bestehen Abhängigkeiten. Zum Beispiel können Regulierungen und Deichbaumaßnahmen zu einer Verschärfung der Hochwassergefahr für Unterlieger oder Anrainer führen. Die Errichtung von Hochwasserrückhaltebecken (Retentionsbecken) verringert das Risiko einer häufigen Überflutung zu Lasten eines seltenen, aber katastrophalen Dammbruchs durch ein Totalversagen des Rückhaltebeckens.
Eine umfassende Strategie zur Verminderung der Folgen eines Hochwassers gibt das Hochwassermanagement.

[Bearbeiten | Quelltext bearbeiten]
Bei allen Hochwasserschutzmaßnahmen ist zu beachten, dass stets ein Restrisiko besteht (Anlageversagen, Überschreitung des Bemessungshochwassers).

Siehe auch: Hochwassereinsatz und Hochwasserschutz



In diesem Artikel oder Abschnitt fehlen noch folgende wichtige Informationen: Hochwasserschutz in der Schweiz, gesetzliche Grundlagen in Österreich, USA pauschalisiert auf Katrina-Folgen Hilf der Wikipedia, indem du sie recherchierst und einfügst.

[Bearbeiten | Quelltext bearbeiten]

Das Wasserhaushaltsgesetz (WHG) definiert seit 2010 erstmals[13] Hochwasser als: „eine zeitlich beschränkte Überschwemmung von normalerweise nicht mit Wasser bedecktem Land“ (§ 72 WHG) durch oberirdische Gewässer (Flüsse, Seen, Meer). Überschwemmungen aus Abwasseranlagen sind in Deutschland ausdrücklich nicht als Hochwasser definiert. Ergänzende Regelungen finden sich in einigen Landeswassergesetzen der Bundesländer. Ein gesetzlich festgeschriebenes Schutzniveau gibt es nicht.
Seit dem Jahr 2009 haben mehrere Bundesländer Informationskampagnen für mehr Naturgefahrenschutz ins Leben gerufen. Sie setzen hauptsächlich auf freiwillige Vorsorge der Bürger.[14]
Die Kosten des Wetterereignisses sind kaum abschätzbar.[15]

[Bearbeiten | Quelltext bearbeiten]
In Österreich werden folgende Schutzziele angestrebt:

HQ30 Untergeordnete Objekte
HQ100 Standardschutz
HQ150 Ausbaugrad Wildbach
Darüber hinausgehende Schutzgrade werden bei besonderer Schutzerfordernis (zum Beispiel für die Stadt Wien) angestrebt.
Das Umweltministerium lässt eine Hochwassersimulation durch VRVis erstellen. Es basiert auf einer Vermessung des Geländes und stellt für Objekte das Schadenrisiko in 3 Kategorien dar. Ab Herbst 2020 sollen alle Gemeinden abgedeckt und unter der Website hora.gv.at (HORA Hochwasserrisikozonierung Austria) abrufbar sein.[16]

[Bearbeiten | Quelltext bearbeiten]
In den Niederlanden werden differenzierte Schutzniveaus hantiert. Während in einigen Teilen des Landes ein Schutzniveau gegen ein HQ 1.250 besteht, wird zum Beispiel ein Großteil der Randstad gegen ein Ereignis, das statistisch einmal in 10.000 Jahren vorkommt, geschützt. Während Rijkswaterstaat für nationalen Hochwasserschutz (d. h. für große Wasserstraßen sowie Küstenschutz) zuständig ist, werden die regionalen Schutzziele von den 26 Waterschappen (ähnlich den Wasserverbänden in NRW) verfolgt.[17]

[Bearbeiten | Quelltext bearbeiten]
In den USA wurde der Hochwasserschutz vom dafür zuständigen US Army Corps of Engineers auf das Niveau eines 230-jährlichen Hochwassers festgelegt. Dieses Niveau ist auch gewährleistet, jedoch hat die Überflutung von New Orleans zu der Erkenntnis geführt, dass dieses Schutzniveau nicht ausreicht.

[Bearbeiten | Quelltext bearbeiten]

[Bearbeiten | Quelltext bearbeiten]
Um die mit dem Hochwasser verbundenen Gefahren sowohl an den deutschen Küsten als auch an den Flüssen einzuschätzen, haben die Bundesländer ein Länderübergreifendes Hochwasserportal[18] im Internet eingerichtet. Regional und lokal gibt es unterschiedliche Warn- und Alarmstufen. Die Meldesysteme arbeiten meist computergestützt und sind in der Lage, Hochwasservorhersagen oder -abschätzungen für mehrere Stunden im Voraus zu liefern. Durch kurzfristige Wetteränderungen sind längerfristige Vorhersagen mit Fehlern behaftet.
Der Katastrophenschutz fällt in die Zuständigkeit der jeweiligen Innenbehörden, die für Rettungsmaßnahmen auf die Feuerwehren, das THW, die Bundeswehr u. a. zurückgreifen. In Deutschland arbeiten derzeit diverse Wasserrettungsorganisationen wie die DLRG und die Wasserwacht.

[Bearbeiten | Quelltext bearbeiten]
Die unmittelbare Hilfe und Abwehr im Hochwasserfall erfolgt durch die örtliche Feuerwehr. Langfristigere Hilfe erfolgt durch den Katastrophenhilfsdienst der Feuerwehr und Assistenzeinsätze des Bundesheeres.
Auch hier ist das meist benutzte Hilfsmittel beim Hochwasserschutz der Sandsack.
Die Errichtung, Erhaltung und Betrieb von Hochwasserschutzmaßnahmen erfolgt durch die individuell Betroffenen, Wassergenossenschaften, Kommunen und Wasserverbände.


Liste von Hochwasser-Ereignissen
Liste nationaler und internationaler hydrographischer und Hochwasserdienste – mit Links auf Wasserstandswerte weltweit




 bei curlie.org (ehemals DMOZ)
Hannah Fuchs:  In: dw.com, 19. Juli 2021
Deutsche Vereinigung für Wasserwirtschaft, Abwasser und Abfall e. V. (DWA): 
Bundesamt für Kartographie und Geodäsie,  (Für Jedermann, kostenfrei, anmeldepflichtig)
Bundesanstalt für Gewässerkunde (BfG), Koblenz: 

Hochwasser-Kompetenz-Centrum e. V. (HKC): 
[Bearbeiten | Quelltext bearbeiten]

„Niederösterreichischer Zivilschutzverband“, 
[Bearbeiten | Quelltext bearbeiten]
Bundesamt für Umwelt (CH), 





Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Orkan (Begriffsklärung) aufgeführt.


Als Orkan werden im weiteren Sinn Winde mit der Stärke 12 auf der Beaufortskala bezeichnet, im engeren Sinn werden darunter Nordatlantiktiefs verstanden, in denen solche Winde mit der Stärke 12 auftreten.
Früher wurden alle Winde mit Orkanstärke als Orkane bezeichnet. Winde mit Orkanstärke können zum Beispiel in tropischen Wirbelstürmen, in kräftigen außertropischen Tiefdruckgebieten, in Tornados und in Downbursts auftreten. Heute werden nur noch nordatlantische Tiefdruckgebiete mit Winden in Orkanstärke als „Orkan“ bezeichnet.



Das Wort „Orkan“ ist eine etymologische Dublette des Wortes „Hurrikan“: beide gehen letztlich wohl auf die Sprache der Taíno, der Ureinwohner der Großen Antillen, zurück. Denkbar, aber nicht bewiesen, ist ein Zusammenhang des Taíno-Wortes (das erstmals 1511/1516 bei Petrus Martyr von Anghiera in der latinisierten Pluralform furacanes dokumentiert ist) mit Huracán bzw. Hun-r-akan, dem Namen einer unter anderem für schwere Stürme verantwortlichen Gottheit der Maya des mittelamerikanischen Festlands, die mit den Taíno allerdings sprachlich nicht verwandt und auch kulturell sehr verschieden waren.[1][2]
Über das Spanische (huracán, erstmals 1526 bezeugt) gelangte dieses Wort noch im 16. Jahrhundert ins Portugiesische (furacão), Englische (hurricane) und Französische (ouragan), im späten 17. Jahrhundert dann über das Niederländische (orkaan; in dieser Schreibung erstmals 1676 bezeugt, zuvor aber auch schon in Formen wie uracaen, horkaen und orancaen) als „Orkan“ schließlich auch ins Deutsche (erstmals 1669)[3][4] und erfreute sich hier in der Folge einiger Beliebtheit in der Barockdichtung, was wiederum den für seine Aversion gegen Fremdwörter bekannten Philipp von Zesen vorschlagen ließ, statt „Orkan“ besser „Höllensturm“ zu schreiben. Diese Eindeutschung (die ihrerseits wohl an den Orcus der römischen Mythologie anknüpft) konnte sich jedoch – anders als einige andere Zesensche Wortschöpfungen wie Anschrift für Adresse oder Leidenschaft für Passion – nicht durchsetzen; im Gegenteil entwickelte sich „Orkan“ auch in der deutschen Wissenschafts- und Alltagssprache zur heute kaum mehr als Fremdwort wahrgenommenen Standardbezeichnung für die atlantischen Stürme, die besonders im Herbst und Winter über Europa hinwegfegen.[5] Als „Hurrikan“ (im 19. Jahrhundert aus dem Englischen entlehnt, zuvor in Formen wie Furacan allenfalls als Exotismus in Reisebeschreibungen anzutreffen) werden heute hingegen die tropischen Wirbelstürme des Nordatlantiks sowie des östlichen Pazifiks bezeichnet.[6][7]


Orkane im engeren Sinn, also außertropische Tiefdruckgebiete, entstehen vor allem im Herbst und Winter, da in dieser Zeit die Temperaturunterschiede zwischen der Polarregion und den Tropen besonders groß sind. Wenn diese Luftmassen aufeinandertreffen (Okklusion), entstehen starke Stürme.
Auf dem Festland sind außer auf exponierten Berggipfeln, Inseln und Küstengebieten mittlere Winde mit Orkanstärke wegen der erhöhten Bodenreibung selten. Meist werden dort solch hohe Windgeschwindigkeiten nur in Böen erreicht.
Der Orkan bzw. die Orkanböe ist per Definition zu unterscheiden vom orkanartigen Sturm bzw. der orkanartigen Böe, bei denen nur eine Windstärke 11 auf der Beaufortskala erreicht wird.


Luciaflut, 13./14. Dezember 1287
Zweite Marcellusflut, 15./17. Januar 1362
Burchardiflut, 11./12. Oktober 1634
Großer Sturm von 1703, Dezember 1703
Märzorkan 1876, März 1876 – Spitzengeschwindigkeit: ca. 170 km/h
Augustorkan 1956, 25. August 1956 – Spitzengeschwindigkeit im Flachland über 120 km/h[8]
Sturmflut 1962, 16./17. Februar 1962
Adolph-Bermpohl-Orkan, 23. Februar 1967 – schwerster bis heute bekannter Orkan an der deutschen Nordseeküste und in der Deutschen Bucht. Mittlere Windgeschwindigkeit über mehrere Stunden: 149 km/h (Helgoland), Spitzenböen konnten nicht gemessen werden;[9] vermutlich deutlich über 200 km/h.
Quimburga (Niedersachsenorkan), 13. November 1972 – Spitzengeschwindigkeit: 245 km/h
Capella, 3. Januar 1976 – Spitzengeschwindigkeit: 145 km/h
Westeuropa-Orkan, 15./16. Oktober 1987
Daria, 26. Januar 1990 – Spitzengeschwindigkeit: 200 km/h
Vivian, 25.–27. Februar 1990 – Spitzengeschwindigkeit: 268 km/h
Wiebke, 28. Februar/1. März 1990 – Spitzengeschwindigkeit: 285 km/h
Anatol, 2./3. Dezember 1999 – Spitzengeschwindigkeit: 183 km/h
Lothar, 26. Dezember 1999 – Spitzengeschwindigkeit: 272 km/h
Jeanett, 26./27. Oktober 2002 – Spitzengeschwindigkeit 183 km/h
Gudrun, 8./9. Januar 2005 – Spitzengeschwindigkeit: 151 km/h
Kyrill, 18. Januar 2007 – Spitzengeschwindigkeit: 225 km/h
Tilo, 9. November 2007 – Spitzengeschwindigkeit: 137 km/h
Paula, 26./27. Januar 2008 – Spitzengeschwindigkeit: 230 km/h
Emma, 1./2. März 2008 – Spitzengeschwindigkeit: 236 km/h
Xynthia, 25.–28. Februar 2010 – Spitzengeschwindigkeit: 238 km/h
Joachim, 16. Dezember 2011 – Spitzengeschwindigkeit 212 km/h
Andrea, 5. Januar 2012 – Spitzengeschwindigkeit: 270 km/h (Meteomedia, Konkordiahütte)
Christian, 27./28. Oktober 2013 – Spitzengeschwindigkeit: 171 km/h (St. Peter-Ording)
Xaver, 5./6. Dezember 2013 – Spitzengeschwindigkeit: 229 km/h (Aonach Mòr, Schottland)
Niklas, 29. März–1. April 2015 – Spitzengeschwindigkeit: 213 km/h (Zugspitze)
Egon, 12./13. Januar 2017 – Spitzengeschwindigkeit: 140 km/h (Deutschland), 154 km/h (Säntis, Schweiz)[10]
Friederike, 18. Januar 2018 – Spitzengeschwindigkeit: 204 km/h (Brocken)[11]
Sabine, 9./10. Februar 2020 – Spitzengeschwindigkeit: 219 km/h (Cap Corse, Frankreich)
Zeynep, 18./19. Februar 2022 – Spitzengeschwindigkeit: 196 km/h




In diesem Artikel oder Abschnitt fehlen noch folgende wichtige Informationen: Globales Ausmaß Hilf der Wikipedia, indem du sie recherchierst und einfügst.


Die wirtschaftlichen Folgen von Orkanen können auf einzelne Gebiete beschränkt sein, aber auch große Regionen treffen. Materielle Schäden lassen sich in direkte Schäden (Gebäude, Infrastruktur, Wälder, Automobile usw.) und indirekte Schäden (Aufräumarbeiten, Produktionsausfälle, Folgekosten usw.) unterteilen. Nicht alle Schäden sind versichert, so dass der Gesamtschaden oft mehr als doppelt so hoch ist wie der versicherte Schaden.[12] Durch die Entwicklung der Informationstechnik hat sich die systematische Erfassung der Schäden in den letzten Jahrzehnten wesentlich verbessert. Bei Aussagen im Rahmen der Kontroverse um die globale Erwärmung ist zu beachten, dass es Unterschiede zwischen persönlichen Beobachtungen, der tatsächlichen Häufigkeit und den bezifferten Schäden gibt. Die Münchener Rückversicherungs-Gesellschaft schreibt dazu: „Verglichen mit vielen Regionen der Welt, werden Deutschland und die anderen Länder Mitteleuropas von Naturgefahren nicht übermäßig bedroht. … Die außerordentlich hohe Besiedlungsdichte und die enormen volkswirtschaftlichen Wertekonzentrationen führen dazu, daß nahezu jedes größere Naturereignis zu einem Schadenereignis – und häufig genug auch zu einer wirklichen Naturkatastrophe – wird.“[13]
Beispiele aus Deutschland sind:

Das Orkantief Quimburga am 13. November 1972 richtete in Deutschland einen Sachschaden von damals 1,34 Mrd. DM (in heutiger Kaufkraft 2,23 Mrd. Euro) an.
Durch den Orkan Kyrill wurden am 18. Januar 2007 bundesweit nach den Daten des Deutschen Forstwirtschaftsrates (DFWR) fast 20 Millionen Kubikmeter Holz vernichtet. Grob hochgerechnet dürfte das mehr als 40 Millionen Bäumen entsprechen. In den Wäldern Nordrhein-Westfalens richtete Kyrill den größten dort jemals festgestellten Schaden an. Besonders betroffen war das Sauer- und Siegerland. Nach den Angaben des Landesbetriebs Forst und Holz knickte er in NRW rund 25 Millionen Bäume um.[14] Nach den Angaben des Gesamtverbandes der Deutschen Versicherungswirtschaft (GDV) vom November 2008 zahlten die deutschen Versicherer für über 2,3 Millionen Schadensfälle rund 2,4 Milliarden Euro an ihre Kunden aus.[15]
In Deutschland sehen Gebäudeversicherungsverträge regelmäßig eine Haftung für Sturmschäden vor. Unter Sturm verstehen die Allgemeinen Versicherungsbedingungen für Wohngebäude (§ 8 VGB 88) eine wetterbedingte Luftbewegung von mindestens Windstärke 8. Ähnlich ist die Definition in § 3 Abs. 3 a FEVB, wonach es sich um eine atmosphärisch bedingte Luftbewegung von mindestens Windstärke 8 nach Beaufort handeln muss. Damit weicht der versicherungsrechtliche Begriff von den meteorologischen Begrifflichkeiten ab. Stärke 8 bedeutet nach der maßgeblichen Beaufortskala „stürmischer Wind, der Zweige von Bäumen bricht und das Gehen im Freien erheblich erschwert“. Der Versicherungsnehmer einer Gebäudeversicherung, der das Vorliegen eines Sturms behauptet, kann in Grenzfällen Nachweisschwierigkeiten ausgesetzt sein. Zum Nachweis eines Sturmschadens ist es freilich nicht erforderlich, dass der Beweis für ein direktes Auftreffen einer Luftbewegung von mindestens Windstärke 8 auf das versicherte Gebäude erbracht wird. Ausreichend ist nach Ansicht des Oberlandesgerichts Karlsruhe,[16] dass am Gebäude von Luftbewegungen verursachte Schäden aufgetreten sind und in seiner näheren Umgebung zu gleicher Zeit ein Sturm der Windstärke 8 aufgetreten ist.


Liste der Winde und Windsysteme
Liste von Wetterereignissen in Europa





Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Sturm (Begriffsklärung) aufgeführt.


Der Begriff Sturm steht für ein Starkwindereignis.





Als Sturm werden Winde mit Geschwindigkeiten von mindestens 20,8 m/s (74,9 km/h) oder 9 Beaufort bezeichnet. Ein Sturm mit einer Windgeschwindigkeit von mindestens 32,7 m/s (117,7 km/h) oder 12 Beaufort wird als Orkan bezeichnet. Dazwischen spricht man bei 10 Beaufort von einem schweren und bei 11 Beaufort von einem orkanartigen Sturm. Erreicht der Wind nur kurzzeitig (für wenige Sekunden) Sturmstärke, so spricht man von einer Sturmböe.
In der Regel sind mit einem Sturm auch starke Regenfälle verbunden, weshalb die Bezeichnung umgangssprachlich oft als Synonym für einen schweren Schauer oder ein Gewitter verwendet wird, beide stellen jedoch nur Begleiterscheinungen bzw. Spezialfälle eines Sturms dar. Auf See ist für den windbedingt hohen Wellengang ebenfalls die Bezeichnung Sturm gebräuchlich, mit einer geringeren Betonung auf den meist gleichzeitigen Niederschlägen. Je nachdem, was ein Sturm aufwirbelt bzw. womit er zusammen auftritt, spricht man des Weiteren von einem Schneesturm, Hagelsturm, Sandsturm (Buran) oder Staubsturm. In Gebirgen entstehen Föhnstürme als Trockenwindereignis.
Auch eine Unterscheidung nach der Jahreszeit wird manchmal genutzt, man spricht dann beispielsweise von einem Wintersturm. Solche Unterscheidungen sind insbesondere bei land- und forstwirtschaftlichen Schäden in der Folgenabschätzung von Bedeutung (etwa Ernteausfälle nach Überschwemmungen, Windbruch und Borkenkäfergefahr).
Weitere Sturmarten sind der Tornado, gelegentlich (Klein-)Trombe, Windhose, Wasserhose oder Twister genannt, sowie der Schneesturm Blizzard.
In Küstenregionen kann es durch das Zusammenwirken von Sturm und Gezeiten zu Sturmfluten kommen.


Sturmwinde können entstehen, wenn hohe Druckgradienten (hohe Druckunterschiede auf relativ kurzer Distanz) auftreten. Diese sind als Sturmtief häufig im Einflussbereich starker Tiefdruckgebiete vorhanden. Ferner können Sturmwinde durch topographisch bedingte Kanalisierung des Windes entstehen, zum Beispiel als Talwind in engen Tälern.
Stürme treten häufig über dem Meer auf, da dort weniger Bodenreibung vorhanden ist. So können sich die Winde besser entfalten als auf dem Festland und erreichen wesentlich häufiger Sturmstärke. Zudem können tropische Wirbelstürme, also Hurrikane und Taifune, nur über dem Meer entstehen und schwächen sich über Landmassen rasch ab.
Darüber hinaus können Gewitter auch durch elektrische Aktivitäten in der Atmosphäre verursacht werden. Blitze sind ein häufiges Zeichen für ein nahes Gewitter. Ein Blitz entsteht, wenn ein Elektronenfluss von einem Ort mit hoher elektrischer Ladung zu einem Ort mit niedriger elektrischer Ladung stattfindet.[1] Dies geschieht, wenn warme Luft schnell aufsteigt und abkühlt, wodurch ein Unterschied in der elektrischen Ladung in der Atmosphäre entsteht. Blitze sind ein häufiges Phänomen bei Sommergewittern und können gefährlich sein, wenn sie sich in Ihrem Weg befinden.

Siehe auch: Perfekter Sturm



Direkte Sturmschäden betreffen vor allem das Abdecken von Dächern oder andere Windverfrachtungen, bei waldreichen Gebieten kommt der Sachschaden durch umgeworfene Bäume hinzu (Sturmholz). Von Bedeutung sind auch indirekte Schäden, zum Beispiel durch die Ablagerungen von Sand auf Landwirtschaftsflächen bei einem Sandsturm oder Hagelschäden. Für Menschen geht die größte Gefahr von herumfliegenden Gegenständen, herabfallenden Ästen und umfallenden Bäumen, sowie gegebenenfalls von beschädigten oberirdischen Stromleitungen aus, so dass es in der Regel am sichersten ist, sich für die Dauer eines Sturms im Inneren von Gebäuden aufzuhalten.
Viele Versicherungsgesellschaften bezahlen einen Sturmschaden – bei abgeschlossener Sturmschadensversicherung – erst, wenn der Wind nachweislich Windstärke 8 (stürmischer Wind, der Versicherungsbegriff „Sturm“ ist hier anders zu interpretieren) erreicht hat. Unter Sturm verstehen die allgemeinen Versicherungsbedingungen für Wohngebäude (Deutschland etwa § 8 VGB 88) eine wetterbedingte Luftbewegung von mindestens Windstärke 8. Ähnlich ist die Definition im deutschen § 3 Abs. 3 a FEVB, wonach es sich um eine atmosphärisch bedingte Luftbewegung von mindestens Windstärke 8 nach Beaufort handeln muss. Damit weicht der versicherungsrechtliche Begriff von den meteorologischen Begrifflichkeiten ab. Stärke 8 bedeutet nach der maßgeblichen Beaufortskala „stürmischer Wind, der Zweige von Bäumen bricht und das Gehen im Freien erheblich erschwert“.
Der Versicherungsnehmer einer Gebäudeversicherung, der das Vorliegen eines Sturms behauptet, kann in Grenzfällen Beweisschwierigkeiten ausgesetzt sein. Zum Nachweis eines Sturmschadens ist es freilich nicht erforderlich, dass der Beweis für ein direktes Auftreffen einer Luftbewegung von mindestens Windstärke 8 auf das versicherte Gebäude erbracht wird. Viele neuere Versicherungsbedingungen lassen genügen, dass (auch) in der Nachbarschaft Sturmschäden aufgetreten sind. Ansonsten genügt nach Ansicht des Oberlandesgerichts Karlsruhe sogar, dass am Gebäude von Luftbewegungen verursachte Schäden aufgetreten sind und in seiner näheren Umgebung zu gleicher Zeit ein Sturm der Windstärke 8 aufgetreten ist.[2]
In der Schifffahrt kann bei Sturm das Abwettern Gefahren vermeiden. Eine besondere Gefahr besteht beim Containertransport, wo Verluste auf See immer wieder vorkommen. An der Verbesserung der Situation werde angeblich bereits seit Jahren gearbeitet. Sowohl für die Freizeitschifffahrt als auch die Berufsschifffahrt bestehen in vielen Ländern offizielle Sturmwarndienste, die für die Schiffsführer über unterschiedliche technische Medien eine offizielle Sturmwarnung herausgeben.


[Bearbeiten | Quelltext bearbeiten]
Bedeutende Sturmkatastrophen in Deutschland:

13. November 1972: Orkan Quimburga, 245 km/h (Brocken), über England, Benelux, Norddeutschland, 73 Tote, Schaden ca. 1,34 Mrd. DM
25.–26. Januar 1990: Orkan Daria, 130 km/h, 8 Tote in Deutschland, Schaden ca. 4,4 Mrd. Euro
27. Februar 1990 Orkan Vivian, 64 Todesopfer, 1,5 Mrd. Euro versicherter Schaden in Deutschland
28. Februar – 1. März 1990 Orkan Wiebke 35 Todesopfer, 1,5 Mrd. Euro versicherter Schaden
26. Dezember 1999: Orkan Lothar, 272 km/h (Hohentwiel), 13 Todesopfer in Deutschland und weitere in der Schadensbeseitigung, Schaden ca. 1,2 Mrd. Euro
18. Januar 2007: Orkan Kyrill, 200 km/h (Wendelstein), 13 Todesopfer und weitere in der Schadensbeseitigung, Schadenshöhe 2,3 Mrd. Euro
31. März – 1. April 2015: Orkan Niklas, 192 km/h (Zugspitze), 9 Todesopfer, Schadenshöhe ca. 750 Millionen Euro
18. Januar 2018: Sturmtief Friederike, 205 km/h als Spitzenbö (Brocken), 8 Todesopfer, Schadenhöhe (geschätzt) 500 Millionen Euro
23. September 2018: Sturmtief Fabienne, Spitzenböen bis 158 km/h[3]
9.–11. Februar 2020 Orkan Sabine, 178 km/h als Spitzenbö (Feldberg), 4 Tote, Schadenhöhe (geschätzt) 600 Millionen Euro
[Bearbeiten | Quelltext bearbeiten]
Bedeutende Sturmkatastrophen in Österreich:[4][5][6]

8. November 1982, der „Jahrhundertföhn“[7]
Februar/März 1990 Vivian und Wiebke (Spitzen Wiebke mit 147 km/h (Hörsching), gemeinsamer Schaden drei Milliarden Schilling (ca. 218 Mio. Euro))
5. April 1997, verbunden mit starken Schneefällen in den nächsten Tagen
5. Februar 1999, Lara mit Sturmspitzen von 130 km/h (Flughafen Wien)
26. Dezember 1999, Orkan Lothar
19. März 2001, Sturmtief Emma (eine Tote und zwei Schwerverletzte in Niederösterreich)
15. Dezember 2005, Sturmtief Dorian
18. Januar 2007 Orkan Kyrill, 216 km/h (Gaisberg), 100 Millionen Euro Schaden, zahlreiche Todesopfer in der Schadensbeseitigung
26.–27. Jänner 2008 Sturmtief Paula, 230 km/h (Schneeberg), große Schäden insbesondere in der Steiermark
1.–2. März 2008 Emma, 222 km/h (Wendelstein)
29. Oktober 2017, Sturmtief Herwart, bis zu 179 km/h, tausende Haushalte ohne Strom, große Schäden in ganz Österreich
21. bis zum 25. Juni 2021 schwere Unwetter mit großem Hagel in Ober- und Niederösterreich, später in der Steiermark[8]
[Bearbeiten | Quelltext bearbeiten]
Die weltweit größten Versicherungsfälle:

Hurrikan Katrina 2005: 125 Mrd. USD. Der Versicherungsschaden belief sich auf 62,2 Mrd. USD.[9]
Hurrikan Andrew 1992: über 20 Mrd. USD[10]
Taifun Mireille 1991: über 7 Mrd. USD[10]
Orkantief Daria 1990: über 6 Mrd. USD[10]
Orkantief Lothar 1999: über 6 Mrd. USD[10]
Hurrikan Hugo 1989: fast 6 Mrd. USD[10]




, Saevert's Naturgewalten





Troglage ist eine Weiterleitung auf diesen Artikel. Zur Troglage als Bauform siehe Einschnitt (Verkehrsweg).

Ein Trog ist ein ausgedehntes Gebiet relativ geringen atmosphärischen Luftdrucks. Bei der Troglage bzw. Trogwetterlage gibt es zwei Ausprägungen: den Höhentrog und den Bodentrog.



Der Bodentrog oder auch Rückseitentrog bezeichnet Gebiete tiefen Luftdrucks an der Rückseite eines kräftigen, bereits alternden Tiefs hinter dessen Kaltfront oder Okklusion. In diesen Gebieten kommt es zu einer erneuten Vertiefung der Zyklone infolge kräftiger Aufgleitvorgänge der Luftmassen, die entstehen, wenn die Höhenwarmluft auf der Vorderseite des Tiefs gegen den Uhrzeigersinn um das Zentrum des Tiefs herumgeführt wird und auf der Rückseite in den Bereich der Kaltluft gelangt.
Bodentröge sind nicht vollständig von höherem Druck umschlossen, was sie von Tiefs unterscheidet. Außerdem weisen sie keine geschlossene Wirbelzirkulation auf. In der Regel (Nordhalbkugel) sind die Isobaren der Kaltluft „sackförmig“ weit in eine südliche Richtung hin ausgebaucht, insofern ist es das Gegenteil einer Omegawetterlage.
Die Isobaren beulen sich vom Kern des Tiefs keil- oder trogförmig aus, wobei der Bodentrog anders als eine Front keine verschiedenen Luftmassen voneinander trennt. Man spricht so lange von einem Trog, wie die Zirkulation nicht abgeschlossen ist. Sobald es im Trogbereich zu einer abgeschlossenen Zirkulation kommt und sich dadurch ein abgeschlossener Kern bildet, spricht man von einem Trogtief.

[Bearbeiten | Quelltext bearbeiten]

Ein Bodentrog kündigt sich dadurch an, dass nach Durchzug der Front nicht wie üblich ein Luftdruckanstieg erfolgt und der Wind nach vorherigem starkem Rechtdrehen wieder rückdreht, sondern der Luftdruck nach kurzem Anstieg erneut schnell weiter fällt. Der Bodentrog folgt einer Kaltfront oder Okklusion meist im Abstand von etwa 15 bis 20 Stunden und bringt dann eine erneute, wesentliche Wetterverschlechterung, die meist von sehr heftigen Windböen begleitet wird.
Die Bewölkung bei Troglagen kann sich grundsätzlich unterscheiden. Manchmal kann eine geschlossene Nimbostratusbewölkung vorherrschen, aus der lang anhaltender bis schauerartiger Niederschlag fällt. Meistens kommt es aber aufgrund der labilen Luftschichtung zu umfangreicher Kumulusbildung mit Schauer- und Gewitterzellen.




Der Höhentrog entsteht durch Mäanderung der Jetstreams. Dabei besteht der Höhentrog aus hochreichender Kaltluft, meist polaren Ursprungs. Beult sich der Jetstream nach Süden aus, so entsteht ein Höhentrog. Beult sich der Jetstream nach Norden aus, so entsteht ein Höhenkeil oder Rücken.
Höhentröge befinden sich meistens in Luftschichten oberhalb von 4000 m. 
Auf einer Trogvorderseite hat der Höhenwind eine südwestliche oder südliche Strömung. Hierbei wird Warmluft nach Nordosten oder Norden transportiert. Auf der Trogrückseite hat der Höhenwind dagegen eine nordwestliche oder nördliche Strömung und es wird Kaltluft nach Südosten oder Süden transportiert.
Tröge und Rücken sind Effekte der Rossby-Wellen.

[Bearbeiten | Quelltext bearbeiten]
Höhentröge sind an den starken zyklonal gekrümmten Isohypsen der Höhenwetterkarte zu erkennen. Als Standardkarte wird meist die Karte der 500-hPa-Druckfläche verwendet, die im Mittel in 5500 Metern Höhe liegt.

[Bearbeiten | Quelltext bearbeiten]
Die Hoch- und Tiefbildung am Boden hängt sehr eng mit den Höhentrögen und -rücken zusammen.

 Isobarenkarte mit Tiefdruckgebiet
In einem Höhentrog besitzen die Höhenlinien (Isohypsen) im Bereich der Trogachse eine starke Krümmung. Vor der Trogachse laufen die Strömungslinien enger zusammen, sie konvergieren. Dadurch nimmt die Windgeschwindigkeit im Bereich der Trogachse zu. Aufgrund der starken Krümmung der Strömungslinien im Bereich der Trogachse wird die Luftmasse abgebremst, was dazu führt, dass sich die Luftmassen vor der Krümmung stauen. Die sich stauenden Luftmassen werden hauptsächlich nach unten abtransportiert, weil nach oben hin das Ende der Troposphäre einen Abtransport verhindert. Absinkende Luftmassen bedeuten am Boden einen steigenden Luftdruck, wodurch auf der Rückseite eines Trogs ein Hochdruckgebiet entsteht.
Hinter der Trogachse nimmt die Krümmung der Stromlinien rasch ab, und die Strömungslinien laufen auseinander, sie divergieren. Dadurch werden am Ausgang des Höhentroges mehr Luftmassen abtransportiert, wodurch es zu einem Massemangel kommt. Als Ausgleich strömen Luftmassen von unten nach. Aufsteigende Luftmassen lassen den Luftdruck am Boden fallen, und es entsteht am Boden ein Tiefdruckgebiet. So sind Tiefdruckgebiete am Boden auf der Vorderseite von Trögen durch die Hebung der Luftmassen sehr wetteraktiv und vertiefen sich hier stark. Für Fronten gilt das Gleiche.
Auch nach der Hoch- und Tiefbildung steuern Höhentröge die Verlagerung der bodennahen Drucksysteme. So verlagern sich bodennahe Tiefs in Abhängigkeit von der Achsenneigung des Höhentrogs zum Tief: Eine vertikale Achsneigung führt zu einem stationären Tief, eine ostwärts geneigte Achse führt zur Entwicklung eines Tiefs bzw. verlagert ein existierendes Tief ostwärts. Eine Rückwärtsneigung der Achse führt analog zur Verlagerung nach Westen bzw. Abschwächung des Tiefs.


An der Grenze zur Warmluft entstehen Kurzwellentröge als kleinere Ausbeulungen am Rande der großräumigen Ausbeulung. Als kleinräumige Tiefdruckgebiete ziehen sie in rascher Folge entlang des Jetstreams nach Nordosten. Sie sind schwerer zu erkennen. Sie sind meistens recht wetterwirksam und können zu Regenfällen, Schnee, heftigen Gewittern und Tornados führen.


Das Hochwasser in West- und Mitteleuropa 2021, bei dem es sich gemessen an der Todeszahl in Deutschland um die schwerste Naturkatastrophe seit der Sturmflut 1962 handelte, wurde von einer Trogwetterlage ausgelöst.


Karl-Heinz Bock, Ralf Brauner, Frank-Ulrich Dentler: Seewetter, DSV-Verlag GmbH, Deutscher Segler-Verband-Verlag GmbH, 2009, ISBN 978-3884123676
 im Wetter-Lexikon von WetterOnline
 bei wissen.de


Dieser Artikel behandelt den Sturm-Typ Tornado. Weitere Bedeutungen finden sich unter Tornado (Begriffsklärung).




Dieser Artikel oder nachfolgende Abschnitt ist nicht hinreichend mit Belegen (beispielsweise Einzelnachweisen) ausgestattet. Angaben ohne ausreichenden Beleg könnten demnächst entfernt werden. Bitte hilf Wikipedia, indem du die Angaben recherchierst und gute Belege einfügst.



Ein Tornado (von spanisch tornar, zu dt. „umkehren, wenden, (sich) drehen“, aus dem lateinischen tornare, mit gleicher Wortbedeutung[1]), auch Großtrombe, Wind- oder Wasserhose, ist ein kleinräumiger Luftwirbel in der Erdatmosphäre mit annähernd senkrechter Drehachse. Er hängt zusammen mit konvektiver Bewölkung (Cumulus und Cumulonimbus) und unterscheidet sich damit von Kleintromben (Staubteufeln). Der Wirbel erstreckt sich durchgehend vom Boden bis zur Wolkenuntergrenze, muss dabei aber nicht durchweg kondensiert sein. Diese Definition geht auf Alfred Wegener (1917) zurück und ist heute noch allgemein anerkannt. Die Bezeichnung Tornado wurde jedoch bereits vorher für Luftwirbel verwendet, und zwar mindestens seit dem 18. Jahrhundert.[2]
Die Benennungen Wind- und Wasserhose (engl.: Waterspout) bezeichnen im deutschen Sprachraum einen Tornado über Land beziehungsweise über größeren Wasserflächen (Meer, große Binnenseen).
Die Benennung Windhose – in der älteren Literatur noch wohldefiniert (Wegener) – wurde in der jüngeren Vergangenheit vermehrt undifferenziert für verschiedene Phänomene im Zusammenhang mit plötzlich auftretenden starken Winden verwendet (zum Beispiel Downburst) oder fälschlich auf Kleintromben bezogen. Zudem wurde der Eindruck eines Unterschieds zwischen großen Tornados in Nordamerika und kleinen Windhosen in Europa erweckt. Ein Unterschied zwischen Windhosen und Tornados besteht jedoch weder bezüglich ihrer physikalischen Natur noch bezüglich ihrer Stärke.




Die Entstehung von Tornados ist sehr komplex und bis heute ein aktueller Forschungsgegenstand. Trotz offener Fragen in Bezug auf Details sind die Voraussetzungen und die prinzipiellen Mechanismen der Tornadogenese recht gut bekannt. Unter den entsprechenden Bedingungen können sich Tornados an jedem Ort während des ganzen Jahres bilden. Trotzdem gibt es sowohl räumliche als auch jahres- und tageszeitliche Schwerpunkte, welche unter Klimatologie weiter unten näher beschrieben sind.


Für die Entstehung eines Tornados müssen zunächst die Voraussetzungen für hochreichende Feuchtekonvektion gegeben sein. Diese sind bedingte Labilität, also eine hinreichend starke vertikale Temperaturabnahme, genügendes Feuchteangebot (latente Wärme) in den unteren 1–2 km der Atmosphäre sowie Hebung der Luftmasse, um die Feuchtekonvektion auszulösen. Hebungsmechanismen können thermischer (Sonneneinstrahlung) oder dynamischer (Fronten) Natur sein. Wesentlicher Energielieferant solcher Stürme und Gewitter allgemein ist die im Wasserdampf der feuchten Luftmasse gespeicherte latente Wärme, welche bei der Kondensation freigesetzt wird. Erst diese zusätzliche Wärmemenge ermöglicht ein hochreichend freies Aufsteigen der Luft (Feuchtekonvektion), da die Atmosphäre gegenüber trockener Konvektion, abgesehen von bodennaher Überhitzung, stabil ist. Im letzteren Fall kann es lediglich zur Bildung von Kleintromben kommen. An der Böenfront eines Schauers oder Gewitters können Kleintromben, die sogenannten Böenfrontwirbel oder Gustnados, entstehen. Diese können sich zu Tornados entwickeln, sofern sie Kontakt zu dem feuchtkonvektiven Aufwind bekommen und so verstärkt werden.


Hinsichtlich der Entstehungsweise lassen sich zwei Klassen von Tornados unterscheiden:



Bei mesozyklonalen Tornados tritt zu den oben beschriebenen grundlegenden Zutaten für Schauer- oder Gewitterwolken eine starke vertikale Windscherung, das heißt eine Zunahme der Windgeschwindigkeit und Änderung der Windrichtung mit der Höhe hinzu. Dieses Windprofil ermöglicht die Bildung von Gewitterzellen mit einem rotierenden Aufwind (Mesozyklone), so genannte Superzellen, welche sich durch Langlebigkeit bis zu mehreren Stunden und heftige Begleiterscheinungen, wie großen Hagel, Sturzregen und Gewitterfallböen bis über 200 km/h auszeichnen. Bei 10–20 % aller Superzellen kommt es zur Bildung von Tornados. Vielfach ist vor der Tornadoentstehung eine Absenkung der rotierenden Wolkenbasis, eine sogenannte Wallcloud (deutsch: Mauerwolke) zu beobachten. Durch die Aufwärtsbewegung im Zentrum strömt im unteren Bereich Luft zur Drehachse hin, was aufgrund des Pirouetteneffekts zu einem enormen Zuwachs der Windgeschwindigkeit zur Achse hin führt. Eine wesentliche Rolle scheint hier die Bodenreibung zu spielen; die Details der Intensivierung der Rotation bis hin zum Bodenkontakt sind aber noch nicht gänzlich verstanden. Die Drehrichtung von mesozyklonalen Tornados ist überwiegend zyklonal, das heißt entgegen dem Uhrzeigersinn auf der Nordhalbkugel und mit dem Uhrzeigersinn auf der Südhalbkugel. Dies ist aber kein unmittelbarer Effekt der Corioliskraft, denn dafür sind Tornados zu kleinräumig. Diese bestimmt vielmehr zusammen mit der Bodenreibung, welche stark orographisch beeinflusst ist, das großräumige Windprofil von Tiefdruckgebieten, in deren Bereich Tornados entstehen können. In den meisten Fällen dreht auf der Nordhalbkugel der Wind mit der Höhe nach rechts, wobei die Luft aus südlicher Richtung in die Mesozyklone einströmt, was zu zyklonaler Rotation entgegen dem Uhrzeigersinn führt. Auf der Südhalbkugel ergibt sich entsprechend ebenfalls zyklonale Rotation, dort aber im Uhrzeigersinn. Gelegentlich bildet sich neben dem zyklonal rotierenden Tornado ein weiterer, antizyklonal rotierender Tornado aus. In solchen Fällen entsteht ein weiterer Aufwindbereich, in dem sich konvektive Wolken bilden. Dieser Aufwindbereich wird vom hinteren rechten Hauptaufwind mitgerissen, wodurch eine sogenannte Antimesozyklone entsteht, aus der sich der antizyklonal rotierende Tornado bilden kann. Eine solche Antimesozyklone ist in der Regel deutlich schwächer als die Hauptmesozyklone und zieht mit dieser mit.[3]


Dieser Entstehungsmechanismus setzt keine Mesozyklone voraus. Vielmehr zerfällt vorhandene bodennahe horizontale Windscherung, z. B. entlang einer Konvergenzlinie in einzelne Wirbel mit vertikaler Achse, welche durch einen darüber befindlichen feuchtkonvektiven Aufwind einer Schauer- oder Gewitterwolke gestreckt und somit intensiviert werden (siehe nebenstehende Abbildung und Literatur). Dies geschieht in sonst eher windschwacher Umgebung bei gleichzeitig starker vertikaler Temperaturabnahme in den unteren Schichten. Im Gegensatz zu Mesozyklonen reicht hier die Rotation nicht weit über die Wolkenbasis hinaus. Die Bindung an Linien mit horizontaler Windscherung, (Konvergenz), welche oft gleichzeitig den Hebungsantrieb für die Feuchtekonvektion darstellt, erzeugt nicht selten entlang der Linie angeordnete Familien von Großtromben.[4] Zu diesem eher schwächeren nicht-mesozyklonalen Tornadotyp zählen auch die meisten Wasserhosen, aber es können auf diese Weise auch Tornados über Land entstehen – im Englischen Landspout genannt. Der Drehsinn von nicht-mesozyklonalen Tornados zeigt eine weniger starke Präferenz für zyklonale Rotation.
Kaltlufttromben hingegen ereignen sich in Verbindung mit konvektiven Wolken, welche sich innerhalb eines Kaltluftreservoirs in Umgebungen mit verhältnismäßig wenig Windscherung in der Höhe entwickeln.[5] Sie erreichen nur sehr selten den Boden, aber manchmal kommt es zu einem Touchdown und sie werden zu schwachen, kurzlebigen Tornados.[6]





Im Anfangsstadium ist ein Tornado zunächst fast unsichtbar. Erst wenn im Inneren des Wirbels durch den Druckabfall und die damit einhergehende adiabatische Abkühlung Wasserdampf kondensiert oder Staub, Trümmer, Wasser und dergleichen aufgewirbelt werden, tritt der Tornado auch optisch in Erscheinung. Eine durchgehende Kondensation von der Wolke bis zum Boden ist nicht in jedem Fall zu beobachten. Eine solche von der Mutterwolke ausgehende Kondensation wird als Trichterwolke (englisch: funnel cloud) bezeichnet. Erreicht der Luftwirbel den Boden nicht, so spricht man von einer Blindtrombe. Für einen Tornado ist der Bodenkontakt des Luftwirbels entscheidend, nicht dessen durchgehende Sichtbarkeit. Sind zum Beispiel unter einer Trichterwolke Windwirkungen nachweisbar, also im Regelfall Schäden am Boden, so handelt es sich um einen Tornado. Die Gestalt des Luftwirbels ist sehr vielfältig und reicht von dünnen schlauchartigen Formen bis zu einem mehr oder weniger breiten, sich nach oben erweiternden Trichter (siehe nebenstehende Abbildungen und Weblinks). Dabei kann der Durchmesser einige Meter bis hin zu 500 m und sogar bis über 1 km betragen. Nicht selten treten – besonders bei großen Durchmessern – mehrere Wirbel auf, die um ein gemeinsames Zentrum kreisen, was als Multivortex-Tornado bezeichnet wird. Staub, Trümmer und kondensiertes Wasser können mitunter verhindern, dass ein Multivortex-Tornado als solcher erkannt wird, weil die Einzelwirbel nicht sichtbar sind.



Die Klassifizierung erfolgt nach der Fujita-Skala, welche über die Windgeschwindigkeit definiert ist. In der Praxis wird diese Skala aber mangels direkter Messungen anhand der vom Tornado verursachten Schäden geschätzt. Diese reichen von leichten Sturmschäden bis zur völligen Zerstörung massiver Gebäude. Bislang wurden Tornadostärken F0 bis F5 in der Realität beobachtet; physikalische Abschätzungen ergeben aus energetischen Gründen die Intensität F6 als Obergrenze. In Europa ist daneben z. B. bei TorDACH die gegenüber der Fujita-Skala doppelt so feine TORRO-Skala in Gebrauch, in den USA wurde die Fujita-Skala zur sogenannten Enhanced Fujita Scale, kurz EF-Skala, weiterentwickelt, die über die Stufen EF0 bis EF5 verfügt und die Tornados anhand von 28 Schadensindikatoren klassifiziert.


Die Kraft eines Tornados kann vielfältige Schäden verursachen. Er kann Häuser und Autos zerstören und stellt eine Gefahr für Tiere und Menschen dar. Auch Steinhäuser sind nicht sicher. Indirekt entstehen viele Schäden durch umherfliegende Trümmer.
Hauptursache der Schäden ist der Staudruck des Windes und oberhalb von circa 300 km/h auch zunehmend indirekte Schäden durch umherfliegende Trümmer.
Die frühere Annahme, der starke Unterdruck innerhalb eines Tornados, der bis zu 100 hPa betragen kann, lasse Gebäude gleichsam explodieren, ist nicht mehr haltbar. Auf Grund ihrer hohen und auf engem Raum wechselnden Windgeschwindigkeiten stellen Tornados prinzipiell eine Gefahr für den Flugverkehr dar; Unfälle sind aber auf Grund der Kleinräumigkeit dieser Wettererscheinung selten. Zu einem spektakulären Fall kam es am 6. Oktober 1981, als der NLM-Cityhopper-Flug 431 in einen Tornado geriet und nach Abriss der rechten Tragfläche abstürzte. Alle 17 Personen an Bord starben.



Die Dauer eines Tornados beträgt zwischen wenigen Sekunden und mehr als einer Stunde, durchschnittlich liegt sie unter zehn Minuten. Die Vorwärtsbewegung eines Tornados folgt der zugehörigen Mutterwolke und liegt im Schnitt bei 50 km/h, kann aber auch deutlich darunter (praktisch stationär, nicht selten bei Wasserhosen) oder darüber (bis über 100 km/h bei starker Höhenströmung) liegen. Dabei ist die Tornadospur im Wesentlichen linear mit kleineren Abweichungen, welche durch die Orographie und das lokale Windfeld in der Umgebung der Gewitterzelle bedingt sind.
Die interne Rotationsgeschwindigkeit des Windes ist jedoch meist wesentlich höher als die der linearen Bewegung und für die schweren Verwüstungen verantwortlich, die ein Tornado hinterlassen kann. Die höchste je registrierte Windgeschwindigkeit innerhalb eines Tornados wurde während des Oklahoma Tornado Outbreak am 3. Mai 1999 bei Bridge Creek, Oklahoma (USA) mit einem Doppler-Radar bestimmt. Mit 496 ± 33 km/h lag sie im oberen Bereich der Klasse F5 der Fujita-Skala; die obere Fehlergrenze reicht sogar in den F6-Bereich. Dies ist damit die höchste je gemessene Windgeschwindigkeit auf der Erdoberfläche überhaupt. Oberhalb der Erdoberfläche erreichten nur Jetstreams höhere Windgeschwindigkeiten. In der offiziellen Statistik fällt dieser Tornado aber mit Rücksicht auf den wahrscheinlichsten Wert und die Unsicherheiten unter F5.
In den USA sind etwa 88 % der beobachteten Tornados schwach (F0, F1), 11 % stark (F2, F3) und unter 1 % verheerend (F4, F5). Diese Verteilungsfunktion ist weltweit sehr ähnlich und in dieser Form von mesozyklonalen Tornados dominiert, welche das volle Intensitätsspektrum ausfüllen. Die Intensität von nicht-mesozyklonalen Tornados geht dagegen kaum über F2 hinaus.


Tornados entstehen über Land am häufigsten im Frühsommer, wobei das Maximum mit zunehmenden Breitengraden später auftritt. Über Wasser wird das Maximum im Spätsommer erreicht, weil dann die Wassertemperatur und folglich die Labilität am höchsten ist. Ähnliches gilt für den Tagesgang. Tornados über Land treten am wahrscheinlichsten in den frühen Abendstunden auf, während bei Wasserhosen das Maximum in den Morgenstunden liegt. Ferner zeigt sich bei Wasserhosen ein klimatologischer Unterschied im Jahresgang, je nachdem, ob diese an Land ziehen oder über dem Wasser verbleiben. Die jahreszeitliche Verteilung für den ersten Fall gleicht der für Tornados über Land, während reine Wasserhosen das besagte Spätsommermaximum zeigen.


Tornados werden weltweit überall da beobachtet, wo es Gewitter gibt. Schwerpunkte sind Regionen mit fruchtbaren Ebenen in den Subtropen bis in die gemäßigten Breiten. An erster Stelle steht der Häufigkeit nach der Mittlere Westen der USA, wo die klimatischen Bedingungen für die Bildung von schweren Gewittern und Superzellen aufgrund der weiten Ebenen (Great Plains) östlich eines Hochgebirges (Rocky Mountains) und nördlich eines tropischen Meeres (Golf von Mexiko) sehr günstig sind. Für Wetterlagen mit hohem Unwetterpotential bedingt das Gebirge relativ trockene und kühle Luftmassen im mittleren bis oberen Bereich der Troposphäre bei südwestlichen bis westlichen Winden, während in den tieferen Schichten feuchtwarme Luftmassen aus der Golfregion ungehindert nach Norden transportiert werden können. Dadurch kommt eine labile Schichtung der Atmosphäre bei einem großen Angebot latenter Wärme mit einer Richtungsscherung des Windes zusammen.


Weitere wichtige Regionen sind Mittel-, Süd- und Osteuropa, Argentinien, Südafrika, Bengalen, Japan und Australien. Zahlreiche, wenn auch im Mittel schwächere, meist nicht-mesozyklonale Tornados treten im Bereich der Front Range (Ostrand der Rocky Mountains), in Florida und über den Britischen Inseln auf.
Jährlich werden in den USA etwa 1200 Tornados registriert, die meisten entstehen in Texas, Oklahoma, Kansas und Nebraska entlang der Tornado Alley mit etwa 500 bis 600 Fällen pro Jahr. Dies ist durch die oben genannten besonderen klimatischen Bedingungen gegeben, welche die Voraussetzungen für die Entstehung speziell von mesozyklonalen Tornados weit häufiger als in anderen Regionen bieten. Darüber hinaus gibt es in den USA mehrere regionale Häufungen, z. B. in Neuengland und in Zentral-Florida.
In Europa liegt die jährliche Zahl der Tornadobeobachtungen bei 330, davon 160 über Wasser, unter Einbeziehung der Dunkelziffer schätzungsweise bei 590 Tornados, davon geschätzt 290 Wasserhosen (2020: 800 gemeldete Ereignisse[7]). Wie in den USA sind auch die meisten europäischen Tornados schwach. Verheerende Tornados sind zwar selten, doch sind bisher acht F4- und zwei F5-Ereignisse aus Deutschland dokumentiert. Letztere wurden bereits von Alfred Wegener 1917 in einer Arbeit zur Tornadoklimatologie Europas beschrieben. Weitere verheerende Fälle sind aus Nordfrankreich, den Benelux-Staaten, Österreich, Oberitalien sowie aus der Schweiz (hier ein F4- und ein F5-Ereignis dokumentiert) bekannt.


In Deutschland liegt die Zahl der jährlich beobachteten Tornados bei durchschnittlich 30 bis 60 mit einer noch recht hohen Dunkelziffer vor allem schwächerer Ereignisse. Genaue Zahlen sind nur auf der Tornadoliste.de verfügbar.[8] Nach den derzeit vorliegenden Zahlen muss jährlich mit etwa fünf oder mehr F2, mit einem F3 alle zwei bis drei Jahre und alle 20 bis 30 Jahre mit einem F4 gerechnet werden. Ein F5 ist nach derzeitigen Erkenntnissen ein Jahrhundertereignis oder noch seltener.
Eine Übersicht zur räumlichen und zeitlichen Verteilung von Tornados in Deutschland und deren Intensität findet sich in den Weblinks. Generell ist festzustellen, dass das Tornadorisiko im Westen der Norddeutschen Tiefebene am höchsten ist.
In Österreich wurden im Schnitt der vergangenen 30 Jahre jährlich etwa drei Tornados beobachtet. Allerdings ist seit 2002 durch die vermehrte Spotter- und Statistiktätigkeit v. a. ehrenamtlicher Helfer eine mittlere Anzahl von etwa fünf Tornados/Jahr zu beobachten. Unter Einbezug einer möglicherweise recht hohen Dunkelziffer sowie der nach wie vor sehr unterrepräsentierten F0-Fälle könnte die tatsächliche, gemittelte, jährliche Anzahl bei bis zu zehn Tornados liegen.
Dabei treten jedes Jahr mehrere F0- und F1-Fälle auf. Im Schnitt kann zudem mit einem F2 jährlich, bzw. einmal in zwei Jahren, alle fünf bis zehn Jahre auch mit einem F3 gerechnet werden. Bisher ist auch ein F4-Tornado in Österreich dokumentiert.
Die höchste Tornadodichte ist dabei in der Südoststeiermark zu beobachten (um drei Tornados/10.000 km²/Jahr), gefolgt von dem Gebiet um den Hausruck in Oberösterreich, dem Wiener Becken, der Region um Linz, dem westlichen Weinviertel, dem Klagenfurter Becken, Bodensee-Region sowie dem Inntal im Bereich von Innsbruck.


Generell ist das Auftreten von Tornados starken Schwankungen unterworfen, was sich in Häufungen (Ausbruch genannt, englisch: Outbreak) innerhalb recht kurzer Zeitspannen – oft an einem einzigen Tag – äußert, gefolgt von recht langen Abschnitten relativer Ruhe. Die Ausbrüche sind durch den engen Zusammenhang mit bestimmten Wetterlagen begründet, wo mehrere Faktoren für die Tornadoentstehung zusammenkommen (siehe oben unter Entstehung). Größere Ereignisse dieser Art mit verheerenden Tornados sind vor allem aus den USA bekannt (siehe folgenden Abschnitt). Für West- und Mitteleuropa sind hier die Jahre 1925, 1927 und 1967 zu nennen mit dem Schwerpunkt Nordfrankreich/Benelux/Nordwestdeutschland. Diese Region kann auch als europäische tornado alley angesehen werden. Der zahlenmäßig bedeutendste Ausbruch in Europa mit insgesamt 105, aber meist schwächeren Tornados (max. F2) traf am 23. November 1981 die Britischen Inseln.
Derzeit erlaubt die Datenbasis für Mitteleuropa keine Aussage, ob Tornados auf Grund der globalen Klimaerwärmung häufiger auftreten, da der Anstieg der beobachteten Fälle vor allem auf eine bessere Erfassung in den letzten Jahren zurückzuführen ist. In den USA existiert dank systematischer Tornadoforschung seit den 1950er Jahren und bedingt durch die hohen Fallzahlen eine belastbare Statistik. Diese zeigt aber weder eine Tendenz zu vermehrtem Auftreten noch zu größerer Heftigkeit von Tornados, wie im IPCC-Bericht von 2001 dargelegt.


→ Hauptartikel: Liste von Tornados



Bereits im 19. Jahrhundert befassten sich amerikanische Meteorologen wie James Pollard Espy mit der Erforschung von Wasserhosen und Stürmen.[9]
In den 1930er und 1940er Jahren machte die Radartechnik große Fortschritte. Man entdeckte, dass z. B. Niederschläge sich auf Radarmessungen auswirkten. Das Wetterradar entstand.
Obwohl Tornados in den USA eine lange bekannte Naturerscheinung sind, ist die Tornadoforschung dort noch recht jung. Die erste erfolgreiche Tornadovorhersage konnte 1948 auf der Tinker Air Force Base gemacht werden. Erst seit den 1950er Jahren widmet man sich in den USA systematisch der Erfassung und Vorhersage.
Interessanterweise ist die Tornadoforschung in Europa älter als in den USA. Pionierarbeit leistete hier Alfred Wegener schon in der ersten Hälfte des 20. Jahrhunderts. In den 1930er Jahren unternahm der heute fast vergessene Meteorologe Johannes Peter Letzmann in Deutschland eine systematische Tornadoforschung, welche durch die Ereignisse des Zweiten Weltkrieges stark eingeschränkt und danach nicht weitergeführt wurde. Im Gegenteil sank das Interesse an Tornados in der Folgezeit praktisch zur Bedeutungslosigkeit herab und beschränkte sich auf einige wenige spektakuläre Fälle wie zum Beispiel den Tornado über Pforzheim 1968. Erst mit der Gründung des Netzwerkes TorDACH 1997 nahm die Tornadoforschung im deutschsprachigen Raum einen neuen Aufschwung. 2003 wurde in Deutschland, Österreich und der Schweiz Skywarn jeweils als Verband ehrenamtlicher Spotter zur Verbesserung der kurzfristigen Unwetterwarnungen im deutschsprachigen Raum gegründet. Auf europäischer Ebene gibt es ein Pilotprojekt zum Aufbau eines European Severe Storms Laboratory, ESSL (siehe Weblink).
Zwei technische Fortschritte brachten die Tornadoforschung stark voran:

Das Doppler-Wetterradar ermöglichte es, zusätzlich zur räumlichen Verteilung der Niederschlagsintensität auch die Radialgeschwindigkeit des Niederschlags zu bestimmen, indem man den Doppler-Effekt maß. Kleinräumige Änderungen in der Radialgeschwindigkeit können Anzeichen von starker Luftzirkulationen sein (→ Windhose, Tornado)
Das Polarimetrische Wetterradar ist ein Doppler-Wetterradar, das Impulse mit verschiedenen Polarisationen senden und empfangen kann. Indem man mehrere Polarisationen elektromagnetischer Wellen sendet, kann man Informationen über die Form und die Art des Niederschlags gewinnen.
→ Hauptartikel: Geschichte des Radars
Viele Kriegsparteien verwendeten Wetterflugzeuge, um Erkenntnisse über Wetterphänomene in großen Höhen zu erlangen. 1931 wurde die erste Druckkabine eingesetzt.



Die Forschung umfasst Aspekte der Psychologie, der Meteorologie und der Katastrophenforschung.
Das Ziel in der Meteorologie ist die Verbesserung der Vorwarnzeit. Die Zeit zwischen Warnung und dem Eintreten des Ereignisses wird als Lead Time bezeichnet. Aktuell beträgt sie im Durchschnitt 13 Minuten. Eine exakte / genaue Vorhersage eines Tornados, seiner Stärke und seines Weges ist mit den aktuellen Mitteln nicht möglich. Dazu bräuchten die Forscher bessere Kenntnisse über die Faktoren Windgeschwindigkeit, Temperatur und Luftdruck.
Wegen des kurzfristigen Auftretens von Tornados konzentriert sich die Wissenschaft auf die frühzeitige Erkennung, wobei das Doppler-Radar ein wesentliches Instrument darstellt. Hiermit lässt sich bereits im Frühstadium verdächtige Rotation in Gewitterwolken nachweisen. Ein deutlicher Hinweis sind Hakenechos auf dem Radarbild.
Die heutige Tornadoforschung konzentriert sich neben der Klimatologie und der Erstellung von Fallstudien auf die Mechanismen der Tornadogenese (siehe oben). Hierzu werden aufwändige numerische Simulationsrechnungen durchgeführt, um ein besseres Verständnis der Entstehung von Tornados zu gewinnen.
Die Methode ist, mittels Vergleich von Tornadoerscheinungen Gemeinsamkeiten und Unterschiede herauszuarbeiten, um die Entstehung und damit die Voraussetzungen von Tornados besser abbilden zu können. Auf diese Weise lassen sich begünstigende Faktoren identifizieren.
Hinzu kommt ein dichtes Netzwerk ehrenamtlicher Beobachter, so genannte Spotter, welche aktuelle Warnmeldungen über gesichtete Tornados und auch andere Wettergefahren, wie zum Beispiel Gewitterfallböen, Hagel und Sturzfluten, in das Kurzfrist-Warnsystem einbringen. Die Spotter sind in dem Netzwerk Skywarn organisiert. Daneben besteht eine wachsende Zahl von storm chasers (privaten Sturmjägern), welche primär aus Faszination an den Naturgewalten Gewitter und Tornados verfolgen, dabei aber auch wertvolle Informationen für die Unwetter- und Tornadoforschung liefern. Für eine gute Forschung sind sie als Augenzeugen unabdingbar, da selbst die besten Radargeräte anfällig für Fehler sind und eine verifizierte Rückmeldung nur durch Beobachter vor Ort erfolgen kann. Hauptquartier der Unwetterforschung in den USA ist das 1964 gegründete National Severe Storms Laboratory (NSSL) mit Sitz in Norman, Oklahoma. Dank des Warnsystems konnte in den USA die Zahl an Tornadoopfern erheblich reduziert werden.
Ein bedeutender Forscher ist Howard Bluestein. Er entwickelte das Doppler-Radar weiter, sodass eine mobile, auf einem Truck installierbare Einheit in der Lage ist, alle 2 Sekunden einen Scan des Himmels durchzuführen. Seine These ist, dass die Regentropfen einen Einfluss auf die Entstehung und Größe eines Tornados haben. Darüber hinaus ergaben seine Forschungen, dass es unterhalb der Wolkengrenze eine regenfreie Zone innerhalb der Aufluft gibt. Daraus könnte sich eine weitere Möglichkeit für eine bessere Vorhersage von Tornados ergeben.[10]
Auch der Deutsche Wetterdienst plant den Aufbau eines Tornado-Frühwarnzentrums, vor allem wegen der zu Beginn des 21. Jahrhunderts gehäuften Tornadomeldungen, die vor allem auf eine erhöhte Sensibilisierung in der Bevölkerung zurückzuführen sind.
Die Psychologie beschäftigt sich mit dem Phänomen der Warnung vor Tornados. Eine Fragestellung ist, wie Vorhersagen gestaltet sein müssen, um die Menschen für das für sie gefährliche Ereignis zu sensibilisieren.
In der Katastrophenforschung geht es darum, anhand der verursachten Schäden herauszufinden, wie die Bausubstanz kostengünstig verbessert werden kann, um die Schäden der Naturerscheinung zu verringern.


Die Bevölkerung wird auf vielfältige Weise geschützt. In den USA gibt es ein Netz aus 159 bodennahen Radarsystemen. Wird ein Tornado erkannt, erfolgt eine Meldung im nationalen TV und in den lokalen Radiostationen. Außerdem werden warnende Sirenen ausgelöst. Durch die Nachrichten erfolgt die Aufforderung, Keller oder Schutzräume aufzusuchen. Mittlerweile wurden diese weiterentwickelt und können bautechnisch verstärkt werden.


Gottlob Burchard Genzmer (1765): Beschreibung des Orcans, welcher den 29. Jun. 1764 einen Strich von etlichen Meilen im Stargardischen Kreise des Herzogthums Mecklenburg gewaltig verwüstet hat. Friedrich Nicolai, Berlin und Stettin 1765. 
Alfred Wegener (1917): Wind- und Wasserhosen in Europa. Vieweg, Braunschweig,  
Johannes Peter Letzmann (1937): Richtlinien zur Erforschung von Tromben, Tornados, Wasserhosen und Kleintromben. Internationale Meteorologische Organisation, Klimatologische Kommission, Publ. 38, Salzburg, S. 91–110. 
Thomas P. Grazulis (1993): Significant Tornadoes: 1860–1991. Environmental Films, ISBN 1-879362-00-7
Nikolai Dotzek (2003): An updated estimate of tornado occurrence in Europe. Atmos. Res. 67–68, 153–161 
James M. Caruso and Jonathan M. Davies (2005) Tornadoes in Non-mesocyclone Environments with Pre-existing Vertical Vorticity along Convergence Boundaries. NWA Electronic Journal of Operational Meteorology 1 June 2005 

Twister
Tornado – Der Zorn des Himmels
Category 6 – Der Tag des Tornado
Category 7 – Das Ende der Welt
Tornado – Niemand wird ihm entkommen






 (archiviert bei YouTube)
Deutschsprachiger Raum:








Europa insgesamt:

 (englisch; PDF-Datei; 12,81 MB)
 (englisch)
 (englisch)
USA/Nordamerika:

 (englisch)
 Essay von Charles A. Doswell, Cooperative Institute for Mesoscale Meteorological Studies, Norman (OK), USA (englisch)
 Die deutsche Übersetzung des Doswell-Artikels von Felix Welzenbach
 (englisch)



Dieser Artikel oder Abschnitt bedarf einer grundsätzlichen Überarbeitung: Skala ist veraltet Bitte hilf mit, ihn zu verbessern, und entferne anschließend diese Markierung.




Dieser Artikel behandelt den tropischen Wirbelsturm. Für das gleichnamige Kartenspiel siehe Hurrikan (Kartenspiel).




Hurrikan wird ein tropischer Wirbelsturm im nördlichen atlantischen Ozean (einschließlich der Karibik und des Golfs von Mexiko) sowie im Nordpazifik östlich von 180° Länge und im Südpazifik östlich von 160° Ost (also östlich der internationalen Datumsgrenze) genannt. Dieser muss mindestens Orkanstärke erreichen, also Windstärke 12 auf der Beaufortskala (das entspricht mehr als 64 Knoten oder 118 km/h oder ca. 32,9 m/s). Hurrikane entstehen in der Regel zwischen Mai und Dezember, die meisten davon zwischen Juli und September. Die offizielle Hurrikansaison dauert im Atlantischen Ozean und im zentralen Nordpazifik vom 1. Juni bis zum 30. November, im östlichen Nordpazifik beginnt sie bereits am 15. Mai.




Die Bezeichnung „Hurrikan“ geht wohl auf die Sprache der Taíno, der indianischen Ureinwohner der Großen Antillen, zurück. Dies geht aus dem ersten schriftlichen Nachweis des Wortes überhaupt hervor. Er findet sich in der ersten der acht „Dekaden“ (erschienen 1511/1516) des von Petrus Martyr von Anghieras auf lateinisch verfassten Werkes De Orbe Novo. Anglerius berichtet hier von einem Sturm, der 1495 den spanischen Stützpunkt La Isabela verwüstete, und bemerkt zu dieser Gelegenheit, dass solcherart Naturgewalten, die den Griechen als typhōn (vgl. Taifun) bekannt seien, von den Eingeborenen Hispaniolas furacanes genannt würden (‚has aeris procellas uti Graeci typhones, furacanes isti appellant‘). Naheliegend, aber nicht bewiesen ist die häufig zu lesende Vermutung, dass hier ein Zusammenhang mit Huracán bzw. Hun-r-akan besteht, dem Namen einer unter anderem für schwere Stürme verantwortlichen Gottheit der Maya des mittelamerikanischen Festlands, die mit den Taíno allerdings sprachlich nicht verwandt und auch kulturell sehr verschieden waren.[1][2]
Über das Spanische (huracán, erstmals 1526 bei Gonzalo Fernández de Oviedo bezeugt) gelangte das Wort noch im 16. Jahrhundert ins Portugiesische (furacão, der Anlaut /f/ erklärt sich als latinisierende Hyperkorrektur) sowie ins Französische (in der obsoleten Form huracan erstmals 1553, in der heutigen Schreibung ouragan 1640 nachgewiesen), im 17. Jahrhundert dann ins Niederländische und von dort ins Deutsche –  allerdings zuerst in der Form „Orkan“, die im heutigen Sprachgebrauch indes keine Tropenwinde bezeichnet, sondern die atlantischen Stürme, die besonders im Herbst und Winter häufiger über Europa hinwegfegen.[3] Die etymologische Dublette „Hurrikan“ als Bezeichnung für tropische Stürme in fernen Gefilden wurde im Deutschen hingegen erst gegen Mitte des 19. Jahrhunderts als Fremd- oder Lehnwort geläufig und zeigt deutlich den Einfluss des Englischen (hurricane, die Schreibung erklärt sich wohl durch eine volksetymologische Assoziation mit hurry, „Eile, Schnelle“; im 17. Jahrhundert, etwa bei Sir Walter Raleigh, finden sich außerdem noch verschiedentlich Formen wie hurlecan, die offenkundig an das Verb hurl „wirbeln“ anknüpfen).[4][5][6]


Der Online-Duden verzeichnet für die deutsche Schreibweise Hurrikan sowohl die deutsche [ˈhʊrikan] als auch die englische Aussprache [ˈhʌrɪkən], wobei die englische zuerst genannt wird. Bei deutscher Aussprache lautet die Mehrzahl Hurrikane, bei englischer hingegen Hurrikans.[7] Der gedruckte Duden von 2005 nennt die Aussprache [ˈharikən], die neben [ˈhʊrika(ː)n] auch in Wörterbüchern von Pons aufscheint.[8]



Als „Hurrikan“ werden heute im Allgemeinen nur tropische Stürme bezeichnet, die die Meere und Küsten östlich und westlich des amerikanischen Doppelkontinents betreffen.
Wirbelstürme im Indischen Ozean (Golf von Bengalen und Arabisches Meer) und im südlichen Pazifischen Ozean werden hingegen als Zyklon bezeichnet.
Stürme, die Ost- und Südostasien oder den nordwestlichen Teil des Pazifiks (westlich der internationalen Datumsgrenze und nördlich des Äquators) betreffen, werden Taifun genannt.
Auch auf dem Mittelmeer werden gelegentlich Stürme beobachtet, die tropischen Wirbelstürmen ähneln. Ein solcher Sturm wird auch Medicane genannt (Kofferwort aus engl. Mediterranean Sea (Mittelmeer) und hurricane).



Atlantische Hurrikane mit den meisten Opfern


Rang

Hurrikan

Jahr

Todesopfer


1

Großer Hurrikan von 1780

1780

22.000+


2

Hurrikan Mitch

1998

11.000–18.000


3

Galveston-Hurrikan 1900

1900

6.000–12.000


4

Hurrikan Fifi

1974

8.000–10.000


5

San-Zenon-Hurrikan

1930

2.000–8.000


6

Hurrikan Flora

1963

7.186–8.000


7

Pointe-à-Pitre

1776

6.000+


8

Neufundland-Hurrikan

1775

4.000–4.163


9

Okeechobee-Hurrikan

1928

3.375–4.075


10

San-Ciriaco-Hurrikan

1899

3.064–3.433+


Rangordnung nach der höchsten angenommenen Opferzahl.

Die hohen Windgeschwindigkeiten, Wellen und schweren Niederschläge eines Hurrikans stellen eine große Gefahr dar. Sie führen zu Sturmflut, Windbruch, Küstenerosion, Erdrutschen, Sturzfluten und Überschwemmungen.
Den bislang höchsten materiellen Schaden richtete im August 2005 mit etwa 81 Milliarden Dollar Hurrikan Katrina an. Katrina zog mit Windgeschwindigkeiten von 250 bis 300 km/h über Florida, Louisiana – insbesondere über den Großraum New Orleans –, Mississippi, Alabama und Tennessee hinweg und forderte über tausend Menschenleben.
Die größte Anzahl von Toten durch einen atlantischen Hurrikan, nämlich rund 22.000 Menschenleben, verursachte der Große Hurrikan von 1780.
Der stärkste bis dato gemessene Hurrikan im Atlantischen Ozean war Hurrikan Wilma. Mit einem Kerndruck von 882 hPa herrschte im Zentrum Wilmas der niedrigste Luftdruck, der jemals auf dem Atlantik gemessen wurde. Außerdem intensivierte sich Wilma vom 18. bis zum 19. Oktober 2005 und damit schneller als alle anderen beobachteten Hurrikane innerhalb nur weniger Stunden von einem tropischen Sturm mit Windgeschwindigkeiten unter 113 km/h zu einem Hurrikan der Kategorie 5 (über 282 km/h).
Der sowohl stärkste Hurrikan im Nordpazifik als auch der stärkste jemals gemessene Hurrikan weltweit war Hurrikan Patricia. Der Kerndruck von Patricia betrug 872 hPa, was einen Rekord auf der westlichen Hemisphäre darstellt. Nur in Taifun Tip konnte mit 870 hPa ein noch niedrigerer Luftdruck gemessen werden. Hurrikan Patricia hält zudem mit 345 km/h (1-minütig) den Rekord für die höchsten anhaltenden Windgeschwindigkeiten, die bis dato in einem tropischen Wirbelsturm gemessen wurden. Zwar wurde im Jahr 1961 in Taifun Nancy derselbe Mittelwind berechnet, allerdings werden die damaligen Messmethoden heute als wenig zuverlässig angesehen[9]. Ein weiterer Rekord von Patricia liegt in deren rapider Intensivierung. Vom 22. auf den 23. Oktober 2015 steigerte sich die einminütige mittlere Windgeschwindigkeit des Hurrikans von 138 km/h auf 335 km/h und somit um 197 km/h innerhalb von 24 Stunden[10].
Sofern ein Hurrikan die Frontalzone der mittleren Breiten überhaupt erreicht, hat er bereits einen größeren Teil seiner Schadenergie verloren und wird dann meist zu einem außertropischen Tiefdrucksystem (extratropical transition) oder in eine niedrigere Kategorie herabgestuft. Ein solches Wettersystem ist immer noch in der Lage, schwere Regenfälle nach Europa zu bringen.
Die Ausprägung einer bevorstehenden atlantischen Hurrikansaison wird jedes Jahr von der National Oceanic and Atmospheric Administration (NOAA) und separat davon vom Tropical Risk Consortium (TSR) sowie einem Team an der Colorado State University mittels einer Witterungsprognose vorhergesagt.




Hurrikane entstehen grundsätzlich in der Passatwindzone über dem Wasser des Atlantiks oder östlichen Pazifiks bei einer Wassertemperatur von über 26,5 °C.[11] Wenn ein gleichmäßiges Temperaturgefälle zu großen Höhen hin ein bestimmtes Maß übersteigt, kann sich ein tropischer Wirbelsturm ausbilden. Das Wasser verdunstet in großen Mengen und steigt durch Konvektion auf. Durch Kondensation bilden sich große Wolken aus.[12]
Diese Kondensation riesiger Wassermassen setzt enorme Mengen Energie frei (latente Wärme).  Über der warmen Meeresoberfläche entsteht ein Unterdruck und aus der Umgebung strömt daraufhin Luft mit einem hohen Wasserdampfanteil nach. Dadurch entsteht oberhalb der Hurrikanwolken eine Zone sehr hohen Luftdrucks, aus der heraus sich die Luft in einem entgegengerichteten Wirbel wieder verteilt (Antizyklone).  
Allerdings ist die Fläche, die ein Hurrikan bedeckt, viel zu groß, als dass sich ein einheitliches geschlossenes Luftpaket bilden könnte, das als Ganzes aufsteigt. Typisch für alle tropischen Zyklone ist daher die Entstehung von spiralförmigen Regenbändern, in denen thermische Aufwinde herrschen, und dazwischenliegenden Zonen, in denen etwas kühlere und trockenere Luft wieder absinkt – ohne Regen. Nachströmende feuchte Luft steigt in den Regenbändern auf und liefert ständig Wasser und Energie nach. Die am Boden zuströmenden Luftmassen werden durch die Corioliskraft in Rotation versetzt, ein großflächiger Wirbel entsteht.
Kommt ein Hurrikan in Landnähe, so verlagern sich auch seine bodennahen Versorgungsströme teilweise über Land, wodurch erheblich trockenere Luft in das System gelangt und die Energiezufuhr reduziert. Zieht ein Hurrikan insgesamt über Land, so versiegt weitgehend sein Wasser- und damit sein Energienachschub: er verliert nach und nach seine Kraft und wird zunächst zum (schwächeren) Tropischen Sturm, um sich dann als tropisches Tief zu verlieren.
Wichtige Voraussetzungen für die tropische Sturmbildung sind also:

Das Meer muss eine Oberflächentemperatur von mindestens 26,5 °C und die Luft eine gleichmäßige Temperaturabnahme („Gradient“) zu großen Höhen hin aufweisen. Bei sehr starker Temperaturabnahme, die das Aufsteigen der feuchtwarmen Luft begünstigt, können niedrigere Wassertemperaturen ausreichen (siehe auch Hurrikan Vince.)
Das betroffene Gebiet gleichmäßiger Bedingungen muss ausgedehnt sein, damit sich der bewegende Wirbelsturm über längere Zeit durch die Wasserdampfbildung aufbauen und genug Energie bis zur Stärke eines Hurrikans sammeln kann.
Der Abstand vom Äquator muss groß genug sein (mindestens 5 Breitengrade oder 550 km), da nur dann die Corioliskraft ausgeprägt genug ist, um den zuströmenden Luftmassen die typische Drehung zu geben.
Das Meer muss mindestens 50 Meter tief sein, da sonst nicht genug Wärme pro Fläche vorhanden ist.
Es darf keine große vertikale Windscherung auftreten, das heißt, dass zur Entstehung eines Hurrikans der Höhenwind mit ähnlicher Stärke und aus der gleichen Richtung wehen muss wie der Bodenwind. Ist dies nicht der Fall, bekommen die aufsteigenden Winde eine Schräglage und der Kamin bricht zusammen.
Der Sturm braucht einen Nukleus, aus dem er sich aufbauen kann, zum Beispiel ein außertropisches Tief.
Die meteorologische und thermodynamische Funktion eines Hurrikans besteht darin, dass er sehr große Mengen Wärme von der Oberfläche der tropischen Ozeane aufnimmt und zunächst in die Höhe und dann in Richtung der Pole transportiert. in der Höhe wird die Energie dann nach und nach ins Weltall abgestrahlt.
Die Intensität tropischer Wirbelstürme folgt nach empirischen Erkenntnissen der Oberflächentemperatur des Meeres. Dabei ist zu beachten, dass diese Temperaturen aus bislang unbekannten Gründen über einen Zeitraum von mehreren Jahrzehnten variieren. Im Nordatlantik wechselt die Atlantic Multidecadal Oscillation (AMO) in einem Rhythmus von etwa 40 bis 80 Jahren zwischen „warm“ und „kalt“, während im Nordostpazifik die Pacific Decadal Oscillation alle 20 bis 30 Jahre einen ähnlichen Wechsel vollzieht. Besonders im Nordatlantik lässt sich hierbei ein Trend erkennen, dass sich bei „warmer“ AMO deutlich intensivere Hurrikansaisons ereignen als bei „kalter“. So ereigneten sich sieben der zehn intensivsten Hurrikansaisons (seit Beginn der Messungen im Jahr 1850) in den vorletzten beiden AMO-Warmphasen von ~1850 bis ~1900 sowie ~1925 bis ~1965. In der darauffolgenden Kaltphase, die bis in die frühen 1990er andauerte, kam es dagegen nur zu vergleichsweise milden Hurrikansaisons. Seit etwa 1995 befindet sich die AMO wieder in einer Warmphase, weshalb die Hurrikanintensität im Trend wieder deutlich zunahm. Forscher der National Oceanic and Atmospheric Administration gehen davon aus, dass diese Phase erhöhter Hurrikanintensität im Atlantischen Ozean noch etwa 10 bis 40 Jahre anhalten wird.[13] Das Auftreten des El-Niño-Phänomens erhöht die Wahrscheinlichkeit von Windscherung an der Ostküste der Vereinigten Staaten, daher fallen hier El-Niño-Jahre mit einer reduzierten Hurrikan-Wahrscheinlichkeit zusammen (für die Westküste ist Gegenteiliges der Fall).



Hurrikane entstehen grundsätzlich in der Passatwindzone, im Atlantischen Ozean meist südwestlich der Kapverden, im Bereich des Karibischen Meeres, der Westindischen Inseln und des Golfes von Mexiko, aus kleineren Störungen der Passatströmung, die knapp südlich der Wüste Sahara ausgehend über den Atlantik hinweg ziehen. Diese Region der Entstehungsorte der meisten Hurrikane nennt sich auch Hurricane Alley.
Im Pazifischen Ozean bilden sich die meisten Hurrikane südlich von Acapulco; sie ziehen meist auf das offene Meer hinaus oder drehen nach Norden ab, wo sie über Niederkalifornien hinwegziehen und das mexikanische Festland erreichen können.
Mit Hurrikan Vince bildete sich am 9. Oktober 2005 erstmals seit dem „Spanien-Hurrikan“ von 1842 ein tropischer Wirbelsturm vor den Küsten Südeuropas und Nordafrikas im östlichen Atlantik. Vince bildete sich zwischen den Azoren und den Kanaren, schwächte sich aber noch vor Erreichen des europäischen Festlandes auf ein Sturmtief ab.
Der tropische Sturm Delta, Hurrikan Epsilon, sowie der tropische Sturm Zeta sind ebenfalls 2005 im östlichen Atlantik entstanden, sodass mit Vince und Delta erstmals zwei Wirbelstürme in einem Jahr die Küsten Europas erreicht haben.



Gemäß der Definition nach der Saffir-Simpson-Skala spricht man von einem Hurrikan, wenn die Windgeschwindigkeit 64 Knoten (118,4 km/h) übersteigt, d. h. Windstärke 12 auf der Beaufort-Skala erreicht:


Die Saffir-Simpson-Hurrikan-Windskala[14]


Kategorie

Wind in kn

Wind in km/h

Flutwelle beim Auftreffen auf Land (in m)

Kerndruck in hPa


Tropischer Sturm

34–63

63–117

0–1,1




1 (schwach)

64–82

118–152

1,2–1,6

über 980


2 (mäßig)

83–95

154–176

1,7–2,5

965–979


3 (stark)

96–113

178–209

2,6–3,8

945–964


4 (sehr stark)

114–135

211–250

3,9–5,5

920–944


5 (verwüstend)

ab 136

ab 252

über 5,5

unter 920

Die Zerstörungskraft eines Hurrikans wächst etwa mit der dritten Potenz der Windgeschwindigkeit.
Die angeführten Windgeschwindigkeitswerte basieren auf einem 1-minütigen Mittelwert, wie er in den USA verwendet wird. Der Umrechnungsfaktor für die entsprechenden 10-Minuten-Mittelwerte ist 0,88.
Von der Windgeschwindigkeit zu unterscheiden ist die Zuggeschwindigkeit des Hurrikans, die mit der Bewegung des Auges gegenüber Grund gemessen wird. Die resultierende Windgeschwindigkeit über Grund ergibt sich aus der Bewegung des Zentrums (Zuggeschwindigkeit) und der umlaufenden Rotationsbewegung des Wirbels. Die Rotationsgeschwindigkeit und die Zuggeschwindigkeit haben zur Folge, dass auf der rechten Seite eines Hurrikans immer stärkere Windgeschwindigkeiten gemessen werden als auf der linken Seite des Auges, die der Zugrichtung entgegen wirkt. Dies ist immer der Fall, da sich Hurrikans auf Grund der Corioliskraft auf der Nordhalbkugel immer linksherum drehen.
In der Seefahrt wird die linke Seite daher auch als navigierbares Viertel (seltener: navigierbarer Halbkreis) bezeichnet. Die Rotationsgeschwindigkeit wächst außerdem mit zunehmender Nähe zum Zentrum und ist im Bereich der Eyewall rund um das fast windstille Auge am größten.
Ein Hurrikan mit bis zu 100 km Durchmesser kann Windgeschwindigkeiten von über 200 km/h erreichen; in den besonders gefährdeten Zonen rechts der Zugrichtung eines verheerenden Hurrikans der Kategorie 5 werden auch 300 km/h überschritten.


Auch wenn sich atlantische Hurrikane kurz nach der Entstehung überwiegend nach Westen bis Nordwesten bewegen und oft zwischen dem 20. und 25. Breitengrad nach Norden bis Nordost abdrehen, so ist dieses typische Verhalten weder zwingend noch sicher zu erwarten.
Von quasi unbewegten Hurrikane, die sich selbst abschwächten, indem sie kühleres Meereswasser an die Wasseroberfläche brachten, bis hin zu tänzelnden, schlingernden und schleifenförmigen Verläufen über Grund ist schon alles beobachtet worden. Auch nach Osten ziehende Wirbelstürme und unerwartete kurzfristige Richtungsänderungen wie plötzliches Abdrehen nach Südwesten sind nicht auszuschließen.
Hurrikane erhalten ihre Energie aus der Verdunstung des warmen Oberflächenwassers. Treffen sie während ihres Zugs auf Land („Landgang“), so schwächt sich ihr Nachschub an Energie ab und sie verlieren an Stärke. Tiefer landeinwärts gelegene Regionen werden deshalb von der Windgeschwindigkeit weniger heftig getroffen. Da sich im Hurrikaneinzugsgebiet aber auch große Wassermassen in den Wolken befinden, kann das Abregnen dieser Wolken auch noch Hunderte von Kilometern von der Küste entfernt als Tropischer Wirbelsturm gigantische Niederschlagsmengen mit sich bringen.
Die Vorhersage der Zugrichtung und der Stärke von Hurrikanen ist wichtig, um die Bevölkerung in den betroffenen Regionen rechtzeitig zu warnen und gegebenenfalls zu evakuieren.
Nach derzeitigem Kenntnisstand ist für die „Bahn“ der Hurrikans langfristig die Position des Azorenhochs entscheidend. Bei der gegenwärtigen Position, die das Azorenhoch seit 1000 BP und zuvor zwischen 5000 und 3400 BP innehatte, erreichen Hurrikans sowohl die Atlantik- als auch die Golfküste. Zwischen 3400 und 1000 BP lag das Azorenhoch weiter südwestlich, etwa über den Bermudas, und lenkte daher deutlich mehr Hurrikans in den Golf von Mexiko. Paläotempestologische Untersuchung zeigten, dass während dieser Zeit drei- bis fünfmal so viele Hurrikane die Golfküste erreichten, jedoch nur halb so viele die Atlantikküste.[15][16]


→ Hauptartikel: Liste der Namen tropischer Wirbelstürme
Ursprünglich erhielten nur besondere Hurrikane einen Namen, etwa „New England Hurricane“. 1950 begannen der National Weather Service mit der Benennung der Hurrikane. In jenem Jahr sowie im Folgejahr waren zunächst Namen im Gebrauch, die dem damaligen internationalen phonetischen Alphabet entsprachen – also Able, Baker, Charlie und so weiter. Englische Frauennamen wurden im Jahre 1953 eingeführt. Ab 1960 wurden vorher festgelegte Namenslisten mit je 21 Namen verwendet. Die Anzahl 21 wurde festgelegt, weil die aktivste atlantische Hurrikansaison 1933 mit 21 registrierten tropischen Wirbelstürmen die bis dahin höchste Aktivität aufwies; sie wurde bislang nur in den Jahren 2005 und 2020 überschritten. Im Jahre 1979 benutzte man zum ersten Mal abwechselnd männliche und weibliche Namen, außerdem ergänzte man die Liste der verwendeten Namen um französische und spanische Namen.
Es gibt derzeit sechs feste, von der World Meteorological Organization (WMO) festgelegte Namenslisten, die im Turnus von sechs Jahren verwendet werden. So werden im Atlantik und im östlichen Pazifik 2012 die Listen des Jahres 2006 im Jahr 2012 wieder verwendet, mit Ausnahme der Namen, die von der WMO gestrichen werden. Dies geschieht auf Antrag des meteorologischen Dienstes eines der betroffenen Länder durch Beschluss der World Meteorological Organization, wenn ein Hurrikan besonders schlimmen Schaden angerichtet hat. So fand sich beispielsweise der Name „Ivan“ mit drei anderen Namen, die 2004 verwendet wurden, nicht mehr in der Liste für 2010 – „Ivan“ wurde durch „Igor“ ersetzt. Die meisten Sturmnamen einer Saison – fünf – wurden bislang von der Namensliste gestrichen, die 2005 zur Anwendung kam: Dennis, Katrina, Rita, Stan und Wilma.
Während der erste Sturm jedes Jahres im Atlantik und im östlichen Pazifik immer einen Namen bekommt, der mit einem A beginnt, wird im Zentralpazifik (beginnend bei 140° West) jeweils der nächste Name der Liste vergeben, unabhängig von Jahr oder Buchstaben.
Beispiel: Der atlantische tropische Wirbelsturm vor Hurrikan „Katrina“ trug den Namen „Jose“. Auf „Katrina“ folgten „Lee“ und „Maria“. Da der erste benannte Sturm eines jeden Jahres mit „A“ anfängt, kann man leicht erkennen, wie viele Stürme es schon gegeben hat: „Katrina“ war der 11. Sturm des Jahres 2005, „Maria“ der 13.
Sollte dieser „Namensvorrat“ in einem Jahr nicht ausreichen, wurden die nachfolgenden tropischen Stürme nach dem Griechischen Alphabet benannt. Dies geschah bislang erst zweimal; erstmals war dies in der Saison 2005 der Fall, als der 22. tropische Sturm der Saison Alpha, der 23. Beta, der 24. Gamma, der 25. Delta und der 26. Epsilon genannt wurden. Der erst einen Monat nach der offiziellen Saison aufgetretene Tropensturm Nummer 27 wurde demnach Zeta genannt, ein weiterer hätte den Namen Eta erhalten. Sollte einer der nach dem griechischen Alphabet benannten Stürme so schwere Schäden verursachen, dass der Name von der Liste gestrichen wird, wird der Sturmname zwar als gestrichen festgestellt, der Name bleibt aber trotzdem künftig verfügbar.[17] Das zweite Mal, dass auf griechische Buchstaben zurückgegriffen werden musste, geschah in der Saison 2020. Seit der Saison 2021 wird für über die normale Namensliste hinausgehende Stürme statt des griechischen Alphabets auf eine weitere Namensliste zurückgegriffen.[18]
Weibliche Hurrikans sorgen im Durchschnitt für mehr Schwerverletzte und Todesopfer, als die mit männlichem Namen. Das liegt daran, dass man Weiblichkeit und Zerstörung nicht so stark miteinander verbindet und einige deshalb unterbewusst unvorsichtiger sind.[19]




Atlantische Hurrikansaisons


1492–1600 |
1601–1700 |
1701–1799 |
1800er |
1810er |
1820er |
1830er |
1840er |
1850er |
1860er |
1870er |
1880–1884 |
1885 |
1886 |
1887 |
1888 |
1889 |
1890 |
1891 |
1892 |
1893 |
1894 |
1895 |
1896 |
1897 |
1898 |
1899 |
1915 |
1916 |
1917 |
1918 |
1919 |
1928 |
1929 |
1930 |
1931 |
1932 |
1933 |
1934 |
1935 |
1936 |
1937 |
1938 |
1939 |
1940 |
1941 |
1942 |
1943 |
1944 |
1945 |
1946 |
1947 |
1948 |
1949 |
1950 |
1951 |
1952 |
1953 |
1954 |
1955 |
1956 |
1957 |
1958 |
1959 |
1960 |
1961 |
1969 |
1970 |
1971 |
1972 |
1973 |
1974 |
1975 |
1976 |
1977 |
1978 |
1979 |
1980 |
1981 |
1982 |
1983 |
1984 |
1985 |
1986 |
1987 |
1988 |
1989 |
1990 |
1991 |
1992 |
1993 |
1994 |
1995 |
1996 |
1997 |
1998 |
1999 |
2000 |
2001 |
2002 |
2003 |
2004 |
2005 |
2006 |
2007 |
2008 |
2009 |
2010 |
2011 |
2012 |
2013 |
2014 |
2015 |
2016 |
2017 |
2018 |
2019 |
2020 |
2021 |
2022 |
2023 |
2024






Pazifische Hurrikansaisons


1960 |
1961 |
1962 |
1963 |
1964 |
1965 |
1966 |
1967 |
1968 |
1969 |
1970 |
1971 |
1972 |
1973 |
1974 |
1975 |
1976 |
1977 |
1978 |
1979 |
1980 |
1981 |
1982 |
1983 |
1984 |
1985 |
1986 |
1987 |
1988 |
1989 |
1990 |
1991 |
1992 |
1993 |
1994 |
1995 |
1996 |
1997 |
1998 |
1999 |
2000 |
2001 |
2002 |
2003 |
2004 |
2005 |
2006 |
2007 |
2008 |
2009 |
2010 |
2011 |
2012 |
2013 |
2014 |
2015 |
2016 |
2017 |
2018 |
2019 |
2020 |
2021 




Siehe auch: Kategorie:Tropische Wirbelsturmsaison

Großer Hurrikan von 1780, Karibik
Galveston-Hurrikan 1900, USA
Okeechobee-Hurrikan 1928, USA
Labor-Day-Hurrikan 1935, USA
Hurrikan Hattie 1961, Mittelamerika
Hurrikan Flora 1963, Karibik
Hurrikan Dora (1964), 1964, USA
Hurrikan Camille 1969, USA
Hurrikan Ginger 1971, North Carolina, Atlantischer Ozean
Hurrikan Fifi 1974, Honduras, Belize, Guatemala (8.000 bis 10.000 Tote)
Hurrikan David 1979, Karibik (ca. 4.000 Tote)
Hurrikan Allen 1980, Karibik
Hurrikan Gilbert 1988, Karibik
Hurrikan Hugo, 1989, Karibik, USA
Hurrikan Bob 1991, USA, versachte auf Long Island einen Stromausfall[20]
Hurrikan Andrew 1992, USA
Hurrikan Mitch 1998, Nicaragua, Honduras
Hurrikan Charley 2004, Kuba, USA
Hurrikan Frances 2004, Bahamas, USA
Hurrikan Ivan 2004, Grenada, Jamaica, Kuba, USA
Hurrikan Jeanne 2004, Haiti, USA
Hurrikan Dennis 2005, Kuba, USA
Hurrikan Katrina 2005, USA
Hurrikan Rita 2005, Kuba, USA
Hurrikan Stan 2005, Mittelamerika
Hurrikan Vince 2005, Azoren, Kanaren, Spanien
Hurrikan Wilma 2005, Mexiko, USA
Hurrikan Dean 2007, Mexiko, Belize, Karibik
Hurrikan Felix 2007, Nicaragua, Honduras
Hurrikan Ike 2008, Kuba, USA
Hurrikan Irene 2011, USA
Hurrikan Sandy 2012, Karibik, USA
Hurrikan Matthew 2016, Kolumbien, USA
Hurrikan Irma 2017, Karibik, USA
Hurrikan Florence 2018, (Ostküste)
Hurrikan Michael 2018, USA (Golf von Mexiko/Florida)
Hurrikan Leslie 2018
Hurrikan Ida 2021, USA (New Orleans)
Südliche Hemisphäre:

Hurrikan Catarina 2004, Süd-Brasilien

Hyperkan



Eric Jay Dolin: A Furious Sky: The Five-Hundred-Year History of America’s Hurricanes. Liveright, New York 2020, ISBN 978-1-63149-527-4.
Stuart B. Schwartz: Sea of Storms: A History of Hurricanes in the Greater Caribbean from Columbus to Katrina. Princeton University Press, Princeton & Oxford 2015, ISBN 978-0-691-15756-6. ()
Matthew Mulcahy: Hurricanes and society in the British Greater Caribbean, 1624–1783. Johns Hopkins University Press, Baltimore 2006, 257 S., ISBN 0-8018-8223-0
Erwin Lausch: Wirbelstürme: Peitschen vom Himmel. In: Geo-Magazin. Hamburg 1979,5, S. 36–62.  Informativer Bericht über die Zerstörungskraft zahlreicher Hurrikane und Zyklone von 1737 bis 1974, sowie über die physikalischen Gesetzmäßigkeiten der Tropenstürme.   ISSN 

Tropenwelt Karibik – Sturm im Paradies. Dokumentation, 45 Min., Produktion: NDR, Erstsendung: 7. Mai 2007





Liste tropischer Stürme (englisch)
Verzeichnis der Hurrikan-Saisons (englisch)
 (englisch)
 (englisch)
 (englisch)
 auf naturgewalten.de
Ausführliche Hurrikan-Informationen im Wiki der Zentrale für Unterrichtsmedien e. V.

 (englisch)

 (ZAMG)



Eine Schneeverwehung ist „vom Winde verwehter“ Schnee. 



Meist ist es Pulverschnee, da dieser leichter als feuchter Schnee ist und dadurch leichter verweht werden kann. Durch den Aufprall der Schneepartikel wird das Material einer Schneeverwehung verfestigt. Der zuerst lose Schnee nimmt dann eine starre Form an. Schneeverwehungen können überall auf weiten Flächen entstehen, aber auch in Ecken oder Mulden, wo neben Windverwirbelungen auch windstille Zonen entstehen und sich der Schnee leichter ablagert. Er kann sich dabei – als sogenannter Triebschnee – meterhoch auftürmen, während in der Umgebung fast kein Schnee liegenbleibt. Schneeverwehungen lassen sich nur sehr schwer vorhersagen, da ihre Entstehung von den lokalen Bedingungen abhängt. Neue Polarstationen werden deshalb auf (verstellbaren) Stelzen gebaut.

Siehe auch: Neumayer-Station III und Forschungsstation Insel Samoilow


Unangenehm und gefährlich sind Schneeverwehungen auf Straßen und Gleisen. Man kann beim Heranfahren aus der Ferne nur schwer erkennen, dass eine Schneeverwehung vorliegt, oder wie hoch selbige ist. Fahrzeuge, die mit hoher Geschwindigkeit in massive Schneeverwehungen hineinfahren, können teilweise nur mit schwerem Gerät (Bergepanzer) wieder herausgezogen werden. Hohe Schneeverwehungen lassen sich nicht mit einem Schneepflug, sondern nur mit einer Schneefräse entfernen. Allerdings können Verwehungen bei gleich bleibendem Wetter in kürzester Zeit wieder neu entstehen. Auch kleine so genannte Schneezungen sind unangenehm zu durchfahren, da man meist nicht mit ihrem Auftreten rechnet und man so die Geschwindigkeit nicht rechtzeitig reduziert. Ein Schleudern kann dann leicht die Folge sein.



Die Gefahr von Schneeverwehungen lässt sich durch das Aufstellen von Lattenrosten (Schneegatter) und Kunststoffnetzen (Schneezaun) reduzieren. Diese verringern auf der Lee-Seite die Windgeschwindigkeit, so dass der Schnee neben dem Gatter oder dem Netz abgelagert wird. Das genaue Aufstellen dieser Schutzvorrichtungen erfordert allerdings Erfahrung, da kleine Winddrehungen sie wirkungslos machen oder die Verwehungen eventuell verstärken. Eine weitere Möglichkeit, Schneeverwehungen zu vermindern, ist die Schneeschutzbepflanzung: ein- oder mehrreihige, bis unten beastete Gehölzpflanzungen, die den vom Wind transportierten Schnee auffangen.



Wechte
Windkolk, durch Wind entstandener Freiraum hinter einem Hindernis
Triebschnee
Portal:Transport und Verkehr/Themenliste Straßenverkehr






Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Taifun (Begriffsklärung) aufgeführt.


Taifun bezeichnet einen tropischen Wirbelsturm in Ost- und Südostasien sowie im nordwestlichen Teil des Pazifiks, westlich der internationalen Datumsgrenze und nördlich des Äquators. Er wird durch ein mächtiges Tiefdruckgebiet gebildet.






Dieser Artikel oder nachfolgende Abschnitt ist nicht hinreichend mit Belegen (beispielsweise Einzelnachweisen) ausgestattet. Angaben ohne ausreichenden Beleg könnten demnächst entfernt werden. Bitte hilf Wikipedia, indem du die Angaben recherchierst und gute Belege einfügst.

Das moderne Wort Taifun (englisch typhoon) geht auf die Überschneidung von zumindest zwei unverwandten Wörtern ähnlicher Aussprache und Bedeutung zurück. Die Bezeichnung Tiphoon für starke Stürme und Wirbelwinde lässt sich für das Jahr 1555 belegen und leitet sich vom griechischen Τυφών typhōn ab, das man mit „Wirbelwind“ übersetzen kann und in der griechischen Mythologie zudem der Name des Riesen Typhon ist. Dessen Rolle als Vater der Winde legt den Ursprung vom griechischen typhen  nahe. Für den modernen Begriff Taifun gibt es dabei verschiedene etymologische Erklärungsansätze.
Im frühen Mittelalter könnte der griechische Begriff in Form des ṭūfān (arabisch طوفان ‚Sturm‘) in das Arabische und Persische übernommen worden sein, wobei jedoch eine Ableitung als Substantiv des arabischen tafa „umdrehen“ ebenso als möglich erscheint. Dieses Wort hat unabhängig von seiner Herkunft eine weite Verbreitung erfahren und ist so auch Ursprung des portugiesischen tufão, das seinerseits einen Einfluss auf den modernen Begriff gehabt haben kann und auch heute noch einen Taifun bezeichnet. Im Zuge der Infiltration sowie späteren Eroberung des indischen Subkontinents durch die Araber im 11. und 12. Jahrhundert hat es sich zudem in den dort ansässigen Sprachen verbreitet, speziell dem Urdu. Die Bedeutung als schwerer Sturm vornehmlich im Indischen Ozean tritt dann auch erstmals 1588 in der englischen Übersetzung eines italienischen Reiseberichts durch Thomas Hickocks auf. Grundlage des Berichts war die Reise des venezianischen Händlers Cesar Fedrici in den 1560er bis 1580er Jahren, wobei dieser sich vor allem in den Städten Bago (Pegu) und Martaban in Myanmar (damals Birma) aufhielt und dort wohl auf Abkömmlinge des arabischen Begriffes traf. Als Folge der Übertragung in das Italienische und später Englische fanden Formen wie touffon und tufan im englischen Sprachraum Verbreitung.
Eine wichtige Bedeutung kommt dem kantonesischen tái fung (chinesisch 颱風 / 台风, Pinyin tái fēng) zu, das die schweren Stürme im chinesischen Meer bezeichnet und dem arabischen Begriff recht ähnlich ist. Die modernen Schreibweisen Taifun und typhoon stellen in ihrem Ursprung wohl lediglich dessen Latinisierung dar. Diese Verknüpfung ist jedoch auch heute noch umstritten und letztendlich nicht bewiesen. Seinerseits geht tái fēng auf eine Kombination aus 大,  dà – „groß“ und 風,  feng – „Wind“ hervor, weist jedoch auch Verbindungen zu 風篩/風颱 hong thai (Min-Dialekt) bzw. dem japanischen taifū (Shinjitai: 台風, Kyūjitai: 颱風) und indonesischen taufan auf, die alle mehr oder weniger „großer Wind“ bedeuten. Als englische Entsprechung tritt 1699 erstmals das Wort tuffoon in Erscheinung, das mit den verschiedenen anderen Formen wechselwirkte und schließlich in der heutigen Schreibweise typhoon mündete. Diese trat erstmals 1819 in Shelleys Prometheus Unbound auf und fand im Verlauf des 19. Jahrhunderts eine weite Verbreitung. Die Bezeichnung „Taifun“ ist dabei eine Eindeutschung.


Taifune gehören zu den schwersten Naturkatastrophen im Nordwestpazifik. Alljährlich richten sie starke Zerstörungen mit hunderten Toten an. Schwere Schäden entstehen nicht nur durch die hohen Windstärken, sondern auch durch die häufig sehr starken in kürzester Zeit fallenden Niederschläge, die zu Überschwemmungen und Bergrutschen führen. So brachte der Taifun Nari am 17. und 18. September 2001 in Taiwan innerhalb eines Tages bis zu 800 mm Regen, was dem ungefähren Jahresdurchschnitt in Deutschland entspricht. Der Taifun Morakot brachte im August 2009 in Taiwan regional 1600 mm Niederschlag in 24 Stunden und forderte 673 Menschenleben.[1] Auf dem Festland bringen Taifune starke Windböen und Regenfälle, schwächen sich dann aber schnell ab, je weiter sie ins Binnenland vordringen. Im globalen Vergleich mit Hurrikans im Golf von Mexiko und Zyklonen im Indischen Ozean sind die tropischen Wirbelstürme im Nordwestpazifik in Bezug auf meteorologische Parameter wie Windstärke und Durchmesser am stärksten.
Das Joint Typhoon Warning Center in Hawaii klassifiziert Taifune mit Windgeschwindigkeiten ab 241 km/h bzw. 67 m/s als Supertaifune, was in der Saffir-Simpson-Hurrikan-Windskala einem Sturm der Kategorie 4 entspricht.


Der verheerendste Taifun im 20. Jahrhundert war Taifun Nina im August 1975 in China. Durch den Taifun brachen zwei große Staumauern und 10 kleinere. Die dadurch verursachten bis zu 10 Meter hohen Flutwellen töteten 100.000 Menschen.[2]
Der von den Versicherungsschäden teuerste Taifun war Taifun Mireille vom September 1991 in Japan, der zwar mit 51 Personen vergleichsweise wenig Todesopfer forderte, aber Kosten von 9 Milliarden US-Dollar verursachte und damit die zehntteuerste Naturkatastrophe war. Übertroffen wurde er diesbezüglich nur durch diverse Hurrikane wie Hurrikan Katrina 2005, Hurrikan Andrew 1992 und das Northridge-Erdbeben (USA 1994).[3]
Die bekanntesten Taifune sind wohl jene, welche die beiden Invasionsversuche in Japan durch den chinesischen Mongolenkaiser Kublai Khan im 13. Jahrhundert zunichtegemacht haben. Sie werden seitdem in Japan 神風 „göttlicher Wind“, „Hauch Gottes“ genannt, als Kamikaze in anderem Zusammenhang bekannt und berüchtigt.
Bekannte Taifune der letzten Jahrzehnte sind beispielsweise:


Vera, Japan (1959)
Nina, China (1975)
Tip, Japan (1979)
Herb, Taiwan/China (1996)
Saomai, China (2000)
Nari, Taiwan (2001)
Tokage, Japan (2004)
Haitang, Taiwan (2005)
Matsa, China (2005)
Talim, China (2005)
Nabi, Japan (2005)
Khanun, China (2005)
Damrey, China (2005)
Longwang, Taiwan/China (2005)
Chanchu, Philippinen/China (2006)
Saomai, China (2006)
Wipha, Taiwan/China (2007)
Nuri, Hongkong/China (2008)
Morakot, Taiwan/China (2009)
Roke, Japan (2011)
Haiyan, Philippinen (2013)
Mangkhut, Philippinen, Hongkong, China (2018)

Der britische Weltumsegler und Freibeuter William Dampier beschrieb einmal einen Taifun, in dem er sich am Nachmittag des 4. Juli 1687 vor der chinesischen Küste befand:



„Der Sturm kam von Nordosten herauf, der Regen fiel in Strömen. Gegen Mitternacht blitzte und donnerte es gewaltig. Am nächsten Morgen flaute der Sturm ab. Die See war unnatürlich ruhig, es war windstill. Am Mittag kam der Wind wieder auf, aus entgegengesetzter Richtung, aus Südwesten. Genau wie in der vergangenen Nacht regnete und stürmte es, aber nicht in dem Maße stark. Dies blieb so bis ca. 22:00-23:00 Uhr. Dampier und seine Crew konnten die ganze Zeit sehr schnell vor dem Wind fahren, obwohl sie nur mit bloßen Masten ‚segelten‘.“



Eine ausführliche und sehr eindrückliche Schilderung eines Taifuns im Chinesischen Meer findet sich in der Erzählung Taifun von Joseph Conrad.


Rose Lesser, Herbert Wüst: Taifun und … More Joy, Kawasaki 1981 (umfangreiche Sammlung von Berichten mit Daten, Fotos und Karten von Taifunen in Japan).



 (englisch)
 (englisch)
 (englisch)
 (englisch)
 (englisch)
 (englisch)
 TV-Dokumentation zur Vorhersage von Taifunen: arte, 14. Januar 2008




Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Hagel (Begriffsklärung) aufgeführt.


Hagel ist eine Form von Niederschlag, der aus Eisklumpen besteht und überwiegend in warmen Jahreszeiten und den Mittleren Breiten auftritt. Zur Abgrenzung spricht man erst bei einem Durchmesser von über 0,5 Zentimetern von Hagel bzw. Eishagel, darunter von Graupel. Bei Aggregaten von Schneeflocken mit einem Durchmesser unter einem Millimeter spricht man von Griesel. Ein Tag, in dessen Verlauf es mindestens einmal hagelte, geht als Hageltag in die klimatologische Statistik ein.



Das Wort Hagel (altdeutsch hagal) ist vermutlich verwandt mit dem griechischen Wort κάχληξ káchlēx „Kieselstein“, das auf der indogermanischen Wurzel *kaghlo-s „kleiner Stein“ beruht.[1][2]
Die ebenfalls gebräuchliche Bezeichnung Schloße für ein Hagelkorn ist namensgebend für den Farbnamen schlohweiß (dissimiliert aus schloßweiß), was also „weiß wie ein Hagelkorn“ bedeutet und einen hellen, fahlen Weißton bezeichnet.[3]




Hagelkörner entstehen in den niedrigeren Schichten von Gewitterwolken bzw. innerhalb einer Gewitterzelle durch unterkühltes Wasser, das an Kristallisationskernen zu Eis gefriert. Diese Kerne müssen dabei in vergleichsweise geringer Zahl vorkommen, so dass die je Kern zur Verfügung stehende Wassermenge ausreichend groß ist, um ein schnelles Wachstum zu ermöglichen. Da es sich also um sehr wasserreiche Wolken handelt, haben die über Phasenumwandlungen umgesetzten latenten Wärmemengen eine starke Labilität der Temperaturschichtung innerhalb der Wolke zur Folge. Die hierdurch erzeugten starken Aufwinde von durchaus 20 bis 30 m/s sind ein weiterer wichtiger Faktor für die Hagelbildung, denn die Gefrierungsprozesse haben eine stetige Massenzunahme der Partikel zur Folge. Ohne einen Aufwind würden die Partikel durch die Schwerkraft absinken, sich aus der Wolke entfernen und dadurch nicht weiter anwachsen können.
Es zeigt sich dabei, dass der Aufwind innerhalb einer Wolke unterschiedlich stark ist und Partikel dadurch einen Kreislauf durchfahren können. Zunächst werden sie durch den Aufwind angehoben, danach fallen sie wieder in tiefere Luftschichten, nehmen weiteres Wasser auf, werden abermals nach oben gerissen, und zusätzliches Wasser gefriert an. Dieser Vorgang wiederholt sich solange, bis ein Hagelkorn zu schwer ist, um von den Aufwinden getragen zu werden. Aus der Größe der Hagelkörner kann daher auf die Windstärke im Inneren der Gewitterwolke geschlossen werden, was in der Umkehrung auch zur Prognose von Hageldurchmessern dient.
Die stufenweise Entstehung der Hagelkörner kann an den einzelnen Anlagerungsschichten, aus denen ein Hagelkorn besteht, abgelesen werden. Dabei deuten die klaren Schichten auf eine sehr wasserreiche Umgebung mit dementsprechend schnellem Gefrieren hin, während die trüben Bereiche auf niedrigere Wassergehalte zurückgehen. Die Trübung selbst wird dabei durch unzählige kleine Lufteinschlüsse hervorgerufen. Ist das Hagelkorn letztendlich zu schwer und sinkt aus dem Aufwindbereich ab, so kommt es aufgrund der Größe des Hagelkorns und einer Temperatur von meist unter 0 °C nicht zu einem Aufschmelzen.


Weltweit sind am stärksten die Mittleren Breiten (Gemäßigte Zone) von Hagelereignissen betroffen, insbesondere Zentral- und Südeuropa, die USA, Mexiko, Ostchina, Argentinien, Südafrika und Südost-Australien. Jedoch sind vereinzelt bei entsprechenden Bodengegebenheiten auch äquatornahe Gebiete betroffen, darunter Kenia (insbesondere die Region Kericho) oder Äthiopien. Auch an Gebirgsrändern tritt häufiger Hagel auf, zum Beispiel an den Anden in Peru, Ecuador und Kolumbien oder am Himalaya im Norden Indiens oder in Nepal.


Die Größe von Hagelkörnern variiert stark: Das Schweizerische Hagel-Register unterscheidet elf Intensitätsklassen, die von kleinem Hagel unter 0,5 cm bis zu außergewöhnlich großem Hagel von über 10 cm Durchmesser reichen.[4] Die Masse der Körner schwankt dabei gemäß der Formel





m
=


π
6


⋅

d

3


⋅

ρ

Hagel




{\displaystyle m={\frac {\pi }{6}}\cdot d^{3}\cdot \rho _{\text{Hagel}}}

 mit 




ρ

Hagel


=
0
,
870



g

c

m

3







{\displaystyle \rho _{\text{Hagel}}=0,870\,\mathrm {\frac {g}{cm^{3}}} }


mit 



d


{\displaystyle d}

 als dem Hageldurchmesser zwischen 0,1 g und mehr als 500 g. Zu Schäden an Autos, Glasscheiben und Zelten kommt es bereits ab einem Durchmesser von etwa 2 cm, bei dem Hagelkörner dieser Größe gemäß der Formel[5]






v

Fall


=




4
3


⋅




ρ

Hagel


⋅
g



ρ

Luft


⋅

c

Luft





⋅
d




{\displaystyle v_{\text{Fall}}={\sqrt {{\frac {4}{3}}\cdot {\frac {\rho _{\text{Hagel}}\cdot g}{\rho _{\text{Luft}}\cdot c_{\text{Luft}}}}\cdot d}}}

 mit 




ρ

Luft


=
1

,

2




k
g


m

3




,
 
g
=
9

,

81



m

s

2




,
 

c

Luft


=
0

,

5


{\displaystyle \rho _{\text{Luft}}=1{,}2\,\mathrm {\frac {kg}{m^{3}}} ,\ g=9{,}81\,\mathrm {\frac {m}{s^{2}}} ,\ c_{\text{Luft}}=0{,}5}


Fallgeschwindigkeiten von etwa 70 km/h erreichen. Kleinerer Hagel dagegen fällt langsamer, während außergewöhnlich großer Hagel umgekehrt Geschwindigkeiten von weit über 150 km/h erreichen kann: Bei 12 Zentimetern Durchmesser etwa sind es bereits über 170 km/h, mit denen ein solches Hagelkorn aufschlägt und dabei gemäß der Formel






E

kin


=


m
2


⋅



v

Fall




2


=


π
9


⋅






ρ

Hagel




2


⋅
g



ρ

Luft


⋅

c

Luft





⋅

d

4


≈
4.319.800



J

m

4




⋅

d

4




{\displaystyle E_{\text{kin}}={\frac {m}{2}}\cdot {v_{\text{Fall}}}^{2}={\frac {\pi }{9}}\cdot {\frac {{\rho _{\text{Hagel}}}^{2}\cdot g}{\rho _{\text{Luft}}\cdot c_{\text{Luft}}}}\cdot d^{4}\approx 4.319.800\,\mathrm {\frac {J}{m^{4}}} \cdot d^{4}}


eine kinetische Energie von fast 900 Joule besitzt. Wie zu sehen, nimmt die Energie der Hagelkörner dabei mit der vierten Potenz ihres Durchmessers zu: ein doppelt so dickes Hagelkorn besitzt dementsprechend bereits das Sechzehnfache an Energie, was die verheerende Wirkung grobkörnigen Hagelschlags erklärt.
Das bisher größte Hagelkorn der US-Geschichte mit 18-20 cm Durchmesser, gemessen an fingerartigen Ausstülpungen, und einem gewogenen Gewicht von 875 g wurde laut Nachrichtensender CNN am 9. August 2010 im amerikanischen Bundesstaat South Dakota gefunden.[6][7]
Das größte jemals in Deutschland registrierte Hagelkorn fiel am 6. August 2013 im Ortsteil Undingen der Gemeinde Sonnenbühl vom Himmel. Sein Durchmesser wurde mit 14,1 cm angegeben. Für seine Masse (Gewicht) und Form fehlen Angaben.[8][9]

Siehe auch: Eis-Eier

 Hagelschaden im Maisfeld

 Zerschlagenes Maisblatt

 Hagelschäden an einem industriellen Luftkühler
Hagelschauer können beträchtliche Schäden verursachen, an Pflanzen und Tieren, aber auch an Gebäuden und Autos.[10] Auch für die Luftfahrt stellen Hagelschäden eine ernste Gefahr dar[11] sowie Industrieanlagen. Der Großteil der landwirtschaftlichen Anbauflächen ist ohne Schutz dem Hagel ausgesetzt. Zudem verursachen Hagelschläge hohe Schäden an Bäumen und senken damit den Waldbestand. Aufgrund der geringen Ausdehnung eines Hagelschlags sind meistens nur begrenzte Schäden zu verzeichnen. Der Hagelschlag mit der höchsten Schadensumme fand 1984 in München statt. Der Schaden belief sich auf über 1,5 Milliarden Euro. 2013 führte Hagelschlag, insbesondere die Ereignisse in Baden-Württemberg und Niedersachsen am 27./28. Juli, zu Schäden von insgesamt 2,7 Milliarden Euro.[12] Auch was Hagelschäden an Autos angeht, war 2013 ein bemerkenswertes Jahr: 635.000 Autos in Deutschland wurden durch Hagelschauer beschädigt – so viele wie noch nie. Dadurch entstand ein versicherter Schaden von 1,5 Milliarden Euro.[13] Hagelschäden an der Karosserie von Fahrzeugen können ab etwa 2 cm Durchmesser entstehen.[14]
Das unter Umständen existenzielle finanzielle Risiko von Ernteausfällen durch Hagel kann nur durch Spezialversicherungen (Hagelversicherung) abgesichert werden. Die Hagelversicherung ist eine Form der Schadenversicherung, bei der die versicherten Bodenerzeugnisse, insbesondere alle wirtschaftlich nutzbaren Pflanzen, gegen Schäden, die durch Einwirkung des Hagelschlags entstehen, versichert sind. Auch Gewächshäuser können eingeschlossen werden. Die Wohngebäudeversicherung übernimmt die Schäden durch Hagel an Häusern[15]. An Fahrzeugen greift bei Hagelschäden die Teilkaskoversicherung.[16]
Wegen der teilweise beträchtlichen Hagelschäden wurde schon recht früh versucht, Mittel und Wege zu entwickeln, um Hagel zu vermeiden.

Siehe auch: Hagelfeiertag und Hagelprozession
Ende August 2022 wurde bei einem Unwetter in La Bisbal d’Empordà, Spanien ein Kleinkind von einem "elf Zentimeter großen Hagelkorn erschlagen".[17]
Ein Helm, bei Fahrt mit Visier, ein Hut, Mütze oder Kapuze, jeweils ausreichend dick können vor besonders am harten Kopf schmerzhaften Folgen von Hagelschlag bewahren oder diese mildern.


Der Klimawandel scheint einen Einfluss auf die Häufigkeit des Auftretens von Hagelunwettern zu haben. Wie Forscher der Universität Karlsruhe herausfanden, hat die Zahl der Hagelgewitter in den letzten Jahrzehnten deutlich zugenommen. Habe die Zahl der Tage mit Hagelschäden 1986 noch bei fünf gelegen, so sei sie 2004 auf 34 gewachsen.[18]
Am 24. Juni 2021 richtete ein Tornado im Süden Tschechiens große Schäden längs einer 26 km langen Schneise von Valtice nächst Österreich bis Hodonín nahe der Slowakei an.[19]  In Schrattenberg im benachbarten Weinviertel durchlöcherte Hagel etwa 250 Dächer. Am Folgetag zerstörte Hagel wiederum abends erneut in Schrattenberg und auch in Allentsteig zahlreiche Dächer. 500 Einsatzkräfte arbeiteten daran, 336 Dächer provisorisch mit Kunststoffplanen oder -folie abzudichten, 250 Helfer unterstützten das Aufräumen. Das Gebiet wurde zum Katastrophengebiet erklärt.[20]


→ Hauptartikel: Hagelabwehr


Zur Vermeidung von Hagelschäden wurden seit der Antike verschiedenste Methoden eingesetzt, von Bittopfer, rituellen Prozessionen, dem Wetterläuten und Schutzzeichen bis zu technischen Methoden wie dem Beschuss der Gewitterwolken mit Böllern, Kanonen und Raketen. Ab der Mitte des 20. Jahrhunderts wurde das Einbringen von Silberiodid (AgI) in die Wolken als Methode entdeckt. Silberiodid ist eiskeimbildend und soll durch zusätzliche Kristallisationskeime die Bildung größerer Hagelkörner verhindern. Die Ausbringung des AgI erfolgt vorwiegend durch Raketen oder speziell ausgerüstete Kleinflugzeuge, sog. Hagelflieger. Die Effektivität der Hagelbekämpfung mit Silberiodid ist wissenschaftlich nicht belegt.
Ein weiterer Versuch wird mit Hagelkanonen unternommen. Hierbei werden im Abstand einiger Sekunden durch Gasexplosionen Schallwellen erzeugt und durch einen Trichter ausgestoßen. Damit soll die Hagelbildung gestört und der Hagel in Nassschnee umgewandelt werden. Die Methode wird von Ingenieuren und Meteorologen für wirkungslos gehalten.
Zudem werden in der Landwirtschaft Hagelschutznetze aus Polyethylen (PE) verwendet, die über komplette Pflanzen gespannt werden und die Hagelkörner im Traufebereich herabfallen lassen.





Hans-Heinrich Schiesser:  In: Historisches Lexikon der Schweiz.





Die Schneelast oder Schneedruck gehört zu den klimatisch bedingten veränderlichen Einwirkungen auf Bauwerke. Sie hängt von Schneeart und Schneemenge ab. Die baulichen Lastannahmen bezüglich der Schneelast, auf die eine Dachkonstruktion auszulegen ist, hängen ab von der geografischen Lage und von der Form des betrachteten Bauwerks.




Schnee ist gefrorener, meist flächig kristallisierter Niederschlag, dessen Dichte und Gewicht primär von der Lufttemperatur abhängen, zur Zeit des Schneefalls – in der ganzen Atmosphärenhöhe – also auch während der Liegedauer: Sie beeinflusst die Kristallisations- und Agglomerationsform. Schnee bildet eine normalerweise sechseckig-sternförmige Kristallform, die sich schon während der Schneebildung zu großen Schneeflocken verzahnen kann. Liegend verändert der Schnee sich durch Auflast weiterer Schichten wie auch Umkristallisation zu einem hochkomplexen Gefüge.
Neuschnee hat spezifisches Gewicht von 0,03 (trockener frisch gefallener Schnee) bis 0,2 (gut gesetzter Neuschnee ohne zusätzlicher Wasseraufnahme).
Ein Meter Pulverschnee entspricht vom Druck her einer etwa fünf bis zehn Zentimeter hohen Wassersäule, bei Pappschnee (Nassschnee) sind es ca. 20 cm, das sind also 50–200 Liter je Quadratmeter Niederschlag (Wasseräquivalent). Ein Kubikmeter Wasser wiegt eine Tonne (1000 kg), ein Kubikmeter Frischschnee also 30–200 kg, längerliegender Schnee oft weitaus mehr.



Schneeart[1]
Massepro m3
Schneehöhebei 100 kg/m2


Trockener, lockerer Neuschnee
030–50 kg
ca. 200–300 cm


Gebundener Neuschnee
050–100 kg
ca. 100–200 cm


Stark gebundener Neuschnee
100–200 kg
ca.050–100 cm


Trockener Altschnee
200–400 kg
ca.025–50 cm


Feuchtnasser Altschnee
300–500 kg
ca.020–35 cm


Mehrjähriger Firn
500–800 kg
ca.012–20 cm


Eis
800–900 kg
ca.011–12 cm


Schneelast wirkt im Allgemeinen als Flächenlast senkrecht zur Grundfläche.
Für statische Nachweise wird in Bezug auf die Lastannahme vereinfachend – und auf der sicheren Seite liegend – mit nassem Schnee und einer Wichte (spezifisches Gewicht, Gewichtskraft je Volumen) von 2 kN/m³ gerechnet, das entspricht etwa dem oben genannten Wert für stark gebundenen Neuschnee.
Schneedruck ist als allgemeines Wort im Bezug auf Landschaft (etwa forstlich oder ökologisch) gleichbedeutend, baufachlich würde man darunter speziell die Gewichtskraft respektive präzise die Kraft je Auflagefläche, also den tatsächlichen Flächendruck verstehen.
Wenn sie sich setzt wird die Schneedecke nicht schwerer, sie verringert nur ihr Volumen. Tatsächlich wird Schnee während des Liegens im Prinzip leichter, sowohl bei Wärme wie bei starker Kälte nach dem Schneefall: Im ersten Fall schmilzt Schnee, sickert durch die Poren und rinnt ab, im zweiten Fall sublimiert („verdunstet“) das Wasser direkt in die Luft. Dies wird durch Sonnenschein und trockene Luft begünstigt. Bautechnisch betrachtet sind auch mehrere Meter trockener Neuschnee auf technisch einwandfreien Dächern keine Bedrohung. Problematisch sind kräftige Schneefälle bei um bis über Null Grad, weil dabei schon von sich aus sehr schwerer Schnee fällt, und noch viel mehr Regenfälle in hohe Schneedecken hinein. Dann können große Wassermengen zusätzlich in der Schneedecke gebunden werden, und die Schneelast wird tatsächlich um ein Vielfaches höher, was zu Spontanversagen eines Daches führen kann. Das kann innerhalb weniger Stunden geschehen. Daher stellen längerdauernde Pappschneefälle und in Regen übergehender Starkschnee akute Krisenszenarien dar.


In Deutschland sind die Schneelasten mit der DIN EN 1991-1-3 (2010-12) und zugehörigem nationalen Anhang geregelt.
In Österreich wurden die Belastbarkeiten von Gebäudeeindeckungen im April 2006 durch die ÖNORM B 1991-1-3:2006-04-01 gesetzlich neu vorgegeben, wobei die Werte wesentlich erhöht wurden.
Sowohl der österreichischen als auch der deutschen Neuregelung liegt die europäische Norm EN 1991-1-3 zugrunde. Sie gelten bis zu Höhen von 1500 m, darüber hinausgehende Höhenlagen werden durch spezielle nationale Anhänge geregelt.
In der Schweiz ist die SIA 261:2003 anzuwenden.[2]


In den Normen werden die Schneelasten in Rechenwerte zur Ermittlung der Tragwerkssicherheit überführt. Dabei wird aufgrund der starken physikalischen und zeitlichen Schwankungen der ausgeprägte stochastische Charakter beachtet. Die Rechenwerte entsprechen der 98 %-Quantile der Jahresmaxima und somit einer mittleren Wiederkehrperiode von 50 Jahren.

[Bearbeiten | Quelltext bearbeiten]
Die maßgebenden Einflussfaktoren auf die Größe der Schneelasten sind die des Standortes mit der lokalen Klimazone und der topografischen Höhe. In den Normen wird das Schneeklima durch eine Karte der Schneelastzonen erfasst, welche die Schneeintensität für verschiedene geographische Regionen angibt.




Dieser Artikel oder Absatz stellt die Situation in Deutschland dar. Bitte hilf uns dabei, die Situation in anderen Staaten zu schildern.



In Deutschland gibt es die Schneelastzonen

Zone 1 (u. a. Mittelrheintal, Niederrheinische Tiefebene)
Zone 1a (Großraum München-Donau)
Zone 2
Zone 2a (Hochschwarzwald, Rhön und Sauerland)
Zone 3 (Alpen, Bayerischer Wald, Thüringer Wald, Erzgebirge, Harz sowie Vorpommern).
Da die Schneehöhe überproportional zur Höhenlage wächst, ist diese als weiterer Einflussfaktor zu berücksichtigen. Damit ergeben sich in Deutschland die folgenden, am Standort anzusetzenden charakteristischen Werte 




s


k





{\displaystyle s_{\mathrm {k} }}

 der Schneelast in kN/m² auf dem Boden, in Abhängigkeit von der Geländehöhe 



A


{\displaystyle A}

 in m über dem Meeresniveau (vgl. Diagramm):

Zone 1:    




s

k


=
0

,

19
+
0

,

91


(



A
+
140

760


)


2


≥
0

,

65


{\displaystyle s_{k}=0{,}19+0{,}91\left({\frac {A+140}{760}}\right)^{2}\geq 0{,}65}


Zone 1a: Multiplikation des 




s


k





{\displaystyle s_{\mathrm {k} }}

-Wertes aus Zone 1 mit dem Faktor 1,25
Zone 2:    




s

k


=
0

,

25
+
1

,

91


(



A
+
140

760


)


2


≥
0

,

85


{\displaystyle s_{k}=0{,}25+1{,}91\left({\frac {A+140}{760}}\right)^{2}\geq 0{,}85}


Zone 2a: Multiplikation des 




s


k





{\displaystyle s_{\mathrm {k} }}

-Wertes aus Zone 2 mit dem Faktor 1,25
Zone 3:    




s

k


=
0

,

31
+
2

,

91


(



A
+
140

760


)


2


≥
1

,

10


{\displaystyle s_{k}=0{,}31+2{,}91\left({\frac {A+140}{760}}\right)^{2}\geq 1{,}10}

Für bestimmte Lagen in Zone 3 können höhere Werte als nach der hier angegebenen Gleichung maßgebend sein; Angaben über die Schneelast in diesen Regionen sind bei den zuständigen Stellen einzuholen.
Für die Schneelastzonen 1 und 2 gilt im nördlichen Teil Deutschlands, dem Norddeutschen Tiefland, dass der Rechenwert des außergewöhnlichen Lastfalls in bestimmten Orten mit dem Faktor 2,3 multipliziert wird; ob ein Ort dazugehört, kann in den technischen Baubestimmungen der Bundesländer ermittelt werden oder in der Schneelastzonentabelle des Deutschen Institut für Bautechnik (siehe Weblinks).

[Bearbeiten | Quelltext bearbeiten]

Die Dachform bzw. Dachneigung eines Bauwerkes ist ein weiterer Parameter für die Schneelast und wird durch Formbeiwerte berücksichtigt. Diese beschreiben das Verhältnis der auf dem Dach liegenden Schneemenge zur gefallenen Schneemenge und erfassen so z. B., dass von einem steilen Dach der Schnee schneller abrutscht als von einem flachen.
Größe und Verteilung der Schneelast kann auch stark durch die Windverhältnisse beeinflusst werden. So bilden sich an Höhensprüngen oft Schneeverwehungen, die zu beachten sind.

[Bearbeiten | Quelltext bearbeiten]
Die am Bauwerk anzusetzende Schneelast 




s


i





{\displaystyle s_{\mathrm {i} }}

 folgt somit aus der lokalen (charakteristischen) Schneelast 




s


k





{\displaystyle s_{\mathrm {k} }}

 multipliziert mit dem Formbeiwert 




μ


i





{\displaystyle \mu _{\mathrm {i} }}

:






s


i



=

μ


i



⋅

s


k





{\displaystyle s_{\mathrm {i} }=\mu _{\mathrm {i} }\cdot s_{\mathrm {k} }}




Eine Höhenmessung und Annahme des spezifischen Gewichts (z. B. Normgewicht) ist ungenau, da hierbei Schneedichte und gegebenenfalls vorliegende Vereisung unzureichend berücksichtigt werden. Eine genauere Schneelastbestimmung erfolgt durch Entnahme und Wiegen einer Schneeprobe, etwa mit einem Schneeprobenentnahmerohr (SPER). Die Auswertung erfolgt mit mindestens drei Proben und mit dem Gewichtsmittelwert. Überschreitet die vorhandene Schneelast den zulässigen Wert, muss die Standsicherheit der Dachkonstruktion durch einen Sachkundigen bewertet oder der Schnee vom Dach geräumt werden.
Weitere Hilfsmittel sind z. B. Schneelastwaagen.


Bei Erreichen oder Überschreiten der rechnerisch angesetzten Schneelast sollte ein Dach geräumt werden. Dies ist am besten abschnittsweise und streifenweise abwechselnd auf den Dachflächen durchzuführen.
Neben der konventionellen Räumung wird erfolgreich das Schmelzen des Schnees mit Heißdampf eingesetzt. Dabei wird die zu schmelzende Schneefläche abgedeckt und mit Dampf aufgeheizt.[3]



Aufgrund wirtschaftlicher Überlegungen sind extreme Schneelasten, die nur sehr selten vorkommen, in den Normen nicht berücksichtigt.
So hatte die Schneelast im schneereichen Winter 2005/2006 den Normwert in Teilen des Alpenraumes und des Bayerischen Waldes deutlich überschritten.[4] Viele Dächer mussten zur Vermeidung eines Versagens geräumt werden.
Es zeigte sich, dass den Schneelasten auf Dächern seinerzeit oft nicht genug Augenmerk geschenkt wurde. Im Gegensatz zur Information über die Lawinenlage fand eine qualifizierte Information von Baufachleuten und Hausbesitzern über die aktuellen Schneelasten durch die Bauaufsichtsbehörden und Wetterdienste nicht statt, selbst bei größeren Überschreitungen der lokalen Normlasten. Beim Ereignis 2006 stürzte am 2. Januar unter einer Schneelast, die die Normvorgaben nicht überschritt, die Eislaufhalle in Bad Reichenhall ein; 15 Menschen kamen zu Tode. Wenige Wochen danach versagte die Dachkonstruktion der Messehalle in Kattowitz und tötete 65 Menschen. Wurden diese Ereignisse anfangs noch als Einzelfälle betrachtet, so änderte sich die Situation schon wenig später, als in vielen Orten Bayerns, Oberösterreichs, der Steiermark und Niederösterreichs zahlreiche Dachstühle unter größeren Schneemassen einbrachen.
Deshalb wurde in den letzten Jahren die Modellierung und Prognose der Schneefälle umfangreich verbessert, sowohl in Hinsicht auf die großräumige Mittelfristprognose, wie auch auf wesentlich kleinräumigere Hotspots. Beim Schneeereignis 2019 konnte schon frühzeitig (im Bereich mehrerer Tage) gewarnt und von den Krisenstäben Hilfskräfte für das präventive Abschaufeln bereitgestellt werden.


Kostenloses Online-Tool zur  und des charakteristischen Werts der Schneelast sk nach Eurocode (auch Windzonen, Erdbebenzonen). In: Dlubal.com
 (PDF-Datei; 63 kB). In: Lawinenwarndienst-Bayern.de
, Schneelastrechner zum Herunterladen. In: DIN1055.de
 auf der privaten Seite Michael-Zimnik.de
Deutsches Institut für Bautechnik: . In: DIBt.de





Glatteis ist eine Weiterleitung auf diesen Artikel. Den Begriff der Meteorologie im Speziellen für die glasartiges Eis bildenden Formen von Eisregen siehe Klareis.





Winterglätte (umgangssprachlich im Verkehr auch Straßenglätte) respektive Glatteis[1] entsteht, wenn sich auf dem Boden eine Eisschicht oder eine andere Gleitschicht bildet. Besonders auf der Fahrbahnoberfläche und anderen Gehanlagen ist das ein großes Verkehrs- und Unfallrisiko.


Für die Winterglätte gibt es verschiedene Ursachen:[2]

Bei Schneeglätte[1] wird bereits vorhandener Schnee durch Druck, z. B. von Autos oder Fußgängern, zu einer glatten Schicht zusammengepresst. Besonders glatt wird diese Schicht, wenn sie leicht antaut und wieder gefriert.
Auch gefrierender Schneematsch führt zu Schneeglätte.
Von Eisglätte[1] (überfrierende Nässe) spricht man, wenn auf der Straße vorhandenes Wasser (Pfützen) gefriert. Das kann durch einen Kälteeinbruch entstehen, sehr häufig und tückisch ist aber etwa durch die Sonne geschmolzener Schnee neben der Fahrbahn, der abends oder gar nur im Schatten wieder überfriert.
Reifglätte entsteht, wenn die Temperatur des Straßenbelags unter dem Taupunkt liegt und somit Luftfeuchtigkeit oder Nebel anfriert. Da Brücken nachts stärker abkühlen, ist hier die Gefahr von Reifglätte besonders groß, desgleichen an anderen windausgesetzten Stellen. In den USA gibt es dafür eigens warnende Verkehrszeichen.
Bei Eisregen, auch als Blitzeis bezeichnet, gefriert frischer Niederschlag beim Auftreffen auf dem Boden. Wenn normale Regentropfen auf dem gefrorenen Boden sofort gefrieren, wird dies als Gefrierender Regen (fachlich Rauheis) bezeichnet. Unterkühlter Regen (fachlich Klar-/Glatteis) entsteht durch unterkühlte Regentropfen, die beim Auftreffen auf den Boden schlagartig gefrieren. Der Unterschied ist, dass letzteres bei Temperaturen über Null Grad vorkommt und wesentlich schwerer vorherzusagen ist als Ersteres, weil die Ursache Minustemperaturen in höheren Luftschichten sind.
Derselbe Effekt kann entstehen, wenn es in wenig tiefen Schnee hineinregnet, aber nicht genug, um ihn wegzuapern, etwa bei leichtem Nieselregen: Dann wandelt sich der Schnee zuerst in Harsch und dann in kompaktes Eis.
Matschglätte kann trotz entsprechender Verkehrssicherungspflichten vor allem im ländlichen Raum auftreten, wenn nasse Bodenreste von landwirtschaftlichen Flächen auf eine Straße verbracht werden.

Gischteis ist eine Sonderform der Küsten, hier friert bei großer Kälte und Sturm nicht Niederschlag im eigentlichen Sinne an, sondern die Brandungsgischt. Das entspricht dem Problem der Schiffsvereisung in der Seefahrt.
Außerdem gibt es Formen, die in verkehrstechnischer Betrachtungsweise als Winterglätte gelten, aber keine Eisbildung sind:

Ungefrorener Schneematsch führt zu Rutscheffekten, wenn er sich vor blockierenden Reifen (vgl. ABS) staut und der sich dadurch bildende Keil aus Schneematsch auf der Straßenoberfläche gleitet. Diese Gefahr kann auch dann entstehen, wenn Winterdienst auf nicht ausreichend geräumten Straßenoberflächen erfolgt.
Salzglätte entsteht, weil das hygroskopische Streusalz Feuchte aus der Luft bildet. Dann können auch apere und trocken erscheinende Straßen rutschig werden.
Allgemein beginnt die Gefahr von Winterglätte bei +4 °C. Hier beginnen moderne Fahrzeuge mit Temperatursensoren und Bordelektronik eine Glättewarnung zu geben.
Warnschilder und andere Warnhinweise befreien einen Straßenverkehrssicherungspflichtigen oder einen Verursacher von Straßenglätte nicht von der Pflicht, Straßenglätte zu bekämpfen, soweit dies rechtlich nicht anders geregelt ist. Die meisten Gemeindesatzungen verpflichten die Anlieger beziehungsweise den Winterdienst zur Beseitigung winterlicher Glätte in der Zeit von 7 bis 20 Uhr, am Wochenende morgens etwas später.
Eine Glättemeldeanlage ist eine Einrichtung zur Erfassung bzw. Prognose von Glatteis bzw. Glatteisgefahr auf Straßen. Solche Anlagen sind auf vielen hochrangigen Straßen (Schnellstraßen und Autobahnen) installiert.
Das sogenannte „Bauernglatteis“ ist eine Form der Straßenglätte, die entgegen ihrem Namen nichts mit Eis im Sinne von gefrorenem Wasser zu tun hat, sondern durch Straßenverunreinigungen verursacht wird.









Dieser Artikel behandelt das Wetterereignis. Zu weiteren Bedeutungen siehe Hitzewelle (Begriffsklärung).

Eine Hitzewelle ist in Meteorologie und Klimatologie eine ungewöhnlich lange Phase aufeinander folgender ungewöhnlich heißer Tage. Etwas abgeschwächt spricht man auch von Wärmewelle für Phasen abnorm hoher Temperaturen. Hitzewellen sind Extremwetterereignisse, die die menschliche Gesundheit, die Ökosysteme und die Infrastruktur schädigen können.[1]




Hitzewellen als solche sind ein relativ junges Forschungsgebiet, früher wurde primär auf Dürren fokussiert.
Es gibt auch keinerlei einheitliche Definition einer Hitzewelle.[2][3][4]
Typische moderne Ansätze für die Quantifizierung einer Hitzewelle sind folgendermaßen aufgebaut:

Zuerst wird eine gewisse Schwelle für den Begriff anomaler Hitze festgelegt, entweder absolut (etwa über den Begriff des heißen Tages, Tageshöchsttemperatur ≥ 30 °C),[5][6] über die Temperaturanomalie (Schwelle einer Grad-Abweichung von einer spezielleren langjährigen Mitteltemperatur, etwa Mittel des jeweiligen Tages oder Monats der letzten 30 Jahre),[7] oder über eine Häufigkeit (etwa Standardabweichung 95-%-Perzentil einer solchen Bemessungsgrundlage).[8][9] Weitere Kriterien wären physiologische Werte[10] wie Gefühlte Temperatur[11] oder der Heat Index (eine Kombination aus Temperatur und Luftfeuchte).[12]
Dann werden Kriterien für den Zeitumfang gewählt, die Episode (etwa eine Mindestdauer von drei oder fünf Tagen;[13][9] auch indem ein einziger Tag unterhalb der Hitzeschwelle die Hitzewelle nicht unterbricht)[14] wie auch den Zeitraum, in dem man überhaupt von Hitzewelle sprechen will (etwa nur den meteorologischen Sommer für die gemäßigten Breiten)[15][6][9]
Es wird ein betroffenes Gebiet festgelegt, aus einer meteorologischen Analyse, in politischen Grenzen, rein messtechnisch über Stationen, oder ein Modellierungsraster[9] – dabei müssen sich der Definitionsbereich der Hitzeschwelle und das Areal nicht decken (so könnte die Schwelle sich auf einzelne Messstationen beziehen, das Areal auf Verwaltungseinheiten).[16]
Es werden Kriterien für die Intensität der Hitzewelle bestimmt, etwa die absolut höchste über die gesamte Periode gemessene Temperatur, die mittlere Maximaltemperatur über alle Messstationen des Gebiets,[17] die maximale oder mittlere Anomalie,[7][17] die Jährlichkeit des Ereignisses, oder Ähnliches.
Damit ergeben sich als Maße für das Ausmaß einer Hitzewelle:[17]

Dauer
Geographischer Umfang
Gewisse Werte der Intensität
Eine für Mitteleuropa verwendete Methode der Auswertung geht auf den tschechischen Meteorologen Jan Kysely zurück, diese Tage der Hitzewelle werden Kysely-Tag genannt:[7]



„Eine Hitzewelle wird festgestellt, sobald an mindestens drei Tagen in Folge die Maximaltemperatur 30 °C überschreitet und hält so lange an, wie die mittlere Maximaltemperatur über die gesamte Periode über 30 °C bleibt und an keinem Tag eine Maximaltemperatur von 25 °C unterschritten wird.“



Für Wärmewellen – etwa für das Winterhalbjahr – sind ähnliche Kriterien mit abgeschwächteren Grenzwerten in Verwendung.[9]
Die zeitlichen und räumlichen Maße können zueinander in Bezug gesetzt werden, doch ist ein Ansatz, wie eine lokale kurze und heftige Hitzewelle mit einer lange andauernden und großräumigen zu vergleichen wäre, und das über verschiedene Klimaregionen, sehr komplex.[18] Diese Abschätzungen einer Vergleichbarkeit über Zeitreihen und Weltgegenden sind in der Meteorologie, der Wettermedizin und der Klimafolgenforschung heute in Entwicklung. Die Definitionen für 'Hitzewelle' können mit der Festlegung gewisser Unwetter-Warnstufen korrelieren.


Hitzewellen haben je nach Weltgegend verschiedene Ursachen. Im Winter führen entsprechende Situationen entweder zu einem Warmlufteinbruch und Tauwetter, oder aber zu einer Kältewelle.

[Bearbeiten | Quelltext bearbeiten]
 Klassisches kontinentales Hoch über Nordamerika
Die klassische sommerliche Hitzewelle der mittleren Breiten entsteht durch ein Hochdruckgebiet und Aufheizung durch lang anhaltenden Sonnenschein. Wärmeeinbrüche allgemein sind etwa für Mitteleuropa meist gut dokumentierte Singularitäten (regelhaft eintretende Ausnahmen), so eben die Hundstage des Hochsommers, aber auch im Winter etwa das Weihnachtstauwetter, sie gliedern die phänologischen Jahreszeiten der Vegetation.


Es gibt einige weitgehend regulär permanent vorhandene Hochdruckzonen, so das Azorenhoch oder das Sibirienhoch, die immer zu sommerlicher Hitze führen. Abnormale Hitzewellen können diese dann verursachen, wenn sie sich irregulär verlagern oder extrem stark ausgebildet sind: So kann das Azorenhoch bis vor Westeuropa liegen, und dann das Wetter des Kontinents direkt besonders beeinflussen (ein Beispiel: Spätsommer 1975). Oder es drängt die Atlantiktiefs übermäßig nach Norden, was zu zonaler Hitze im gesamten Mittelmeerraum führt (Juli 2015, zweite Phase). Weil diese Hochs selbst stabilisierend sind, können sich solche Hitzewellen über viele Wochen oder eine ganze Saison erstrecken, und auch zu Dürren führen. Verstärkt wird dieser Effekt, wenn sich Hochdruckbrücken zwischen den Hochs ausbilden, dann werden diese Ereignisse auch recht großräumig.

 Rossby-Wellen der Jet-Streams
Eine Ausnahmeerscheinung in den gemäßigten Breiten entsteht durch eine Blockade:[9] In gewissen Abständen geht der Jetstream in eine besonders wellige Form über, die Westwinddrift bricht ab, die Tiefdrucksysteme kommen nicht voran, und die Hochs dazwischen bleiben ortsfest liegen. Das kann zu ein- bis mehrwöchigen Hitzeperioden führen. Diese Verlagerung der Polarfront führt auch jeweils zu starkem Wärmeaustausch von den Tropen in die polaren Gebiete und kann auch im höheren Norden zu abnormer Wärme führen.[19]


Eine weitere Form der mittleren Breiten sind mächtige Tiefdrucksysteme (Zyklone). Diese können dann an ihrer südwärtigen Warmfront bis in die Subtropen greifen, und davor enorme Warmluftmassen nach Norden pumpen. Hierbei handelt es sich um kurzfristigere Warmlufteinbrüche bis zu einigen Tagen, solche Situationen können auch im Winter zu Wärmewellen führen. Für Europa typisch sind südwestliche Höhenströmungen nordafrikanischer Luft, oft mit Saharastaub-Ereignissen. Ein typisches Beispiel ist der Sommer 2013.

 Überschlagender Jetstream mit extremer Omegalage (2010)
Extrem werden kann die Kombination dieser Situationen: Ist bei einer Blockade das Hoch östlich und westlich von kräftigen Tiefs flankiert, entsteht die Omegalage, entsprechend dem Zeichen 



Ω


{\displaystyle \Omega }

, mit einer Kombination aus Blockade und südlichen Luftströmungen, wodurch sich die Hitze verstärkt. Typisch dafür sind die Tropennächte, weil auch die nächtliche Abkühlung durch erhöhte Abstrahlung bei normalen Hochdruckwetter wegfällt. In Europa entsteht durch trockene Saharaluft oder Föhn-Effekte an Pyrenäen und Alpen eine Kombination mit abnormer Trockenheit, oft entfallen dann die typischen Wärmegewitter, die sonst für Sommerhitze charakteristisch sind, womit ein weiterer Abkühlungsfaktor entfällt. Charakteristisch war das etwa in den Jahrhundertsommern 2003 und 2015 (erste und dritte Phase).

[Bearbeiten | Quelltext bearbeiten]

Eine weitere Ursache sind Schwankungen der warmen ozeanischen Strömungen in Intensität und Lage, was die Lagen der Aktionszentren und atmosphärischen Strömungen grundlegend beeinflusst. Bekanntestes Phänomen dieser Art ist das El-Niño-System, das an den Westküsten beider Amerikas zu Hitzewellen führen kann (und wohl auch das Wetter weltweit beeinflusst). Da dieses System gewisse regelmäßige Wiederkehr zeigt (El Niño-Southern Oscillation, ENSO), und auch andere globale Wetterzusammenhänge in Perioden ablaufen, zeigen auch Extremwetter wie Hitzewellen gewisse Häufungsphasen.

[Bearbeiten | Quelltext bearbeiten]

Siehe auch: Folgen der globalen Erwärmung für die Gesundheit
Dass die globale Erwärmung regional eine veränderte Häufigkeit und Dauer von Hitzewellen zur Folge hat, gilt heute als gesichert.[20] Gemäß Weltklimarat IPCC ist es praktisch sicher (99–100 % Wahrscheinlichkeit), dass Hitzewellen seit den 1950er Jahren in den meisten Regionen häufiger und intensiver wurden, wobei der anthropogenen Klimawandel mit großer Sicherheit der Hauptfaktor für diese Entwicklung ist. Zudem hält der IPCC fest, dass das Auftreten einiger beobachteter Hitzeextreme der 2010er Jahre ohne menschengemachten Klimawandel extrem unwahrscheinlich gewesen wäre. Auch das Auftreten von Hitzewellen in den Meeren verdoppelte sich etwa seit den 1980er Jahren, wobei menschliche Einfluss sehr wahrscheinlich zu den meisten von diesen, die seit mindestens 2006 aufgetreten sind, beigetragen hat. Mit jeder weiteren Erwärmung werden Hitzewellen gemäß IPCC zudem mit sehr großer Wahrscheinlichkeit intensiver werden und häufiger vorkommen.[21]



Mit einer Hitzewelle kann eine Dürre verbunden sein, das muss aber nicht sein, ebenso gibt es schwül-feuchte niederschlagsreiche Hitzeperioden.
Extreme Niedrigwasser verursachen erhebliche Probleme für die Schifffahrt und die Ökologie von Gewässern. Niedrigwasser während Hitzewellen mit gleichzeitig langsamen Fließbewegungen begünstigt aufgrund geringeren Sauerstoffgehalts des Wassers außerdem Fischsterben.


Hitze und Hitzewellen haben eine Vielzahl negativer Auswirkungen auf die Gesundheit. Zu diesen zählen u. a. Erkrankungen und Sterblichkeit aufgrund von Hitzestress und Hitzeschlag oder die Verschlimmerung von Herz-Kreislauf- und Atemwegserkrankungen. Am stärksten betroffen sind ältere Menschen über 65 Jahre, Menschen mit Vorerkrankungen, Menschen, die im Freien oder in ungekühlten Gebäuden arbeiten und solche, die in Regionen der Erde leben, die bereits an der Grenze der menschlichen Bewohnbarkeit angekommen sind.[22]
Hitzewellen zählen zu den gefährlichsten Naturgefahren und können u. a. mit einem Anstieg hitzebedingter Todesfälle erhebliche gesellschaftliche Auswirkungen nach sich ziehen. Durch den Klimawandel nimmt die Hitzebelastung der Bevölkerung weiter zu.[23] Gemäß Weltklimarat IPCC haben steigende Temperaturen zusammen mit Hitzewellen bereits zu einem Anstieg von Mortalität und Morbidität geführt, wobei die genauen Auswirkungen abhängig sind von verschiedenen Faktoren wie Alter, Geschlecht, Urbanisierungsgrad und weiteren sozioökonomischen Faktoren. Ein signifikanter Anteil der hitzebedingten Sterblichkeit in der warmen Jahreszeit in gemäßigten Regionen wird dabei auf den beobachteten menschengemachten Klimawandel zurückgeführt, während für tropische Regionen in Afrika weniger Daten verfügbar sind.[24] Für die Zukunft wird infolge der globalen Erwärmung ein weiterer Anstieg der Mortalität erwartet. Nach einer 2017 veröffentlichten Studie in 27 europäischen Staaten sterben in Europa im Durchschnitt mehr als 28.000 Menschen pro Jahr infolge von Hitzewellen, davon ca. 5.600 Menschen in Deutschland. Prozentual treten die höchsten Sterberaten in Portugal, Spanien und Frankreich auf. Auch in Deutschland lagen die Sterbefälle leicht über dem europäischen Durchschnitt. Betroffen sind vor allem ältere Menschen und solche mit Vorerkrankungen.[25]
Die Auswirkungen von Hitze können durch weitere Faktoren verstärkt werden. Beispielsweise belastet feuchte Hitze belastet den Organismus stärker als trockene Hitze.[26] Es wird zudem vermutet, dass sich Belastungen durch Hitze und durch Ozon in ihrer Kombinationswirkung verstärken können.[27]
Die folgende Liste (Stand 2015) gibt diejenigen zehn Hitzewellen, die die meisten Todesopfer gefordert haben sollen. Dabei ist zu beachten, dass auch dieses Phänomen erst seit jüngsten Jahren quantifiziert wird: Es herrscht kein klarer Begriff, wer das Opfer einer Hitzeanomalie sei. Im Unterschied etwa zu unmittelbar durch Sturm- oder Hochwasserkatastrophen Verunglückten werden hierbei allenfalls hitzebedingte Sterbefälle durch Kreislauf- oder Herzversagen gemeldet – unberücksichtigt bleiben wohl beispielsweise Krankheitsfälle durch allgemeine Schwächung, Unfälle durch erhöhte Belastung, oder gar Mangelernährungsopfer durch folgende Missernten aufgrund einer verbundenen Dürre. Moderne Ansätze rechnen die Opfer rein statistisch als Erhöhung aus der durchschnittlichen natürlichen Mortalität heraus.[28]
Die Berechnungsgrundlagen für die jüngeren Ereignisse Europas[29]
und andere Weltgegenden dürften dabei durchaus unterschiedlich sein. Historische Daten und insbesondere Vergleichbarkeit bestehen kaum – für Indien, das alleine in den letzten 15 Jahren vier schwere Hitzewellen erlebte, dürften beispielsweise gar keine Zahlen über „reguläre“ Mortalität vorliegen. Angaben zu Hitzeopfern einzelner Ereignisse können je nach Quelle stark abweichen und sind insgesamt mit Vorbehalt zu sehen (Stand 2015).



Region
Jahr
Dauer inWochen
Tmax
Opferzahl[30]


Europa
2003
2
47 °C
70.000


Russland
2010
8
>40 °C
55.000


Europa
2006
5
39 °C
3.500


Indien
1998
10
50 °C
2.500


Indien
2015
6
49 °C
2.500


USA, Kanada
1936
2
44 °C
1.700


USA
1980
≈10
45 °C
1.300


Pakistan
2015
2
45 °C
1.300


Indien
2003
3
50 °C
1.200


Indien
2002
2
49 °C
1.000


Griechenland, Türkei
1987
2
50 °C
1.000

Siehe auch: Hitzebelastung als Klimafolge in Deutschland

Marine Hitzewelle
Temperaturextrema
Jahrhundertsommer, Waldbrand – auch zu historischen Hitzewellen
Hitzewelle in Europa 2003
Hitzewellen in Europa 2015
Hitze und Unwetter in Europa 2017
Dürre und Hitze in Europa 2018
Hitzewelle in Australien 2018/2019
Hitzewelle in Indien 2019
Hitzewellen in Europa 2019
Hitzewelle in Sibirien 2020
Hitzewelle in Nordamerika 2021
Hitzewelle in Südasien 2022
Dürre und Hitze in Europa 2022


 des ZEITmagazin 31/2018, 25. Juli 2018
Bundesamt für Meteorologie und Klimatologie: 

Als Jahrhundertsommer bezeichnet man umgangssprachlich einen außergewöhnlich heißen, sonnigen und trockenen Sommer, also einen Sommer mit einer ausgeprägten Hitzeanomalie oder hitzebedingter Dürre (Niederschlagsanomalie).[1][2]
Beispielsweise werden die Sommer 1947[3] und 1983 als Jahrhundertsommer bezeichnet.[2] Auch der Sommer 2003 mit Temperaturabweichungen von über 3 Grad und der Sommer 2018 mit der längsten Dürreperiode seit Beginn der Wetteraufzeichnungen gelten als solche.[1][4]
Ein Jahr mit verheerender Dürre in Europa war auch 1540.[5][6]


Folgen der globalen Erwärmung#Regionale Wärmerekorde
Liste von Wetterereignissen in Europa
Liste extremer Wetterereignisse weltweit
Omegahoch – stabiler als normale Hochdruckgebiete; bewirkt dort eine typische sommerliche Schönwetterlage mit ausgeprägter Trockenheit und Wärme bis hin zu Hitzewellen und Dürren




Flavio Lehner et al. / National Center for Atmospheric Research (2016): 


Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Tauwetter (Begriffsklärung) aufgeführt.




Dieser Artikel oder nachfolgende Abschnitt ist nicht hinreichend mit Belegen (beispielsweise Einzelnachweisen) ausgestattet. Angaben ohne ausreichenden Beleg könnten demnächst entfernt werden. Bitte hilf Wikipedia, indem du die Angaben recherchierst und gute Belege einfügst.


Der Begriff Tauwetter bezeichnet in der Meteorologie eine Wetterlage, in der Schnee und Eis (gegebenenfalls auch Gletscher) aufzutauen beginnen. Gegenüber kalten, aber als schön empfundenen Schneeperioden wird Tauwetter häufig als feuchtes Schmuddelwetter gesehen. Es geht im Allgemeinen mit Nasskälte und in Regen übergehendem Schnee einher. Schnee taut, sobald die Taupunkttemperatur der Luft über 0 °C ansteigt. Beim Tauen kondensiert Wasserdampf auf dem Schnee, wodurch große Energiemengen umgesetzt werden und ein dementsprechend starker Abbau einer Schneedecke eintritt.



Eine Kältewelle ist eine in relativ kurzer Zeit auftretende starke Abkühlung auf unterdurchschnittliche Werte der Lufttemperatur. Sowohl am Anfang wie am Ende des Winters spricht man von Wintereinbruch.



Kältewellen beginnen, wenn hochreichende Kaltluft aus dem Gebiet über der Arktis
im Zusammenhang mit einer kräftigen Tiefdruckentwicklung auf der Rückseite eines Höhentrogs weit nach Süden vordringen kann (siehe auch Polarwirbel).
Über einer Schneedecke kann die Lufttemperatur durch Ausstrahlung extrem niedrige Werte erreichen.


In Mitteleuropa entstehen Kältewellen im Winter insbesondere durch Advektion sehr kalter Festlandsluft aus Nord-Ost. Klassisches Aktionszentrum ist ein dominantes Russlandhoch über Sibirien, das großräumig arktische Kaltluft nach Mitteleuropa führt. Mitunter bildet dieses sibirische Hochdruckgebiet einen Hochdruckkeil bis nach Skandinavien aus, so dass bei gleichzeitig tiefem Luftdruck über dem Mittelmeer mit einer östlichen Strömung Kaltluft bis nach Südwesteuropa vorstoßen kann.[1]
Die Kältewellen sind für Mitteleuropa meist gut dokumentierte Singularitäten (regelhaft eintretende Ausnahmen), in der kalten Jahreshälfte, verfrüht Mitte Oktober bis hin verspätet zu den Eisheiligen als Wintereinbrüche oder Hochwinterphasen, in der warme Jahreszeit als Zwischenphasen der sommerlichen Wärme. Sie treffen mit signifikanter Häufigkeit rund um gewisse Termine ein, können aber stark um diese schwanken oder gänzlich ausfallen.



Anders als bei arktischer Polarluft in Europa mit den Alpen als Wetterscheide kann die eisige, klirrende Kälte aus der Arktis wegen der geologischen Verhältnisse in Nordamerika weiter nach Süden vordringen und neben Kanada auch die USA erreichen. Durch die Anordnung der Gebirge auf dem Kontinent in Nord-Süd-Richtung und der fehlenden Erwärmung über einem Meer können Minustemperaturen 20 Grad Celsius unter Null mit ausgeprägten Temperatursprüngen so auch Millionen Menschen betreffen. Anfang 2019 erreichte eine Kältewelle etwa den Süden Kanadas und den mittleren Westen und Nordosten der Vereinigten Staaten mit minus 31 Grad Celsius in Chicago. Auch der Jetstream spielt eine andere Rolle als in Europa.[2]


Jahrtausendwinter von 1708/1709
Liste von Wetterereignissen in Europa (sortierbar auch für Kälteanomalien)
Naturereignisse und Unglücke in Ostpreußen
Sibirienhoch


 (pdf), Münchener Rück
, Die Presse online (Quelle: ZAMG)
Bundesamt für Meteorologie und Klimatologie: 

Meyers Lexikonredaktion (Hrsg.): Meyers kleines Lexikon. Meteorologie, Mit Unterstützung des Deutschen Wetterdienstes. Meyers Lexikonverlag 1992, Mannheim/ Wien/ Zürich, S. 199, 202




Dieser Artikel behandelt Ebbe und Flut speziell auf der Erde. Die Ursachen für die Gezeiten auf allen Himmelskörpern stehen im Artikel Gezeitenkräfte.




Tide ist eine Weiterleitung auf diesen Artikel. Weitere Bedeutungen sind unter Tide (Begriffsklärung) aufgeführt.




Die Gezeiten oder Tiden (niederdeutsch Tid, Tied [tiːt] „Zeit“; Pl. Tiden, Tieden [tiːdən] „Zeiten“) sind die Wasserbewegungen der Ozeane, die infolge der Gravitation des Mondes und der Sonne durch die zugehörigen Gezeitenkräfte verursacht werden. Die Gezeiten, die ohne den Effekt von Kontinenten bei knapp einem halben Meter liegen würden, verstärken sich durch Resonanzeffekte an den Küsten auf Werte von bis zu mehreren Metern. Die Hauptkomponente geht vom Mond aus. Da dieser nicht nach 24 Stunden, sondern nach 24 Stunden 50 Minuten 28 Sekunden wieder etwa an der gleichen Stelle am Himmel steht, gibt es eben nach dieser Zeitspanne je zweimal Hochwasser und Niedrigwasser.
Die Gezeitenkräfte wirken im Sinne einer symmetrischen Streckung der Erde entlang der Linie zum Mond bzw. zur Sonne. Da sich wegen der Erdrotation keine stabile Deformation einstellen kann, regen die Gezeitenkräfte in den Ozeanen vor allem in mittleren Breiten periodisch Strömungen an. Diese bewirken das periodische Steigen und Fallen des Wasserspiegels. Bei Voll- und Neumond stehen Sonne und Mond von der Erde aus auf einer gleichen Linie, weshalb sich ihre Wirkungen zu einer besonders großen Tide, der Springtide, addieren. Bei Halbmond dagegen stehen Sonne und Mond rechtwinklig zueinander und so ergibt sich eine besonders kleine Tide, die Nipptide. Die Gezeitenkräfte der Sonne betragen zwischen 37 % und 57 % (im Mittel etwa 46 %) derjenigen des Mondes.[1] Besonders große Gezeitenkräfte und Springtiden ergeben sich etwa alle 29 Wochen, wenn eine Perigäum des Mondes mit einer Springflut zusammenfällt. Maximal wird eine Springtide, wenn sich zusätzlich der Mond in der Nähe eines Knotenpunktes (dann bilden Mond, Erde und Sonne eine exakte Linie) und die Erde in Sonnennähe befindet (Ende Dezember/Anfang Januar).
Die Lehre von den maritimen Gezeiten der Erde heißt Gezeitenkunde. Ihre Grundaussagen sind Bestandteil der nautischen Ausbildung.






Einige Stichpunkte bedürfen einer grundsätzlichen Überarbeitung: * HW und NW stehen laut  nicht (mehr?) für einen Zeitpunkt sondern für einen Wasserstand (höchster/niedrigster) in einer Zeitspanne* Kentern: nach jetziger Beschreibung ist das gleichbedeutend mit HW und NW* Stauwasser: nach jetziger Beschreibung auch zum Zeitpunkt des Niedrigwassers!? Bitte hilf mit, sie zu verbessern, und entferne anschließend diese Markierung.

Flut – Zeitraum und Vorgang ansteigenden, „auflaufenden“ Wassers
Ebbe – Zeitraum und Vorgang sinkenden, „ablaufenden“ Wassers
Hochwasser (HW) – Zeitpunkt des höchsten Wasserstandes
Niedrigwasser (NW) – Zeitpunkt des tiefsten Wasserstandes
Kentern – Zeitpunkt des Wechsels von auflaufendem zu ablaufendem Wasser oder umgekehrt (Beim Kentern der Tide kommt es für kurze Zeit zu einem Stillstand der Gezeitenströmung.)
Stauwasser – Stillstand der Gezeitenströmung beim Kentern
Tidenkurve – Zeitlicher Verlauf des Wasserstandes zwischen Niedrigwasser, Hochwasser und darauf folgendem Niedrigwasser
Siehe auch: Gezeitenrechnung#Begriffsdefinitionen


[Bearbeiten | Quelltext bearbeiten]
[Bearbeiten | Quelltext bearbeiten]


Deutsch

Abk.

Englisch

Abk.

Bedeutung


Höchstmöglicher Gezeitenwasserstand



Highest Astronomical Tide

HAT

Bezug für Durchfahrtshöhe unter Brücken


Mittleres Springhochwasser

MSpHW

Mean High Water Spring

MHWS




Mittleres Hochwasser,Mittleres Tidenhochwasser

MHWMThw

Mean High Water

MHW

Definition der Küstenlinie in Land- und Seekarten


Mittleres Tidenmittelwasser

MTmw

Mean Sea Level

MSL




Mittelwasser (gezeitenfreie Gewässer, Tidenhub geringer als 30 cm)

MW

Seekartennull in gezeitenfreien Gewässern (Tidenhub geringer als 30 cm), dort Übereinstimmung der Wassertiefen in See- und Landkarten


Mittleres Niedrigwasser,Mittleres Tidenniedrigwasser

MNWMTnw

Mean Low Water

MLW

Wattgrenze in Landkarten


Mittleres Springniedrigwasser

MSpNW

Mean Low Water Spring

MLWS

früher Nullebene für Wassertiefen (lt. IHO veraltet)


Niedrigst möglicher Gezeitenwasserstand

NGzW

Lowest Astronomical Tide

LAT

Seekartennull in GezeitengewässernNullebene für Wassertiefen in SeekartenWattgrenze in Seekarten

Die deutschen Abkürzungen werden in offiziellen Werken der IHO nicht mehr verwendet.
Das Pegelportal[2] der Wasserstraßen- und Schifffahrtsverwaltung des Bundes verwendet für Pegel in der Nordsee außer „MThw“ und „MTnw“ auch die empirischen Werte „HThw“ (Höchstes Tidenhochwasser) und „NTnw“ (Niedrigstes Tidenniedrigwasser), Beispiel Pegel Norderney Riffgat:[3]

HThw = 906 cm (am 6. Dezember 2013) – Höchstes Tidenhochwasser in einer Zeitspanne (01.11.2005 – 31.10.2015)
MThw = 622 cm – Mittleres Tidenhochwasser in einer Zeitspanne (01.11.2005 – 31.10.2015)
MTnw = 375 cm – Mittleres Tidenniedrigwasser in einer Zeitspanne (01.11.2005 – 31.10.2015)
NTnw = 251 cm (am 13. Dezember 2008) – Niedrigstes Tidenniedrigwasser in einer Zeitspanne (01.11.2005 – 31.10.2015)
PNP = −5,00 m. ü. NHN – Pegelnullpunkt, Höhenlage des Nullpunktes der Pegellatte bezogen auf ein amtlich festgelegtes Höhensystem (in Deutschland: DHHN92)
Für die Ostsee verwendet das Pegelportal folgende Pegelparameter,[4] erklärt mit Beispielwerten vom Pegel LT Kiel:[5]

HW = 670 cm (am 1. November 2006) – Hochwasser, höchster Wasserstand in einer Zeitspanne (01.11.2005 – 31.10.2015)
MHW = 615 cm – Mittleres Hochwasser, mittlerer höchster Wert der Wasserstände in einer Zeitspanne (01.11.2005 – 31.10.2015)
MW = 501 cm – Mittlerer Wasserstand, Mittelwert der Wasserstände in einer Zeitspanne (01.11.2006 – 31.10.2015)
MNW = 383 cm – Mittleres Niedrigwasser, mittlerer niedrigster Wert der Wasserstände in einer Zeitspanne (01.11.2005 – 31.10.2015)
NW = 322 cm (am 1. November 2006) – Niedrigwasser, niedrigster Wasserstand in einer Zeitspanne (01.11.2005 – 31.10.2015)
PNP = −4,99 m. ü. NHN – Pegelnullpunkt
[Bearbeiten | Quelltext bearbeiten]
Hochwasserhöhe (HWH) – Wasserstand zum Zeitpunkt HW
Niedrigwasserhöhe (NWH) – Wasserstand zum Zeitpunkt NW. Aufeinander folgende Hochwasser- und Niedrigwasserhöhen am selben Ort sind im Allgemeinen unterschiedlich, da sich die Stellungen von Mond und Sonne relativ zu diesem Ort ändern.


Deutsch

Abk.

Englisch

Abk.

Bedeutung


Höhe der Gezeit



Height of Tide



Gezeitenbedingte Höhe des aktuellen Wasserstandes bezogen auf das örtliche Seekartennull SKN (meistens LAT)


Seekartennull

SKN

Chart Datum

CD

Grundlage für• amtliche Definition der Basislinie• Nullebene für die Messung von Wassertiefenist bezogen auf• LAT Lowest Astronomical Tide (oder MLLW)• oder auf MSL in tidenfreien Gewässern

[Bearbeiten | Quelltext bearbeiten]
Tidenstieg (TS) – Höhenunterschied zwischen Niedrigwasserhöhe NWH und der folgenden Hochwasserhöhe HWH
Tidenfall (TF) – Höhenunterschied zwischen Hochwasserhöhe HWH und der folgenden Niedrigwasserhöhe NWH
Tidenhub – Mittelwert aus Tidenstieg und Tidenfall


Deutsch

Abk.

Englisch

Abk.

Bedeutung


Mittlerer Springtidenhub

MSpTH

Mean Spring Tidal Range



Unterschied von Niedrig- und Hochwasser bei Springzeit (Tidenhub am größten)


Mittlerer Nipptidenhub

MNpTH

Mean Neap Tidal Range



Unterschied von Niedrig- und Hochwasser bei Nippzeit (Hub am kleinsten)


Dass Ebbe und Flut vorwiegend mit dem Mond korreliert sind,[6] dürfte zu den ersten astrophysikalischen Erkenntnissen des Menschen gehören. Denn es ist an den Ozeanküsten unmittelbar zu beobachten, dass der bei Hochwasser sichtbare Mond regelmäßig beim übernächsten Hochwasser wieder fast an gleicher Stelle steht, also zwei Tiden während eines seiner scheinbaren Umläufe auftreten. Auch detailliertere Kenntnisse über den Zusammenhang zwischen Mond und Gezeiten, bis hin zur längerfristigen Periodizität abhängig von Mondphasen und Jahreszeiten, sind schon im alten Indien, bei den Phöniziern und Karern nachgewiesen,[7] und waren auch dem Seefahrer und Entdecker Pytheas bekannt.[8]
Der griechische Astronom Seleukos von Seleukia übernahm im zweiten vorchristlichen Jahrhundert das heliozentrische Weltbild des Aristarchos und baute darauf seine Theorie der Gezeiten auf.[9] Ein umfangreiches Werk von Poseidonios aus dem 1. Jahrhundert v. Chr. ist zwar verschollen, aber aus antiken Zitaten lässt sich schließen, dass es die lunisolare Theorie enthielt, also die Erklärung der täglichen und monatlichen Effekte aufgrund gegenseitiger Einwirkung der drei Himmelskörper.[10]
Im 14. Jahrhundert veröffentlicht Jacopo de Dondi (dall’Orologio), Vater des Giovanni de Dondi (dall’Orologio), De fluxu et refluxu maris, wohl angeregt durch griechisch-byzantinische Quellen.[11]
Im 16. Jahrhundert gab Andrea Cesalpino in seinem Werk Quaestiones Peripatetica (1571) eine Erklärung der Gezeiten durch die Erdbewegung – ähnlich dem Hin- und Herschwappen von Wasser in einem bewegten Eimer. 1590 erklärte Simon Stevin die Anziehung durch den Mond zur Ursache der Gezeiten.
Johannes Kepler skizzierte 1609 im Vorwort seiner Astronomia Nova eine Theorie der Schwere, nach der alle Materie gegenseitig anziehend wirkt, sodass der Mond durch die Anziehung der Ozeane die Gezeiten verursacht. Kepler interpretierte schon qualitativ richtig, warum Ebbe und Flut an verschiedenen Küsten unterschiedlich stark und gegenüber dem Mond unterschiedlich phasenverschoben sind, konnte aber nur eine Tide pro Tag erklären.[12] Galileo Galilei verneinte jeden Einfluss des Mondes und interpretierte 1616 in seinem Discorso sopra il Flusso e Reflusso del Mare (unveröffentlicht) und im Dialogo (herausgegeben 1632) die Gezeiten als Folge der Erdrotation kombiniert mit dem Erdumlauf um die Sonne: Von der Sonne aus gesehen bewegt sich die Tagseite der Erde langsamer als die Nachtseite, wodurch sich die Gezeiten, allerdings auch nur einmal täglich, aufgrund der unterschiedlichen Beschleunigungen ergeben sollen.[8] René Descartes gab im 17. Jahrhundert eine Erklärung auf Basis einer Reibung des „Äthers“ zwischen Erde und Mond, die allerdings schnell widerlegt wurde.[13]


Isaac Newton ging 1687 in seinem Werk Mathematische Prinzipien der Naturlehre von dem Modell eines Zweikörpersystems von Erde und Mond aus, das um den gemeinsamen Schwerpunkt, das Baryzentrum, rotiert. Als Erster konnte er die an verschiedenen Orten der Erde unterschiedlichen Anziehungskräfte von Mond und Sonne und die daraus resultierende Verformung der Meeresoberfläche berechnen, die richtig zu zwei – allerdings viel zu schwach ausgeprägten – Tiden pro Tag führt. Daniel Bernoulli, Leonhard Euler, Pierre-Simon Laplace und Thomas Young erweiterten Newtons Betrachtung und fanden heraus, dass die Hebung und Senkung der Wasseroberfläche weniger durch die vertikalen Komponenten der Gezeitenkräfte verursacht wird als durch die Strömungen, die von den horizontalen Komponenten angetrieben werden. Damit bestätigten sie den Ansatz von Cesalpino („Schwappen in einem Gewässerbett“) und Kepler. Dabei entdeckte Euler 1739 die mathematische Herleitung der Phänomene der erzwungenen Schwingungen und der Resonanz, und Young gab 1823 erstmals deren vollständige mathematische Beschreibung an. Die durch Rechnung gewonnenen Voraussagen waren allerdings sehr ungenau. Erst mit zunehmender Kenntnis der Mechanik der erzwungenen Schwingungen in strömenden Flüssigkeiten sowie der Massen der beteiligten Himmelskörper wurden die Ergebnisse ab Mitte des 19. Jahrhunderts allmählich genauer.


Historische Übersicht


1. Jh. v. Chr.
Poseidonios
Der Mond hat auf die Gezeiten mehr Einfluss als die Sonne


1590
Simon Stevin
Anziehung des Mondes


1609
Johannes Kepler
Anziehung durch Gravitation des Mondes


1616/1632
Galileo Galilei
kinematische Gezeitentheorie


17. Jh.
René Descartes
Reibung des „Äthers“ zwischen Erde und Mond


1687
Isaac Newton
Berechnung der Anziehungskräfte von Mond und Sonne


1740
Daniel Bernoulli
Gleichgewichtstheorie


1740
Leonhard Euler
erzwungene Schwingung


1799
Pierre-Simon Laplace
dynamische Gezeit


1824
Thomas Young
Theorie auf Basis der vollständigen Formeln der erzwungenen Schwingung


1831
William Whewell
Gezeitenwellen


1842
George Biddell Airy
Theorie auf Basis einfach geformter Becken mit gleichförmiger Tiefe


1867
William Thomson
harmonische Analyse


20. Jh.
Sydney Hough
dynamische Theorie unter Einbeziehung der Corioliskraft


Gezeiten entstehen durch das Zusammenwirken der täglichen Drehung der Erde im (nahezu feststehenden) Gravitationsfeld von Mond und Sonne und der Tatsache, dass dieses Gravitationsfeld nicht überall gleich stark ist, sondern die Erde etwas in die Länge zieht. Die Kräfte, die das verursachen, heißen Gezeitenkräfte. Ein Ort der Erdoberfläche erreicht bei jeder Umdrehung je zweimal einen Punkt mit maximaler und mit minimaler Gezeitenkraft. Die Gezeitenkraft macht zwar weniger als ein zehnmillionstel der Erdanziehung aus, stellt aber eine periodische Störung eines ansonsten stabilen Gleichgewichtszustands dar. Auf diese Störung reagieren die Ozeane mit hin und her schwingenden Strömungen, die sich an Küsten durch periodisches Heben und Senken des Meeresspiegels bemerkbar machen. Dabei werden an vielen Orten Höhenunterschiede von deutlich über 1 Meter erreicht.

[Bearbeiten | Quelltext bearbeiten]
Ein Gravitationsfeld ruft an einem ansonsten kräftefreien Massepunkt (Masse 



m


{\displaystyle m}

) am Ort 






r
→





{\displaystyle {\vec {r}}}

 durch die Gravitationskraft 






F
→



(



r
→



)
=
m




a
→



(



r
→



)


{\displaystyle {\vec {F}}({\vec {r}})=m\;{\vec {a}}({\vec {r}})}

 eine Beschleunigung 








r
→


¨



=



a
→



(



r
→



)


{\displaystyle {\ddot {\vec {r}}}={\vec {a}}({\vec {r}})}

 hervor. Betrachtet man eine ausgedehnte Wolke von Massepunkten, die keine anderen als diese Gravitationskräfte spüren, dann wird der Massenmittelpunkt der Wolke an seinem Ort 






R
→





{\displaystyle {\vec {R}}}

 eine bestimmte Beschleunigung 








R
→


¨





{\displaystyle {\ddot {\vec {R}}}}

 zeigen, als ob die Summe der Gravitationskräfte aller Massepunkte hier auf einen Körper mit der Summe ihrer Massen einwirkte (siehe Schwerpunktsatz).


Man bezieht die Gravitationsbeschleunigung des Massenpunkts am Ort 






r
→





{\displaystyle {\vec {r}}}

 auf die Beschleunigung des Massenmittelpunkts. Die Differenz ist die an diesem Ort der Wolke herrschende Gezeitenbeschleunigung:









a
→




Gez


(



r
→



)
=



a
→



(



r
→



)
−





R
→


¨





{\displaystyle {\vec {a}}_{\text{Gez}}({\vec {r}})={\vec {a}}({\vec {r}})-{\ddot {\vec {R}}}}


Die Gezeitenbeschleunigung zeigt sich direkt in der Beschleunigung der Bewegung des (ansonsten kräftefreien) Massepunkts relativ zum Massenmittelpunkt der Wolke. Im Bezugssystem, in dem der Massenmittelpunkt ruht, verhält jeder Massepunkt sich so, als ob auf ihn die Gezeitenkraft









F
→




Gez


(



r
→



)
=
m





a
→




Gez


(



r
→



)


{\displaystyle {\vec {F}}_{\text{Gez}}({\vec {r}})=m\;{\vec {a}}_{\text{Gez}}({\vec {r}})}


wirkt. Alternativ zu dieser Herleitung kann man explizit eine Transformation des Bezugssystems von einem Inertialsystem in das Ruhesystem des Massenmittelpunkts der Wolke vornehmen. Dies Bezugssystem ist mit 








R
→


¨





{\displaystyle {\ddot {\vec {R}}}}

 beschleunigt, daher wirkt in ihm eine überall gleiche Trägheitskraft 







F
→




Träg


(



r
→



)
=
−
m






R
→


¨





{\displaystyle {\vec {F}}_{\text{Träg}}({\vec {r}})=-m\;{\ddot {\vec {R}}}}

, die man zu der äußeren Kraft 






F
→



(



r
→



)
=
m




a
→



(



r
→



)


{\displaystyle {\vec {F}}({\vec {r}})=m\;{\vec {a}}({\vec {r}})}

 zu addieren hat. Das Ergebnis für die Gezeitenkraft – das ist die in diesem Bezugssystem wirksame Kraft – ist das gleiche.
Dieselbe Gezeitenkraft wirkt auch, wenn die Massepunkte, aus denen der betrachtete Himmelskörper besteht, weitere Kräfte spüren, z. B. gegenseitige Gravitation, Kohäsion etc., aber auch ein weiteres äußeres Kraftfeld. Nur zeigt sich in der beschleunigten Bewegung eines Massepunkts die Gezeitenkraft dann nicht unmittelbar, sondern nur in der Summe mit den anderen auf den Massepunkt wirkenden Kräften. Sie kann dann z. B. Verformungen und/oder Strömungen hervorrufen, je nachdem, wie fest die Massenpunkte an ihren Ort gebunden sind.
Diese Herleitung von Gezeitenbeschleunigung und Gezeitenkraft gilt unabhängig von der Bahn oder dem Bewegungszustand des betrachteten Himmelskörpers (z. B. ob linear oder kreisförmig, ob mit oder ohne Eigenrotation). Die in vielen Lehrbüchern getroffenen Annahmen etwa über dessen Kreisbewegungen und die zugehörigen Zentrifugalkräfte (die übrigens nur für eine gleichförmige Kreisbewegung exakt sind) dienen dort lediglich dazu, die Beschleunigung des Massenmittelpunktes 








R
→


¨





{\displaystyle {\ddot {\vec {R}}}}

 zu ermitteln, um die Transformation in dessen Ruhesystem vornehmen zu können.[14]
Die von einem Himmelskörper hervorgerufene Gezeitenkraft ist am stärksten an den beiden entgegengesetzten Punkten der Erdoberfläche, die den kleinsten bzw. größten Abstand zum Himmelskörper haben. Sie weist dort vertikal nach außen, also beim kleinsten Abstand direkt auf den Himmelskörper zu, beim größten Abstand direkt von ihm weg. An den Punkten der Erdoberfläche, die den gleichen Abstand vom Himmelskörper haben wie der Massenmittelpunkt der Erde, ist die Gezeitenkraft am kleinsten und weist vertikal nach innen. In einem mittleren Bereich ist die Gezeitenkraft parallel zur Erdoberfläche gerichtet und kann daher im Ozean effizient Strömungen antreiben.

[Bearbeiten | Quelltext bearbeiten]
Für eine einfache Erklärung betrachte man wie eben anstelle der festen Erde eine fiktive kugelförmige Wolke kleiner Teilchen, die gemeinsam die Sonne umkreisen, aber keinerlei Kräfte aufeinander ausüben (auch keine Schwerkraft). Alle Teilchen bewegen sich (zunächst) mit derselben Winkelgeschwindigkeit 



ω


{\displaystyle \omega }

 um die Sonne, teils etwas näher, teils etwas weiter von ihr entfernt. Dann liefert die gesamte Gravitationskraft, die die Sonne auf die Teilchen ausübt, am Ort des Schwerpunkts der Wolke genau die Zentripetalbeschleunigung 




ω

2


R


{\displaystyle \omega ^{2}R}

, die zur Fortführung von dessen Kreisbewegung (mit Radius 



R


{\displaystyle R}

) nötig ist (siehe Schwerpunktsatz). Verglichen mit dem Massenmittelpunkt brauchen die Teilchen, die näher an der Sonne sind, bei gleicher Winkelgeschwindigkeit eine kleinere Zentripetalbeschleunigung für ihre Kreisbahn, spüren aber eine stärkere Anziehungskraft der Sonne. Daher wird ihre Bahn stärker zur Sonne hin gekrümmt und sie entfernen sich zunehmend schneller vom Mittelpunkt der Wolke. Umgekehrt spüren die Teilchen mit größerem Abstand als 



R


{\displaystyle R}

 eine geringere Anziehungskraft der Sonne und können von dieser nicht auf einer Kreisbahn gehalten werden. Diese Teilchen werden sich also nach außen beschleunigt vom Mittelpunkt entfernen. Ergebnis: die Wolke wird längs der Linie zur Sonne nach beiden Richtungen auseinandergezogen. Bei Kometen, die einem Planeten zu nahe kommen, hat man diesen „Gezeitenaufbruch“ schon beobachtet (siehe Shoemaker-Levy 9). Nun ist die Erde keine Wolke nicht wechselwirkender Teilchen, aber die Gezeitenkräfte sind die gleichen. Als ein fester Körper mit gewisser Elastizität verformt die Erde sich, und zwar (durch Sonne und Mond zusammen) um ±30 bis ±60 cm (siehe Erdgezeiten), während in den beweglichen Luft- und Wassermassen von Atmosphäre und Ozeanen Strömungen erzeugt werden.


Gezeitenbeschleunigungen sind Beschleunigungsdifferenzen zwischen verschiedenen Punkten eines äußeren Feldes. Das äußere Feld ist stets eine Überlagerung von Zentralfeldern, hier hauptsächlich von Sonne und Mond. Am einfachsten ist der Fall eines Zentralfeldes, also von Sonne oder Mond. Die Beschleunigungen werden anhand einer Testmasse ermittelt, die einmal an den Ort des Massenmittelpunkts der Erde und einmal an den interessierenden Ort gesetzt wird. Die Beschleunigung am Massenmittelpunkt ist gleich der Beschleunigung einer starren Erde.[15] Der andere Ort der Testmasse kann irgendwo in der Erde liegen, z. B. in der beweglichen Hydrosphäre.





a
(
r
)
=



G
M


r

2






{\displaystyle a(r)={\frac {GM}{r^{2}}}}


ist der durch das Newtonsche Gravitationsgesetz gegebene Betrag der Beschleunigung im Gravitationsfeld des anderen Himmelskörpers (Sonne oder Mond). Darin ist 



r


{\displaystyle r}

 der Abstand der Testmasse von der verursachenden Masse 



M


{\displaystyle M}

 und 



G


{\displaystyle G}

 die Gravitationskonstante. Für Punkte auf der Verbindungslinie vom Massenmittelpunkt der Erde zum Himmelskörper sind die Beschleunigungen parallel, daher ist die maximale und die minimale Gezeitenbeschleunigung einfach durch die Differenz der Beträge an den Stellen 



R


{\displaystyle R}

 und 



R
±

r

0




{\displaystyle R\pm r_{0}}

 zu berechnen (




r

0




{\displaystyle r_{0}}

 für den mittleren Erdradius):






a

Gez


(
±

r

0


)
=
a
(
R
±

r

0


)
−
a
(
R
)
 
≈
 
−



2
G
M


R

3





⋅
(
±

r

0


)


{\displaystyle a_{\text{Gez}}(\pm r_{0})=a(R\pm r_{0})-a(R)\ \approx \ -{\frac {2GM}{R^{3}}}\;\cdot (\pm r_{0})}

.
Mit 




r

0


=
6,371
⋅

10

6




m



{\displaystyle r_{0}=6{,}371\cdot 10^{6}\,{\text{m}}}

 und den Werten für den Mond, 



G
M
=
4

,

90
⋅

10

12





m


3



/



s


2




{\displaystyle GM=4{,}90\cdot 10^{12}\,{\text{m}}^{3}/{\text{s}}^{2}}

 und 



R
=
3

,

84
⋅

10

8




m



{\displaystyle R=3{,}84\cdot 10^{8}\,{\text{m}}}

, ergibt sich






a

Gez


(
+

r

0


)
=
−
1

,

07


10

−
6




m/s


2




{\displaystyle a_{\text{Gez}}(+r_{0})=-1{,}07\,10^{-6}{\text{m/s}}^{2}}

 und





a

Gez


(
−

r

0


)
=
+
1

,

13


10

−
6




m/s


2




{\displaystyle a_{\text{Gez}}(-r_{0})=+1{,}13\,10^{-6}{\text{m/s}}^{2}}

.
Das ist etwa ein Dreißigstel der Beschleunigung der Erde zum Mond hin. Die Fallbeschleunigung auf der Erde, 9,81 m/s2, ist etwa 107-fach größer.

[Bearbeiten | Quelltext bearbeiten]
Für die Vertikal- und die Horizontalkomponente der Gezeitenbeschleunigung an einem beliebigen Ort der Erdoberfläche, der vom Erdmittelpunkt aus gesehen um den Winkel 



θ


{\displaystyle \theta }

 von der Richtung Erde→Mond abweicht, gilt[16]






a

v


=
−



G
⋅
M
⋅

r

0




R

3




(
3
⋅

cos

2



θ
−
1
)


{\displaystyle a_{\text{v}}=-{\frac {G\cdot M\cdot r_{0}}{R^{3}}}(3\cdot \cos ^{2}\,\theta -1)}

 für die Vertikalkomponente und





a

h


=


3
2


⋅



G
⋅
M
⋅

r

0




R

3




⋅
sin

2
θ


{\displaystyle a_{\text{h}}={\frac {3}{2}}\cdot {\frac {G\cdot M\cdot r_{0}}{R^{3}}}\cdot \sin \,2\theta }

 für die Horizontalkomponente der Gezeitenbeschleunigung.
Die Grafik rechts zeigt die Zerlegung Gezeitenbeschleunigung in Komponenten senkrecht und parallel zur Erdoberfläche.


[Bearbeiten | Quelltext bearbeiten]
Mit den Konstanten






M

=
1,989
⋅

10

30




kg



{\displaystyle {\text{M}}=1{,}989\cdot 10^{30}\,{\text{kg}}}

 für die Masse der Sonne, und





R

=
1,496
⋅

10

11




m



{\displaystyle {\text{R}}=1{,}496\cdot 10^{11}\,{\text{m}}}

 für die Entfernung von der Sonne,
ergibt sich






a

m


=
5,928
⋅

10

−
3




m


/



s


2




{\displaystyle a_{\text{m}}=5{,}928\cdot 10^{-3}\,{\text{m}}/{\text{s}}^{\text{2}}}


für die von der Sonne herrührende Gravitationsbeschleunigung der Erde sowie






a

g


≈
∓
 
5,048
⋅

10

−
7




m


/



s


2




{\displaystyle a_{\text{g}}\approx \mp \ 5{,}048\cdot 10^{-7}\,{\text{m}}/{\text{s}}^{\text{2}}}


für die Gezeitenbeschleunigung.
Die Gezeitenbeschleunigung variiert mit der dritten Potenz des Abstandes vom Gravitationszentrum und fällt damit schneller ab als die quadratisch variierende Gravitationsbeschleunigung. Obwohl die Sonne am Ort der Erde eine fast 180-fach stärkere Gravitationsbeschleunigung erzeugt als der Mond, erreicht die von ihr verursachte Gezeitenbeschleunigung nur 46 % der durch den Mond verursachten.

[Bearbeiten | Quelltext bearbeiten]
Die von Mond und Sonne verursachten Gezeitenkräfte addieren sich. Die stärkste Gesamtkraft ergibt sich, wenn Sonne, Erde und Mond auf einer Linie liegen, was bei Voll- und Neumond mit einer Periode von etwa 14¾ Tagen näherungsweise eintritt. Dann heben sie den Wasserspiegel des Ozeans bei Hochwasser etwa ¾ Meter (etwa ½ Meter durch den Mond und etwa ¼ Meter durch die Sonne) an.[17]

[Bearbeiten | Quelltext bearbeiten]

Massen und Abstände


Objekt

Masse

Abstand zur Erde


Periapsis
Mittel
Apoapsis


Mond

m☾ = 7,346 · 1022 kg

s☾p = 363300 km

s☾ = 384400 km

s☾a = 405500 km


Sonne

m☉ = 1,9884 · 1030 kg

s☉p = 147,100 · 106 km

s☉ = 149,598 · 106 km

s☉a = 152,096 · 106 km

Die Gezeitenkräfte rechnen sich zu m/s3, normiert auf m☾/s☾3 betragen sie:



Objekt

Relative Stärke (m/s3) / (m☾/s☾3)


Periapsis
Mittel
Apoapsis


Mond

n☾p = 1,185

n☾  = 1

n☾a = 0,852


Sonne

n☉p = 0,483

n☉  = 0,459

n☉a = 0,437

In allen Fällen ist die Tide des Mondes die dominierende Tide.
Nipp- und Springtiden liegen damit zwischen



Tide

Min
Mittel
Max


Nipptide

n☾a − n☉p = 0,369

n☾ − n☉ = 0,548

n☾p − n☉a = 0,748


Springtide

n☾a + n☉a = 1,289

n☾ + n☉ = 1,459

n☾p + n☉p = 1,668

Die Verhältnisse zwischen Spring- und Nipptide liegen 1,72 (naher Mond, ferne Sonne) und 4,52 (ferner Mond, nahe Sonne), im Mittel bei 2,7.

Mittlere Periodendauer

Die Mondtide ist dominierend, d. h. ihre Amplitude ist immer größer als die Amplitude aller anderen Effekte. Daher ist sie allein für die mittlere Periodendauer der Tiden verantwortlich.

Siderischer Tag:  t1 = 23 Stunden 56 Minuten 4,0905 Sekunden = 23,9344696 Stunden
Siderischer Monat:  t2 = 27,321661 Tage = 655,719864 Stunden
1 / (1/t1 − 1/t2) = 24,8411997 Stunden = 24 Stunden 50 Minuten 28,32 Sekunden
Änderungen der Mondbahn und der Tageslänge verändern die Periodendauer. Bei gebundener Rotation mit t1 = t2 verschwindet die Tide.


Wenn der Ozean die ganze Erde bedecken würde, würden bei der täglichen Drehung der Erde die Wasserberge und -täler auf der Erde umlaufen. Durch die Kontinente ist der Ozean in mehrere mehr oder weniger geschlossene Becken aufgeteilt, an deren Rändern das anströmende Wasser nicht nur aufgehalten, sondern auch reflektiert wird. Eine Wasserwelle läuft zurück und wird am gegenüberliegenden Rand erneut reflektiert. Das Wasser schwappt mit etwa 12½-stündiger Periode in den Ozeanbecken hin und her, wobei sich durch die Erddrehung kreisförmig umlaufende Wellen herausbilden. Bei Resonanz zwischen der Wellenausbreitung und dem von der Erddrehung verursachten Wechsel der Gezeitenkräfte kann sich die Wellenamplitude stark vergrößern.

[Bearbeiten | Quelltext bearbeiten]

Nach dem Ansatz von George Biddell Airy, der von Henri Poincaré, Joseph Proudman und Arthur Doodson weiterentwickelt wurde, entstehen die Gezeiten im Wesentlichen durch die horizontale Komponente der Gezeitenbeschleunigung vor allem im tiefen Ozean. Obwohl die Strömungen die gesamte Tiefe umfassen, handelt es sich um Flachwasserwellen, denn die Wellenlänge ist wesentlich größer als die Wassertiefe. Dann wird die Ausbreitungsgeschwindigkeit der Wellen nur von der Wassertiefe bestimmt. Ihre Periodendauer ist durch die der Gezeitenkräfte festgelegt. Ausbreitungsgeschwindigkeit und Periodendauer ergeben zusammen einen typischen Knotenabstand von etwa 5000 Kilometern in stehenden Wellen in den Ozeanen, siehe Bild. In den Knoten ist die Amplitude des Pegels gering, die Strömungsgeschwindigkeit groß. Als Folge der Corioliskraft entstehen kreisende bis elliptische Bewegungen um die Knotenpunkte (Amphidromie). In den Schelfmeeren ist die Wellenlänge wegen der geringeren Wassertiefe kürzer. So gibt es in der relativ zu den Ozeanen kleinen Nordsee allein drei Amphidromiepunkte.

[Bearbeiten | Quelltext bearbeiten]
Die Amplituden der Gezeitenwellen sind wegen der geringeren Wassertiefe der Schelfe vor den Küsten deutlich höher als in den sonst tiefen Ozeanen. Die geringere Wassertiefe bedeutet geringere Ausbreitungsgeschwindigkeit der Wellen, was zum Anstieg der Wasserpegel führt. In Buchten und Mündungstrichtern von Flüssen verursacht die Querschnittsverringerung ein weiteres Abbremsen und Erhöhung der Wellenamplitude. Besonders großer Tidenhub tritt immer an solchen Stellen auf. Oftmals kommen rein topographisch begünstigte Resonanzüberhöhungen hinzu wie in der Fundy-Bucht, in der es den weltweit höchsten Tidenhub gibt. Sie ist gerade so lang, dass sich die rücklaufende Welle außerhalb der Bucht zu einem dort gerade angekommenen erneuten Wasserberg addiert.
An steilen Küsten mit großer Wassertiefe ist der Tidenhub klein, weil die Wellenausbreitung im Gegensatz zu einer Küste mit vorgelagerten Inseln nicht verlangsamt wird.

[Bearbeiten | Quelltext bearbeiten]


„Die Ursache der Gezeiten ist eine astronomische, die Reaktion der Meere darauf hingegen ist eine geographische.“


– Wolfgang Glebe: Ebbe und Flut – Das Naturphänomen der Gezeiten einfach erklärt[18]
Die Gezeiten sind einer größeren Zahl individueller Zeitabhängigkeiten unterworfen, die im Wesentlichen astronomische Ursachen haben. Die Ortsabhängigkeit ist wegen der vielfältigen Form der Küste und des vorgelagerten Meeresbodens zwar groß, ist aber mit Hilfe weniger, prinzipiell beschreibbarer topographischer Parameter erklärbar. Dennoch werden Tidenvoraussagen im Allgemeinen nicht für größere Küstenabschnitte erstellt, sondern in der Regel nur für einen Ort, z. B. einen Hafen.
Die scheinbare Umlaufzeit des Mondes und die Periode der Mondphasen sind mit etwa 24 Stunden und 53 Minuten bzw. mit etwa 29½ Tagen Mittelwerte aus sowohl kurzfristig als auch aus längerfristig deutlich veränderlichen Werten. Durch harmonische Analyse der tatsächlichen Tiden-Verläufe wurden zusätzliche kleine Anteile mit anderer Periodendauer getrennt sichtbar gemacht. Der spätere Lord Kelvin baute bereits 1872/76 eine erste Gezeitenrechenmaschine, mit deren Hilfe schon zehn unterschiedliche Schwingungsvorgänge zur Simulation des längerfristigen Verlaufs der Tiden in der Themse zusammengesetzt wurden (harmonische Synthese). Heutige Gezeitenrechnungen setzen etwa hundert Teilschwingungen zusammen, deren astronomischer Hintergrund meist, aber nicht immer, bekannt ist.

[Bearbeiten | Quelltext bearbeiten]
Wegen der zur Erd- und zur Mondbahn nicht senkrechten Erdachse haben zwei aufeinanderfolgende Gezeiten an einem Ort abseits des Äquators nicht den gleichen Tidenhub. Zu den Hochwasserzeiten befindet sich der Ort an Stellen, an denen die Gezeitenkräfte nicht gleich groß sind.[19][20]

[Bearbeiten | Quelltext bearbeiten]
Wegen des Wechsels der Mondlage relativ zur Sonne (Mondphasen) schwankt die Resultierende aus den von Mond und Sonne verursachten Gezeitenkräften, was zur etwa halbmonatlichen Periode der Tidenamplitude führt: Spring- und Nipptiden.[21][22][23]
Beim Anstieg des Tidenhubs von Tag zu Tag bis hin zur Springtide folgen sich die Fluten in geringeren Zeitabständen als beim Abstieg zur Nipptide. Die in den Ozeanen entstandenen Pegelwechsel kommen als höhere Wellen über den Schelfen schneller voran als die weniger hohen.[24][25]
Im halbjährigen Rhythmus der Tagundnachtgleichen stehen die Sonne und annähernd auch der Mond senkrecht zur Erdachse. Die Gezeitenkräfte haben über die Erde als Ganzes gesehen dann die größte Wirkung.[26][27]

[Bearbeiten | Quelltext bearbeiten]
Die etwa elliptische Mondbahn dreht sich in ihrer Ebene in etwa 8,65 Jahren einmal um 360°. An einer bestimmten Bahnstelle bei gleicher Lage der Bahn befindet sich ein Voll- oder Neumond nach etwa 4½ Jahren wieder und hat denselben Abstand von der Erde. Die Wirkung des unterschiedlichen Abstandes auf den Gezeitenhub ist gering, aber als Effekt mit etwa 4½-jähriger Periode in langzeitigen Vergleichen – zum Beispiel der bereits extremen Springtiden an oder zeitnah bei den Tagundnachtgleichen – erkennbar.[28]
Die Mondbahn um die Erde und die Erdbahn um die Sonne schneiden einander unter einem Winkel von etwa 5°. Die Schnittlinie (Knotenlinie) dreht sich in etwa 18,6 Jahren einmal um 360°. Wenn sich der Mond in einem der beiden Knoten befindet, gleichzeitig Voll- oder Neumond ist und Springtiden stattfinden,[29] so ist der Tidenhub in diesem Rhythmus von etwa 9¼ Jahren nochmals geringfügig höher. Ursache ist die exakt gleiche Richtung der vom Mond und von der Sonne verursachten Gezeitenkräfte.[30]


→ Hauptartikel: Gezeitenvorausberechnung und Gezeitenrechnung
Mit Gezeitenrechnungen werden Vorhersagen über den zeitlichen Verlauf der Tiden und die Höhen von Hoch- und Niedrigwasser erstellt. Sie sind vorwiegend für die küstennahe Schifffahrt, die bei zu geringer Wassertiefe Einschränkungen unterliegt, von Bedeutung. Die Gezeitenströmung kann die Schifffahrt beschleunigen oder verlangsamen. Von besonderer Bedeutung ist die Vorhersage des Zeitpunktes, an dem sie ihre Richtung ändert (Kenterpunkt). Für die Schifffahrt in Flussmündungen sind Voraussagen über die Gezeitenwelle, die bei Flut stromaufwärts läuft, von besonderer Bedeutung.



In Küstennähe sind die Gezeiten erheblich durch die geometrische Form der Küsten beeinflusst. Das betrifft sowohl den Tidenhub als auch den Zeitpunkt des Eintretens von Hoch- und Niedrigwasser. Die für jeden Ort ungefähr konstant bleibende Zeitdifferenz zwischen Hochwasser und Höchststand des Mondes wird als Hafenzeit, Tiden- oder Hochwasserintervall bezeichnet. In der Nordsee z. B. laufen Ebbe und Flut in einer Kreiswelle herum, so dass es an den Nordseeküsten Paare von Orten gibt, wo der eine gerade Hochwasser hat, wenn am anderen Niedrigwasser ist. Der Tidenhub unterscheidet sich nicht nur zwischen verschiedenen Regionen; an vorgelagerten Inseln und Kaps ist er geringer als an der Festlandsküste, in Buchten und Flussmündungen manchmal höher als an der vorderen Küste.
Der Tidenhub ist an den Küsten der Weltmeere oft größer als auf offener See. Das gilt insbesondere für trichterförmige Küstenverläufe. Das Meer schwappt bei Flut gewissermaßen an die Küste. So beträgt der Tidenhub in der westlichen Ostsee nur etwa 30 Zentimeter, an der deutschen Nordseeküste etwa ein bis zwei Meter. In Ästuaren (Mündungen) der tidebeeinflussten Flüsse, zum Beispiel Elbe und Weser, beträgt der Tidenhub aufgrund der Trichterwirkung in diesen auch Tidefluss genannten Abschnitten bis über vier Meter. Noch höher ist der Tidenhub beispielsweise bei St. Malo in Frankreich oder in der Severnmündung zwischen Wales und England. Er kann dort über acht Meter erreichen. In der Bay of Fundy treten die weltweit höchsten Gezeiten mit 14 bis 21 Metern auf.
Die Zunahme der Höhe der Flutwelle an den Küsten erfolgt in etwa nach dem gleichen Prinzip wie bei einem Tsunami. Die Geschwindigkeit der Flutwelle verringert sich in flachem Wasser, wobei sich die Höhe der Welle vergrößert. Im Gegensatz zum Tsunami ist die Gezeitenwelle aber nicht Resultat eines einzelnen Impulses, sondern enthält einen Anteil, der durch die Gezeitenkraft stets neu angeregt wird.
Die durch die Tide auf hoher See an den Küsten angeregten Meeresschwingungen können auch zu Schwingungsknoten führen, an denen gar kein Tidenhub auftritt (Amphidromie). Ebbe und Flut rotieren gewissermaßen um solche Knoten herum. Herrscht auf der einen Seite Ebbe, so herrscht auf der gegenüberliegenden Seite Flut. Dieses Phänomen findet man vor allem in Nebenmeeren, wie der Nordsee, die drei solcher Knoten aufweist (siehe diesbezügliche Abbildung im Artikel Amphidromie). Herausragend ist hierbei vor allem die Tideresonanz der Bay of Fundy.
Durch die Gezeiten werden insbesondere in Küstennähe erhebliche Energiemengen umgesetzt. Dabei kann die kinetische Energie der Strömungen oder auch die potentielle Energie mittels eines Gezeitenkraftwerks genutzt werden.

[Bearbeiten | Quelltext bearbeiten]




Tidenhub[31]

Ort

Lage


typ.

max.


0,79–1,82 m
2,39 m
Lerwick[32]
Shetland-Inseln


2,01–3,76 m
4,69 m
Aberdeen[33]
Mündung des Dee-River in Schottland


2,38–4,61 m
5,65 m
North Shields[34]
Mündung des Tyne-Ästuars


2,31–6,04 m
8,20 m
Kingston upon Hull[35]
Nordseite des Humber-Ästuars


1,75–4,33 m
7,14 m
Grimsby[36]
Südseite des Humber-Ästuars weiter seewärts


1,98–6,84 m
6,90 m
Skegness[37]
Küste von Lincolnshire nördlich des Ästuars The Wash


1,92–6,47 m
7,26 m
King’s Lynn[38]
Mündung der Great Ouse in das Ästuar The Wash


2,54–7,23 m

Hunstanton
Ostecke des Ästuars The Wash


2,34–3,70 m
4,47 m
Harwich[39]
Küste East Anglias nördlich der Themsemündung


4,05–6,62 m
7,99 m
London Bridge[40]
oben am Themse-Ästuar


2,38–6,85 m
6,92 m
Dunkerque (Dünkirchen)[41]
Dünenküste östlich der Straße von Dover


2,02–5,53 m
5,59 m
Zeebrugge[42]
Dünenküste westlich des Rhein-Maas-Schelde Deltas


3,24–4,96 m
6,09 m
Antwerpen[43]
oben im südlichsten Ästuar des Rhein-Maas-Schelde Deltas


1,48–1,90 m
2,35 m
Rotterdam[44]
Grenzbereich von Ästuardelta[45] und klassischem Delta


1,10–2,03 m
2,52 m
Katwijk[46]
Mündung des Uitwateringskanaals des Oude Rijn in die Nordsee


1,15–1,72 m
2,15 m
Den Helder.[47]
Nordende der holländischen Dünenküste westlich des Ijsselmeers


1,67–2,20 m
2,65 m
Harlingen[48]
östlich des IJsselmeers, in das der Rheinarm IJssel mündet


1,80–2,69 m
3,54 m
Borkum[49]
Insel vor der Emsmündung


2,96–3,71 m
4,38 m
Emden-Seeschleuse[50]
an der Emsmündung


2,60–3,76 m
4,90 m
Wilhelmshaven[51]
Jadebusen


2,66–4,01 m
4,74 m
Bremerhaven[52]
an der Wesermündung


3,59–4,62 m
5,26 m
Bremen-Oslebshausen[53]
Bremer Industrie-Seehäfen oben im Weserästuar


3,30–4,00 m

Bremer Weserwehr[54]
künstliche Tidengrenze der Weser


2,54–3,48 m
4,63 m
Cuxhaven[55]
an der Elbmündung


3,40–3,90 m
4,63 m
Hamburg St. Pauli[56]
Hamburg Landungsbrücken, oben am Elbästuar


1,39–2,03 m
2,74 m
Westerland[57]
Insel Sylt vor der nordfriesischen Küste


2,80–3,49 m

Dagebüll[58]
Küste des Wattenmeers in Nordfriesland


1,10–2,10 m
2,17 m
Esbjerg[59][60]
Nordende der Wattenküste in Dänemark


0,50–1,10 m

Hvide Sande[59]
dänische Dünenküste, Einfahrt zur Lagune Ringkøbing Fjord


0,30–0,50 m

Thyborøn[59]
dänische Dünenküste, Einfahrt zur Lagune Nissum Bredning


0,20–0,40 m

Hirtshals[59]
Skagerrak, gleiche Hübe wie Hanstholm und Skagen


0,14–0,30 m
0,26 m
Tregde[61]
Skagerrak, Südnorwegen, östlich eines Amphidromiezentrums


0,25–0,60 m
0,65 m
Stavanger[61]
nördlich des Amphidromiezentrums


0,64–1,20 m
1,61 m
Bergen[61]



[Bearbeiten | Quelltext bearbeiten]
Mit der Ausbaggerung von Fahrrinnen für den Schiffsverkehr reicht der hohe Tidenhub der Mündung heute in den Ästuaren weit flussaufwärts, wo er früher schon deutlich nachließ (Vgl. Elbvertiefung und Weserkorrektion). Flussaufwärts wird der Tidenbereich heutzutage vielerorts durch Wehre begrenzt, die gleichzeitig als Staustufen in den zuführenden Flüssen einen Mindestwasserstand für die Schifffahrt garantieren können (zum Beispiel Richmond Lock in der Themse), aber auch teilweise für die Nutzung der Wasserkraft geeignet sind (siehe Untersuchungen für die Themse[62] und das bestehende Weserkraftwerk Bremen).
Die Mündung der Themse mit ihrem relativ hohen Tidenhub ist ein klassisches Beispiel, dass bei sehr starken Tidenströmen die Erosion so stark und die Sedimentation so gering ist, dass sich ein Ästuar ausbildet. Im Rhein-Maas-Schelde-Delta haben Sedimentation und Erosion jahrtausendelang zusammengewirkt. Die Sedimentation hat bewirkt, dass die einmündenden Flüsse versandeten und in neue Betten ausbrachen, wodurch eine Vielzahl von Flussmündungen entstand. Zwischen Antwerpen und Rotterdam, wo der Tidenhub groß ist, haben die gezeitenbedingten Pendelströme diese Flussmündungen zu Ästuaren aufgeweitet. An der flachen Küste östlich des holländischen Dünengürtels sind vom frühen 12. bis ins frühe 16. Jahrhundert Sturmfluten weit ins Land gedrungen und haben von der Mündung des östlichsten Rheinarms IJssel aus die Zuiderzee ausgewaschen, an der Mündung der Ems den Dollart und noch weiter östlich den Jadebusen. Zwischen diesem und dem Ästuar der Weser bestand von Anfang des 14. bis Anfang des 16. Jahrhunderts ein Weserdelta aus Ästuaren und Hochwasserrinnen, das dem Delta in Zeeland ähnelte.
Die weitreichendsten Auswirkungen haben die Gezeiten auf den Amazonas, die Flutwelle läuft auf Grund der sehr breiten Mündung und dem extrem geringen Gefälle etwa 800 km ins Inland bis etwa Óbidos.



Nodaltide


 auf YouTube
 auf YouTube
 auf YouTube
 auf YouTube
 auf YouTube
 auf YouTube

Wolfgang Glebe: Ebbe und Flut: das Naturphänomen der Gezeiten einfach erklärt. Delius Klasing, Bielefeld 2010, ISBN 978-3-7688-3193-2.
Werner Kumm: Gezeitenkunde. 2. Auflage. Delius Klasing, Bielefeld 1996, ISBN 3-87412-141-0.
Andreas Malcherek: Gezeiten und Wellen – Die Hydromechanik der Küstengewässer. Vieweg + Teubner, Wiesbaden 2010, ISBN 978-3-8348-0787-8.
Günther Sager: Mensch und Gezeiten: Wechselwirkungen in zwei Jahrtausenden. Deubner, Köln 1988, ISBN 3-7614-1071-9.
Jean-Claude Stotzer: Die Darstellung der Gezeiten auf alten Karten. In: Cartographica Helvetica. Heft 24, 2001, S. 29–35, doi:10.5169/seals-12590.
John M. Dow: Ocean tides and tectonic plate motions from Lageos. Beck, München 1988, ISBN 3-7696-9392-2 (englisch).
Bruce B. Parker: Tidal hydrodynamics. Wiley, New York NY 1991, ISBN 0-471-51498-5 (englisch).
Paul Melchior: The tides of the planet earth. Pergamon Press, Oxford 1978, ISBN 0-08-022047-9 (englisch).
David E. Cartwright: Tides – a scientific history. Cambridge Univ. Press, Cambridge 1999, ISBN 0-521-62145-3 (englisch).






 bei WeltDerPhysik.de.







Der Titel dieses Artikels ist mehrdeutig. Weitere Bedeutungen sind unter Smog (Begriffsklärung) aufgeführt.

Smog bezeichnet eine durch Emissionen verursachte Luftverschmutzung, die insbesondere in Großstädten auftritt. Im allgemeinen Sprachgebrauch beschreibt er die Anwesenheit von Luftschadstoffen in gesundheitsschädlichen und sichtbeeinträchtigenden Konzentrationen. Wissenschaftlich gesehen, bezeichnet Smog stark erhöhte Luftschadstoffkonzentrationen über dicht besiedeltem Gebiet infolge besonderer meteorologischer Bedingungen (z. B. Inversionswetterlage). Generell tritt Smog nur während windschwacher Wetterlagen auf. Auch eine durch Tal- oder Kessellagen ungünstige Topografie fördert die Entstehung von Smog. So kann in ländlichen Regionen, in denen intensiv Holz verfeuert wird, bei ungünstiger Geländeform Smog auftreten.



Der Begriff wurde Ende 1905 auf einem in London abgehaltenen Kongress für Gesundheitspflege geprägt, und zwar als Kofferwort, das sich aus den englischen Worten smoke (‚Rauch‘) und fog (‚Nebel‘) zusammensetzt. Die Kongressteilnehmer waren der Überzeugung, es würde durch die bloße Bekanntgabe rasch populär.[1] Anfang des 20. Jahrhunderts war Smog in London eine häufige Erscheinung, die damals auch London Peculiars (‚Londoner Eigenheiten‘) genannt wurde.


[Bearbeiten | Quelltext bearbeiten]

Die Mischung aus Ruß, Schwefeldioxid (SO2), Staub (trockener Dunst) und Nebel kann sich unter den ungünstigen Bedingungen einer Inversionswetterlage, insbesondere vom Typ Fumigation, lange über einer Stadt halten und ist meist gesundheitsschädlich. Der Rauch stammt dabei aus verschiedenen Quellen wie Wärmekraftwerken, Holzfeuerungen und Fahrzeugen mit Verbrennungsmotoren.
Aus Schwefeldioxid und Wasser bilden sich Sekundärschadstoffe wie Schweflige Säure (H2SO3) und Schwefelsäure (H2SO4). Diese führen zu Schäden an Pflanzen, Gebäuden sowie zu Reizungen der Atemwege und Augen beim Menschen.
Diese Art von Smog wird auch Wintersmog oder London-Smog genannt. Es handelt sich um reduzierenden Smog. Zusätzlich zu dieser eigentlichen Bedeutung unterscheidet man auch noch den Sommersmog (Los-Angeles-Typ).

[Bearbeiten | Quelltext bearbeiten]
Kohlenstoffmonoxidkonzentrationen von mehr als 0,01 % führen zu Kopfschmerzen und Übelkeit. Hohe Konzentrationen führen zu Bewusstlosigkeit und zum Tod durch Sauerstoffmangel. Stickoxide und Ozon reizen die Schleimhäute und können zu chronischen Atemwegserkrankungen führen. Hohe Feinstaubkonzentrationen führen zu einer Belastung des Herz-/Kreislaufsystems und sind zunehmend mit Krankenhausaufenthalten und Todesfällen wegen Herzkrankheiten verbunden. Kohlenwasserstoffverbindungen können krebserregend sein. Stärkere körperliche Belastungen (auch Sport) sollen bei Smog-Alarm vermieden werden.
Smog ist ein Problem vieler Großstädte. Bei hohen Schadstoffkonzentrationen sind einige Städte dazu übergegangen, Fahrverbote für Kraftfahrzeuge auszusprechen.
Der Autofahrer selbst hat – solange der Verkehr noch läuft – die Möglichkeit, sich vor diesen Smog-Substanzen zu schützen, indem er einen hochwertigen Kabinenluftfilter (Innenraumfilter) in sein Fahrzeug einbaut und diesen regelmäßig erneuert – die Hersteller empfehlen einen jährlichen Tausch.
Allerdings ist nicht jede Regierung und Verwaltung aus wirtschaftlichen Gründen bereit, das Phänomen „Smog“ anzuerkennen.

[Bearbeiten | Quelltext bearbeiten]

Die Smog-Krise im Ruhrgebiet 1962 forderte 150 Todesopfer. Smogalarm der Stufe I wurde dort erstmals am 17. Januar 1979 ausgelöst.[2] Aufgrund einer ausgeprägten Inversionswetterlage musste sechs Jahre später, am 18. Januar 1985, für das westliche Ruhrgebiet, zum ersten Mal in der Bundesrepublik Deutschland, Smogalarm der Stufe III, verbunden mit Fahrverboten für den Privatverkehr und Einschränkungen für die Industrie, ausgelöst werden.[3][4] West-Berlin hatte die erste Smogsituation im Dezember 1968.[5]
In den 1980er-Jahren gab es in West-Berlin mehrere Smogalarme, so am 17. und 18. Januar 1980 (Stufe I), erneut am 24. Januar 1980, am 19. Dezember 1981 und vom 1. bis 3. Februar 1987 (Stufe I und Fahrverbot).[6] Am 2. Februar 1987 erfolgte Smogalarm (Stufe II ohne Fahrverbot) im Raum Braunschweig/Wolfenbüttel. Am 3. Februar 1987 wurde in Hamburg die Smogalarmstufe I mit einem achtstündigen Fahrverbot ausgerufen.
In der DDR war der Raum Leipzig mit seinen Braunkohlekraftwerken und seiner veralteten chemischen Großindustrie stark smoggefährdet.[7][8][9]
Hier wurde am 1. Dezember 1989 der erste Smogalarm der DDR ausgerufen (Stufe zwei) und infolgedessen ein Fußballspiel zwischen den 1. FC Lokomotive Leipzig und Dynamo Dresden abgesagt.[10]
Zum letzten Mal wurden die Messwerte für eine Auslösung der Smog-Vorwarnstufe im Januar 1991 in Berlin erreicht. Durch bessere Filtertechnik in Kraftwerken, umfassende Einführung der Katalysatortechnik bei Kraftfahrzeugen und den Wegfall der alten DDR-Industrie hat sich die Luftqualität in Deutschland insgesamt so stark gebessert, dass alle Bundesländer in den 1990er-Jahren ihre Smog-Verordnungen abgeschafft haben.

[Bearbeiten | Quelltext bearbeiten]
Im Dezember 1952 wurde die Stadt London von einer schweren Smog-Katastrophe heimgesucht, die bis zu 12.000 Einwohner das Leben kostete, weshalb dieses Ereignis auch den Namen The Great Smog trägt. Die britische Regierung weigerte sich, den Rauch durch die intensive Nutzung von Kohle als Energielieferant als Ursache der Tode anzuerkennen und schob zunächst eine Grippeepidemie vor. Im Nachgang dieser Katastrophe wurde der Clean Air Act verabschiedet, ein Bündel von Maßnahmen, um die Luftqualität in der Metropole nachhaltig zu verbessern. Seither gibt es diese Art von Wintersmog in London kaum mehr.
In Paris wurde im März 2014 – zum ersten Mal seit 1997 – ein partielles Fahrverbot wegen Wintersmog verhängt. Dieses endete am 17. März 2014. Von diesem Wintersmog waren etwa 30 Départements betroffen.[11]
In Peking leiden die Menschen bei bestimmten Witterungslagen an Smog. Im Dezember 2015 wurden rund 1000 Fabriken vorübergehend geschlossen, um die Luftbelastung mit Schadstoffen für die Bevölkerung zu minimieren.[12] Im November 2017 wurden zur Vorbeugung weiterer schwerer Smogperioden eine Reihe von Notmaßnahmen vereinbart. Unter anderem wurden tausende Fabriken und Baustellen von Mitte November 2017 bis Mitte März 2018 geschlossen, ein partieller Baustopp für Kohlekraftwerke verhängt, in Peking die Nutzung von Kohle für den Hausbrand untersagt und angekündigt, Zehntausende kleinerer Hochöfen zu schließen. Zudem dürfen nur noch LKWs durch Tianjin und Peking fahren, die die Abgasnormen erfüllen. 2012 lagen die Feinstaubwerte teils bei 1000 mg/m³ Luft; der internationale Grenzwert liegt bei 30 mg/m³. 2015 starben in China etwa 1,8 Millionen Menschen an Luftverschmutzung.[13]
Im November 2017 kam es in Delhi ebenfalls zu starkem Smog. Die Grenzwerte wurden teils um das Zehnfache überschritten. Unter anderem stellte United Airlines die Flüge in die Stadt ein, da die Flugsicherheit nicht mehr gegeben sei. Zudem forderte die indische Menschenrechtskommission die Politik auf, den Smog zu bekämpfen. Der Staat könne „seine Bürger nicht in diesem Giftnebel sterben lassen.“[13]
Starke Smog-Belastung herrscht ebenfalls in Polen, wo sich laut Angaben der Weltgesundheitsorganisation 33 der 50 EU-Städte mit der höchsten Luftbelastung befinden. Gerade in Südpolen werden zum Teil Werte gemessen, die Werte mancher chinesischer Städte übersteigen. Eine große Rolle spielt der Umstand, dass in Polen viele Privathaushalte mit Kohle und zum Teil auch Abfall heizen und die Häuser schlecht gedämmt sind, was zu einem sehr hohen Heizenergiebedarf führt.[14]
Städte des Balkans, wie Sarajevo, Pristina, Belgrad und Skopje, sind ebenfalls betroffen.[15] In der EU ist besonders die Po-Ebene in Italien stark belastet.[16]



→ Hauptartikel: Sommersmog
[Bearbeiten | Quelltext bearbeiten]
Die andere, heute häufigere Smog-Art, ist der Photosmog (auch Sommersmog, Ozon-Smog oder LA-Smog genannt). Es handelt sich um oxidierenden Smog.
Er tritt in den wärmeren Monaten des Jahres auf, wenn die einfallende UV-Strahlung in Verbindung mit

Stickoxiden (NOx) aus beispielsweise Autoabgasen oder Kraftwerken,
Wasserstoffperoxid,
Kohlenmonoxid und
flüchtigen organischen Verbindungen (VOC)
zu erhöhten Konzentrationen an Photooxidantien (Ozon, Peroxyacetylnitrat, Aldehyden, HNO3) führt.
Zur Bildung hoher Ozonkonzentrationen müssen folgende Voraussetzungen erfüllt sein: Das Vorhandensein der beiden Vorläuferstoffe NOx und (NM)VOC, intensive Sonnenstrahlung und eine mehrere Tage andauernde stabile Schönwetterperiode, die zu einer Speicherung von Ozon innerhalb der atmosphärischen Mischungsschichten führt.

[Bearbeiten | Quelltext bearbeiten]
In mehreren europäischen Ländern (etwa in Frankreich, Luxemburg und der Schweiz) existieren Gesetze, die beim Überschreiten bestimmter Ozonkonzentrationen niedrigere Geschwindigkeitsbeschränkungen oder sogar Fahrverbote vorschreiben. In Deutschland liegt dies in der Verantwortung der Länder. Ein bundeseinheitliches Sommersmoggesetz war von 1995 bis 1999 gültig.
In Deutschland wurde zum ersten Mal am 26. Juli 1994 für das Bundesland Hessen ein solcher Ozonalarm ausgelöst, da die Konzentration von 180 Mikrogramm pro Kubikmeter überschritten worden war, es galt drei Tage lang Tempo 90 auf Autobahnen und Tempo 80 auf Landstraßen.[17][18]



Als Haze (englisch für ‚Dunst‘, ‚Dunstglocke‘) wird eine Form von Smog bezeichnet, die infolge unkontrollierter Brände, Brandrodungen oder Naturkatastrophen entsteht.[19] Insbesondere wird die Bezeichnung im Zusammenhang mit immer wieder auftretenden Luftverunreinigungen in Südostasien verwendet, die in Malaysia, Singapur, Südthailand oder Indonesien auftreten. Hintergrund sind meist Brandrodungen auf Sumatra und dem indonesischen Teil von Borneo zur Erweiterung von Ölpalm-Plantagen.[20]
Die Schadstoffwerte in der Luft schwanken je nach Wetterlage und Ort. Bei stark erhöhten Schadstoffwerten können Augen und Atemwege gereizt werden. Insbesondere gefährdete Personengruppen wie Senioren und kleine Kinder sollten dann körperliche Anstrengungen im Freien vermeiden. Asthmatiker und Allergiker halten sich am besten in geschlossenen Räumen auf.[21]
Nachdem 1997 durch Brände auf mehr als neun Millionen Hektar Land Hazes in Brunei, Indonesien, Malaysia, den Philippinen, Singapur und Thailand auftraten, initiierten die ASEAN-Staaten ein Programm zur Beobachtung und Verhinderung von Hazes, das 2002 in dem Umweltabkommen ASEAN Agreement on Transboundary Haze Pollution mündete.[22]
2006 und 2015 traten in Südostasien zwei weitere schwere Hazefälle auf. Bei massiven Waldbränden in Indonesien kam es im September und Oktober 2015 zu einer schweren Smogkrise, die in Südostasien etwa 100.000 Menschenleben durch Luftverschmutzung forderte.[23]


Laut Modellrechnungen könnte China die Produktion von Solarstrom mit einer vehementen Bekämpfung von Smog vor Ort massiv erhöhen. Dem Modell zufolge würde sich die Sonneneinstrahlung durch strenge Luftreinhaltemaßnahmen im landesweiten Durchschnitt um 11 Prozent verstärken.[24][25]





Dieser Artikel oder nachfolgende Abschnitt ist nicht hinreichend mit Belegen (beispielsweise Einzelnachweisen) ausgestattet. Angaben ohne ausreichenden Beleg könnten demnächst entfernt werden. Bitte hilf Wikipedia, indem du die Angaben recherchierst und gute Belege einfügst.




Dieser Artikel oder Absatz stellt die Situation in Deutschland dar. Bitte hilf uns dabei, die Situation in anderen Staaten zu schildern.

Nach dem Wegfall der Smog-Verordnungen aus den 1980er-Jahren treten inzwischen andere Formen der Luftverunreinigung in den Vordergrund bei den gesetzlichen Regelungen. Die EU-Grenzwerte für Dieselruß und andere Staubteilchen wurden in Deutschland 1993 durch die 22. BImSchV umgesetzt. Diese Regelungen wurden im Laufe der Jahre – zuletzt durch die 39. BImSchV – erweitert und verschärft. Bei starker Luftverschmutzung können deshalb Fahrverbote angeordnet werden. In Deutschland ist außerdem im Gespräch, den Schadstoffausstoß von PKW und LKW durch neue Tempo-30-Zonen zu senken, obwohl dies möglicherweise die Emissionen auch steigern könnte, da die wenigsten Autofahrer früh in den höheren Gang schalten und viele dann nur noch maximal den 3. Gang für die Stadt benutzen könnten. Nach Einführung der LKW-Maut ist in Deutschland auch eine Innenstadtmaut angesprochen worden.
Anfang 2005 klagten zahlreiche Anwohner von Hauptverkehrsstraßen erfolgreich bei Verwaltungsgerichten auf Durchsetzung der EU-Richtlinie. Die betroffenen Kommunen erarbeiten daher Maßnahmen, um partikelemittierende Fahrzeuge (ältere Dieselfahrzeuge) aus feinstaubbelasteten Zonen herauszuhalten. Als wahrscheinlichste Regelung wird ein generelles Fahrverbot für Dieselfahrzeuge ohne Rußfilter u. a. in den Innenstädten von München, Stuttgart und Frankfurt erwartet. Kritiker befürchten Versorgungsprobleme bzw. massive Preissteigerungen des Einzelhandels in den Innenstädten, da diese meist über ältere Transportfahrzeuge verfügen, deren Nachrüstung unverhältnismäßig teuer wäre. Zudem sind ältere Dieselfahrzeuge noch immer nicht zweifelsfrei als Hauptverursacher der erhöhten Feinstaubwerte identifiziert. So wurden überhöhte Feinstaubkonzentrationen auch aus ländlichen Gebieten gemeldet.


Aerosol
Trübung der Atmosphäre

E. Meyer: Schwefeldioxid-Emission und Smog-Bildung. In: Chemie Ingenieur Technik, 1969, 41, 1056–1059; doi:10.1002/cite.330411905.
I. Barnes, K.-H. Becker, P. Wiesen: Organische Verbindungen und der Photosmog. In: Chemie in unserer Zeit, 2007, 41, 200–210; doi:10.1002/ciuz.200700415.









Heuschreckenplage ist eine Weiterleitung auf diesen Artikel. Zur biblischen Erzählung siehe Zehn Plagen, zur Heuschreckenplage 2019/2020 am Horn von Afrika siehe Heuschreckenplage 2019/2020.




Als Wanderheuschrecken bezeichnet man Arten aus der Familie der Feldheuschrecken (Acrididae), die in zwei in Aussehen und Körperbau (morphologisch) und im Verhalten unterschiedlichen Formen (Morphen) auftreten, einer „solitären“ Form, die wie die meisten Heuschrecken einzeln lebt, und einer „gregären“ Form (oder auch Wanderform), deren Individuen sich zu großen Schwärmen zusammenschließen, die ihren ursprünglichen Lebensraum gemeinsam verlassen. Diese können bei Massenauftreten ganze Landstriche verwüsten. Etliche afrikanische Staaten werden regelmäßig von Heuschreckenschwärmen heimgesucht. Ein einziger Heuschreckenschwarm kann aus mehr als einer Milliarde Tiere bestehen, das entspricht einem Gewicht von 1.500 Tonnen. Da diese Insekten ungefähr ihr eigenes Körpergewicht an pflanzlichem Material pro Tag vertilgen, ist der wirtschaftliche Schaden für die betroffenen Länder beträchtlich.



Wanderheuschrecken (englisch migratory locust oder auch nur locust) im engeren Sinne sind nur Arten, bei denen eine solitäre und eine Wanderform klar unterschieden werden können, auch wenn es oft Übergangsformen mit intermediärer Morphologie geben kann (zur Definition vgl.[1]). Bei Arten, die in morphologisch klar unterscheidbaren Formen vorkommen, spricht man allgemein von Polymorphismus. Bei den Wanderheuschrecken sind die beiden Formen genetisch identisch, welche Form ausgebildet wird, wird ausschließlich durch Umweltreize bestimmt. Im Gegensatz zum meist genetisch determinierten Polymorphismus wird dafür heute der neu geprägte Begriff Polyphänismus bevorzugt. Schwarmbildend sind nicht ausschließlich die ausgewachsenen Heuschrecken (Adulti oder Imagines). Oft schließen sich bereits die Larvenstadien (bei Heuschrecken Nymphen genannt) zu großen, über Land wandernden Schwärmen zusammen. Wanderheuschrecken sind keine ganz eindeutig abgrenzbare Gruppe. Zum Beispiel gibt es einige Arten, die sich zu Schwärmen zusammenschließen, deren Individuen aber nicht von einzeln lebenden unterschieden werden können. Diese werden von einigen Autoren zu den Wanderheuschrecken gerechnet, von anderen nicht.
Die folgenden Arten werden zu den Wanderheuschrecken gerechnet:[1][2]
Unterfamilie Cryptanthacridinae

Schistocerca gregaria
Schistocerca picifrons. Mittelamerika und nördliches Südamerika
Schistocerca cancellata. südliches Südamerika
Schistocerca interrita. Peru
Nomadacris septemfaciata. Afrika südlich der Sahara und Madagaskar
Patanga succincta. Südasien
Austracris guttulosa. Australien. nur Adultschwärme, Phasen morphologisch nicht unterscheidbar
Anacridium melanorhodon. Sahelzone Afrikas. Phasen an der Färbung unterscheidbar, bevorzugt Akazienblätter
Unterfamilie Oedipodinae

Locusta migratoria. Europa, Afrika, Asien, Australien, Neuseeland
Locustana pardalina. südliches Afrika
Oedaleus senegalensis. Tropen der Alten Welt
Gastrimargus musicus. Australien
Pyrgodera armata. Mittelmeergebiet bis Zentralasien. bisher nur Nymphenschwärme beobachtet.
Chortoicetes terminifera. Australien. schwärmende Individuen gleich gefärbt, aber unterschiedliches Verhalten.
Austroicetes cruciata. Westaustralien.
Aiolopus simulatrix (Synonym: A. savignyi). Afrika
Ceracris kiangsu. China. monophag an Bambus-Arten
Unterfamilie Calliptaminae

Calliptamus italicus. Europa, Nordafrika, Nordasien
Unterfamilie Gomphocerinae

Dociostaurus maroccanus. Nordafrika, Mittelmeerregion bis Zentralasien
Rhammatocerus schistocercoides. Südamerika: Brasilien
Gomphocerus sibiricus (Synonym: Aeropus sibiricus). Europa, Nordasien
Unterfamilie Melanoplinae

Melanoplus spretus. Nordamerika. ausgestorben
Melanoplus sanguinipes. Nordamerika. schwärmt nur bei extremer Dichte
Melanoplus differentialis. Nordamerika. schwärmt nur bei extremer Dichte
Unterfamilie Proctolabinae

Coscineuta virens. Trinidad
Andere Arten, darunter die Ägyptische Wanderheuschrecke (Anacridium aegyptium, Heimat Mittelmeergebiet) werden aufgrund von Verwandtschaft und Aussehen manchmal angeschlossen, obwohl sie niemals Heuschreckenschwärme ausbilden.


Wanderheuschrecken kommen auf allen Kontinenten, mit Ausnahme der Antarktis, vor. Die Europäische Wanderheuschrecke (Locusta migratoria) trat über Jahrhunderte immer wieder in ganz Mitteleuropa auf. Die letzte große Heuschreckenplage trat in Mitteleuropa 1749 auf.[3] Dennoch kamen die Tiere bis ins 19. Jahrhundert hinein noch am Unterlauf der Donau und in den Wolgasteppen vor. Mittlerweile ist sie in Europa selten geworden. In Afrika treten hingegen vier Arten von Wanderheuschrecken auf: die Wüstenheuschrecke (Schistocerca gregaria), die Wanderheuschrecke, die Rote Heuschrecke (Nomadacris septemfasciata) sowie die Braune Heuschrecke (Locustana pardalina). Die in Afrika häufigste und den größten Schaden anrichtende Art ist die Wüstenheuschrecke. Ihr Vorkommen reicht von Nordafrika und Südeuropa bis in die Steppen Kasachstans und nach Indien. In Zentralasien sind, neben der Europäischen Wanderheuschrecke, die Italienische Schönschrecke und die Marokkanische Wanderheuschrecke am meisten gefürchtet.[4]
In den östlichen Teilen Australiens ist der Australian plague locust (Chortoicetes terminifera) weit verbreitet und richtet dort den größten ökonomischen Schaden an.[5]


Wanderheuschrecken kommen in zwei Formen vor, und zwar als weitgehend ortstreue, einzeln lebende Tiere (solitäre Phase) und als umherziehende Schwarmtiere (gregäre Phase). Der Übergang von der solitären zur gregären Phase wird durch das Hormon Serotonin ausgelöst, das produziert wird, wenn sich genügend solitäre Tiere treffen, insbesondere berühren. Entscheidend für die Wandelung zu Schwarmtieren ist die Menge der Artgenossen, die die Tiere sehen, riechen oder spüren, wenn sich ihre Hinterbeine berühren. Das Schwarmverhalten geht mit einer Zunahme der Serotonin-Konzentration in Teilen des Nervensystems einher.[6]
Die beiden Phasen unterscheiden sich sowohl im Verhalten und in der Färbung als auch morphologisch (z. B. Verhältnis Flügellänge zu Länge des Sprungbeins). Die morphologischen Unterschiede zwischen den solitär lebenden und den schwärmenden Heuschrecken sind so groß, dass sie bis in die 1920er Jahre unterschiedlichen Arten zugeordnet wurden. Solitäre Heuschrecken haben im Gegensatz zu gregären eine größere Vermehrungsfähigkeit, leben unauffällig in meist abgelegenen Gebieten und sind nicht von wirtschaftlicher Bedeutung; gregäre dagegen halten sich in Gruppen auf, weisen ein charakteristisches Nachahmungsverhalten und eine synchrone Entwicklung auf und wandern schließlich aus ihren Rückzugsgebieten gemeinsam aus.


Im Gegensatz zu anderen Heuschreckenarten legen die Weibchen der Afrikanischen Wüstenheuschrecke nicht einmal, sondern mehrmals im Jahr ihre Eier. Die Embryonalentwicklung dauert bei einer Temperatur von 36 °C etwa 20 Tage. Der Schlupf der Tiere erfolgt nur bei sehr hoher Luftfeuchtigkeit, im Allgemeinen also während oder nach einem Regen. Nach dem Schlupf durchlaufen die zu den hemimetabolen Insekten zählenden Heuschrecken fünf Larven- und Nymphenstadien, von denen jedes durch eine Häutung abgeschlossen wird. Während das erste Stadium (wurmförmige Larve) fünf Tage in Anspruch nimmt, dauern alle weiteren etwa sechs Tage. Nach der letzten Häutung benötigen die Heuschrecken noch etwa 16 bis 18 Tage zur Geschlechtsreife.
Die in der solitären Phase einzeln lebenden Tiere sind an das trockene Klima von Halbwüsten angepasst. Begünstigen die ökologischen Bedingungen wie hohe Temperatur, lockere Bodenbeschaffenheit und Regen die Eientwicklung und übersteigt die Populationsdichte – also die Individuenzahl pro Fläche – ein bestimmtes Maß, werden Nachkommen hervorgebracht, die sich von der Ausgangspopulation sowohl äußerlich als auch im Verhalten unterscheiden. Nach wenigen Generationen hat sich so die typische Wanderform gebildet (gregäre Phase), deren Individuen größer und dunkler sind und über größere Flügel verfügen. Bei der Afrikanischen Wüstenheuschrecke liegt die Vorzugstemperatur für den Übergang von einer Phase zur anderen zwischen 20 und 30 °C. Massenwanderungen als Ausdruck höchster Aktivität finden nur zwischen 27 und 40 °C statt. Das Schwarmverhalten wird neuester Forschung zufolge ausgelöst, wenn die Tiere häufig Berührungsreize von Artgenossen an ihren Hinterfüßen empfangen, wenn sie also in dichter Menge umherlaufen. Die Umwandlung selbst von einer Phase zur anderen wird wahrscheinlich durch ein oder mehrere Gregarisierungspheromone gesteuert.
Bei Heuschrecken geht man aufgrund von Verhaltensversuchen von folgenden Pheromontypen aus:

Gregarisierungspheromone, die den Übergang von der solitären zur gregären Phase bewirken
Solitarisierungspheromone, die den Übergang von der gregären zur solitären Phase bewirken
Reifungspheromone, die die rasche Reifung der Tiere bewirken
von Männchen produzierte Pheromone, die die Eiablage stimulieren
Sexualpheromone
Aggregationspheromone, die das „Zusammenrotten“ der Heuschrecken unterstützen.


[Bearbeiten | Quelltext bearbeiten]


In Schwärmen auftretende Wanderheuschrecken können große Teile landwirtschaftlich angebauter Pflanzen vernichten. Schon in vorgeschichtlicher Zeit wurden menschliche Siedlungen von gefräßigen Schwärmen der Wanderheuschrecken heimgesucht.
Um das Anwachsen der Heuschreckenpopulationen zu unterbinden, setzt man heute Insektizide wie Organophosphate (z. B. Malathion), Carbamate (z. B. Bendiocarb) und synthetische Pyrethroide (z. B. Deltamethrin) ein, so dass die Zahl der Larven reduziert wird. Intensiv wird auch nach biologischen Heuschreckenbekämpfungsmitteln (wie Pheromonen) geforscht. Diese lassen eine artspezifische Bekämpfung der Heuschrecken zu, schädigen nicht die natürlichen Feinde der Heuschrecken und führen allenfalls zu geringen Umweltbelastungen.[7]
Ähnliche Wirkungen erzielt man mit den Inhaltsstoffen des Niembaumöls. Die wichtigsten Wirkstoffe sind Azadirachtin, Salannin, Meliantriol, Nimbin und Nimbidin. Azadirachtin ist der Hauptbestandteil des Niemöls und wird aus den gepressten Samen des Niembaumes gewonnen. Der Stoff hemmt die Larvenentwicklung, während Meliantriol die Nutzpflanzen direkt schützt und Wanderheuschrecken abschreckt. Für Menschen, Säugetiere und viele andere Insekten sind die Niemwirkstoffe dagegen relativ unschädlich.
Haben sich die Tiere bereits zu einem Schwarm zusammengeschlossen, werden handelsübliche Insektizide eingesetzt. Am wirkungsvollsten ist dies in der Morgendämmerung, wenn die Tiere noch inaktiv sind. Zu diesem Zeitpunkt kann dann per Flugzeug eine große Menge Insektizid über dem Gebiet verteilt werden, um idealerweise den ganzen Schwarm zu töten.
In China wurden um die Jahrtausendwende Enten erfolgreich gegen eine Heuschreckenplage eingesetzt.[8]

[Bearbeiten | Quelltext bearbeiten]
In der Europäischen Union ist eine Wanderheuschreckenart, die Europäische Wanderheuschrecke (Locusta migratoria), seit 12. November 2021 als Lebensmittel zugelassen.[9][10] In der Schweiz ist diese bereits seit dem 1. Mai 2017 als Lebensmittel zugelassen. Diese Heuschrecken dürfen damit unter bestimmten Voraussetzungen als ganze Tiere, zerkleinert oder gemahlen als Lebensmittel an Verbraucher abgegeben werden.[11]


Martin Battran: Wanderheuschrecken – eine ständige Bedrohung Afrikas. In: Naturwissenschaftliche Rundschau. Band 58(7), 2005, S. 357–362.
R. F. Chapman: A biology of locusts. (= The Institute of Biology's Studies in Biology, 71). E. Arnold, London 1976, ISBN 0-7131-2618-3.
V. M. Dirsh: Genus Schistocerca. (= Series Entomologica, 10). W. Junk, The Hague 1974, ISBN 90-6193-120-7.
H. Weidner: Die Wanderheuschrecken. (= Die Neue Brehm-Bücherei. Band 96). Akad. Verlagsgesellschaft Geest und Portig K.-G., Leipzig 1953 (Westarp-Wiss.-Verl.-Ges., Hohenwarsleben 2003, ISBN 3-89432-571-2).
D. H. Whitman: Grasshopper Chemical Communication. In: The biology of grasshoppers. 1990, Kap. 12, S. 357.
Hannelore Kluge: Niembaum – die Kraft der indischen Wunderpflanze. Ludwig, München 1996, ISBN 3-7787-3580-2.
Bernhard Lübbers: Die Heuschreckenplage des Jahres 1749 in Bayern und Franken. Wahrnehmungen und Bewältigungsstrategien einer frühneuzeitlichen Naturkatastrophe. In: Bayerisches Jahrbuch für Volkskunde 2018, S. 97–110, ISSN .









Die Artikel Planetare Verteidigung, Impakt und Einschlagkrater überschneiden sich thematisch. Informationen, die du hier suchst, können sich also auch in den anderen Artikeln befinden.Gerne kannst du dich an der betreffenden Redundanzdiskussion beteiligen oder direkt dabei helfen, die Artikel zusammenzuführen oder besser voneinander abzugrenzen (→ Anleitung).


Ein Impakt (Einschlag, Aufprall, von lat. impactus = eingeschlagen) oder Einschlag bezeichnet die Kollision zweier Himmelskörper mit sehr hoher Geschwindigkeit.[1] Zahlreiche Einschläge von Kleinkörpern (Meteoroide, Asteroiden und Kometen) sind auf der Erde, dem Mond und anderen Himmelskörpern belegt.[2] Auf dem Festland bildet sich ein Einschlagkrater (Impaktkrater). Die Gesteinsreste des eingeschlagenen Kleinkörpers sind die Meteorite.



Die zirka 4,6 Milliarden Jahre alte Erdgeschichte ist wesentlich durch Einwirkung von Meteoriteneinschlägen geprägt.[3] Die Entstehung der Erde und ihrer heutigen Gestalt ist ohne die anfänglichen Kollisionen mit Asteroiden jeder Größe nicht denkbar, denn diese Ereignisse sorgten nicht nur möglicherweise für die Herkunft des irdischen Wassers in Form der Ozeane, sondern könnten bis vor etwa 3,9 Milliarden Jahren – durch das hypothetische „Late Heavy Bombardement“ – auch die Bildung einer stabilen Erdkruste verhindert haben.
Ein Großteil der Materie des Sonnensystems wurde bereits in dieser Frühzeit durch die Gravitation der Erde und der anderen Planeten eingefangen. Jährlich fallen jedoch noch etwa 20.000 Meteorite zur Erde, meist ohne in der Landschaft deutliche Spuren zu hinterlassen. Die von den größten Impaktoren ausgelösten Naturkatastrophen der Vergangenheit lassen sich oft nur noch indirekt, zum Beispiel durch ein von ihnen ausgelöstes Massenaussterben oder einen globalen Klimawandel nachweisen,[4] da auf der Erde – anders als beispielsweise auf dem Mond – die Erosionswirkung von Wind und Wasser die eigentlichen Impaktkrater innerhalb geologisch kurzer Zeiträume wieder abträgt.
Eine weitere Nachweismethode besteht in der geochemischen und mineralogischen Untersuchung entsprechender Gesteinsschichten und des darin eingebundenen Meteorstaubs. Große Einschläge hinterlassen unter geeigneten Bedingungen typische Ablagerungen, die neben Seltenen Erden außerirdischen Ursprungs mit charakteristischen Isotopensignaturen (Iridium, Platin, Osmium) auch geschockte Quarzminerale oder Impaktgläser (Tektite) enthalten können. Da sich diese Minerale aufgrund der großen Energiemengen, die ein Impakt freisetzt, weiträumig über Landflächen und Ozeanböden verteilten, sind diese Spuren oftmals der einzige Hinweis auf einen stattgefundenen Einschlag, während der eigentliche Krater bereits abgetragen oder von Sedimenten bedeckt wurde.


Alle kleinen Körper, die auf dem Mond, dem Mars oder anderen (nahezu) atmosphärelosen Himmelskörpern sichtbare Spuren in Form von Kratern hinterlassen würden, verglühen wegen der Reibung mit den Teilchen der Erdatmosphäre in dieser, bevor sie die Erdoberfläche erreichen können. Größere Körper hingegen können auf die Oberfläche aufschlagen, doch würden sie mit 71 % Wahrscheinlichkeit in einen der Ozeane stürzen, die den Großteil der Erde bedecken. Da Meeresböden durch den plattentektonischen Prozess der Subduktion ständig in die Tiefen des Erdmantels „abtauchen“, andererseits an den Spreizungszonen permanent neu gebildet werden, beträgt das Durchschnittsalter der ozeanischen Kruste etwa 80 Millionen Jahre. Somit sind Einschlagskrater in den Meeren im Regelfall nur aus jüngerer erdgeschichtlicher Zeit nachweisbar.
Die Spuren der auf Festland treffenden Himmelskörper werden über kurz oder lang ebenfalls getilgt:
Krater größerer Meteoriten werden im Verlauf von wenigen Jahrzehnten bis Jahrhunderten durch Pflanzenbewuchs unkenntlich gemacht und durch atmosphärisch bedingte Verwitterung in Jahrtausenden (geologisch eine kurze Zeit) bis zur Unkenntlichkeit verformt. Im Verlauf von mehreren hundert Jahrmillionen bis Milliarden Jahren bewirken tektonische Prozesse eine Erneuerung nahezu der gesamten Erdoberfläche. Auch terrassenartige Absenkungen, wie sie in manchen Einbruchsbecken auftreten, können Impaktspuren verwischen. Allerdings konnte in den letzten Jahrzehnten eine Reihe weitgehend erodierter Impaktstrukturen mit Hilfe von Satelliten als solche identifiziert werden.
Nur die Einschlagkrater der größten und damit folgenschwersten Einschläge der letzten Jahrmillionen sind heute noch im Landschaftsbild sichtbar. Als Faustregel für das Verhältnis des Durchmessers des Einschlagkörpers zum Durchmesser des resultierenden Kraters gilt 1:20 für Steinmeteoriten und 1:40 für Eisenmeteoriten (für große bekannte Einschlagkrater siehe den Artikel über Einschlagkrater).

Wird durch einen großen Einschlag beim Impakt ausgeworfenes Material weiträumig verteilt, so kann dieses Material in der geologischen Schichtfolge der betreffenden Gebiete über sehr lange Zeiträume nachgewiesen werden. Ein bekanntes Beispiel ist der Nachweis des durch den Chicxulub-Impakt ausgeworfenen und global verteilten Materials anhand von dessen Iridium-Gehalt. Eine solche Schicht wird als Impakt-Lage bezeichnet, im Hinblick auf den Chicxulub-Einschlag, der sich vor 66 Millionen Jahren an der geologischen „Nahtstelle“ von Mesozoikum und Känozoikum beziehungsweise von Kreide und Paläogen ereignete, auch als Grenzton.

Siehe auch: Liste der Einschlagkrater der Erde


Global gefährlich sind Objekte mit einem Durchmesser von mehr als 500 m. Wissenschaftler in New Mexico (USA) zählten mehr als 1.100 Asteroiden mit einem Durchmesser von mehr als 1 km, die sich auf einer Umlaufbahn befinden, die sie der Erde gefährlich nahe bringen könnten. Einschläge von Objekten dieser Größe würden verheerende Auswirkungen haben: Vermutlich wären Milliarden von Menschen von den Primär- und Sekundärfolgen einer derartigen Katastrophe betroffen, wie Druck- und Hitzewellen, einer sich anschließenden rapiden Abkühlung infolge einer starken Trübung der Atmosphäre durch Aerosole („Impaktwinter“, vergleichbar einem nuklearen Winter), verbunden mit saurem Regen und gravierenden Ernteausfällen.[5] Ein Asteroideneinschlag in den Ozean hätte ebenfalls weitreichende Folgen,[6] vor allem durch die Entstehung eines Megatsunamis mit einer Wellenhöhe von über 100 m am Entstehungsort, der ganze Küstenlandschaften und deren Hinterland weiträumig überschwemmen würde.[7][8][9] Ein Impakt könnte auch Einfluss auf Ionosphäre und Magnetosphäre des Planeten haben.[10]
Rein statistisch gesehen muss man mit einem derartigen Einschlag alle 500.000 bis 10 Millionen Jahre rechnen.[11] Ereignisse wie der Impakt an der Kreide-Paläogen-Grenze sollen etwa alle 100 Millionen Jahre stattfinden. Der Impaktor des Chicxulub-Kraters (ein Asteroid oder Komet) wird im Durchmesser auf etwa 10 bis 15 km geschätzt.[12] Vergleichsweise kleinere Einschläge ereignen sich häufiger. So verwüstete der Einschlag im Nördlinger Ries (mit einem Impaktor-Durchmesser von etwa 1,5 km), eventuell begleitet von einem zweiten Einschlag im Steinheimer Becken, vor etwa 14,6 Millionen Jahren weite Teile Europas.[13] Mitunter kam es in der Erdgeschichte zu einer Häufung von großen Impaktereignissen innerhalb weniger Jahrmillionen, wie im Oberdevon mit dem australischen Woodleigh-Krater, dem Alamo-Einschlag im heutigen Nevada und der schwedischen Siljan-Impaktstruktur.
Aber auch kleinere Meteoriten können lokal oder regional immensen Schaden anrichten.[14] So sollen nach historischen Berichten im Jahr 1490 in China bei einem Meteoriteneinschlag mehr als 10.000 Menschen getötet worden sein.[15] Auch das Tunguska-Ereignis, das 1908 eine Fläche von etwa 2.000 km² in Sibirien verwüstete, wird häufig einem Meteoriten zugeschrieben, der in der Atmosphäre explodierte. Ferner wird auf der Grundlage einer kontrovers diskutierten Hypothese vermutet, dass die prähistorische nordamerikanische Clovis-Kultur infolge der Detonation eines Himmelskörpers unmittelbar vor dem Kälterückfall der Jüngeren Dryaszeit (vor etwa 12.800 Jahren) vernichtet wurde.[16][17]


Impaktereignisse können zu Massenaussterben führen. Der Mensch ist zwar Verursacher des gegenwärtigen Massenaussterbens, andererseits jedoch hat die Evolution mit ihm eine Art hervorgebracht, die das Potential hat, in absehbarer Zeit Bedrohungen wie Impaktereignisse abzuwehren, die ihrerseits Massenaussterben verursachen können. So wurden bereits entsprechende Forschungsprogramme gestartet.
Michael Schmidt-Salomon ist sich im Klaren, dass es merkwürdig, ja geradezu verrückt anmutet, die Menschheit, die bereits große Schäden anrichtete, nicht als Zerstörer, sondern als Retter der Artenvielfalt zu präsentieren. Es gäbe aber plausible Argumente, die Grund zur Hoffnung geben, dass die Menschheit die ökologischen Probleme besser in den Griff bekommen kann. Er meint, analog zu biologischen Selektionsprozessen fände ein ähnlicher auf kosmischer Ebene statt, und dass nur solche Planeten langfristig höhere Lebensformen erhalten, die Spezies hervorbringen, die die Artenvielfalt gegenüber äußeren Bedrohungen schützen können.[18]


[Bearbeiten | Quelltext bearbeiten]
Die US-Raumfahrtbehörde NASA ließ im Sommer 2007 verlauten, dass man mit einer speziellen Raumsonde Asteroiden aus ihrer Bahn lenken könnte. Diese Sonde würde ein großes Sonnensegel mit sich führen, das Sonnenstrahlung auf einen kleinen Bereich des Asteroiden konzentrieren würde.[19] Durch die dadurch erzeugte Wärme würde Materie des Asteroiden verdampfen und einen Rückstoß bewirken, der den Asteroiden von seiner Bahn ablenken würde. Die NASA schätzt, dass diese Methode für Asteroiden bis 500 m Durchmesser geeignet ist.

[Bearbeiten | Quelltext bearbeiten]
Die genaueste Methode zur Ablenkung eines Asteroiden ist der Einsatz der Schwerkraft. Es reicht, einen 20 Tonnen schweren Satelliten ein Jahr lang in 150 m Abstand zum Mittelpunkt eines Asteroiden über diesem schweben zu lassen, um den Asteroiden ausreichend abzulenken und dadurch die Erde vor einem 20 Jahre später drohenden Einschlag zu schützen.[20] Ohne Raketenantrieb würde der Satellit, der über dem Asteroiden schwebt, binnen kurzem auf diesem abstürzen. Es ist daher ein geringer kontinuierlicher Antrieb nötig, um den Satelliten in der Schwebe zu halten. Da der Satellit den Asteroiden genauso stark anzieht, wie der Asteroid den Satelliten, zieht der Satellit den Asteroid entsprechend (extrem langsam, aber zur Ablenkung binnen Jahrzehnten ausreichend) hinter sich her. Solche Antriebe sind als Ionenantrieb kommerziell verfügbar, sie lassen sich über Solarpanele oder Kernreaktoren mit elektrischer Energie speisen.
Aufgrund der exakten Kontrollierbarkeit des Satellitenantriebs und der präzise bekannten Wirkung der Schwerkraft ist dieses Ablenkverfahren das genaueste.

[Bearbeiten | Quelltext bearbeiten]
Die ESA arbeitet an einem Abwehrprojekt namens „Don Quijote“. Die zwei Sonden „Sancho“ und „Hidalgo“ könnten zum Asteroiden fliegen, wo ihn „Hidalgo“ als vier Tonnen schwerer Impaktor rammen würde, während „Sancho“ im Orbit des Asteroiden Daten über seine Geschwindigkeit, Zusammensetzung und Erfolg von „Hidalgo“ sammelt. Auch wenn vier Tonnen im Vergleich zu einem Asteroiden wenig erscheinen, können bereits wenige Bogensekunden ausreichen, um den Asteroiden von seinem Kollisionskurs abzubringen. Nach Angaben der ESA ist diese Methode für Objekte bis 1 km Durchmesser wirkungsvoll und die Mission würde gestartet werden, falls die Einschlagswahrscheinlichkeit eines Asteroiden wie Apophis über 1 % steigt.
Zur Abwehr von Apophis erwägen Wissenschaftler der Tsinghua-Universität, eine solargetriebene Sonde auf Kollisionskurs zu steuern.[21]
Im Januar 2012 wurde das internationale Forschungsprojekt „NEOShield“ gegründet, welches sich ebenfalls mit Möglichkeiten zur planetaren Verteidigung auseinandersetzt. Am 22. Mai 2013 wurde das Europäische Warnsystem für gefährliche Asteroiden eröffnet.[22]

[Bearbeiten | Quelltext bearbeiten]
In Filmen wie Deep Impact und Armageddon landen Raumschiffe auf der Oberfläche der Impaktkörper, um sie mithilfe von Nuklearwaffen zu sprengen. Bei Objekten mit mehreren hundert Kilometern Durchmesser, wie in letztgenanntem Film gezeigt, wäre eine Atombombe bei Weitem nicht stark genug, um überhaupt eine Wirkung zu erzielen.[23] Zudem gelten alle Asteroiden dieser Größenordnung als vollständig bekannt und besitzen alle stabile Umlaufbahnen, auch insofern ist das in Armageddon dargestellte Szenario also unrealistisch. Die Wirkung eines realistischen Einsatzes auf ein erdbahnkreuzendes Objekt mit Durchmessern von weniger als einigen Kilometern wurde bislang nicht genauer untersucht.

[Bearbeiten | Quelltext bearbeiten]
Um die Erde zu schützen, müsste der Körper nicht nur vollständig gesprengt werden, sondern der Großteil der Masse des ursprünglichen Körpers ausreichend stark beschleunigt werden, dass er die Erde verfehlt. Dann ist es aber einfacher, auf die Sprengung zu verzichten und den Asteroiden als Ganzes mit einer Sprengung so abzulenken, dass er die Erde verfehlt. Hierfür wird die Explosion einer Nuklearwaffe in relativ geringer Entfernung zum Asteroiden als praktikabel erachtet. Die bei der Explosion freigesetzte Strahlung würde schlagartig Materie von der Oberfläche des Körpers verdampfen, aus der sich dann ein Feuerball bildet. Der sich im heißen Gas aufbauende Druck würde den Asteroiden dann in Richtung der von der Explosion abgewandten Seite beschleunigen.
Aufgrund zahlreicher Unsicherheiten, etwa der genauen von der Kernwaffe freigesetzten Energiemenge, dem materialabhängigen Absorptionsverhalten der Asteroidenoberfläche und der genauen Dynamik des erzeugten Feuerballs ist die Ablenkung via Kernwaffenexplosion von allen genannten Methoden die ungenaueste. Sie ist aber auch die stärkste und könnte die einzig nutzbare Methode sein, wenn ein Asteroid auf Einschlagskurs zu spät entdeckt wird, um noch die anderen Methoden zu nutzen.


Durchschlagskraft von Meteoriten, Geschossen und anderen Impaktoren nach Newton
Global Killer
Datenbanken irdischer Impaktstrukturen
Asteroid#Einschlagwahrscheinlichkeit und -wirkung
Asteroid Day
Erdnahes Objekt
Impaktmetamorphose
Regentropfeneinschlagkrater

Christian Koeberl: Katastrophen aus dem All – Impaktereignisse in der Erdgeschichte. in: Thomas Myrach: Science & Fiction – Imagination und Realität des Weltraums. Haupt Verlag, Bern 2009, ISBN 978-3-258-07560-0, S. 91–132.
Vitaly Adushkin: Catastrophic events caused by cosmic objects. Springer, Dordrecht 2007, ISBN 978-1-4020-6451-7.
Charles Cockell: Biological processes associated with impact events. Springer, Berlin 2006, ISBN 3-540-25735-7.
Christian Köberl: Impact tectonics. Springer, Berlin 2005, ISBN 3-540-24181-7.
Peter T. Bobrowsky, Hans Rickman: Comet/Asteroid Impacts and Human Society – An Interdisciplinary Approach. Berlin 2007, ISBN 978-3-540-32709-7.
Bevan M. French: Traces of Catastrophe – A Handbook of Shock-Metamorphic Effects in Terrestrial Meteorite Impact Structures. Hrsg.: Lunar and Planetary Inst. Houston 1998 ( [PDF; 20,0 MB; abgerufen am 1. Mai 2009]). 


 (englisch)
 (englisch)
 (mehrsprachig)
Mineralienatlas:Impakt – Geologie, Auswirkungen, bekannte Krater etc.
Bericht der NASA an den US-Kongress:  (PDF; 790 kB)
Vorlage:Toter Link/impact.arc.nasa.gov (Seite nicht mehr abrufbar. .)
International Academy of Astronautics:  (abgerufen am 18. Mai 2021)




Der Sonnenwind ist ein Strom geladener Teilchen, der ständig von der Sonne in alle Richtungen abströmt – etwa 1 Million Tonnen pro Sekunde. Im Vergleich zum Sternwind anderer Fixsterne ist er jedoch schwach und muss bei der Ursonne stärker gewesen sein.[1]
Der Sonnenwind ist ein Hauptbestandteil des interplanetaren Mediums und tritt als ein niederenergetischer Bestandteil der kosmischen Strahlung in Erscheinung. Er ist anders als die Sonnenstrahlung keine elektromagnetische Strahlung, sondern ein Teilchenstrom aus Protonen und Elektronen. Gelegentlich wird auch der falsche Begriff Sonnenstaub (analog zu Sternenstaub) verwendet, was insbesondere bei der Berichterstattung der Presse zur Genesis-Sonde der Fall war. Geschwindigkeit und Dichte des Sonnenwindes sind sehr variabel. Er setzt sich aus sehr verschiedenen Arten von Teilchenströmen zusammen. Seine extreme Form sind koronale Massenauswürfe (CME), die auch auf der Erde massive Folgen hervorrufen können.



Der Sonnenwind besteht hauptsächlich aus ionisiertem Wasserstoff (Protonen und Elektronen) sowie aus 8 % Helium-4-Atomkernen (Alphateilchen). Daneben enthält er Spuren von ionisierten Atomkernen der Elemente Kohlenstoff, Stickstoff, Sauerstoff, Neon, Magnesium, Silizium, Schwefel und Eisen.[2] Nichtionisierte (elektrisch neutrale) Atome sind kaum enthalten. Der Sonnenwind stellt ein sogenanntes Plasma dar, das elektrisch hoch leitfähig ist.[3] Allerdings hat der interplanetare Raum wegen der geringen Teilchendichte nur eine sehr geringe  Ladungsträgerdichte.[4]
Man unterscheidet den langsamen und den schnellen Sonnenwind. Diese beiden unterscheiden sich nicht nur durch ihre Geschwindigkeit, sondern auch durch ihre chemische Zusammensetzung,[5] ihre Temperatur und ihr Strömungsverhalten. Obwohl er aus den äußeren Schichten der Sonne stammt, spiegelt der Sonnenwind die Elementhäufigkeit dieser Schichten nicht exakt wider. Denn durch Fraktionierungsprozesse (FIP-Effekt) werden manche Elemente im Sonnenwind angereichert beziehungsweise verdünnt. Im Inneren der Sonne wurden seit ihrer Entstehung die Elementhäufigkeiten durch die dort ablaufende Kernfusion geändert; da aber die äußeren Sonnenschichten nicht mit den inneren gemischt sind, entspricht deren Zusammensetzung noch jener des Urnebels, aus dem sich das Sonnensystem gebildet hat.[6] Die Erforschung des Sonnenwindes ist deshalb auch interessant, um sowohl auf die chemische Zusammensetzung als auch auf die Isotopenhäufigkeiten des Urnebels schließen zu können.
Die Sonne verliert durch den Sonnenwind pro Sekunde etwa eine Million Tonnen ihrer Masse mit nur geringer zeitlicher Variation.[7][8]
Außerhalb der Beschleunigungszone von 10 bis 20 Sonnenradien ändert sich die Geschwindigkeit des Sonnenwindes kaum noch,[9] sodass seine Dichte mit dem Quadrat der Entfernung abnimmt. In Erdnähe hat der Sonnenwind eine Dichte von ungefähr 5 · 106 Teilchen pro Kubikmeter.




Das Plasma der unteren Sonnenkorona wird mit der Rotation der Sonne mitgedreht. Ab einem gewissen Abstand, etwa 2,5 Sonnenradien (~2,5 · R☉[10]) wächst der thermische Druck über den magnetischen hinaus und das Plasma strömt ab diesem Punkt radial von der Sonne fort. Es werden zwei Arten des Sonnenwinds unterschieden, der langsame und der schnelle.
Der langsame Sonnenwind hat eine Zusammensetzung ähnlich der Sonnenkorona. Während er von der Sonne abströmt, verdoppelt er seine Geschwindigkeit von 150 km/s im Abstand von 5 · R☉ auf 300 km/s im Abstand 25 · R☉. Sein Ursprung ist noch nicht abschließend geklärt. Man nimmt an, dass beobachtete tropfenartige Plasma-Ablösungen von Helmet Streamern zum langsamen Sonnenwind beitragen. Der Hauptanteil des langsamen Sonnenwinds dürfte jedoch aus Regionen außerhalb der Helmet Streamer stammen, wahrscheinlich aus den inneren Begrenzungsrändern von koronalen Löchern.[11] Er beschleunigt während seines Fortströmens von der Sonne weiter und strömt nach Messungen von Sonden wie Ulysses in einem bestimmten Abstand zur Sonne vor allem nahe deren Äquatorebene, zwischen etwa 20° Nord und 20° Süd. Er benötigt 5 oder mehr Tage,[12] nach anderen Angaben etwa 20 Tage,[13] um die Region der Erde zu erreichen. In Erdbahnnähe hat er eine Geschwindigkeit von etwa 300 bis 500 km/s und eine Temperatur im Bereich von etwa 1,4 · 106 K bis 1,6 · 106 K.[14] Die Plasmaschallgeschwindigkeit beträgt in Erdbahnnähe etwa 50 km/s, der Sonnenwind ist also deutlich überschallschnell.[15]
Der schnelle Sonnenwind hat eine Zusammensetzung ähnlich der Photosphäre der Sonne. Er tritt aus dem Inneren von koronalen Löchern (also vorwiegend, insbesondere zu Zeiten des Sonnenfleckenminimums, in der Nähe der Sonnenpole) aus, wird zwischen 1,5 · R☉ und 2,5 · R☉ auffallend stark beschleunigt und besitzt in der Bereichsmitte, also bei 2 · R☉, eine Geschwindigkeit von 300 km/s. Dabei sind die Sauerstoffionen erheblich schneller als die leichteren Protonen. Die Messungen durch das Ultraviolet Coronal Spectrometer (UVCS) des Forschungssatelliten Solar and Heliospheric Observatory (SOHO) ergaben, dass der schnelle Sonnenwind über den Polen der Sonne erheblich schneller beschleunigt wird, als durch die Thermodynamik erklärt werden kann.[16] Diese Theorie sagt voraus, dass die Schallgeschwindigkeit etwa vier Sonnenradien über der Photosphäre überschritten werden sollte. Tatsächlich findet man diese Grenze bereits in etwa 25 % dieser Distanz. Als Ursache dieser Beschleunigung werden Alfvén-Wellen angesehen. Der schnelle Sonnenwind beschleunigt weiter bis etwa 10 bis 20 Sonnenradien Distanz, ab dann strömt er mit ungefähr konstanter Überschallgeschwindigkeit fort. Der schnelle Sonnenwind benötigt etwa 2 bis 4 Tage, um die Region der Erde zu erreichen.[17] In Erdbahnnähe hat er eine Geschwindigkeit von etwa 750 km/s und eine Temperatur von etwa 8 · 105 K.[18]
Der Sonnenwind strömt radial von der Sonne fort. Aufgrund der Sonnenrotation – eine Umdrehung in etwa 27 Tagen, bezogen auf die Erde – bildet er jedoch dabei spiralig gekrümmte Kurven, ähnlich dem Wasserstrahl eines Sprinklers.[19] Der schnelle Sonnenwind formt dabei steilere Spirallinien als der langsame Sonnenwind (siehe nebenstehende Abbildung). Hierdurch entstehen an den Kreuzungspunkten Druckwellen, bestehend aus einem vorwärts und einem rückwärts gerichteten Wellenpaar. Diese werden co-rotating interaction regions (CIRs) genannt. Mit den Voyager-Sonden wurde entdeckt, dass Gruppen dieser CIRs ihrerseits miteinander verschmelzen können, wodurch merged interaction regions (MIRs) entstehen. Diese Interaktionen geschehen typischerweise bis etwa 10 AE. Jenseits davon bestehen komplexe Strukturen, so dass der Sonnenwind auch in großer Entfernung kein homogener Fluss ist.[20]
Der Sonnenwind strömt so lange mit Überschallgeschwindigkeit von der Sonne fort und dünnt sich dabei mit dem Quadrat der Entfernung aus, bis sein fortwährend geringer werdender Druck den Partikeln und Feldern des lokalen interstellaren Mediums nicht mehr standhalten kann. An dieser Stelle, der Randstoßwelle (termination shock), wird der Sonnenwind abrupt von ca. 350 km/s auf ca. 130 km/s, und damit auf Unterschallgeschwindigkeit, abgebremst. Dabei verdichtet er sich und heizt sich auf.[21] Die genaue Form und Größe der Randstoßwelle ist variabel, da sie von Dichteschwankungen des Sonnenwinds ebenso wie von Stärkeschwankungen des interstellaren Mediums abhängt. Die Raumsonden Voyager 1 und Voyager 2 erreichten die Randstoßwelle bei 94 AE bzw. 84 AE Entfernung.
Jenseits der Randstoßwelle befindet sich die Zone der Heliohülle (heliosheath). In dieser vermischen sich die Teilchen des abgebremsten Sonnenwinds mit denen des lokalen interstellaren Mediums. An der Heliopause schließlich sind die Sonnenwindteilchen mit dem interstellaren Medium im Gleichgewicht.




Ein deutlich sichtbares Anzeichen für die Existenz des Sonnenwinds liefern die Kometen: Durch die Wirkung des Sonnenwindes wird Material aus der Koma eines Kometen gerissen. Der bläulich leuchtende Gasschweif eines Kometen zeigt immer in gerader Linie von der Sonne weg, unabhängig von der Bewegungsrichtung des Kometen. Auch der Staubschweif eines Kometen zeigt von der Sonne weg, aber da die Staubpartikel deutlich langsamer als die Gas-Ionen sind, ist der Staubschweif wegen der Eigenbewegung des Kometen gekrümmt und sein Winkel zur Sonne ist kleiner als 180 Grad.[22]
Koronale Massenauswürfe und Sonneneruptionen führen zu enormen Stoßwellen im sonst kontinuierlichen Sonnenwind. Deren Auswirkungen im erdnahen Bereich werden als Weltraumwetter bezeichnet.
Da der Sonnenwind ein elektrisch leitendes Plasma darstellt, verformt er sowohl das Magnetfeld der Sonne als auch das der Erde. Das irdische Magnetfeld hält den Teilchenschauer zum größten Teil von der Erde ab. Bei einem starken Sonnenwind kann das Plasma das Erdmagnetfeld so stark verformen, dass durch magnetische Rekonnexion geladene Teilchen zur Erde beschleunigt werden und in den hohen Schichten der Erdatmosphäre Polarlichter hervorrufen. Hierbei handelt es sich um sogenannte sekundäre Teilchen, da diese nicht von der Sonne stammen, sondern aus der Magnetosphäre der Erde.
Starke Sonnenwinde haben auch Einfluss auf die Ausbreitung von elektromagnetischen Wellen und können unter anderem den Kurzwellenfunk und die Kommunikation mit Satelliten stören. Sonnenwinde und ihre Auswirkungen auf die Technik sind seit z. B. 1847, 1859, 1921 und 1940 bekannt, weil es zu Störungen in der Telegraphie, an Signalanlagen der Bahn, bei der Radiokommunikation und vereinzelt sogar zum explosionsartigen Durchschmoren von Transformatoren gekommen ist (zu einem Transformatorenausfall ist es z. B. am 13. März 1989 in Quebec gekommen). Es wird für möglich gehalten, dass besonders starke Sonnenwinde zu einem globalen Totalausfall von Stromversorgung und Computerfunktionen führen könnten.
Innerhalb der Heliosphäre gibt es eine Schicht, in der das Magnetfeld der Sonne seine Polarität ändert. Dadurch entstehen elektrische Ströme im Sonnenwind, die von Raumsonden gemessen werden konnten. Diese Schicht ist unregelmäßig geformt und heißt Heliosphärische Stromschicht.



Bereits beim Carrington-Ereignis von 1859 beobachtete der Forscher Richard Carrington einen Zusammenhang zwischen Sonnenflares und zeitlich versetzten irdischen Magnetfeldstürmen, was – obwohl damals unerklärlich – ein frühes Indiz für die Existenz des Sonnenwindes war. Anfang des 20. Jahrhunderts vertrat der norwegische Physiker Kristian Birkeland die Auffassung, die Polarlichter würden durch Teilchenströme von der Sonne ausgelöst. Seine Idee wurde jedoch ebenso wenig ernst genommen wie die des deutschen Physikers Ludwig Biermann, der eine „Solare Teilchenstrahlung“ annahm, um die Richtung der Kometenschweife erklären zu können. Denn Astronomen ist schon lange bekannt, dass die Kometenschweife nicht exakt von der Sonne weg gerichtet waren, sondern einen kleinen Winkel dazu aufwiesen. Biermann erklärte diese Eigenschaft 1951 durch die Bewegung des Kometen in einem sich ebenfalls bewegenden Teilchenstrom, gewissermaßen ein seitliches Abdriften durch die Strömung. E. N. Parker hat 1959 die englische Bezeichnung solar wind eingeführt und eine magnetohydrodynamische Theorie zur Beschreibung des Sonnenwindes vorgeschlagen.
Experimentell konnte die Existenz des Sonnenwinds 1959 durch die sowjetische Lunik 1 und 1962 durch die amerikanische Raumsonde Mariner 2 auf ihrem Weg zur Venus bestätigt werden. Ein weiterer Meilenstein in der Erforschung des Sonnenwindes waren die Sonnenwindsegel, die bei den Apollo-Missionen 11, 12 und 14 bis 16 aufgestellt wurden und Daten über die Isotopenhäufigkeiten der Edelgase Helium, Neon und Argon im Sonnenwind lieferten. Viele weitere Missionen haben zum Verständnis des Sonnenwindes beigetragen. Die Raumsonden Pioneer 10 und 11, Voyager 1 und 2 und die Ulysses-Mission lieferten Daten des Sonnenwindes außerhalb der Erdumlaufbahn, während Helios 1/2 und die Mariner- und Pioneer-Missionen zur Venus sowie russische Vega-Sonden Daten von innerhalb der Erdumlaufbahn lieferten. IMP 1–8, AIMP 1/2, ACE, ISEE 1–3 Sonden sowie das Sonnenobservatorium SOHO und die Raumsonde Wind lieferten Sonnenwinddaten in Erdnähe. Die Ulysses-Mission lieferte auch Daten über den Sonnenwind außerhalb der Ekliptik. Im Jahr 2001 wurde die Genesis-Mission gestartet, bei der hochreine Kristalle in einem der Lagrange-Punkte (L1) des Erde-Sonne-Systems dem Sonnenwind ausgesetzt wurden und danach zur Untersuchung zur Erde zurückgebracht werden sollten. Die Mission schlug bei ihrem Abschluss im Jahr 2004 fehl, weil die Kapsel mit den Sonnenwindteilchen nicht abgebremst wurde, sondern auf dem Erdboden zerschellte. Voyager 1 erreichte im Dezember 2004 die Randstoßwelle und Voyager 2 im August 2007.
Es gibt Bemühungen, den Sonnenwind mit Hilfe von Sonnensegeln zum Antrieb von Raumfahrzeugen zu nutzen.


Magnetischer Sturm

John C. Brandt: Introduction to the solar wind. Freeman, San Francisco 1970, ISBN 0-7167-0328-9.
Syun-Ichi Akasofu: The solar wind and the earth. Terra Scientific Publ., Tokyo 1987, ISBN 90-277-2472-5.
Marco Velli: Solar wind ten. American Inst. of Physics, Melville 2003, ISBN 0-7354-0148-9, 
Nicole Meyer-Vernet: Basics of the solar wind. Cambridge Univ. Press, Cambridge 2012, ISBN 978-1-107-40745-9.



 im Katalog der Deutschen Nationalbibliothek
 aus der Fernseh-Sendereihe alpha-Centauri (ca. 15 Minuten). Erstmals ausgestrahlt am 5. Aug. 2001.

Wiener Zeitung:  (Memento vom 19. April 2005 im Internet Archive)
 (englisch)
 (englisch)
 (englisch)
 ("San Francisco Chronicle", 7. März 2006 – vgl. , )

Naturkatastrophen in Deutschland
Extreme Naturereignisse sind dem dynamischen Planet Erde immanent und damit Bestandteil unserer Umwelt. Sie können auch in Deutschland zu enormen Schäden führen. Ob aus Naturereignissen Katastrophen werden, hängt von der Anfälligkeit und Vorsorge der Gesellschaft ab. Anzahl und Intensität solcher Extremereignisse sind starken Schwankungen unterworfen. Aufgrund der treibhausbedingten Erhöhung der sensiblen und latenten Energieanteile in der Atmosphäre ist künftig mit einer Zunahme von wetterbedingten Extremereignissen zu rechnen. Jedoch lassen vor allem zunehmende Wertekonzentration und Anfälligkeit höhere Schäden durch Naturgefahren erwarten.
Atmosphäre und Lithosphäre sind die Hauptquellen von extremen Naturereignissen. So lassen sich Stürme, Starkniederschläge, Hagelereignisse, Hitze- und Kältewellen sowie Blitzschlag den direkten atmosphärischen Auswirkungen zuschreiben. Daraus resultieren Sturmfluten an den Küsten, Sturzfluten in steilen Einzugsgebieten oder in bebauten Gebieten und Überflutungen durch Flusshochwasser. Auch Dürreperioden aufgrund lang anhaltend hoher Temperaturen mit großen Verdunstungsraten sowie Waldbrände sind indirekte atmosphärische Auswirkungen. Die Prozesse der festen Gesteinshülle bis 100 km Tiefe können Erdbeben und Vulkanausbrüche hervorrufen. Obgleich es in Deutschland momentan keine aktiven Vulkane gibt, sprechen Vulkanologen dennoch von der Möglichkeit, dass es in der Eifel wieder zu Eruptionen kommen kann. Erdrutsche, Muren und Lawinen können atmosphärisch oder lithospärisch bzw. durch eine Interaktion verschiedenerAuslöser verursacht werden. So kann eine Hangrutschung durch leichtere Erdbeben im Zusammenspiel mit atmosphärischen Vorbedingungen wie lang anhaltende Niederschläge und mächtige Schneeauflagen ausgelöst werden.
Selten bedacht und dennoch möglich sind extraterrestrisch verursachte Naturgefahren. Solare Eruptionen führen zu magnetischen Stürmen, die beispielsweise großräumige Stromausfälle infolge von Störströmen in Überlandleitungen oder Fehlfunktionen von Satelliten mit Störungen von Navigations- oder Kommunikationssystemen nach sich ziehen können. Die denkbar verheerendsten Naturkatastrophen sind Meteoriteneinschläge mit Einschlagkratern bis zu mehreren 100 km Durchmesser und globalen Auswirkungen. Außerdem ist noch der Mensch als Auslöser oder Verstärker von Katastrophen zu nennen, z. B. bei vorsätzlich gelegten Waldbränden oder bei Lawinen und Erdrutsche auf entwaldeten Flächen. Letztes vom Menschen verursachtes Ereignis war der Erdrutsch auf einer ehemaligen Abraumhalde eines Braunkohletagebaus im Sachsen-Anhaltischen Nachterstedt im Juli 2009. Erdmassen rutschten 40 m tief in einen Tagebaurestsee und rissen mehrere Gebäude mit sich. Diese Katastrophe forderte drei Todesopfer und 41 Menschen verloren ihr Obdach.
Volkswirtschaftliche Schäden durch Naturgefahren Welche volkswirtschaftliche Gesamtschäden Naturgefahren verursachen können, zeigen die letzten großen Naturkatastrophen in Deutschland – der Wintersturm Kyrill 2007 mit 4,2 Mrd. € (Münchener Rück 2008) und das Elbe-Hochwasser 2002 mit 11,8 Mrd. €. [8] Betrachtet man alle Naturereignisse im Zeitraum von 1970 bis 1998, wird deutlich, dass Sturmereignisse die teuersten Naturgefahren in Deutschland sind. Sie machen 75% des volkswirtschaftlichen Gesamtschadens aus. 19% werden durch Flussüberschwemmungen und Sturzfluten, 5% durch weitere atmosphärisch bedingte Gefahren wie Hitzewellen, Frost und Waldbrände verursacht. Erdbeben und Erdrutsche haben in diesen drei Dekaden einen geringen Anteil von 1% zum volkswirtschaftlichen Gesamtschaden beigetragen. [9] Aus diesen Zahlen lässt sich jedoch nicht schließen, dass Erdbeben und Sturmfluten vernachlässigbar sind. Überschlägige Berechnungen schätzen, dass worst-case-Ereignisse (z. B. Sturmflut im Raum Hamburg, Starkbeben bei Köln oder Frankfurt/M.) zu volkswirtschaftlichen Schäden in der Größenordnung von mehreren Zehnern Milliarden Euro führen können. So haben z. B. paläoseismologische Untersuchungen ein Erdbeben mit einer Momentenmagnitude von 6,7 in der niederrheinischen Bucht in der Nähe von Köln nachgewiesen. Ein Vergleich von Hochwasser- und Erdbebenrisiko für das Stadtgebiet Köln zeigte, dass für Extremereignisse mit kleinen Eintrittswahrscheinlichkeiten (< ca. 200-jährliches Ereignis) die Auswirkungen eines Erdbebens diejenigen eines Hochwassers übertreffen. [3]
Räumlicher und zeitlicher Wirkungsbereich von Naturgefahren Im Bild sind mögliche Naturgefahren für Deutschland mit ihren räumlichen und zeitlichen Wirkungsbereichen dargestellt. Ereignisse mit kleinem, lokal begrenztem Einflussbereich von bis zu 10 km sind vor allem konvektive Starkniederschlagsereignisse und Sturzfluten, Gewitter, Blitzschläge und Hagel. Sehr lokal wirken auch Lawinen und Erdmassentransporte wie Hangrutschungen, Muren und Bergstürze. Andere Naturgefahren können deutlich größere Gebiete betreffen. So weisen Tornados Zuglängen von bis zu 100 km auf, wohingegen die wirksame Zugbreite meist nicht größer als 500 m ist. Auch Überschwemmungen durch Sturmfluten, wie 1962 in Hamburg und Bremen, oderFlusshochwasser,wie 2002 an Elbe und Donau, sind regional oder überregional entlang von Küstenabschnitten oder Flusstälern, bis auf mehrere 100 km, wirksam. In diese Kategorie fallen auch Erdbeben, Vulkanausbrüche und magnetische Stürme. Deutschlandweit, also mit Einflussbereichen > 500 km, wirken Naturgefahren wie Winterstürme mit Windfeldbreiten bis zu 1000 km und Zuglängen bis zu 5000 km. Ebenso für die Gesamtfläche Deutschlands wirksam sind Kälte- und Hitzewellen. Aus Trockenheit und Dürre können Schäden in der Landwirtschaft ganzer Regionen, beeinträchtigte Binnenschifffahrt und Engpässe in der Stromproduktion durch unzureichende Kühlleistung der aufgewärmten Flüsse resultieren. Die Dauer von extremen Naturereignissen ist unterschiedlich. Die Zeitskala reicht von wenigen Sekunden bis zu Monaten. In den meisten Fällen gilt, dass eine längere Wirkdauer zu höheren Schäden führt. Kurze Ereignisdauern von Sekunden und Minuten haben Blitzschlag, Tornados, Massenbewegungen und Lawinen, sowie Erdbeben und Meteoriteneinschläge. Letztere haben bei extrem kurzer Wirkdauer aber eine so große Energiefreisetzung, dass sie Gebiete von der Größe Deutschlands verwüsten könnten. Davon zeugt das Nördlinger Ries auf der Schwäbischen Alb, ein Einschlagkrater mit 24 km Durchmesser, der vor ca. 14,5 Mio. Jahren entstand [9]. Hagel, Starkniederschläge, Sturzfluten, Winterstürme, Waldbrände, Überschwemmungen, Vulkanausbrüche und magnetische Stürme wirken länger, meist dauern sie Stunden bis zu wenigen Tagen. Einige Tage bis wenige Monate dauern insbesondere Kälte- und Hitzewellen. Vor allem lang anhaltend hohe Temperaturen sind eine große Belastung für das menschliche Herz-Kreislaufsystem und führen immer wieder zu zahlreichen Hitzetoten – so geschehen im Rekordsommer 2003, als von Juni bis August die mittlere Temperatur um 3,4 °C über dem klimatologischen Durchschnittswert des Zeitraums 1961–1990 lag. In Deutschland waren 9000, in ganz Europa über 70000 Todesopfer zu beklagen. Der volkswirtschaftliche Gesamtschaden wurde auf 1,3 Mrd. Euro beziffert. [7] [6] Höheres Risiko durch Naturereignisse? Die Schäden durch extreme Naturereignisse sind in den letzten Jahrzehnten global, aber auch in Deutschland dramatisch gestiegen. Zu diesem Anstieg tragen vielfältige Einflüsse bei, wie z. B. zunehmende Besiedlung von gefährdeten Bereichen, Akkumulation von Werten, veränderte Anfälligkeit durch zunehmende Vernetzung der Gesellschaft und der Klimawandel. Aufgrund der Vielfältigkeit dieser Einflüsse und der Zufälligkeit der verursachenden Naturprozesse ist es bis heute kaum möglich, die einzelnen Anteile der verschiedenen Einflüsse zu beziffern. Im Zusammenhang mit atmosphärisch bedingten Naturgefahren wird der Klimawandel häufig als der Hauptverursacher für die steigenden Schäden gesehen. Aufgrund des Anstiegs der globalen Oberflächentemperatur verändern sich Häufigkeit und Magnituden von klimatischen Extremereignissen. So nehmen Energie- und Wassergehalt derAtmosphäre zu,was auch eine Erhöhung des Potenzials für Gewitterstürme zur Folge hat. [4] Ebenso werden Winterstürme durch den Klimawandel beeinflusst. Diese haben eine große geographische Ausdehnung über ganz Europa und können hohe Schäden hervorrufen. Der Klimawandel nimmt entscheidenden Einfluss auf die Zugbahnen der Winterstürme, die sich dadurch weiter nach Norden verschieben. Dabei wird der Kerndruck dieser Luftmassen gesenkt und einzelne Ereignisse können verheerender sein als bisher. [12] Witterung und Klima lassen sich zusammenfassend durch die Charakterisierung der atmosphärischen Zirkulationsformen („Großwetterlagen“) beschreiben. In mehreren Untersuchungen wurde in den letzten Jahren die Änderung der Auftretenshäufigkeiten von Großwetterlagen untersucht. (z. B. [2], [10] und [11]) Dabei wurde für die Wintermonate eine statistisch signifikante Zunahme der zonalen Westlagenhäufigkeiten nachgewiesen. Deren Auftreten korreliert wiederum  mit großräumigen und lang andauernden Niederschlägen für bestimmte Regionen Mitteleuropas (z. B. Südwestdeutschland), so dass sich weiterhin eine Korrelationen zwischen den Zunahmen dieser Wetterlagen und gehäuften Hochwasserereignissen in den Wintermonaten ableiten lassen. Für Nordostdeutschland sind diese Westwetterlagen weniger relevant. Hier wurde eine erhöhte Auftretenswahrscheinlichkeit der Wetterlage „Hochdruckbrücke über Mitteleuropa (BM)“ und der TrM-Wetterlage (TrM: Trog über Mitteleuropa) mit der sogenannten Vb-Zugbahn von Tiefdruckgebieten in den Sommermonaten anhand der langjährigen Zeitreihe von Wetterlagen seit 1881 analysiert. Erstere ist mit Trockenheiten in den Sommermonaten verbunden, wohingegen die zweite Wetterlage große Hochwasserereignisse auslösen kann. Auch für die Entstehung von Hochwassern aufgrund der Schneeschmelze können Klimaänderungen einen beträchtlichen Einfluss haben. Durch veränderte Temperaturen werden Zeitpunkt, Intensität und Abfolge von Schneeschmelzereignissen variiert. Auch kann die zeitliche Veränderung von Schneeakkumulation und Schneeschmelze in Verbindung mit einerzeitlichen Änderung des Regenverhaltens zu einer nachteiligen Überlagerung von Hochwasserereignissen aus Schneeschmelze und Starkniederschlägen und dann zu einer Zunahme des Spitzenabflusses führen. Bronstert diskutiert die Relevanz dieses hydrologisch-klimatologischen Zusammenhangs für das Rheineinzugsgebiet. Dort könnten möglicherweise zukünftig das gehäufte frühere Auftreten von Schmelzhochwassern aus dem alpinen Gebiet mit Regenhochwassern aus dem Mittelgebirge zu einem deutlich erhöhten Überflutungsrisiko am Mittel- und Niederrhein führen. Auf der anderen Seite würde ein verminderter Abfluss aus den Gletscher- und Schneegebieten im Sommer und Frühherbst Niedrigwasserereignissen wahrscheinlich werden lassen. [2] Für Deutschland wurde durch eine Analyse von Hochwasserzeitreihen von über 100 Einzugsgebieten die Veränderung der Hochwassergefährdung während der letzten fünf Dekaden untersucht. [10] [11] Es wurde gezeigt, dass die Hochwassergefährdung im Winterhalbjahr im Westen, Süden und im Zentrum Deutschlands zugenommen hat. Die Änderungen der Hochwassergefährdung im hydrologischen Sommerhalbjahr sind gering. Aufgrund der Detektion von räumlich und saisonal kohärenten Trends – über Einzugsgebietsgrenzen hinweg kann angenommen werden, dass es sich um klimabezogene Veränderungen handelt und nicht um zufällige lokale und durch anthropogene Eingriffe in den Einzugsgebieten hervorgerufene Trends. Trotz solcher ersten Hinweise auf ungünstige Einflüsse des Klimawandels auf atmosphärisch bedingte Naturereignisse sind seine Auswirkungen auf die verschiedenen Naturgefahren auf regionaler Skala noch weithin unklar. Zu den wenigen Studien, die versuchten, den Beitrag des Klimawandels auf den Anstieg von Schäden durch Naturgefahren zu quantifizieren, gehört [1]. Für den Zeitraum 1970–2006 wurde eine Zeitreihe der volkswirtschaftlichen Schäden aufgrund großer Hochwasser in 31 europäischen Ländern erstellt. Diese Zeitreihe zeigt deutlich größere Schäden in jüngerer Zeit. In einem zweiten Schritt wurde die Zeitreihe normalisiert, d. h. Effekte aufgrund Inflation, Bevölkerungswachstum und ökonomischem Wachstum wurden herausgerechnet. Diese normalisierte Zeitreihe der Hochwasserschäden zeigt keinen signifikanten Trend, d. h. der Anstieg der Hochwasserschäden der letzten Jahrzehnte in Europa lässt sich allein mittels sozio-ökonomischer Faktoren erklären. Umgang mit extremen Naturereignissen Ob sich extreme Naturereignisse zu Katastrophen ausweiten, hängt von der Vorsorge der Gesellschaft und ihrer Reaktion in Krisensituationen ab. Denn Katastrophen durch extreme Naturereignisse werden nicht durch die Natur allein bestimmt, sondern vor allem durch die Art und Weise, wie die betroffenen Menschen mit Ereignissen umgehen, die den gewöhnlichen Schwankungsbereich überschreiten. [5] Somit spielen gesellschaftliche Veränderungen eine wichtige Rolle. Die Zeitskala der erwarteten Klimaänderung ist vergleichbar mit dem Planungshorizont für neue Bauten, Infrastrukturanlagen und Raumnutzungsentscheiden. Die Berücksichtigung des Faktors WetterKlima-Naturkatastrophen als eine sich ändernde Rahmenbedingung wird für Planungsaufgaben immer wichtiger [12]. Aussagen über die zukünftige Entwicklung des Klimas und die regionalen Auswirkungen von Klimaänderungen sind mit sehr großen Unsicherheiten behaftet. Deshalb sind anpassungsfähige Lösungen gefragt, die den heutigen Bedürfnissen genügen und sich flexibel an möglicherweise deutlich andere zukünftige Anforderungen anpassen lassen. So kann ein Frühwarnsystem einfacher an neue Randbedingungen angepasst werden als etwa bauliche Schutzmaßnahmen. Eine Erhöhung des Risikobewusstseins und der Selbsthilfe der Bevölkerung ist eine sinnvolle Maßnahme zur Risikoreduzierung – unabhängig davon, ob und wie stark der Klimawandel Häufigkeit und Magnitude von Naturereignissen erhöht.

Naturkatastrophen – so verhalten Sie sich richtigNaturkatastrophen treten meist plötzlich und unvorhersehbar auf. Deswegen kann Sie ein Naturereignis auch auf einer Urlaubsreise treffen. Bei einer Reise in seismisch aktive Gebiete oder Länder, die regelmäßig von Wetterphänomenen wie Hurrikans oder Monsunregen betroffen sind, sollten Sie sich schon vor dem Antritt der Reise über das Verhalten im Falle eines solchen Ereignisses informieren. Wenn die Natur Ihr Reiseziel heimsucht, hat Ihre Sicherheit die höchste Priorität. Hier erfahren Sie, wie Sie sich im Katastrophenfall am besten schützen.

Mit einer Magnitude von 7,8 und mehr als 15.000 Toten zählt das Erdbeben in der Türkei und Syrien zu den schlimmsten Naturkatastrophen der vergangenen 100 Jahre. Dabei gab es in dieser Zeit viele sehr schwere Erdbeben.

22. Mai 1960: Großes Chile-ErdbebenErst bei 9,5 stoppte der Zeiger auf der Momenten-Magnituden-Skala: Nie zuvor und bislang auch nie wieder danach haben Erdbebenmessgeräte derart weit ausgeschlagen wie am 22. Mai 1960 an der Südküste Chiles. Beim Beben von Valdivia am Pazifik, das als „Großes Chile-Erdbeben“ in die Geschichte eingegangen ist, schoben sich zwei Kontinentalplatten um mehr als 30 Meter gegeneinander und setzten eine gewaltige Menge Energie frei. Energie, die im Frühjahr 1960 ganze Städte innerhalb von nur zehn Minuten in Trümmer legte und die Geografie einer ganzen Region veränderte.Zwischen 1600 und 6000 Menschen sind damals in der Erdbebenregion ums Leben gekommen - rückblickend hat Chile damit das wohl schwerste Beben der Menschheitsgeschichte vergleichsweise glimpflich überstanden. Der durch das Beben ausgelöste Tsunami tötete später noch 130 Menschen in Japan und 61 auf Hawaii.27. März 1964: Karfreitagsbeben in AlaskaWaren die USA beim „Großen Chile-Beben“ nur am Rande betroffen, wurde die Supermacht vier Jahre später am Karfreitag zum Epizentrum des zweitstärksten Bebens, das jemals registriert wurde. Das „Große Alaska-Erdbeben“ mit einer Stärke von 9,2 zerstörte am 27. März 1964 um 17:36 Uhr Ortszeit Teile der Infrastruktur in Süd- und Zentralalaska.Doch die USA hatten vor fast 60 Jahren Glück im Unglück. Karfreitag waren keine Schüler in den Schulgebäuden - viele Unternehmen waren ebenfalls geschlossen. Trotzdem: In der wichtigsten Stadt Anchorage sackten nach den vier lange Minuten dauernden Erdstößen ganze Straßenzüge ab und die Küstenorte überspülte späte eine riesige Tsunami-Welle. Viele der insgesamt 139 Toten ertranken damals in den Fluten.26. Dezember 2004: Tsunami im Indischen OzeanBei Beben unter dem Meer oder in Meeresnähe entstehen häufig Tsunamis. Sie führen noch weit entfernt vom Epizentrum zu Todesopfern. Beim Sumatra-Andamanen-Beben 85 Kilometer vor der Nordwestküste der indonesischen Insel Sumatra waren im Winter 2004 keine Verschütteten durch die Erdstöße selbst zu beklagen.Das Beben entfaltete seine tödliche Wirkung vielmehr durch zahlreiche bis zu 30 Meter hohe Flutwellen, die mehr als 240.000 Menschen in insgesamt 14 Anrainer-Staaten des Pazifiks töteten. Mit einer Stärke von 9,1 war das Beben nicht nur eines der stärksten jemals gemessenen Erschütterungen auf der Welt, sondern auch eines mit einer besonders hohen Zahl an Opfern.11. März 2011: Drama um FukushimaIn Erinnerung geblieben ist das großeSeebeben am 11. März 2011 vor der japanischen Region Tōhoku als größte Nuklearkatastrophe der vergangenen 25 Jahre. Mit einer Stärke von 9,1 auf der Momenten-Magnituden-Skala löste das Beben aber auch Tsunami-Wellen aus, die auf einer Fläche von mehr als 500 km² die japanische Pazifikküste überfluteten. Rund 22.000 Menschen verloren in Folge der kombinierten Naturkatastrophe ihr Leben - rund 400.000 Gebäude wurden vollständig zerstört oder stürzten ein. Nachdem das Kernkraftwerk Fukushima von einer 14 Meter hohen Tsnuami-Welle getroffen war, kam es dort zu mehreren Unfällen und demAustritt von Radioaktivität. Als Reaktion auf das Reaktorunglück änderten mehrere Staatenihre Energiepolitik.23. Januar 1556: Trauriger Opferrekord beim Beben vom ShaanxiAls die Hofchronisten des chinesischen Kaisers nach dem 23. Januar 1556 ihre düsteren Beobachtungen zu Papier brachten, lag die Welt um sie herum in Trümmern: „An manchen Orten brach die Erde auf und Wasserströme sprangen hervor […]. An anderen Orten versanken Stadtmauern und Häuser im Boden. Oder Berge formten sich, wo vorher ebene Erde war. An manchen Orten gab es viele Beben an einem Tag, an anderen hörten die Beben mehrere Tage lang nicht auf.“Rund 830.000 identifizierte Menschen sind in der Folge des Bebens von Shaanxi mit einer rückblickend errechneten Stärke von 8,25 ums Leben gekommen. Das Epizentrum lag etwa 80 km nordöstlich von Xi'an, der Hauptstadt von Shaanxi. In einigen Bezirken des Katastrophengebietes sollen mehr als zwei Drittel der Einwohner ihr Leben verloren haben. Bis heute waren bei keinem weiteren Beben so viele Opfer zu beklagen wie im 16. Jahrhundert im Herzen Chinas.28. Juli 1976: Beben von TangshanAm 28. Juli 1976 kam der Tod für Hunderttausende in der Nacht. Um 03:42 Uhr Ortszeit zerstörte ein Beben der Stärke 7,1 fast vollständig die Großstadt Tangshan mit heute mehr als sieben Millionen Einwohnern. Das Epizentrum damals lag 20 Kilometer südwestlich von Tangshan, die Erdstöße waren aber auch noch in der 140 Kilometer entfernten Hauptstadt Peking zu spüren.Mehr als fünf Millionen Häuser wurden durch das Beben unbewohnbar - die Behörden registrierten offiziell 242.000 Todesopfer. Schätzungen allerdings gehen von bis zu 650.000 Toten aus, womit das Beben von Tangshan das opferreichste Beben der vergangenen 100 Jahre gewesen sein könnte und das zweitverheerendste der Menschheitsgeschichte.16. Dezember 1920: Beben von GansuChina…immer wieder China. In den 1920er-Jahren kam es zu mehreren schweren Erdbeben in Ostasien. Mit mehr als 200.000 Toten war das Beben von Gansu am 16. Dezember 1920 das folgenreichste einer ganzen Serie von Beben in dieser Zeit. Beim Erdbeben von Gansu, das auch als Beben von Haiyuan in die Geschichtsbücher eingegangen ist, wurden mehr als 200.000 Menschen getötet.Die Erdstöße mit einer Stärke von 7,8 überraschten die Menschen um 20:06 Uhr Ortszeit. Im Zentrum des Bebens in Zentralchina wurden fast alle Häuser zerstört - ein Erdrutsch begrub ein ganzes Dorf unter Schlamm. Rund um das Epizentrum kam es zu einer Vielzahl von Erdrutschen und Bodenrissen - Flüsse wurden aufgestaut oder änderten ihren Lauf.12. Januar 2010: Ausgerechnet HaitiWenn es heute zu schweren Erdbeben kommt, läuft die internationale Hilfsmaschinerie schon wenige Stunden später auf Hochtouren. Das war auch am 12. Januar 2010 der Fall, nachdem in Haiti um 16:53 Uhr Ortszeit die Erde bebte. Mit einer Stärke von 7,0 der Momenten-Magnituden-Skala zählt das Beben nicht zu den stärksten der vergangenen 100 Jahre, aber zu den folgenreichsten.Das ärmste Land der westlichen Hemisphäre war denkbar schlecht auf die Naturkatastrophe vorbereitet. In manchen Regionen Haitis wurden bis zu 90 Prozent der Häuser zerstört. Exakte Zahlen über die Todesopfer gibt es bis heute nicht: Internationale Organisationen gehen von einer Zahl zwischen 200.000 und 500.000 getöteter Menschen aus. Das überbevölkerte und unter einer korrupten Elite leidende Land hat sich trotz internationaler Unterstützung bis heute nicht von dieser Katastrophe erholt.Autor: Andreas Noll   

 1 von 14 
 2 von 14 
 3 von 14 
 4 von 14 
 5 von 14 
 6 von 14 
 7 von 14 
 8 von 14 
 9 von 14 
 10 von 14 
 11 von 14 
 12 von 14 
 13 von 14 
 14 von 14 
Das Leid in Japan ist nicht quantifizierbar. Und doch gibt es Zahlen, die das Ausmaß der Katastrophe definieren. Schon jetzt steht fest, dass am 11. März 2011 die größte Naturkatastrophe der Weltgeschichte geschehen ist.
Nach Schätzungen der Regierung könnte sie Schäden von umgerechnet 220 Milliarden Euro verursacht haben. Damit ist die Katastrophe deutlich teurer als das Beben in der japanischen Großstadt Kobe 1995 oder der Wirbelsturm „Katrina“ im Jahr 2005 an der Küste des Golfes von Mexiko.
Im Kernkraftwerk ist die Lage nach wie vor nicht unter Kontrolle. Das heißt: Noch immer besteht die Gefahr einer Kernschmelze. In der Region um Fukushima bebte außerdem wieder die Erde, einmal mit einer Stärke von 6,0, das zweite Mal von 5,8.
Weil Schwarzer Rauch aus einem der sechs Reaktoren aufstieg, mussten die Arbeiter die Anlage verlassen. Eine Erklärung für den Rauch gab es erst einmal nicht, die Arbeiter werden zur Sicherheit erst Donnerstag zurückkehren.
Der Ablauf ist immer der gleiche. „Ore ore“, sagt der Anrufer. „Ich bin’s“, heißt das auf Japanisch. Der Empfänger ist froh, der Enkel ist dran, der Neffe, Sohn oder Schwiegersohn. Dann geht es ganz schnell, der Anrufer hat Geldnot, der Empfänger will helfen, und schon ist er um sein Erspartes gebracht. „Ore ore“ heißt die Tat in Japan, in Deutschland heißt sie „Enkeltrick“. Weil ihr vor allem alte Leute zum Opfer fallen. In Japan hat sich der Trick in den letzten Jahren zu einem Problem ausgeweitet.
Die Not nach dem Tsunami war und ist gigantisch, und dennoch haben sich die Leute gestützt. Plünderungen, Diebstahl, so was gab es hier nicht. Bislang, schreibt der „Daily Telegraph“, haben sich die Menschen in ihrer Not alltägliche Gegenstände genommen, die aus den Häusern gespült wurden und keinem Besitzer mehr zuzuordnen waren.
Die Lage scheint sich nun zu verändern. Durch den „Ore ore“-Trick versuchen Menschen nun, Profit aus der Katastrophe zu schlagen – sie geben sich selbst am Telefon als Tsunami-Opfer aus oder sie versuchen, den Angerufenen zu überreden, einen angeblichen Verwandten im Katastrophengebiet zu unterstützen.
Kein Grund zur Sorge, Japan ist weit. Das teilte sinngemäß das Bundesamt für Strahlenschutz mit. In der Atmosphäre über Deutschland seien keine radioaktiven Partikel aus Fukushima nachweisbar. Die Behörde untersucht die Luft über Deutschland laufend mit einem sehr genauen Messnetz auf Strahlenbelastungen.
Die Bevölkerung wird sofort informiert, sobald Radioaktivität aus Japan Deutschland erreicht. Generell sei aber nur mit äußerst geringen Spuren zu rechnen, von denen keine Gefahr ausgeht. Die Entfernung nach Japan sei so groß, dass die radioaktiven Teilchen Deutschland nur in verschwindend geringen Konzentrationen erreichen könnten. Auch bei der Kontrolle von Lebensmitteln aus Japan sind bislang keine erhöhten Strahlenbelastungen aufgefallen.
Der Ausfall ist nicht annähernd so schlimm wie die Havarie im Atomkraftwerk. Die Folgen für Tokio sind trotzdem gravierend. Es ist kaum bekannt, dass am 11. März nicht nur Fukushima 1, sondern auch zwei große Wärmekraftanlagen beschädigt wurden. Die beiden Kraftwerke produzieren zusammen so viel Strom wie das havarierte Kernkraftwerk.
Die Menschen in Tokio und Umgebung müssen deshalb noch lange mit Stromausfällen rechnen. Tepco plant noch mindestens ein Jahr lang Stromsparmaßnahmen. Der Strom soll den ganzen Sommer und den folgenden Winter über weiter zeitweise abgestellt werden. Der Konzern plant zwar unter anderem, Elektrizität von Gasfirmen und anderen Produzenten einzukaufen.
Das reiche aber dennoch nicht, um den Bedarf der vielen Millionen Haushalte im Großraum Tokio zu decken. „Wir werden wahrscheinlich einen Drahtseilakt vollziehen müssen, nicht nur diesen Sommer und Winter, sondern auch den Sommer danach“, sagte ein Tepco-Mitarbeiter der Zeitung „Asahi Shimbun“.
So eine Krise wirkt sehr lange nach. Es sind die Bilder vom verwüsteten Atomkraftwerk, die Meldungen über verseuchtes Essen, die ständigen Beben und drohenden Tsunamis, die Japans Ruf als sicheres Reiseziel erschüttert haben. Viele Touristen haben ihre Reise storniert. Das ist verständlich – und für Japan ein weiterer Verlust. In Ginza, einem bekannten Einkaufsviertel in Tokio, wo sich sonst unzähligen Besucher in Kimono-Geschäften und Nobelboutiquen tummeln, sind die Touristenströme verebbt. Die Straßen wirken trostlos, abends werden die Lichter abgeschaltet.
Internationale Unternehmen mussten profitable Buchungen streichen. Die Flüge von Japan sind ausgebucht mit Ausländern, die fliehen. Die Flüge nach Japan sind fast leer. Die Krise schlug gerade zum Auftakt der Touristensaison zu. Japans Tempel und Thermen haben schon immer Touristen angezogen, doch die Branche lag weit hinter der industriellen Produktion und Exporten.
Als das Wachstum abflaute – und weil die Bevölkerung rasant altert –, ordnete der Ministerpräsident Naoto Kan an, dass sich das Inselreich nach außen öffnen muss. Die meisten Besucher kamen aus China und Südkorea. Mehr als 1,4 Millionen Chinesen besuchten Japan im vergangenen Jahr, an erster Stelle stehen weiter die Südkoreaner mit 2,4 Millionen Besuchern.
Die Auswirkungen der Krise auf Besucherzahlen aus beiden Ländern sind dramatisch. Die Japaner sind über die USA und Südkorea verärgert, die Reisewarnungen für das ganze Land aussprechen, anstatt nur für den Nordosten des Landes. Selbst die Internationale Zivilluftfahrtorganisation, eine UN-Organisation, verkündete, es gebe keine Grundlage für Reiseeinschränkungen für Gebiete, die nicht vom Tsunami betroffen sind.
Demos, Wahlkampf, Talkshows – seit der Havarie in Fukushima ist das Thema Atom allgegenwärtig. Und treibt bisweilen ungewöhnliche Blüten. Wegen des schweren Reaktorunglücks ist das deutsche Jugendmagazin „Bravo“ erstmals in seiner rund 55-jährigen Geschichte mit einer politischen Botschaft in Posterform erschienen.
Der neuen Ausgabe liegt ein herausnehmbares Plakat mit einem Aufruf zum Ausstieg aus der Atomkraft bei. Bislang hat sich die Zeitschrift auf Musiker, Schauspieler und Sportler beschränkt. Als einziger Politiker schaffte es bislang US-Präsident Barack Obama nach seiner Wahl 2008 auf ein „Bravo“-Plakat. „Unsere Leser sind die Generation, die mit den Folgen unserer heutigen politischen Entscheidung Pro oder Contra Atomkraft leben müssen“, erklärte Chefredakteur Philipp Jessen.
Die Lage in Fukushima sorge bei Jugendlichen für Betroffenheit, wie viele Briefe und E-Mails an die Redaktion zeigten. „Mit dem Poster sprechen wir unseren Lesern aus dem Herzen“, sagte Jessen.
Tepco – Man hat fast den Eindruck, das Land werde von einem einzigen Energieproduzenten versorgt. Und tatsächlich ist Tepco der größte Stromkonzern Japans. Chubu Electric Power kommt erst auf Platz drei. Doch das Unternehmen will seine eigenen Konsequenzen aus der Katastrophe ziehen. Um sein Kernkraftwerk an der Küste südlich von Tokio will die Firma einen zwölf Meter hohen Tsunami-Schutzwall bauen. Zudem soll der Bau eines sechsten Reaktors in der Anlage um ein Jahr verschoben. An einem anderen Plan hält der Konzern fest: Bis zum Jahr 2030 will er ein zweites Atomkraftwerk bauen.
Es gibt kaum einen Lebensbereich, auf den die Lage in Japan keine Auswirkungen hat. Auch der Sport ist auf die eine oder andere Art betroffen. Zunächst sorgte das italienische IOC-Mitglied Mario Pescante für Verwirrung, als er sagte, dass Japan seine Bewerbung für die Olympischen Spiele 2020 angesichts der Lage im Land nicht weiterverfolge. Ein Sprecher des Japanischen Olympischen Komitees zeigte sich erstaunt. Eine Entscheidung darüber sei überhaupt noch nicht gefallen, sagte er.
Unterdessen wurden neun Japanerinnen nach dem katastrophenbedingten Ausfall der WM-Qualifikation in Nagoya zum London-Marathon eingeladen. Sie können sich nun bei dem Rennen für die Leichtathletik-WM 2011 im südkoreanischen Daegu qualifizieren. „Wir haben nach dieser schlimmen Katastrophe gleich unsere Hilfe angeboten, als wir vom Ausfall des Frauen-Marathons in Nagoya hörten“, sagte Dave Bedford, Direktor des Rennens in London.
Eine weitere sportliche Solidaritätsbekundung kommt aus Frankreich. Nach der Absage der Eiskunstlauf-WM in Tokio hat das Land als kommender Gastgeber dem japanischen Eislaufverband die Ausrichtung der Wettkämpfe für 2012 angeboten. „Wir alle haben ein Herz und stehen solidarisch zu Japan, dem japanischen Volk und dem japanischen Verband“, sagte am Mittwoch der Präsident des französischen Eissportverbandes, Didier Gailhaguet.
Die größten Sorgen bleiben im Katastrophengebiet. Die Überlebenden müssen die Todesopfer in provisorischen Särgen bestatten. In Higashimatsushima, rund 320 Kilometer nordöstlich von Tokio, ließen Soldaten schlichte Sperrholzsärge in die Gräber hinab und salutierten, während Familienangehörige aus der Entfernung zuschauten.
Am späten Mittwochabend gab die nationale Polizeibehörde von Japan die neuesten Opferzahlen bekannt. Mittlerweile gibt es 9523 bestätigte Todesopfer. Fast 16100 Menschen werden noch immer vermisst. Und Hunderttausende Japaner sind obdachlos. „Über eine Woche nach den verheerenden Erdbeben gibt es kleine Momente der Hoffnung“, berichtet WELT-Korrespondentin Carolina Drüten aus dem türkischen Ort Kahramanmaras. Die Bergungsteams seien seit Stunden zu Gange, um noch drei Leben zu retten. 
 Quelle: WELT 
Das Erdbeben im türkisch-syrischen Grenzgebiet ist nach Einschätzung der Weltgesundheitsorganisation (WHO) die „schlimmste Naturkatastrophe“ in Europa seit einem Jahrhundert. WHO-Regionaldirektor Hans Kluge hob am Dienstag hervor, dass das ganze Ausmaß der Schäden noch gar nicht feststehe. Unicef sprach von mindestens sieben Millionen betroffenen Kindern. Die Hilfseinsätze konzentrieren sich mittlerweile auf die Versorgung der obdachlosen Überlebenden, auch die Hilfsanstrengungen für das Bürgerkriegsland Syrien wurden verstärkt.
„Wir sind Zeugen der schlimmsten Naturkatastrophe in der WHO-Europa-Region seit einem Jahrhundert“, sagte WHO-Regionaldirektor Kluge in Kopenhagen. Zur WHO-Region Europa gehören 53 Länder, darunter die Türkei sowie einige zentralasiatische Länder. Die WHO hatte kürzlich mitgeteilt, sie gehe davon aus, dass 26 Millionen Menschen in der Türkei und Syrien betroffen sein könnten.
Das UN-Kinderhilfswerk Unicef erklärte, von dem Erdbeben seien in der Türkei 4,6 Millionen Kinder und in Syrien rund 2,5 Millionen Kinder betroffen. Es sei zu befürchten, dass durch das Beben am Montag vergangener Woche „viele tausend“ Kinder ums Leben gekommen seien, sagte Unicef-Sprecher James Elder. Viele der überlebenden Kinder litten nun an Unterkühlung und Atemwegsinfektionen. 
In Berlin versicherte Innenministerin Nancy Faeser (SPD), die Bundesregierung setze ihre Hilfe für die Erdbebenopfer „mit Hochdruck weiter fort“. Demnach sind weitere Hilfsflüge in die Türkei geplant. Deutschland hat laut Bundesinnenministerium bereits Hilfsgüter im Wert von gut 8,4 Millionen Euro bereitgestellt, davon mehr als drei Viertel für die Türkei.
Die Einsatzteams des Technischen Hilfswerks (THW) und der Hilfsorganisation Isar Germany kehrten am Dienstag nach mehrtägigen Rettungseinsätzen im Erdbebengebiet nach Deutschland zurück. Es gab kaum noch Hoffnung, Überlebende unter den Trümmern zu finden, vielerorts wurde die Suche eingestellt. Am Montag konnten jedoch der achtjährige Harun und sein 15-jähriger Bruder Eyüphan 181 Stunden nach dem Beben noch lebend geborgen werden, wie die staatliche Nachrichtenagentur Anadolu berichtete. 
In der Provinz Kahramanmaras hätten Helfer zudem am Dienstagmorgen zwei 17 und 21 Jahre alte Brüder gerettet, berichteten Anadolu und der Sender CNN Türk. Sie lagen demnach 198 Stunden unter den Trümmern. In der Provinz Adiyaman wurde demnach ein 18-Jähriger, der ebenfalls 198 Stunden verschüttet war, gerettet. Unabhängig überprüfen ließen sich die Angaben zunächst nicht.
Die Hilfseinsätze konzentrieren sich nun aber auf die Versorgung der zahlreichen obdachlos gewordenen Überlebenden. Laut türkischer Regierung wurden etwa 206.000 Zelte errichtet, 1,2 Millionen Menschen wurden in Studentenwohnheimen untergebracht und 400.000 Überlebende aus den verwüsteten Gebieten fortgebracht.
In der Stadt Antakya begannen bereits Aufräumarbeiten. Arbeiter stellten behelfsmäßige Toiletten auf, das Telefonnetz funktionierte in Teilen der Stadt wieder, wie ein AFP-Reporter berichtete.
Das Beben der Stärke 7,8 hatte am vergangenen Montag das türkisch-syrische Grenzgebiet erschüttert. Die Zahl der bestätigten Todesopfer stieg seitdem auf mehr als 40.000, davon 35.418 in der Türkei und mindestens 5900 in Syrien. Die wirtschaftlichen Kosten des Erdbebens könnten sich auf bis zu 84,1 Milliarden Dollar (rund 78 Milliarden Euro) belaufen, davon fast 71 Milliarden Dollar (66 Milliarden Dollar) für den Wohnungsbau, wie der türkische Arbeitgeberverband Türkonfed am Montag berichtete.
Im Bürgerkriegsland Syrien wird die Versorgung der Erdbebenopfer dadurch erschwert, dass das Katastrophengebiet teils von der Regierung in Damaskus, teils von Rebellen kontrolliert wird. Am Dienstag traf erstmals seit dem Beben eine UN-Delegation im von oppositionellen Milizen kontrollierten Katastrophengebiet im Nordwesten Syriens ein, wie der Direktor des Welternährungsprogramms für Syrien, Kenn Crossley, AFP sagte.
Es gehe zunächst darum, den genauen Hilfsbedarf in der hart getroffenen Region festzustellen, sagte Crossley. Zu der Delegation zählten der stellvertretende regionale Koordinator für humanitäre Hilfe, David Carden, und die Leiterin des UN-Büros für die Koordinierung humanitärer Angelegenheiten (OCHA) in der Türkei, Sanjana Quazi.
Zuvor hatte Syriens Machthaber Baschar al-Assad um internationale Unterstützung für die Erdbebenopfer in seinem Land gebeten. Nach UN-Angaben sagte er zugleich zu, zusätzlich zu Bab al-Hawa zwei weitere Grenzübergange für Hilfsgüter zu öffnen. Dadurch komme mehr Hilfe „schneller“ ins syrische Erdbebengebiet, erklärte UN-Generalsekretär António Guterres am Montag.
Der Hilfsbedarf in Syrien ist riesig. Am Dienstag landete erstmals seit 2012 ein Flugzeug aus Saudi-Arabien in dem Bürgerkriegsland. Die Maschine brachte 35 Tonnen Lebensmittel für die Erdbebenopfer in das von der syrischen Regierung kontrollierte Aleppo, weitere Hilfsflüge waren für Mittwoch und Donnerstag geplant.
„Kick-off Politik“ ist der tägliche Nachrichtenpodcast von WELT. Das wichtigste Thema analysiert von WELT-Redakteuren und die Termine des Tages. Abonnieren Sie den Podcast unter anderem bei Spotify, Apple Podcasts, Amazon Music, Google Podcasts oder direkt per RSS-Feed.Eine Wetterkatastrophe erschüttert die Vereinigten Staaten: Nach einer Reihe von Tornados ist die Zahl der Toten auf mindestens 32 gestiegen.
Das ging am Sonntag aus Stellungnahmen der Behörden in den Regionen im Süden und Mittleren Westen des Landes hervor, in denen die durch ein monströses Sturmsystem ausgelösten Wirbelstürme wahre Schneisen der Verwüstung geschlagen hatten.
Zudem gab es Dutzende Verletzte. Wegen Sturmschäden waren am Sonntag noch rund 100.000 Haushalte und Firmen ohne Strom, wie aus Daten der Seite „poweroutage.us“ hervorging. Medien sprachen von einem seltenen „Monster-Sturmsystem“, das sich vom Süden der USA bis in die Region der Großen Seen im Norden erstreckte.
Man sei immer noch dabei, das volle Ausmaß der Schäden abzuschätzen, teilte US-Präsident Joe Biden mit. Unter anderem wurde die Hauptstadt des US-Staats Arkansas getroffen, Little Rock. Alleine dort kamen nach Angaben von Gouverneurin Sarah Huckabee Sanders fünf Menschen ums Leben. Sanders rief den Katastrophenfall aus und mobilisierte die Nationalgarde. 
Auch in Tennessee hinterließ ein Tornado eine Schneise der Verwüstung, verdrehte Bäume, verwandelte Häuser in Schutthaufen und zerriss Mauern. Die zunächst auf sieben bezifferte Opferzahl stieg später auf neun, wie der Sender WREG berichtete.
„So etwas habe ich noch nie gesehen“, berichtete Melissa Keller aus Tennessee. Es habe sich angehört wie ein Zug, der plötzlich durch die Ortschaft raste, erzählte sie der Zeitung „The Tennessean“. Auch andere Augenzeugen berichteten, es sei kurz davor total ruhig gewesen, dann auf einmal ohrenbetäubend laut.
Sie habe im Badezimmer Schutz gesucht, erzählte Keller weiter. Ihr Haus blieb weitgehend verschont. „Doch das Gebäude dort hat der Sturm um 15 Fuß (rund 4,5 Meter) verschoben.“ Auf Bildern und Videos waren vor ihrer Tür und auch anderswo in den betroffenen Gegenden Berge von Trümmern, abgedeckte Häuser und umgeknickte Bäume zu sehen. Auf dem Dach liegende Autos zeugten von der Gewalt des Sturms.
Auch in Indiana, Mississippi, Alabama und Delaware kamen Menschen bei den Unwettern ums Leben. Insgesamt wurden laut dem Wetterdienst in sieben Bundesstaaten vor allem im Süden und im Mittleren Westen des Landes mehr als 50 Wirbelstürme gezählt, die als Tornados eingestuft werden könnten. Die endgültige Einstufung folgt erst in einigen Tagen.
In Illinois stürzte das Dach und Teile der Fassade eines Veranstaltungsorts ein, als dort gerade ein Heavy-Metal-Konzert lief. Videos in Online-Netzwerken zeigten Konzertbesucher, die auf Tragen aus der hüfthoch mit Schutt bedeckten Halle getragen wurden, und ein großes Loch in der Decke. Laut Feuerwehrchef Shawn Schadle kam ein Mensch ums Leben, 28 weitere wurden verletzt.
Tornados sind schwer vorherzusagen. In den USA kommen sie relativ häufig vor, insbesondere im Zentrum und im Süden des Landes. 
„Kick-off“ ist der tägliche Nachrichtenpodcast von WELT. Das wichtigste Thema analysiert von WELT-Redakteuren und die Termine des Tages. Abonnieren Sie den Podcast unter anderem bei Spotify, Apple Podcasts, Amazon Music, Google Podcasts oder direkt per RSS-Feed.Beim Durchzug eines Sturmtiefs sind in mehreren US-Bundesstaaten mindestens 21 Menschen getötet worden. Dutzende weitere wurden bei den Tornados verletzt, alleine im besonders hart getroffenen Tennessee starben der Katastrophenschutzbehörde des Staates zufolge seit Freitag sieben Menschen. In den Südstaaten Arkansas, Mississippi und Alabama sowie in den weiter nördlich gelegenen Indiana und Illinois richteten Unwetter ebenfalls Verwüstungen an.
Am Freitag hinterließen mehrere Tornados in Arkansas eine Schneise der Zerstörung. Alleine in der Hauptstadt Little Rock kamen nach Angaben von Gouverneurin Sarah Huckabee Sanders fünf Menschen ums Leben. Häuser wurden dem Erdboden gleich gemacht, Autos umgeweht, Bäume entwurzelt und Strommasten zerstört. Gouverneurin Sanders rief den Katastrophenfall aus und mobilisierte rund hundert Nationalgardisten. Am Samstag sagte sie vor Journalisten, sie habe mit US-Präsident Joe Biden über die Situation beraten.
Am späten Samstagabend (Ortszeit) waren der Website Poweroutage.us zufolge fast 610.000 Haushalte in den betroffenen Bundesstaaten ohne Strom. Im nördlichen Bundesstaat Illinois kam es am Freitagabend zu einem Unglück in einer Konzerthalle.
Infolge schwerer Stürme stürzte in der westlich von Chicago gelegenen Kleinstadt Belvidere während eines Heavy-Metal-Konzerts das Dach und ein Teil der Fassade ein. Dem örtlichen Feuerwehrchef Shawn Schadle zufolge kam ein Mensch ums Leben, 28 weitere wurden verletzt. Fünf davon seien mit schweren Verletzungen ins Krankenhaus eingeliefert worden.
Im Nachbarstaat Indiana sprach die Polizei gegenüber dem Fernsehsender WTHI von drei Toten nach dem Durchzug eines Sturms im Landkreis Sullivan County. Auf Fotos des Senders im Onlinedienst Twitter waren umgeknickte Telefonmasten, zertrümmerte Häuser und von Schutt übersäte Straßen zu sehen. 
Der Katastrophendienst im US-Bundesstaat Mississippi meldete einen Toten und mehrere Verletzte im Landkreis Pontotoc rund 200 Kilometer südlich von Memphis. In Alabama starb beim Durchzug eines Tornados ein Mensch in seinem Haus, wie die Behörden der Stadt Huntsville in der Nähe der Grenze zum Bundesstaat Tennessee mitteilten. 
Tornados sind schwer vorherzusagen. In den USA kommen sie relativ häufig vor, insbesondere im Zentrum und im Süden des Landes. Zweieinhalb Wochen nach der Erdbeben-Katastrophe im türkisch-syrischen Grenzgebiet ist die Zahl der Toten auf mehr als 50.000 gestiegen. Alleine in der Türkei liege die Zahl bei 44.218, meldete die türkische Katastrophenbehörde Afad am Freitagabend. Aus Syrien wurden zuletzt 5900 Tote gemeldet.
Immer wieder erschüttern Nachbeben die Region und lösen bei den Anwohnern oft Panik aus. Laut türkischer Regierung sind 20 Millionen Menschen im Land von den Auswirkungen des Bebens betroffen. Für Syrien gehen die Vereinten Nationen von 8,8 Millionen Betroffenen aus.
Die Erdbebengebiete waren zunächst teilweise schwer zugänglich, Bergungsarbeiten werden aber weiter fortgesetzt, mit deren Fortschreiten steigen die Opferzahlen. Berichte über die Rettung von Überlebenden gab es in den vergangenen Tagen nicht mehr.
Begonnen hatte die Serie an Erdbeben am 6. Februar, als zwei Beben der Stärke 7,7 und wenig später der Stärke 7,6 die Südosttürkei und den Norden Syriens erschütterten. Darauf folgten nach türkischen Angaben mehr als 9000 Nachbeben.
Nach Angaben der Vereinten Nationen war die Erdbeben-Katastrophe nicht nur nach Todesopfern die schlimmste in der türkischen Geschichte. Auch die Berge an Schutt und Geröll seien beispiellos, sagte Louisa Vinton, die Vertreterin des UN-Entwicklungsprogramms (UNDP) in der Türkei. Der türkischen Regierung zufolge sind bisher mehr als 173.000 Gebäude als eingestürzt oder stark beschädigt registriert.
Die türkischen Behörden begannen nach eigenen Angaben mit dem Bau erster Unterkünfte für die von dem jüngsten verheerenden Erdbeben obdachlos gewordenen Menschen. Arbeiten zum Erdaushub seien in den Städten Nurdagi und Islahiye in der Provinz Gaziantep im Gang, twitterte der Minister für Umwelt, Stadtplanung und Klimawandel, Murat Kurum. Zunächst seien 855 Wohnungen geplant.
Die Opposition macht die seit 20 Jahren regierende Regierung Erdogans für das Ausmaß der Katastrophe verantwortlich, weil sie die Einhaltung von Bauvorschriften nicht durchgesetzt habe. Für Mai oder Juni werden in der Türkei Parlaments- und Präsidentschaftswahlen erwartet.
Der türkische Justizminister Bekir Bozdag sagte am Donnerstagabend, gegen 583 Bauunternehmer oder andere mutmaßlich für eingestürzte Bauten zuständige Personen werde ermittelt. 171 seien festgenommen worden.
In der Türkei sind elf Provinzen von dem Erdbeben betroffen, in Syrien der Nordwesten. Aus dem Bürgerkriegsland gibt es nur spärliche Informationen über die Lage. Angesichts jahrelanger Bombardements und Kämpfe lebten viele Menschen dort schon vor den Beben unter prekären Umständen.Eine Woche nach dem verheerenden Erdbeben im syrisch-türkischen Grenzgebiet ist die Zahl der Todesopfer auf mehr als 37.500 gestiegen. Alleine in er Türkei gebe es inzwischen 31.643 Todesopfer, meldete die staatliche Nachrichtenagentur Anadolu am Montag unter Berufung auf die Katastrophenschutzbehörde Afad. Mehr als 80 000 Menschen wurden demnach verletzt. Nach Angaben der Weltgesundheitsorganisation WHO beträgt die Opferzahl in Syrien mindestens 5900. Tausende Menschen werden noch vermisst.
Am frühen Montagmorgen vor einer Woche hatte das erste Beben der Stärke 7,7 um 2.17 Uhr (MEZ) die Region erschüttert, Stunden später folgte ein zweites schweres Beben der Stärke 7,6. Das Epizentrum lag in der südtürkischen Provinz Kahramanmaras. 
Die Katastrophenschutzbehörde Afad registrierte bislang mehr als 2400 Nachbeben. In der Türkei sind zehn Provinzen von dem Beben betroffen – dort gilt inzwischen ein dreimonatiger Ausnahmezustand.
Und doch gibt es sie noch: berührende Einzelschicksale, die nimmermüden Rettungskräften und verzweifelten Angehörigen Hoffnung machen. So zogen Helfer in Kahramanmaras 112 Stunden nach dem Beben einen 46 Jahre alten Mann aus der Ruine eines siebenstöckigen Gebäudes, wie die staatliche Nachrichtenagentur Anadolu berichtete.
In der Provinz Gaziantep wurde eine verschüttete Schwangere nach 115 bangen Stunden vor dem Tod bewahrt. Ebenfalls in Gaziantep bargen Retter ein neunjähriges Mädchen nach 108 Stunden aus dem Schutt – für ihre beiden Eltern und ihre Schwester kam jedoch jede Hilfe zu spät. In der osttürkischen Provinz Hatay wurde gar ein zwei Monate altes Baby lebend aus Trümmern geborgen. Der Säugling sei 128 Stunden lang unter Schutt begraben gewesen, bevor er herausgezogen und in ein Krankenhaus gebracht wurde.
Und in Syrien haben Retter zwei Menschen in der Küstenstadt Dschabla aus einem eingestürzten Wohnhaus befreit. Mutter und Sohn erlitten demnach mehrere Knochenbrüche. Ihr gesundheitlicher Zustand sei ansonsten aber stabil.
Andere Fälle hingegen enden tragisch: Eine Frau, die ein deutsches Rettungsteam nach Tagen im türkischen Erdbebengebiet aus den Trümmern bergen konnte, ist in der Nacht zum Samstag in einem Krankenhaus gestorben. Wie die Hilfsorganisation ISAR Germany mitteilte, berichteten die Angehörigen der 40-Jährigen, die den Vornamen Zeynep trägt, den Rettungskräften über ihren Tod.
„Wir sind wirklich sehr traurig und betroffen“, sagte ISAR-Sprecher Stefan Heine der Nachrichtenagentur AFP. „Aber wir sind froh, dass sie durch die Bergung wenigstens noch einmal die Chance hatte, ihre Familie wiederzusehen.“
„Deutschland trauert mit den Menschen in Türkiye“, schrieb Bundeskanzler Olaf Scholz (SPD) in das Kondolenzbuch in der türkischen Botschaft in Berlin, wie er über Twitter mitteilte. „Wir werden jede mögliche Unterstützung leisten, um in diesen schweren Stunden zu helfen.“
Nach Angaben des türkischen Vize-Präsidenten Fuat Oktay sind inzwischen mehr als eine Million Menschen in Behelfsunterkünften untergebracht. Rund 160.000 Such- und Rettungskräfte seien im Einsatz, teilte die Katastrophenschutzbehörde Afad mit. Aus dem Ausland seien mehr als 7700 Helfer ins Erdbebengebiet geschickt worden.
Bundesagrarminister Cem Özdemir sprach sich für rasche Einreise-Erleichterungen aus, damit Betroffene des Erdbebens zu Angehörigen nach Deutschland kommen können. „Viele Menschen in Deutschland haben Verwandte in der Katastrophenregion und sorgen sich verzweifelt um sie“, sagte der Grünen-Politiker der Deutschen Presse-Agentur. Die Bundesregierung hatte eine „pragmatische Lösung“ bei der Visa-Vergabe an Überlebende der Erdbebenkatastrophe in Aussicht gestellt.
Für Hilfsgüter von der Hauptstadt in die Türkei soll es laut Berlins Regierender Bürgermeisterin Franziska Giffey eine Luftbrücke geben. „Und es ist gelungen mit vielen, die gespendet haben, (...) dass wir eine Luftbrücke von Berlin in die Türkei bauen, auch in Zusammenarbeit mit der türkischen Botschaft, mit dem Generalkonsulat“, sagte die SPD-Politikerin am Samstag bei einem Gedenken an die Erdbebenopfer am Brandenburger Tor.
„Wir haben am Flughafen BER eine über 6000 Quadratmeter große Halle, die jetzt gefüllt wird mit Tonnen von Spenden, mit Tausenden von Paletten, die gerade gesammelt werden und die in die Türkei gehen. Die ersten Flüge sind schon gelaufen“, sagte Giffey.
Berlins Innensenatorin Iris Spranger (SPD) hatte bereits am Freitag angekündigt, vom Erdbeben betroffenen Menschen mit Verwandten in der Hauptstadt die Einreise nach Deutschland zu erleichtern. Sie sollen schneller als sonst das nötige Visum erhalten können. Dazu erließ die Berliner Senatsinnenverwaltung eine sogenannte Globalzustimmung, die sonst erforderliche Beteiligung des Berliner Landesamts für Einwanderung entfällt.
Auf den Nachweis von Deutschkenntnissen werde verzichtet, hieß es. Die Regelung betreffe nahe Angehörige wie minderjährige Kinder sowie Ehepartner und -partnerinnen. Die Beschleunigung der Visa-Erteilung gilt demnach bis zum 31. Juli 2023.Die Zahl der Erdbebenopfer in Syrien ist deutlich höher als bislang angegeben. Nach Informationen der Weltgesundheitsorganisation (WHO) sind in den Rebellengebieten im Nordwesten mindestens 4500 Menschen ums Leben gekommen, in Regionen unter Regierungskontrolle etwa 1400. Die Zahlen nannte der Nothilfekoordinator für die WHO-Region Östliches Mittelmeer, Richard Brennan, am Samstag in der syrischen Hauptstadt Damaskus. Die Zahl dürfte aber weiter steigen, sagte Brennan. Die Gesamtzahl der Toten in der Türkei und Syrien steigt damit auf mehr als 35.000.
Es werden noch Tausende weitere Opfer befürchtet. Unzählige Häuser sind bei der Naturkatastrophe zerstört worden.
Nach Schätzungen der Vereinten Nationen könnte die Zahl noch auf 50.000 oder mehr steigen. Der UN-Nothilfekoordinator Martin Griffiths sagte dem Sender Sky News am Sonntag im Erdbebengebiet Kahramanmaras, Schätzungen seien schwierig, aber die Zahl der Todesopfer könnte sich „verdoppeln oder mehr“. „Und das ist erschreckend“, sagte er.
Die betroffenen Gebiete waren zunächst schwer zugänglich, mit dem Fortschreiten der Bergungsarbeiten steigen die Opferzahlen. Es gibt kaum noch Chancen, Überlebende unter den Trümmern zu finden.
Weitere Hilfen sollen nun von der EU kommen. EU-Kommissionspräsidentin Ursula von der Leyen sagte dem türkischen Präsidenten Recep Tayyip Erdogan am Sonntag in einem Telefonat die Lieferung von weiteren Zelten, Decken und Heizvorrichtungen zu. Die Kommission mobilisiere auch den Privatsektor, um die erforderliche Unterstützung so schnell wie möglich zu leisten, teilte in Brüssel eine Sprecherin am Abend nach dem Gespräch mit.
Über das sogenannte EU-Katastrophenschutzverfahren wurden der Türkei nach Angaben vom Sonntag schon jetzt 38 Rettungsteams mit 1651 Helfern und 106 Suchhunden angeboten. Zudem hätten zwölf EU-Staaten bereits 50.000 winterfeste Familienzelte, 100.000 Decken und 50.000 Heizgeräte zur Verfügung gestellt. Hinzu kämen 500 Notunterkünfte, 8000 Betten und 2000 Zelte, die die Kommission mobilisiert habe.
Von der Leyen selbst schrieb über den Kurznachrichtendienst Twitter, sie habe mit Erdogan telefoniert, um die weitere Unterstützung zu besprechen und um den Menschen in der Türkei ihr tief empfundenes Beileid für den katastrophalen Verlust von Menschenleben und die Zerstörung zu übermitteln.
Am frühen Montagmorgen hatte ein Beben, dessen Stärke das Deutsche Geoforschungszentrum (GFZ) mit 7,7 angibt, das türkisch-syrische Grenzgebiet erschüttert. Am Montagmittag folgte dann ein weiteres Beben der Stärke 7,6 in derselben Region. In den Tagen danach gab es laut türkischen Angaben mehr als 2000 Nachbeben.
Im Bürgerkriegsland Syrien ist der Norden betroffen. Von dort gibt es nur spärlich Informationen über die Lage. In der Türkei gab es in zehn Provinzen schwere Schäden durch die Beben. Dort ist inzwischen ein dreimonatiger Ausnahmezustand in Kraft getreten.
Im Süden der Türkei wurden mehrere Haftbefehle erlassen. Die Beschuldigten sollen für Baumängel verantwortlich sein, die den Einsturz der Gebäude begünstigt hätten, meldete die staatliche Nachrichtenagentur Anadolu unter Berufung auf Strafverfolger.Die Zahl der Erdbebenopfer in Syrien ist deutlich höher als bislang angegeben. Nach Informationen der Weltgesundheitsorganisation (WHO) sind in den Rebellengebieten im Nordwesten mindestens 4500 Menschen ums Leben gekommen, in Regionen unter Regierungskontrolle etwa 1400. Die Zahlen nannte der Nothilfekoordinator für die WHO-Region Östliches Mittelmeer, Richard Brennan, am Samstag in der syrischen Hauptstadt Damaskus. Die Zahl dürfte aber weiter steigen, sagte Brennan. Die Gesamtzahl der Toten in der Türkei und Syrien steigt damit auf mehr als 35.000.
Es werden noch Tausende weitere Opfer befürchtet. Unzählige Häuser sind bei der Naturkatastrophe zerstört worden.
Nach Schätzungen der Vereinten Nationen könnte die Zahl noch auf 50.000 oder mehr steigen. Der UN-Nothilfekoordinator Martin Griffiths sagte dem Sender Sky News am Sonntag im Erdbebengebiet Kahramanmaras, Schätzungen seien schwierig, aber die Zahl der Todesopfer könnte sich „verdoppeln oder mehr“. „Und das ist erschreckend“, sagte er.
Die betroffenen Gebiete waren zunächst schwer zugänglich, mit dem Fortschreiten der Bergungsarbeiten steigen die Opferzahlen. Es gibt kaum noch Chancen, Überlebende unter den Trümmern zu finden.
Weitere Hilfen sollen nun von der EU kommen. EU-Kommissionspräsidentin Ursula von der Leyen sagte dem türkischen Präsidenten Recep Tayyip Erdogan am Sonntag in einem Telefonat die Lieferung von weiteren Zelten, Decken und Heizvorrichtungen zu. Die Kommission mobilisiere auch den Privatsektor, um die erforderliche Unterstützung so schnell wie möglich zu leisten, teilte in Brüssel eine Sprecherin am Abend nach dem Gespräch mit.
Über das sogenannte EU-Katastrophenschutzverfahren wurden der Türkei nach Angaben vom Sonntag schon jetzt 38 Rettungsteams mit 1651 Helfern und 106 Suchhunden angeboten. Zudem hätten zwölf EU-Staaten bereits 50.000 winterfeste Familienzelte, 100.000 Decken und 50.000 Heizgeräte zur Verfügung gestellt. Hinzu kämen 500 Notunterkünfte, 8000 Betten und 2000 Zelte, die die Kommission mobilisiert habe.
Von der Leyen selbst schrieb über den Kurznachrichtendienst Twitter, sie habe mit Erdogan telefoniert, um die weitere Unterstützung zu besprechen und um den Menschen in der Türkei ihr tief empfundenes Beileid für den katastrophalen Verlust von Menschenleben und die Zerstörung zu übermitteln.
Am frühen Montagmorgen hatte ein Beben, dessen Stärke das Deutsche Geoforschungszentrum (GFZ) mit 7,7 angibt, das türkisch-syrische Grenzgebiet erschüttert. Am Montagmittag folgte dann ein weiteres Beben der Stärke 7,6 in derselben Region. In den Tagen danach gab es laut türkischen Angaben mehr als 2000 Nachbeben.
Im Bürgerkriegsland Syrien ist der Norden betroffen. Von dort gibt es nur spärlich Informationen über die Lage. In der Türkei gab es in zehn Provinzen schwere Schäden durch die Beben. Dort ist inzwischen ein dreimonatiger Ausnahmezustand in Kraft getreten.
Im Süden der Türkei wurden mehrere Haftbefehle erlassen. Die Beschuldigten sollen für Baumängel verantwortlich sein, die den Einsturz der Gebäude begünstigt hätten, meldete die staatliche Nachrichtenagentur Anadolu unter Berufung auf Strafverfolger.Weinende Kinder, eingestürzte Häuser und überfüllte Krankenhäuser – die Bilder aus dem Erdbebengebiet sind für syrische Familien und Sanitäter nach zwölf Jahren Bürgerkrieg, Bombenhagel und Vertreibung nur zu bekannt. Das Erdbeben der Stärke 7,7 trieb die Menschen auf die Straßen im Norden des Landes, wo Luftangriffe und Granatbeschuss die Menschen bereits seelisch und die Gebäude in ihren Fundamenten erschüttert hat.
In der immer noch von Rebellen gehaltenen Stadt Jandaris in der Provinz Aleppo liegen Schutthaufen, Stahl-Streben und Kleiderbündel, wo einst ein mehrstöckiges Gebäude stand. „Zwölf Familien sind da drunter. Nicht ein einziger kam heraus. Nicht ein einziger“, sagt ein dünner, junger Mann unter Schock mit weit aufgerissenen Augen und einer bandagierten Hand. Sein Atem wirft einen weißen Schleier in der kalten Winterluft. „Wir haben nachts um drei Menschen mit bloßen Händen aus eingestürzten Häusern herausgezogen.“
Andere Männer sind zu sehen, die sich auf der Suche nach Überlebenden durch Trümmer wühlen und mit Hämmern auf Betonblöcke einschlagen. Daneben liegen verbeulte Wassertanks und Solar-Anlagen, die von Dächern stürzten.
Den Weiß-Helmen zufolge, einer Rettungsorganisation in den Rebellen-Gebieten, sind mindestens 147 Menschen in dieser Region im Nordwestens Syriens gestorben. In den von der Regierung kontrollierten Gebieten sollen es nach offiziellen Angaben mehr als 300 Tote und über 1000 Verletzte sein. „Wir sind in einem Rennen gegen die Zeit. Selbst wenn unsere Teams erschöpft sind, wir müssen weitermachen“, sagt der Leiter der Weiß-Helme, Raed al-Saleh, per Telefon. Die Luftangriffe der vergangenen Jahre hätten die Gebäude so geschwächt, dass sie sofort zusammenbrachen.
Millionen Menschen gerade im Nordwesten Syriens sind den Vereinten Nationen zufolge so besonders vom Krieg getroffen worden. 2,9 Millionen Menschen in der Region wurden vertrieben, 1,8 Millionen leben in Flüchtlingscamps. Die Hilfsorganisationen haben seit Jahren mitten im Krieg versucht zu helfen. „Wenigstens jetzt bombardiert uns keiner, während wir helfen“, sagt Al-Saleh.
 Das Erdbeben hatte die Südosttürkei am Morgen erschüttert. Im Lauf des Tages traf ein weiteres Erdbeben der Stärke 7,5 dieselbe Region. Die Zahl der Todesopfer wird vermutlich noch deutlich steigen. Unsere Türkei-Korrespondentin Carolina Drüten über die aktuelle Lage. 
 Quelle: WELT 
Aber die Kälte ist eine neue Herausforderung für die Helfer. Denn viele Familien sind den Temperaturen um den Gefrierpunkt und Regenschauern fast schutzlos ausgeliefert. In der Provinz Idlib habe das Beben die brüchigen Hütten der Flüchtlingsunterkünfte beschädigt, sagt Ahmad al-Scheich, ein Bewohner einer angrenzenden Stadt.
Weiter westlich ist das größte Krankenhaus in Afrin mit Verletzten überfüllt, die auf dem Fußboden liegen. Frauen versuchen daneben verzweifelt, Angehörige und Freunde anzurufen, doch eine Verbindung kommt nur selten zustande. Während Kleinkinder im Hintergrund schreien, verschließen Sanitäter schwarze Leichensäcke auf dem blutbefleckten Boden. 
Eine Außenamtssprecherin in Berlin verweist bei der Frage nach der Hilfe für die syrischen Erdbebenopfer auf die Zusammenarbeit mit Hilfsorganisationen. Hier würden nun „eingespielte Kanäle“ zur Unterstützung genutzt.
 „Die Opferzahlen steigen stündlich“, berichtet Türkei-Korrespondentin Marion Sendker. Aus dem ganzen Land würden Rettungskräfte in die Unglückorte gebracht. Die Bevölkerung würde zu Blutspenden aufgerufen. 
 Quelle: WELT Weinende Kinder, eingestürzte Häuser und überfüllte Krankenhäuser – die Bilder aus dem Erdbebengebiet sind für syrische Familien und Sanitäter nach zwölf Jahren Bürgerkrieg, Bombenhagel und Vertreibung nur zu bekannt. Das Erdbeben der Stärke 7,7 trieb die Menschen auf die Straßen im Norden des Landes, wo Luftangriffe und Granatbeschuss die Menschen bereits seelisch und die Gebäude in ihren Fundamenten erschüttert hat.
In der immer noch von Rebellen gehaltenen Stadt Jandaris in der Provinz Aleppo liegen Schutthaufen, Stahl-Streben und Kleiderbündel, wo einst ein mehrstöckiges Gebäude stand. „Zwölf Familien sind da drunter. Nicht ein einziger kam heraus. Nicht ein einziger“, sagt ein dünner, junger Mann unter Schock mit weit aufgerissenen Augen und einer bandagierten Hand. Sein Atem wirft einen weißen Schleier in der kalten Winterluft. „Wir haben nachts um drei Menschen mit bloßen Händen aus eingestürzten Häusern herausgezogen.“
Andere Männer sind zu sehen, die sich auf der Suche nach Überlebenden durch Trümmer wühlen und mit Hämmern auf Betonblöcke einschlagen. Daneben liegen verbeulte Wassertanks und Solar-Anlagen, die von Dächern stürzten.
Den Weiß-Helmen zufolge, einer Rettungsorganisation in den Rebellen-Gebieten, sind mindestens 147 Menschen in dieser Region im Nordwestens Syriens gestorben. In den von der Regierung kontrollierten Gebieten sollen es nach offiziellen Angaben mehr als 300 Tote und über 1000 Verletzte sein. „Wir sind in einem Rennen gegen die Zeit. Selbst wenn unsere Teams erschöpft sind, wir müssen weitermachen“, sagt der Leiter der Weiß-Helme, Raed al-Saleh, per Telefon. Die Luftangriffe der vergangenen Jahre hätten die Gebäude so geschwächt, dass sie sofort zusammenbrachen.
Millionen Menschen gerade im Nordwesten Syriens sind den Vereinten Nationen zufolge so besonders vom Krieg getroffen worden. 2,9 Millionen Menschen in der Region wurden vertrieben, 1,8 Millionen leben in Flüchtlingscamps. Die Hilfsorganisationen haben seit Jahren mitten im Krieg versucht zu helfen. „Wenigstens jetzt bombardiert uns keiner, während wir helfen“, sagt Al-Saleh.
 Das Erdbeben hatte die Südosttürkei am Morgen erschüttert. Im Lauf des Tages traf ein weiteres Erdbeben der Stärke 7,5 dieselbe Region. Die Zahl der Todesopfer wird vermutlich noch deutlich steigen. Unsere Türkei-Korrespondentin Carolina Drüten über die aktuelle Lage. 
 Quelle: WELT 
Aber die Kälte ist eine neue Herausforderung für die Helfer. Denn viele Familien sind den Temperaturen um den Gefrierpunkt und Regenschauern fast schutzlos ausgeliefert. In der Provinz Idlib habe das Beben die brüchigen Hütten der Flüchtlingsunterkünfte beschädigt, sagt Ahmad al-Scheich, ein Bewohner einer angrenzenden Stadt.
Weiter westlich ist das größte Krankenhaus in Afrin mit Verletzten überfüllt, die auf dem Fußboden liegen. Frauen versuchen daneben verzweifelt, Angehörige und Freunde anzurufen, doch eine Verbindung kommt nur selten zustande. Während Kleinkinder im Hintergrund schreien, verschließen Sanitäter schwarze Leichensäcke auf dem blutbefleckten Boden. 
Eine Außenamtssprecherin in Berlin verweist bei der Frage nach der Hilfe für die syrischen Erdbebenopfer auf die Zusammenarbeit mit Hilfsorganisationen. Hier würden nun „eingespielte Kanäle“ zur Unterstützung genutzt.
 „Die Opferzahlen steigen stündlich“, berichtet Türkei-Korrespondentin Marion Sendker. Aus dem ganzen Land würden Rettungskräfte in die Unglückorte gebracht. Die Bevölkerung würde zu Blutspenden aufgerufen. 
 Quelle: WELT Bei Lawinenabgängen in Österreich und der Schweiz sind seit Freitag mindestens acht Menschen ums Leben gekommen. Die Wintersportler starben in den österreichischen Bundesländern Tirol und Vorarlberg. In der Schweiz verunglückten am Samstag zwei Skifahrer im Kanton Graubünden tödlich.
Im österreichischen Kaltenbach im Zillertal starb am Samstag ein Wintersportler, wie ein Polizeisprecher im Bundesland Tirol der Nachrichtenagentur AFP sagte. Laut der österreichischen Nachrichtenagentur APA handelte es sich um einen 17-jährigen Neuseeländer, der abseits der Piste unterwegs war.
Bereits am Vormittag wurde im Kleinwalsertal im Bundesland Vorarlberg ein Mann, der am Vortag als vermisst gemeldet worden war, tot unter einer Lawine gefunden. Laut APA handelte es sich um einen 50-Jährigen. In Sölden im Ötztal (Tirol) war am Freitag ein 32-jähriger chinesischer Skifahrer unter einer Lawine ums Leben gekommen. Auch er soll außerhalb der markierten Pisten gefahren sein.
Trotz der Warnstufe vier auf der fünfstelligen Skala im Westen Österreichs waren laut APA zahlreiche Wintersportler im freien Gelände unterwegs. Mehrere Menschen wurden demnach bei Abgängen verschüttet und verletzt.
Wie die Polizei im schweizerischen Kanton Graubünden mitteilte, waren zwei Skifahrer am Samstagmorgen abseits der Pisten unterwegs und wurden dort von einer Lawine erfasst. Ein drittes Mitglied der Gruppe sei unverletzt geblieben. Bei den beiden Toten handele es sich um eine 56-jährige Frau und einen 52-jährigen Mann. Die Rettungsaktion musste aufgrund der schlechten Sicht und der schlechten Wetterbedingungen zeitweise unterbrochen werden.
Auch in den bayerischen Alpen hatten starke Schneefälle die Lawinengefahr zuletzt gefährlich steigen lassen. Teilweise herrsche die Stufe vier von fünf, was große Gefahr bedeutet, wie die Lawinenwarnzentrale im bayerischen Landesamt für Umwelt am Freitag mitteilte.Angesichts der vielfach geringen Schneedecke in den Alpen und des regenarmen Februars droht laut Experten bald massive Trockenheit. In Frankreich, der Schweiz, Italien und in Teilen Österreichs liege aktuell viel weniger Schnee als viele Jahre üblich, sagte der Meteorologe Klaus Haslinger von Geosphere Austria.
In Italien schlägt die Umweltorganisation Legambiente Alarm und warnt, dass in den dortigen Alpen in den vergangenen Monaten 53 Prozent weniger Schnee als im langjährigen Mittel gefallen sei. Das Problem ist nicht nur der Mangel an Schnee, sondern auch der ausbleibende Regen. Im Becken des Po, des größten Flusses Italiens, sind die Niederschläge um 61 Prozent gesunken. In Frankreich wird nach mehreren praktisch regenfreien Wochen schon jetzt ein zweiter Dürre-Sommer in Folge befürchtet.
Verantwortlich für den geringen Niederschlag sind blockierende Hochdruckgebiete über Westeuropa, die Regenfronten abdrängen. Es sei nicht das erste Mal, dass solche Wetterlagen für extrem regenarme Jahre sorgten, sagte Haslinger. Schon vor 60 Jahren habe es über Jahre wegen einer bestimmten Temperaturverteilung über Land und Meer sehr wenig geregnet. „Damals fiel der Pegel der Donau auf ein Rekord-Tief“, so der Meteorologe. Es gebe Indizien, dass die globale Erwärmung diese Temperatur-Muster begünstigen könnte.
„Wenn im Frühjahr das Wetter so ähnlich ist wie 2022 wird sich die Trockenheit deutlich verschärfen“, warnt der Agrarmeteorologe an der Universität für Bodenkultur in Wien, Josef Eitzinger. Es zeichne sich ab, dass die Flüsse viel weniger Schmelzwasser transportieren werden. „Damit fehlt die Frühjahrsspitze, die auch wichtig für das Auffüllen von Grundwasser wäre.“ In Frankreich weisen nach aktuellen Daten des nationalen Wassermonitorings von 422 beobachteten Grundwassergebieten schon jetzt 125 ein sehr niedriges Niveau auf, 120 ein niedriges Niveau und 97 ein mäßig niedriges Niveau.
Der Wassermangel setzt auch Venedig zu. Viele Gondeln liegen im Schlamm. Wegen des niedrigen Wasserstandes sind die kleineren Kanäle nicht mehr befahrbar. Bei Ebbe wurde zuletzt ein Wasserstand von mehr als 65 Zentimetern unter dem normalen Niveau gemessen. Ganz Norditalien leidet unter langanhaltender Trockenheit. 
Nach dem regenfreien Februar im italienischen „Food Valley“ drohe ein Minus bei der nationalen Lebensmittelproduktion um 40 Prozent, schrieb die Zeitung „La Repubblica“. Niemand könne sich dort an eine schlimmere Trockenheit erinnern.
Der Lago Maggiore ist laut Presseberichten nur noch zu 38 Prozent gefüllt, beim Comer See sieht es nicht besser aus. Aber auch weiter südlich in Italien macht sich die Trockenheit bemerkbar. Am Tiber in Rom sei der Wasserstand schon um 1,50 Meter gesunken, meldete die Hauptstadtzeitung „Il Messaggero“.
„Das Schneedefizit von heute ist die Trockenheit im nächsten Sommer und Herbst“, sagte Manuela Brunner, Leiterin Hydrologie und Klimafolgen in Gebirgsregionen beim WSL-Institut für Schnee- und Lawinenforschung SLF in Davos. Die Auswirkungen haben über die Jahrzehnte deutlich zugenommen. Sie hat in einer Studie festgestellt, dass die Zahl der Dürren, die durch Schneeschmelzdefizite ausgelöst wurden, im Zeitraum 1994 bis 2017 um 15 Prozent höher war als in den Jahren 1970 bis 1993. Sie geht davon aus, dass der Trend sich fortsetzt, weil die Schneefallgrenze steige. Damit sinke die Menge an Wasserreserven, die im Schnee gespeichert seien.
Wegen Rekord-Tiefstständen beim Grundwasser südlich von Wien müssten sich viele Landwirte auf Einschränkungen bei der Bewässerung der Felder einstellen, meint Eitzinger. Der Pegel des ökologisch besonders wertvollen Neusiedler Sees an der Grenze zu Ungarn – er wird vor allem von Regenwasser gespeist – ist so niedrig wie nie.
„Aha! Zehn Minuten Alltags-Wissen“ ist der Wissens-Podcast von WELT. Immer dienstags und donnerstags beantworten wir darin Alltagsfragen aus dem Bereich der Wissenschaft. Abonnieren Sie den Podcast unter anderem bei Spotify, Apple Podcasts, Deezer, Amazon Music oder direkt per RSS-Feed.Ein schweres Erdbeben in Indonesien hat am Montagabend über Hunderte Kilometer Erschütterungen ausgelöst. Die US-Erdbebenwarte USGS gab die Stärke mit 7,6 an. Die indonesische Behörde BMKG schätzte die Stärke auf 7,9. Einwohner in der nordaustralischen Stadt Darwin rund 600 Kilometer weiter südlich spürten die Auswirkungen deutlich, wie die australische Webseite news.com.au berichtete. Einige sprachen in sozialen Medien von den schwersten Erschütterungen seit Jahrzehnten. Nach diesen Angaben dauerte das Beben zwei Minuten.
Es passierte in den frühen Morgenstunden des Dienstags (Ortszeit) – Montagabend in Mitteleuropa. Die indonesischen Behörden gaben zunächst eine Tsunamiwarnung heraus, aber befürchtete Wellen an den Küsten blieben nach ersten Berichten aus.
Das Epizentrum war etwa 350 Kilometer nordöstlich von Osttimor im Meer. Der Herd lag nach Angaben der US-Erdbebenwarte rund 95 Kilometer unter dem Meeresboden. Das ist relativ tief. Die Beben mit den größten Zerstörungen passieren in der Regel deutlich näher an der Oberfläche.
Indonesien liegt am sogenannten Feuergürtel, einem Bogen im Pazifischen Ozean, wo Erdplatten aufeinandertreffen. Dort liegen zahlreiche Vulkane. Es kommt dort immer wieder zu schweren Erdbeben.
Naturkatastrophen verursachen im ersten Halbjahr 2022 Gesamtschäden von 65 Mrd. US$, davon war etwas mehr als die Hälfte versichert
Extreme mehrtägige Regenfälle und schlimme Überschwemmungen in Australien führten zu einer Spitzenbelastung für die Versicherungswirtschaft von mindestens 3,7 Mrd. US$ 
USA erneut schadenreichstes Land in der Summe aller Wetterkatastrophen
Zahl der Todesopfer durch Naturkatastrophen ist gegenüber dem 1. Halbjahr 2021 auf 4.300 gestiegen
Hitze, Dürre und Waldbrände nehmen in vielen Regionen der Welt zu, Wissenschaft geht von zunehmenden Wahrscheinlichkeiten durch den Klimawandel ausNaturkatastrophen verursachen im ersten Halbjahr 2022 Gesamtschäden von 65 Mrd. US$, davon war etwas mehr als die Hälfte versichert
Extreme mehrtägige Regenfälle und schlimme Überschwemmungen in Australien führten zu einer Spitzenbelastung für die Versicherungswirtschaft von mindestens 3,7 Mrd. US$ 
USA erneut schadenreichstes Land in der Summe aller Wetterkatastrophen
Zahl der Todesopfer durch Naturkatastrophen ist gegenüber dem 1. Halbjahr 2021 auf 4.300 gestiegen
Hitze, Dürre und Waldbrände nehmen in vielen Regionen der Welt zu, Wissenschaft geht von zunehmenden Wahrscheinlichkeiten durch den Klimawandel aus


Naturkatastrophen verursachen im ersten Halbjahr 2022 Gesamtschäden von 65 Mrd. US$, davon war etwas mehr als die Hälfte versichert
Extreme mehrtägige Regenfälle und schlimme Überschwemmungen in Australien führten zu einer Spitzenbelastung für die Versicherungswirtschaft von mindestens 3,7 Mrd. US$ 
USA erneut schadenreichstes Land in der Summe aller Wetterkatastrophen
Zahl der Todesopfer durch Naturkatastrophen ist gegenüber dem 1. Halbjahr 2021 auf 4.300 gestiegen
Hitze, Dürre und Waldbrände nehmen in vielen Regionen der Welt zu, Wissenschaft geht von zunehmenden Wahrscheinlichkeiten durch den Klimawandel aus 
Torsten Jeworrek
 Die Naturkatastrophen-Bilanz des ersten Halbjahres ist von Wetterkatastrophen geprägt. In den USA zerstörten extreme Tornados Milliardenwerte, Teile der Ostküste Australiens versanken in Fluten und im Süden Europas herrschten Hitze, Waldbrände und Dürre. Der vor wenigen Monaten veröffentlichte Bericht des Weltklimarats IPCC mahnt eine Anpassung der Schadenmodelle der Versicherer an, um das sich ändernde Risiko adäquat zu bewerten. Schadenprävention ist ein zentraler Baustein, um die ökonomischen Folgen des Klimawandels abzumildern. Umso dramatischer ist es, dass die Versicherungsdurchdringung in Entwicklungs- und Schwellenländern bei weit unter zehn Prozent stagniert und auch in den Industriestaaten noch Luft nach oben ist. 
Inhalte teilen
Torsten Jeworrek
Member of the Board of Management
Gesamtschäden niedriger als 2021 – Hoher Anteil versicherter Schäden durch Katastrophen in USA
Im ersten Halbjahr 2022 haben Naturkatastrophen weltweit geringere Schäden angerichtet als im Vergleichszeitraum 2021. Überflutungen, Erdbeben und Stürme verursachten einen Gesamtschaden von etwa 65 Mrd. US$ nach 105 Mrd. US$ im sehr schadenträchtigen Vorjahr. Die versicherten Schäden lagen mit etwa 34 Mrd. US$ im Rahmen der vergangenen Jahre.
Fluten in Australien die teuerste Katastrophe in Hinblick auf versicherte Schäden
Im Spätsommer/Frühherbst kam es im Osten Australiens zu extremen Regenfällen und Überschwemmungen, die Schäden in Höhe von 6,6 Mrd. US$ verursachten. In Teilen von Queensland und New South Wales gab es Rekordniederschläge und Überschwemmungen. Die letzte Februarwoche war die niederschlagreichste Woche seit 1900. In einigen Gebieten wurden die höchsten Überschwemmungen seit 1893 verzeichnet. Die vorläufigen Kosten für die Versicherungswirtschaft werden derzeit auf 3,7 Mrd. US$ geschätzt.

Auch andere Länder in der Region Asien-Pazifik waren von schweren Katastrophen betroffen: 
In Japan ereignete sich ein schweres Erdbeben der Magnitude 7.3 östlich der Hauptinsel Honshu. Das Epizentrum lag unweit der Stelle, wo vor elf Jahren das heftige Tohoku-Erdbeben den Tsunami auslöste, der die Atomkatastrophe von Fukushima zur Folge hatte. Auch wenn das Beben im März 2022 deutlich schwächer war, summierten sich die Gesamtschäden auf 8,8 Mrd. US$, wovon 2,8 Mrd. US$ versichert waren.

Insgesamt entfielen 22 Mrd. US$ der Gesamtschäden aus Naturkatastrophen im ersten Halbjahr auf die Region Asien-Pazifik – mehr als üblich. 8 Mrd. US$ waren versichert.

USA dominieren Schadenstatistik
Auf die USA entfielen im ersten Halbjahr mit rund 28 Mrd. US$ fast die Hälfte der Gesamtschäden und mit 19 Mrd. US$ knapp zwei Drittel der versicherten Schäden. Serien von Schwergewittern mit Tornados waren dafür die Hauptursache. Allein eine Gewitterfront Anfang April mit zahlreichen Tornados zerstörte Werte von mehr als 3 Mrd. US$, davon waren mehr als drei Viertel versichert – ein Beispiel für die Abmilderung ökonomischer Schocks bei hoher Versicherungsdichte. Insgesamt hinterließen Schwergewitter in der ersten Jahreshälfte in den USA Gesamtschäden von 22 Mrd. US$, davon entfielen auf die Versicherer 17 Mrd. US$.

Für die diesjährige Tropensturmsaison wird im Nordatlantik mit mehr Stürmen als üblich gerechnet. Grund ist die natürliche Klimaschwankung ENSO im Pazifik. Derzeit herrschen so genannte La Niña-Bedingungen, die im tropischen Nordatlantik die Bildung von Hurrikanen begünstigen. Führende Forschungsinstitute gehen davon aus, dass die aktuell schwachen La Niña-Bedingungen zur Hauptphase der Hurrikansaison im September noch ausgeprägter werden könnten. Munich Re rechnet mit 18 (±3) benannten tropischen Stürmen, 8 (±2) Hurrikanen und 4 (±2) schweren Hurrikanen. Prognosemodelle externer Institute lassen eine Sturmaktivität eher am oberen Ende der Spanne erwarten. Bis Ende Juni formierten sich im Nordatlantik drei tropische Wirbelstürme, von denen keiner Hurrikanstärke erreichte.

Die größte humanitäre Katastrophe des ersten Halbjahres war ein schweres Erdbeben in Afghanistan. Etwa 1.200 Menschen starben, als das Beben der Magnitude 5,9 den Osten des Landes erschütterte. Weltweit kamen in der ersten Jahreshälfte 2022 rund 4.300 Menschen durch Naturkatastrophen ums Leben – bedauerlicherweise mehr als in den Vorjahren.

Hitze, Waldbrand und Dürre in Teilen Europas – und auch Winterstürme
In Europa führten schon im Frühsommer Hitze und Trockenheit insbesondere in Italien, Spanien und Portugal zu Wassermangel und Waldbränden. Die Schäden durch Hitze und Dürre lassen sich oft nicht genau beziffern, da Effekte wie zum Beispiel Produktionsausfälle der Industrie durch fehlendes Kühlwasser oder in der Landwirtschaft durch die Trockenheit erst später feststehen.

Vermutlich auch bedingt durch den hohen Temperaturanstieg im Mai/Juni kam es an der Marmolata, dem höchsten Berg der italienischen Dolomiten, zu einem außergewöhnlich großen Gletscherabbruch.

Die aktuelle Hitzewelle (Juli 2022) ist auf eine spezielle Konstellation eines Hochdruckgebiets über Mitteleuropa und eines Tiefdruckgebiets vor Westeuropa zurückzuführen. Dadurch gelangt heiße Luft aus der Sahara und Nordafrika in höhere Breitengrade. Der menschengemachte Klimawandel hat bereits dazu geführt, dass die jährlichen Mitteltemperaturen in weiten Teilen Europas gegenüber dem Beginn der systematischen Aufzeichnungen am Ende des 19. Jahrhunderts um mehr als 1,5°C angestiegen sind – also mehr als der globale Mittelwert der Erwärmung von 1,2°C. Ernst Rauch, Chef-Klimatologe von Munich Re und Leiter der Climate Solutions-Einheit: „Aus ehemals warmen Tagen werden heiße Tage und aus ehemals heißen Tagen werden extreme Hitzetage. Eine direkte Folge sind Dürren und Waldbrände.“

Stürme fegten vor allem im Februar teilweise mit Orkangeschwindigkeiten über den Nordwesten Europas und das nördliche Mitteleuropa hinweg. Irland, England, Teile Belgiens, die Niederlande und der Norden Deutschlands sowie Gebiete um die Ostsee waren besonders betroffen. Die Folge: Ein Gesamtschaden von 5,2 Mrd. US$.

Ernst Rauch kommentiert die verschiedenen Unwetterkatastrophen im ersten Halbjahr 2022: „Es sind zwar alles einzelne Ereignisse mit unterschiedlichen Auslösern, aber in der Gesamtschau wird ziemlich deutlich: Die Macht des Klimawandels wird immer offensichtlicher! Die Folgen für die Menschen werden überall auf der Welt wahrnehmbar. Der Weltklimarat hat zuletzt noch deutlicher als bislang diagnostiziert, dass Wetterkatastrophen wie Hitzewellen, Starkniederschläge oder Dürren auf einer wärmeren Erde häufiger zu erwarten sind und an Intensität zunehmen. Hitzewellen beispielsweise werden tendenziell länger dauern und extremere Temperaturen haben. Das ist regional unterschiedlich – in Europa etwa wird der Süden besonders betroffen sein.“

Naturkatastrophen verursachen im ersten Halbjahr 2022 Gesamtschäden von 65 Mrd. US$, davon war etwas mehr als die Hälfte versichert
Extreme mehrtägige Regenfälle und schlimme Überschwemmungen in Australien führten zu einer Spitzenbelastung für die Versicherungswirtschaft von mindestens 3,7 Mrd. US$ 
USA erneut schadenreichstes Land in der Summe aller Wetterkatastrophen
Zahl der Todesopfer durch Naturkatastrophen ist gegenüber dem 1. Halbjahr 2021 auf 4.300 gestiegen
Hitze, Dürre und Waldbrände nehmen in vielen Regionen der Welt zu, Wissenschaft geht von zunehmenden Wahrscheinlichkeiten durch den Klimawandel aus